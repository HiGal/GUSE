{"id": "25507", "url": "https://en.wikipedia.org/wiki?curid=25507", "title": "Roman Empire", "text": "Roman Empire\n\nThe Roman Empire (; Koine and Medieval Greek: Βασιλεία τῶν Ῥωμαίων, tr. ) was the post-Roman Republic period of the ancient Roman civilization, characterized by government headed by emperors and large territorial holdings around the Mediterranean Sea in Europe, Africa and Asia. The city of Rome was the largest city in the world BC , with Constantinople (New Rome) becoming the largest around AD 500, and the Empire's populace grew to an estimated 50 to 90 million inhabitants (roughly 20% of the world's population at the time). The 500-year-old republic which preceded it was severely destabilized in a series of civil wars and political conflict, during which Julius Caesar was appointed as perpetual dictator and then assassinated in 44 BC. Civil wars and executions continued, culminating in the victory of Octavian, Caesar's adopted son, over Mark Antony and Cleopatra at the Battle of Actium in 31 BC and the annexation of Egypt. Octavian's power was then unassailable and in 27 BC the Roman Senate formally granted him overarching power and the new title \"Augustus\", effectively marking the end of the Roman Republic.\n\nThe imperial period of Rome lasted approximately 1,500 years compared to the 500 years of the Republican era. The first two centuries of the empire's existence were a period of unprecedented political stability and prosperity known as the \"Pax Romana\", or \"Roman Peace\". Following Octavian's victory, the size of the empire was dramatically increased. After the assassination of Caligula in AD 41, the Senate briefly considered restoring the republic, but the Praetorian Guard proclaimed Claudius emperor instead. Under Claudius, the empire invaded Britannia, its first major expansion since Augustus. After Claudius' successor, Nero, committed suicide in AD 68, the empire suffered a series of brief civil wars, as well as a concurrent major rebellion in Judea, during which four different legionary generals were proclaimed emperor. Vespasian emerged triumphant in AD 69, establishing the Flavian dynasty, before being succeeded by his son Titus, who opened the Colosseum shortly after the eruption of Mount Vesuvius. His short reign was followed by the long reign of his brother Domitian, who was eventually assassinated. The Senate then appointed the first of the Five Good Emperors. The empire reached its greatest extent under Trajan, the second in this line.\n\nA period of increasing trouble and decline began with the reign of Commodus. Commodus' assassination in 192 triggered the Year of the Five Emperors, of which Septimius Severus emerged victorious. The assassination of Alexander Severus in 235 led to the Crisis of the Third Century in which 26 men were declared emperor by the Roman Senate over a fifty-year time span. It was not until the reign of Diocletian that the empire was fully stabilized with the introduction of the Tetrarchy, which saw four emperors rule the empire at once. This arrangement was ultimately unsuccessful, leading to a civil war that was finally ended by Constantine I, who defeated his rivals and became the sole ruler of the empire. Constantine subsequently shifted the capital to Byzantium, which was renamed \"Constantinople\" in his honour. It remained the capital of the east until its demise. Constantine also adopted Christianity which later became the official state religion of the empire. This eastern part of the empire (modernly called \"Byzantine Empire\") remained one of the leading powers in the world alongside its arch-rival the Sassanid Empire, which had inherited a centuries-old Roman-Persian conflict from its predecessor the Parthians. Following the death of Theodosius I, the last emperor to rule a united Roman Empire, the dominion of the empire was gradually eroded by abuses of power, civil wars, barbarian migrations and invasions, military reforms and economic depression. The Sack of Rome in 410 by the Visigoths and again in 455 by the Vandals accelerated the Western Empire's decay, while the deposition of the emperor, Romulus Augustulus, in 476 by Odoacer, is generally accepted to mark the end of the empire in the west. However, Augustulus was never recognized by his Eastern colleague, and separate rule in the Western part of the empire only ceased to exist upon the death of Julius Nepos, in 480. The Eastern Roman Empire endured for another millennium, eventually falling to the Ottoman Turks in 1453.\n\nThe Roman Empire was among the most powerful economic, cultural, political and military forces in the world of its time. It was one of the largest empires in world history. At its height under Trajan, it covered 5 million square kilometres. It held sway over an estimated 70 million people, at that time 21% of the world's entire population. The longevity and vast extent of the empire ensured the lasting influence of Latin and Greek language, culture, religion, inventions, architecture, philosophy, law and forms of government on the empire's descendants. Throughout the European medieval period, attempts were even made to establish successors to the Roman Empire, including the Empire of Romania, a Crusader state, and the Holy Roman Empire. By means of European colonialism following the Renaissance, and their descendant states, Greco-Roman and Judaeo-Christian culture was exported on a worldwide scale, playing a crucial role in the development of the modern world.\n\nRome had begun expanding shortly after the founding of the republic in the 6th century BC, though it did not expand outside the Italian Peninsula until the 3rd century BC. Then, it was an \"empire\" long before it had an emperor. The Roman Republic was not a nation-state in the modern sense, but a network of towns left to rule themselves (though with varying degrees of independence from the Roman Senate) and provinces administered by military commanders. It was ruled, not by emperors, but by annually elected magistrates (Roman Consuls above all) in conjunction with the senate. For various reasons, the 1st century BC was a time of political and military upheaval, which ultimately led to rule by emperors. The consuls' military power rested in the Roman legal concept of \"imperium\", which literally means \"command\" (though typically in a military sense). Occasionally, successful consuls were given the honorary title \"imperator\" (commander), and this is the origin of the word \"emperor\" (and \"empire\") since this title (among others) was always bestowed to the early emperors upon their accession.\n\nRome suffered a long series of internal conflicts, conspiracies and civil wars from the late second century BC onwards, while greatly extending its power beyond Italy. This was the period of the Crisis of the Roman Republic. Towards the end of this era, in 44 BC, Julius Caesar was briefly perpetual dictator before being assassinated. The faction of his assassins was driven from Rome and defeated at the Battle of Philippi in 42 BC by an army led by Mark Antony and Caesar's adopted son Octavian. Antony and Octavian's division of the Roman world between themselves did not last and Octavian's forces defeated those of Antony and Cleopatra at the Battle of Actium in 31 BC. In 27 BC the Senate and People of Rome made Octavian \"princeps\" (\"first citizen\") with proconsular \"imperium\", thus beginning the Principate (the first epoch of Roman imperial history, usually dated from 27 BC to AD 284), and gave him the name \"Augustus\" (\"the venerated\"). Though the old constitutional machinery remained in place, Augustus came to predominate it. Although the republic stood in name, contemporaries of Augustus knew it was just a veil and that Augustus had all meaningful authority in Rome. Since his rule ended a century of civil wars and began an unprecedented period of peace and prosperity, he was so loved that he came to hold the power of a monarch \"de facto\" if not \"de jure\". During the years of his rule, a new constitutional order emerged (in part organically and in part by design), so that, upon his death, this new constitutional order operated as before when Tiberius was accepted as the new emperor. The 200 years that began with Augustus's rule is traditionally regarded as the \"Pax Romana\" (\"Roman Peace\"). During this period, the cohesion of the empire was furthered by a degree of social stability and economic prosperity that Rome had never before experienced. Uprisings in the provinces were infrequent, but put down \"mercilessly and swiftly\" when they occurred. The sixty years of Jewish–Roman wars in the second half of the 1st century and the first half of the 2nd century were exceptional in their duration and violence.\n\nThe success of Augustus in establishing principles of dynastic succession was limited by his outliving a number of talented potential heirs. The Julio-Claudian dynasty lasted for four more emperors — Tiberius, Caligula, Claudius and Nero — before it yielded in 69 AD to the strife-torn Year of Four Emperors, from which Vespasian emerged as victor. Vespasian became the founder of the brief Flavian dynasty, to be followed by the Nerva–Antonine dynasty which produced the \"Five Good Emperors\": Nerva, Trajan, Hadrian, Antoninus Pius and the philosophically-inclined Marcus Aurelius. In the view of the Greek historian Dio Cassius, a contemporary observer, the accession of the emperor Commodus in 180 AD marked the descent \"from a kingdom of gold to one of rust and iron\"—a famous comment which has led some historians, notably Edward Gibbon, to take Commodus' reign as the beginning of the decline of the Roman Empire. \n\nIn 212, during the reign of Caracalla, Roman citizenship was granted to all freeborn inhabitants of the empire. But despite this gesture of universality, the Severan dynasty was tumultuous — an emperor's reign was ended routinely by his murder or execution — and, following its collapse, the Roman Empire was engulfed by the Crisis of the Third Century, a period of invasions, civil strife, economic disorder, and plague. In defining historical epochs, this crisis is sometimes viewed as marking the transition from Classical Antiquity to Late Antiquity. Aurelian (reigned 270–275) brought the empire back from the brink and stabilized it. Diocletian completed the work of fully restoring the empire, but declined the role of \"princeps\" and became the first emperor to be addressed regularly as \"domine\", \"master\" or \"lord\". This marked the end of the Principate, and the beginning of the Dominate. Diocletian's reign also brought the empire's most concerted effort against the perceived threat of Christianity, the \"Great Persecution\". The state of absolute monarchy that began with Diocletian endured until the fall of the Eastern Roman Empire in 1453. \n\nDiocletian divided the empire into four regions, each ruled by a separate emperor, the Tetrarchy. Confident that he fixed the disorders that were plaguing Rome, he abdicated along with his co-emperor, and the Tetrarchy soon collapsed. Order was eventually restored by Constantine the Great, who became the first emperor to convert to Christianity, and who established Constantinople as the new capital of the eastern empire. During the decades of the Constantinian and Valentinian dynasties, the empire was divided along an east–west axis, with dual power centres in Constantinople and Rome. The reign of Julian, who attempted to restore Classical Roman and Hellenistic religion, only briefly interrupted the succession of Christian emperors. Theodosius I, the last emperor to rule over both East and West, died in 395 AD after making Christianity the official religion of the empire.\n\nThe Western Roman Empire began to disintegrate in the early 5th century as Germanic migrations and invasions overwhelmed the capacity of the Empire to assimilate the migrants and fight off the invaders. The Romans were successful in fighting off all invaders, most famously Attila, though the empire had assimilated so many Germanic peoples of dubious loyalty to Rome that the empire started to dismember itself. Most chronologies place the end of the Western Roman Empire in 476, when Romulus Augustulus was forced to abdicate to the Germanic warlord Odoacer. By placing himself under the rule of the Eastern Emperor, rather than naming himself Emperor (as other Germanic chiefs had done after deposing past emperors), Odoacer ended the Western Empire by ending the line of Western emperors.\n\nThe empire in the East — often known as the Byzantine Empire, but referred to in its time as the Roman Empire or by various other names — had a different fate. It survived for almost a millennium after the fall of its Western counterpart and became the most stable Christian realm during the Middle Ages. During the 6th century, Justinian I reconquered Northern Africa and Italy. But within a few years of Justinian's death, Byzantine possessions in Italy were greatly reduced by the Lombards who settled in the peninsula. In the east, partially resulting from the destructive Plague of Justinian, the Romans were threatened by the rise of Islam, whose followers rapidly conquered the territories of Syria, Armenia and Egypt during the Byzantine-Arab Wars, and soon presented a direct threat to Constantinople. In the following century, the Arabs also captured southern Italy and Sicily. Slavic populations were also able to penetrate deep into the Balkans. \n\nThe Romans, however, managed to stop further Islamic expansion into their lands during the 8th century and, beginning in the 9th century, reclaimed parts of the conquered lands. In 1000 AD, the Eastern Empire was at its height: Basil II reconquered Bulgaria and Armenia, culture and trade flourished. However, soon after, the expansion was abruptly stopped in 1071 with the Byzantine defeat in the Battle of Manzikert. The aftermath of this important battle sent the empire into a protracted period of decline. Two decades of internal strife and Turkic invasions ultimately paved the way for Emperor Alexios I Komnenos to send a call for help to the Western European kingdoms in 1095.\n\nThe West responded with the Crusades, eventually resulting in the Sack of Constantinople by participants in the Fourth Crusade. The conquest of Constantinople in 1204 fragmented what remained of the Empire into successor states, the ultimate victor being that of Nicaea. After the recapture of Constantinople by Imperial forces, the Empire was little more than a Greek state confined to the Aegean coast. The Roman Empire finally collapsed when Mehmed the Conqueror conquered Constantinople on 29 May 1453.\n\nThe Roman Empire was one of the largest in history, with contiguous territories throughout Europe, North Africa, and the Middle East. The Latin phrase \"imperium sine fine\" (\"empire without end\") expressed the ideology that neither time nor space limited the Empire. In Vergil's epic poem the \"Aeneid,\" limitless empire is said to be granted to the Romans by their supreme deity Jupiter. This claim of universal dominion was renewed and perpetuated when the Empire came under Christian rule in the 4th century.\n\nIn reality, Roman expansion was mostly accomplished under the Republic, though parts of northern Europe were conquered in the 1st century AD, when Roman control in Europe, Africa and Asia was strengthened. During the reign of Augustus, a \"global map of the known world\" was displayed for the first time in public at Rome, coinciding with the composition of the most comprehensive work on political geography that survives from antiquity, the \"Geography\" of the Pontic Greek writer Strabo. When Augustus died, the commemorative account of his achievements \"(Res Gestae)\" prominently featured the geographical cataloguing of peoples and places within the Empire. Geography, the census, and the meticulous keeping of written records were central concerns of Roman Imperial administration.\nThe Empire reached its largest expanse under Trajan (reigned 98–117), encompassing an area of 5 million square kilometres. The traditional population estimate of inhabitants accounted for between one-sixth and one-fourth of the world's total population and made it the largest population of any unified political entity in the West until the mid-19th century. Recent demographic studies have argued for a population peak ranging from to more than . Each of the three largest cities in the Empire—Rome, Alexandria, and Antioch— was almost twice the size of any European city at the beginning of the 17th century.\n\nAs the historian Christopher Kelly has described it:\n\nTrajan's successor Hadrian adopted a policy of maintaining rather than expanding the empire. Borders \"(fines)\" were marked, and the frontiers \"(limites)\" patrolled. The most heavily fortified borders were the most unstable. Hadrian's Wall, which separated the Roman world from what was perceived as an ever-present barbarian threat, is the primary surviving monument of this effort.\n\nThe language of the Romans was Latin, which Virgil emphasizes as a source of Roman unity and tradition. Until the time of Alexander Severus (reigned 222–235), the birth certificates and wills of Roman citizens had to be written in Latin. Latin was the language of the law courts in the West and of the military throughout the Empire, but was not imposed officially on peoples brought under Roman rule. This policy contrasts with that of Alexander the Great, who aimed to impose Greek throughout his empire as the official language. As a consequence of Alexander's conquests, koine Greek had become the shared language around the eastern Mediterranean and into Asia Minor. The \"linguistic frontier\" dividing the Latin West and the Greek East passed through the Balkan peninsula.\nRomans who received an elite education studied Greek as a literary language, and most men of the governing classes could speak Greek. The Julio-Claudian emperors encouraged high standards of correct Latin \"(Latinitas)\", a linguistic movement identified in modern terms as Classical Latin, and favoured Latin for conducting official business. Claudius tried to limit the use of Greek, and on occasion revoked the citizenship of those who lacked Latin, but even in the Senate he drew on his own bilingualism in communicating with Greek-speaking ambassadors. Suetonius quotes him as referring to \"our two languages\".\n\nIn the Eastern empire, laws and official documents were regularly translated into Greek from Latin. The everyday interpenetration of the two languages is indicated by bilingual inscriptions, which sometimes even switch back and forth between Greek and Latin. After all freeborn inhabitants of the empire were universally enfranchised in 212 AD, a great number of Roman citizens would have lacked Latin, though they were expected to acquire at least a token knowledge, and Latin remained a marker of \"Romanness.\"\n\nAmong other reforms, the emperor Diocletian (reigned 284–305) sought to renew the authority of Latin, and the Greek expression \"hē kratousa dialektos\" attests to the continuing status of Latin as \"the language of power.\" In the early 6th century, the emperor Justinian engaged in a quixotic effort to reassert the status of Latin as the language of law, even though in his time Latin no longer held any currency as a living language in the East.\n\nReferences to interpreters indicate the continuing use of local languages other than Greek and Latin, particularly in Egypt, where Coptic predominated, and in military settings along the Rhine and Danube. Roman jurists also show a concern for local languages such as Punic, Gaulish, and Aramaic in assuring the correct understanding and application of laws and oaths. In the province of Africa, Libyco-Berber and Punic were used in inscriptions and for legends on coins during the time of Tiberius (1st century AD). Libyco-Berber and Punic inscriptions appear on public buildings into the 2nd century, some bilingual with Latin. In Syria, Palmyrene soldiers even used their dialect of Aramaic for inscriptions, in a striking exception to the rule that Latin was the language of the military.\n\nThe Babatha Archive is a suggestive example of multilingualism in the Empire. These papyri, named for a Jewish woman in the province of Arabia and dating from 93 to 132 AD, mostly employ Aramaic, the local language, written in Greek characters with Semitic and Latin influences; a petition to the Roman governor, however, was written in Greek.\n\nThe dominance of Latin among the literate elite may obscure the continuity of spoken languages, since all cultures within the Roman Empire were predominantly oral. In the West, Latin, referred to in its spoken form as Vulgar Latin, gradually replaced Celtic and Italic languages that were related to it by a shared Indo-European origin. Commonalities in syntax and vocabulary facilitated the adoption of Latin.\n\nAfter the decentralization of political power in late antiquity, Latin developed locally into branches that became the Romance languages, such as Spanish, Portuguese, French, Italian and Romanian, and a large number of minor languages and dialects. Today, more than 900 million people are native speakers worldwide.\n\nAs an international language of learning and literature, Latin itself continued as an active medium of expression for diplomacy and for intellectual developments identified with Renaissance humanism up to the 17th century, and for law and the Roman Catholic Church to the present.\n\nAlthough Greek continued as the language of the Byzantine Empire, linguistic distribution in the East was more complex. A Greek-speaking majority lived in the Greek peninsula and islands, western Anatolia, major cities, and some coastal areas. Like Greek and Latin, the Thracian language was of Indo-European origin, as were several now-extinct languages in Anatolia attested by Imperial-era inscriptions. Albanian is often seen as the descendant of Illyrian, although this hypothesis has been challenged by some linguists, who maintain that it derives from Dacian or Thracian. (Illyrian, Dacian, and Thracian, however, may have formed a subgroup or a Sprachbund; see Thraco-Illyrian.) Various Afroasiatic languages—primarily Coptic in Egypt, and Aramaic in Syria and Mesopotamia—were never replaced by Greek. The international use of Greek, however, was one factor enabling the spread of Christianity, as indicated for example by the use of Greek for the Epistles of Paul.\n\nThe Roman Empire was remarkably multicultural, with \"a rather astonishing cohesive capacity\" to create a sense of shared identity while encompassing diverse peoples within its political system over a long span of time. The Roman attention to creating public monuments and communal spaces open to all—such as forums, amphitheatres, racetracks and baths—helped foster a sense of \"Romanness\".\n\nRoman society had multiple, overlapping social hierarchies that modern concepts of \"class\" in English may not represent accurately. The two decades of civil war from which Augustus rose to sole power left traditional society in Rome in a state of confusion and upheaval, but did not affect an immediate redistribution of wealth and social power. From the perspective of the lower classes, a peak was merely added to the social pyramid. Personal relationships—patronage, friendship \"(amicitia)\", family, marriage—continued to influence the workings of politics and government, as they had in the Republic. By the time of Nero, however, it was not unusual to find a former slave who was richer than a freeborn citizen, or an equestrian who exercised greater power than a senator.\n\nThe blurring or diffusion of the Republic's more rigid hierarchies led to increased social mobility under the Empire, both upward and downward, to an extent that exceeded that of all other well-documented ancient societies. Women, freedmen, and slaves had opportunities to profit and exercise influence in ways previously less available to them. Social life in the Empire, particularly for those whose personal resources were limited, was further fostered by a proliferation of voluntary associations and confraternities (\"collegia\" and \"sodalitates\") formed for various purposes: professional and trade guilds, veterans' groups, religious sodalities, drinking and dining clubs, performing arts troupes, and burial societies.\n\nInfanticide has been recorded in the Roman Empire and may have been widespread.\n\nAccording to the jurist Gaius, the essential distinction in the Roman \"law of persons\" was that all human beings were either free \"(liberi)\" or slaves \"(servi)\". The legal status of free persons might be further defined by their citizenship. Most citizens held limited rights (such as the \"ius Latinum,\" \"Latin right\"), but were entitled to legal protections and privileges not enjoyed by those who lacked citizenship. Free people not considered citizens, but living within the Roman world, held status as \"peregrini\", non-Romans. In 212 AD, by means of the edict known as the \"Constitutio Antoniniana\", the emperor Caracalla extended citizenship to all freeborn inhabitants of the empire. This legal egalitarianism would have required a far-reaching revision of existing laws that had distinguished between citizens and non-citizens.\n\nFreeborn Roman women were considered citizens throughout the Republic and Empire, but did not vote, hold political office, or serve in the military. A mother's citizen status determined that of her children, as indicated by the phrase \"ex duobus civibus Romanis natos\" (\"children born of two Roman citizens\"). A Roman woman kept her own family name \"(nomen)\" for life. Children most often took the father's name, but in the Imperial period sometimes made their mother's name part of theirs, or even used it instead.\nThe archaic form of \"manus\" marriage in which the woman had been subject to her husband's authority was largely abandoned by the Imperial era, and a married woman retained ownership of any property she brought into the marriage. Technically she remained under her father's legal authority, even though she moved into her husband's home, but when her father died she became legally emancipated. This arrangement was one of the factors in the degree of independence Roman women enjoyed relative to those of many other ancient cultures and up to the modern period: although she had to answer to her father in legal matters, she was free of his direct scrutiny in her daily life, and her husband had no legal power over her. Although it was a point of pride to be a \"one-man woman\" \"(univira)\" who had married only once, there was little stigma attached to divorce, nor to speedy remarriage after the loss of a husband through death or divorce.\n\nGirls had equal inheritance rights with boys if their father died without leaving a will. A Roman mother's right to own property and to dispose of it as she saw fit, including setting the terms of her own will, gave her enormous influence over her sons even when they were adults.\n\nAs part of the Augustan programme to restore traditional morality and social order, moral legislation attempted to regulate the conduct of men and women as a means of promoting \"family values\". Adultery, which had been a private family matter under the Republic, was criminalized, and defined broadly as an illicit sex act \"(stuprum)\" that occurred between a male citizen and a married woman, or between a married woman and any man other than her husband. Childbearing was encouraged by the state: a woman who had given birth to three children was granted symbolic honours and greater legal freedom (the \"ius trium liberorum)\".\n\nBecause of their legal status as citizens and the degree to which they could become emancipated, women could own property, enter contracts, and engage in business, including shipping, manufacturing, and lending money. Inscriptions throughout the Empire honour women as benefactors in funding public works, an indication they could acquire and dispose of considerable fortunes; for instance, the Arch of the Sergii was funded by Salvia Postuma, a female member of the family honoured, and the largest building in the forum at Pompeii was funded by Eumachia, a priestess of Venus.\n\nAt the time of Augustus, as many as 35% of the people in Italy were slaves, making Rome one of five historical \"slave societies\" in which slaves constituted at least a fifth of the population and played a major role in the economy. Slavery was a complex institution that supported traditional Roman social structures as well as contributing economic utility. In urban settings, slaves might be professionals such as teachers, physicians, chefs, and accountants, in addition to the majority of slaves who provided trained or unskilled labour in households or workplaces. Agriculture and industry, such as milling and mining, relied on the exploitation of slaves. Outside Italy, slaves made up on average an estimated 10 to 20% of the population, sparse in Roman Egypt but more concentrated in some Greek areas. Expanding Roman ownership of arable land and industries would have affected preexisting practices of slavery in the provinces. Although the institution of slavery has often been regarded as waning in the 3rd and 4th centuries, it remained an integral part of Roman society until the 5th century. Slavery ceased gradually in the 6th and 7th centuries along with the decline of urban centres in the West and the disintegration of the complex Imperial economy that had created the demand for it.\nLaws pertaining to slavery were \"extremely intricate\". Under Roman law, slaves were considered property and had no legal personhood. They could be subjected to forms of corporal punishment not normally exercised on citizens, sexual exploitation, torture, and summary execution. A slave could not as a matter of law be raped, since rape could be committed only against people who were free; a slave's rapist had to be prosecuted by the owner for property damage under the Aquilian Law. Slaves had no right to the form of legal marriage called \"conubium\", but their unions were sometimes recognized, and if both were freed they could marry. Following the Servile Wars of the Republic, legislation under Augustus and his successors shows a driving concern for controlling the threat of rebellions through limiting the size of work groups, and for hunting down fugitive slaves.\n\nTechnically, a slave could not own property, but a slave who conducted business might be given access to an individual account or fund \"(peculium)\" that he could use as if it were his own. The terms of this account varied depending on the degree of trust and co-operation between owner and slave: a slave with an aptitude for business could be given considerable leeway to generate profit, and might be allowed to bequeath the \"peculium\" he managed to other slaves of his household. Within a household or workplace, a hierarchy of slaves might exist, with one slave in effect acting as the master of other slaves.\n\nOver time slaves gained increased legal protection, including the right to file complaints against their masters. A bill of sale might contain a clause stipulating that the slave could not be employed for prostitution, as prostitutes in ancient Rome were often slaves. The burgeoning trade in eunuch slaves in the late 1st century AD prompted legislation that prohibited the castration of a slave against his will \"for lust or gain.\"\n\nRoman slavery was not based on race. Slaves were drawn from all over Europe and the Mediterranean, including Gaul, Hispania, Germany, Britannia, the Balkans, Greece... Generally slaves in Italy were indigenous Italians, with a minority of foreigners (including both slaves and freedmen) born outside of Italy estimated at 5% of the total in the capital at its peak, where their number was largest. Those from outside of Europe were predominantly of Greek descent, while the Jewish ones never fully assimilated into Roman society, remaining an identifiable minority. These slaves (especially the foreigners) had higher mortality rates and lower birth rates than natives, and were sometimes even subjected to mass expulsions. The average recorded age at death for the slaves of the city of Rome was extraordinarily low: seventeen and a half years (17.2 for males; 17.9 for females).\n\nDuring the period of Republican expansionism when slavery had become pervasive, war captives were a main source of slaves. The range of ethnicities among slaves to some extent reflected that of the armies Rome defeated in war, and the conquest of Greece brought a number of highly skilled and educated slaves into Rome. Slaves were also traded in markets, and sometimes sold by pirates. Infant abandonment and self-enslavement among the poor were other sources. \"Vernae\", by contrast, were \"homegrown\" slaves born to female slaves within the urban household or on a country estate or farm. Although they had no special legal status, an owner who mistreated or failed to care for his \"vernae\" faced social disapproval, as they were considered part of his \"familia\", the family household, and in some cases might actually be the children of free males in the family.\n\nTalented slaves with a knack for business might accumulate a large enough \"peculium\" to justify their freedom, or be manumitted for services rendered. Manumission had become frequent enough that in 2 BC a law \"(Lex Fufia Caninia)\" limited the number of slaves an owner was allowed to free in his will.\n\nRome differed from Greek city-states in allowing freed slaves to become citizens. After manumission, a slave who had belonged to a Roman citizen enjoyed not only passive freedom from ownership, but active political freedom \"(libertas)\", including the right to vote. A slave who had acquired \"libertas\" was a \"libertus\" (\"freed person,\" feminine \"liberta\") in relation to his former master, who then became his patron \"(patronus)\": the two parties continued to have customary and legal obligations to each other. As a social class generally, freed slaves were \"libertini\", though later writers used the terms \"libertus\" and \"libertinus\" interchangeably.\n\nA \"libertinus\" was not entitled to hold public office or the highest state priesthoods, but he could play a priestly role in the cult of the emperor. He could not marry a woman from a family of senatorial rank, nor achieve legitimate senatorial rank himself, but during the early Empire, freedmen held key positions in the government bureaucracy, so much so that Hadrian limited their participation by law. Any future children of a freedman would be born free, with full rights of citizenship.\n\nThe rise of successful freedmen—through either political influence in imperial service, or wealth—is a characteristic of early Imperial society. The prosperity of a high-achieving group of freedmen is attested by , and by their ownership of some of the most lavish houses at Pompeii, such as the House of the Vettii. The excesses of \"nouveau riche\" freedmen were satirized in the character of Trimalchio in the \"Satyricon\" by Petronius, who wrote in the time of Nero. Such individuals, while exceptional, are indicative of the upward social mobility possible in the Empire.\n\nThe Latin word \"ordo\" (plural \"ordines\") refers to a social distinction that is translated variously into English as \"class, order, rank,\" none of which is exact. One purpose of the Roman census was to determine the \"ordo\" to which an individual belonged. The two highest \"ordines\" in Rome were the senatorial and equestrian. Outside Rome, the decurions, also known as \"curiales\" (Greek \"bouleutai\"), were the top governing \"ordo\" of an individual city.\n\"Senator\" was not itself an elected office in ancient Rome; an individual gained admission to the Senate after he had been elected to and served at least one term as an executive magistrate. A senator also had to meet a minimum property requirement of 1 million \"sestertii,\" as determined by the census. Nero made large gifts of money to a number of senators from old families who had become too impoverished to qualify. Not all men who qualified for the \"ordo senatorius\" chose to take a Senate seat, which required legal domicile at Rome. Emperors often filled vacancies in the 600-member body by appointment. A senator's son belonged to the \"ordo senatorius\", but he had to qualify on his own merits for admission to the Senate itself. A senator could be removed for violating moral standards: he was prohibited, for instance, from marrying a freedwoman or fighting in the arena.\n\nIn the time of Nero, senators were still primarily from Rome and other parts of Italy, with some from the Iberian peninsula and southern France; men from the Greek-speaking provinces of the East began to be added under Vespasian. The first senator from the most eastern province, Cappadocia, was admitted under Marcus Aurelius. By the time of the Severan dynasty (193–235), Italians made up less than half the Senate. During the 3rd century, domicile at Rome became impractical, and inscriptions attest to senators who were active in politics and munificence in their homeland \"(patria)\".\n\nSenators had an aura of prestige and were the traditional governing class who rose through the \"cursus honorum\", the political career track, but equestrians of the Empire often possessed greater wealth and political power. Membership in the equestrian order was based on property; in Rome's early days, \"equites\" or knights had been distinguished by their ability to serve as mounted warriors (the \"public horse\"), but cavalry service was a separate function in the Empire. A census valuation of 400,000 sesterces and three generations of free birth qualified a man as an equestrian. The census of 28 BC uncovered large numbers of men who qualified, and in 14 AD, a thousand equestrians were registered at Cadiz and Padua alone. Equestrians rose through a military career track \"(tres militiae)\" to become highly placed prefects and procurators within the Imperial administration.\n\nThe rise of provincial men to the senatorial and equestrian orders is an aspect of social mobility in the first three centuries of the Empire. Roman aristocracy was based on competition, and unlike later European nobility, a Roman family could not maintain its position merely through hereditary succession or having title to lands. Admission to the higher \"ordines\" brought distinction and privileges, but also a number of responsibilities. In antiquity, a city depended on its leading citizens to fund public works, events, and services \"(munera)\", rather than on tax revenues, which primarily supported the military. Maintaining one's rank required massive personal expenditures. Decurions were so vital for the functioning of cities that in the later Empire, as the ranks of the town councils became depleted, those who had risen to the Senate were encouraged by the central government to give up their seats and return to their hometowns, in an effort to sustain civic life.\n\nIn the later Empire, the \"dignitas\" (\"worth, esteem\") that attended on senatorial or equestrian rank was refined further with titles such as \"vir illustris\", \"illustrious man\". The appellation \"clarissimus\" (Greek \"lamprotatos\") was used to designate the \"dignitas\" of certain senators and their immediate family, including women. \"Grades\" of equestrian status proliferated. Those in Imperial service were ranked by pay grade (\"sexagenarius\", 60,000 sesterces per annum; \"centenarius,\" 100,000; \"ducenarius\", 200,000). The title \"eminentissimus\", \"most eminent\" (Greek \"exochôtatos\") was reserved for equestrians who had been Praetorian prefects. The higher equestrian officials in general were \"perfectissimi\", \"most distinguished\" (Greek \"diasêmotatoi\"), the lower merely \"egregii\", \"outstanding\" (Greek \"kratistos\").\n\nAs the republican principle of citizens' equality under the law faded, the symbolic and social privileges of the upper classes led to an informal division of Roman society into those who had acquired greater honours \"(honestiores)\" and those who were humbler folk \"(humiliores)\". In general, \"honestiores\" were the members of the three higher \"orders,\" along with certain military officers. The granting of universal citizenship in 212 seems to have increased the competitive urge among the upper classes to have their superiority over other citizens affirmed, particularly within the justice system. Sentencing depended on the judgement of the presiding official as to the relative \"worth\" \"(dignitas)\" of the defendant: an \"honestior\" could pay a fine when convicted of a crime for which an \"humilior\" might receive a scourging.\n\nExecution, which had been an infrequent legal penalty for free men under the Republic even in a capital case, could be quick and relatively painless for the Imperial citizen considered \"more honourable\", while those deemed inferior might suffer the kinds of torture and prolonged death previously reserved for slaves, such as crucifixion and condemnation to the beasts as a spectacle in the arena. In the early Empire, those who converted to Christianity could lose their standing as \"honestiores\", especially if they declined to fulfil the religious aspects of their civic responsibilities, and thus became subject to punishments that created the conditions of martyrdom.\n\nThe three major elements of the Imperial Roman state were the central government, the military, and provincial government. The military established control of a territory through war, but after a city or people was brought under treaty, the military mission turned to policing: protecting Roman citizens (after 212 AD, all freeborn inhabitants of the Empire), the agricultural fields that fed them, and religious sites. Without modern instruments of either mass communication or mass destruction, the Romans lacked sufficient manpower or resources to impose their rule through force alone. Cooperation with local power elites was necessary to maintain order, collect information, and extract revenue. The Romans often exploited internal political divisions by supporting one faction over another: in the view of Plutarch, \"it was discord between factions within cities that led to the loss of self-governance\".\n\nCommunities with demonstrated loyalty to Rome retained their own laws, could collect their own taxes locally, and in exceptional cases were exempt from Roman taxation. Legal privileges and relative independence were an incentive to remain in good standing with Rome. Roman government was thus limited, but efficient in its use of the resources available to it.\n\nThe dominance of the emperor was based on the consolidation of certain powers from several republican offices, including the inviolability of the tribunes of the people and the authority of the censors to manipulate the hierarchy of Roman society. The emperor also made himself the central religious authority as Pontifex Maximus, and centralized the right to declare war, ratify treaties, and negotiate with foreign leaders. While these functions were clearly defined during the Principate, the emperor's powers over time became less constitutional and more monarchical, culminating in the Dominate.\n\nThe emperor was the ultimate authority in policy- and decision-making, but in the early Principate he was expected to be accessible to individuals from all walks of life, and to deal personally with official business and petitions. A bureaucracy formed around him only gradually. The Julio-Claudian emperors relied on an informal body of advisors that included not only senators and equestrians, but trusted slaves and freedmen. After Nero, the unofficial influence of the latter was regarded with suspicion, and the emperor's council \"(consilium)\" became subject to official appointment for the sake of greater transparency. Though the senate took a lead in policy discussions until the end of the Antonine dynasty, equestrians played an increasingly important role in the \"consilium.\" The women of the emperor's family often intervened directly in his decisions. Plotina exercised influence on both her husband Trajan and his successor Hadrian. Her influence was advertised by having her letters on official matters published, as a sign that the emperor was reasonable in his exercise of authority and listened to his people.\n\nAccess to the emperor by others might be gained at the daily reception \"(salutatio)\", a development of the traditional homage a client paid to his patron; public banquets hosted at the palace; and religious ceremonies. The common people who lacked this access could manifest their general approval or displeasure as a group at the games held in large venues. By the 4th century, as urban centres decayed, the Christian emperors became remote figureheads who issued general rulings, no longer responding to individual petitions.\n\nAlthough the senate could do little short of assassination and open rebellion to contravene the will of the emperor, it survived the Augustan restoration and the turbulent Year of Four Emperors to retain its symbolic political centrality during the Principate. The senate legitimated the emperor's rule, and the emperor needed the experience of senators as legates \"(legati)\" to serve as generals, diplomats, and administrators. A successful career required competence as an administrator and remaining in favour with the emperor, or over time perhaps multiple emperors.\n\nThe practical source of an emperor's power and authority was the military. The legionaries were paid by the Imperial treasury, and swore an annual military oath of loyalty to the emperor \"(sacramentum)\". The death of an emperor led to a crucial period of uncertainty and crisis. Most emperors indicated their choice of successor, usually a close family member or adopted heir. The new emperor had to seek a swift acknowledgement of his status and authority to stabilize the political landscape. No emperor could hope to survive, much less to reign, without the allegiance and loyalty of the Praetorian Guard and of the legions. To secure their loyalty, several emperors paid the \"donativum\", a monetary reward. In theory, the Senate was entitled to choose the new emperor, but did so mindful of acclamation by the army or Praetorians.\n\nThe soldiers of the Imperial Roman army were professionals who volunteered for 20 years of active duty and five as reserves. The transition to a professional military had begun during the late Republic, and was one of the many profound shifts away from republicanism, under which an army of conscripts had exercised their responsibilities as citizens in defending the homeland in a campaign against a specific threat. For Imperial Rome, the military was a full-time career in itself.\n\nThe primary mission of the Roman military of the early empire was to preserve the Pax Romana. The three major divisions of the military were:\n\nThe pervasiveness of military garrisons throughout the Empire was a major influence in the process of cultural exchange and assimilation known as \"Romanization,\" particularly in regard to politics, the economy, and religion. Knowledge of the Roman military comes from a wide range of sources: Greek and Roman literary texts; coins with military themes; papyri preserving military documents; monuments such as Trajan's Column and triumphal arches, which feature artistic depictions of both fighting men and military machines; the archaeology of military burials, battle sites, and camps; and inscriptions, including military diplomas, epitaphs, and dedications.\n\nThrough his military reforms, which included consolidating or disbanding units of questionable loyalty, Augustus changed and regularized the legion, down to the hobnail pattern on the soles of army boots. A legion was organized into ten cohorts, each of which comprised six centuries, with a century further made up of ten squads \"(contubernia)\"; the exact size of the Imperial legion, which is most likely to have been determined by logistics, has been estimated to range from 4,800 to 5,280.\n\nIn AD 9, Germanic tribes wiped out three full legions in the Battle of the Teutoburg Forest. This disastrous event reduced the number of the legions to 25. The total of the legions would later be increased again and for the next 300 years always be a little above or below 30. The army had about 300,000 soldiers in the 1st century, and under 400,000 in the 2nd, \"significantly smaller\" than the collective armed forces of the territories it conquered. No more than 2% of adult males living in the Empire served in the Imperial army.\n\nAugustus also created the Praetorian Guard: nine cohorts, ostensibly to maintain the public peace, which were garrisoned in Italy. Better paid than the legionaries, the Praetorians served only sixteen years.\n\nThe \"auxilia\" were recruited from among the non-citizens. Organized in smaller units of roughly cohort strength, they were paid less than the legionaries, and after 25 years of service were rewarded with Roman citizenship, also extended to their sons. According to Tacitus there were roughly as many auxiliaries as there were legionaries. The \"auxilia\" thus amounted to around 125,000 men, implying approximately 250 auxiliary regiments. The Roman cavalry of the earliest Empire were primarily from Celtic, Hispanic or Germanic areas. Several aspects of training and equipment, such as the four-horned saddle, derived from the Celts, as noted by Arrian and indicated by archaeology.\n\nThe Roman navy (Latin: \"classis,\" \"fleet\") not only aided in the supply and transport of the legions, but also helped in the protection of the frontiers along the rivers Rhine and Danube. Another of its duties was the protection of the crucial maritime trade routes against the threat of pirates. It patrolled the whole of the Mediterranean, parts of the North Atlantic coasts, and the Black Sea. Nevertheless, the army was considered the senior and more prestigious branch.\n\nAn annexed territory became a province in a three-step process: making a register of cities, taking a census of the population, and surveying the land. Further government recordkeeping included births and deaths, real estate transactions, taxes, and juridical proceedings. In the 1st and 2nd centuries, the central government sent out around 160 officials each year to govern outside Italy. Among these officials were the \"Roman governors\", as they are called in English: either magistrates elected at Rome who in the name of the Roman people governed senatorial provinces; or governors, usually of equestrian rank, who held their \"imperium\" on behalf of the emperor in provinces excluded from senatorial control, most notably Roman Egypt. A governor had to make himself accessible to the people he governed, but he could delegate various duties. His staff, however, was minimal: his official attendants \"(apparitores)\", including lictors, heralds, messengers, scribes, and bodyguards; legates, both civil and military, usually of equestrian rank; and friends, ranging in age and experience, who accompanied him unofficially.\n\nOther officials were appointed as supervisors of government finances. Separating fiscal responsibility from justice and administration was a reform of the Imperial era. Under the Republic, provincial governors and tax farmers could exploit local populations for personal gain more freely. Equestrian procurators, whose authority was originally \"extra-judicial and extra-constitutional,\" managed both state-owned property and the vast personal property of the emperor \"(res privata)\". Because Roman government officials were few in number, a provincial who needed help with a legal dispute or criminal case might seek out any Roman perceived to have some official capacity, such as a procurator or a military officer, including centurions down to the lowly \"stationarii\" or military police.\n\nRoman courts held original jurisdiction over cases involving Roman citizens throughout the empire, but there were too few judicial functionaries to impose Roman law uniformly in the provinces. Most parts of the Eastern empire already had well-established law codes and juridical procedures. In general, it was Roman policy to respect the \"mos regionis\" (\"regional tradition\" or \"law of the land\") and to regard local laws as a source of legal precedent and social stability. The compatibility of Roman and local law was thought to reflect an underlying \"ius gentium\", the \"law of nations\" or international law regarded as common and customary among all human communities. If the particulars of provincial law conflicted with Roman law or custom, Roman courts heard appeals, and the emperor held final authority to render a decision.\n\nIn the West, law had been administered on a highly localized or tribal basis, and private property rights may have been a novelty of the Roman era, particularly among Celtic peoples. Roman law facilitated the acquisition of wealth by a pro-Roman elite who found their new privileges as citizens to be advantageous. The extension of universal citizenship to all free inhabitants of the Empire in 212 required the uniform application of Roman law, replacing the local law codes that had applied to non-citizens. Diocletian's efforts to stabilize the Empire after the Crisis of the Third Century included two major compilations of law in four years, the \"Codex Gregorianus\" and the \"Codex Hermogenianus\", to guide provincial administrators in setting consistent legal standards.\n\nThe pervasive exercise of Roman law throughout Western Europe led to its enormous influence on the Western legal tradition, reflected by the continued use of Latin legal terminology in modern law.\n\nTaxation under the Empire amounted to about 5% of the Empire's gross product. The typical tax rate paid by individuals ranged from 2 to 5%. The tax code was \"bewildering\" in its complicated system of direct and indirect taxes, some paid in cash and some in kind. Taxes might be specific to a province, or kinds of properties such as fisheries or salt evaporation ponds; they might be in effect for a limited time. Tax collection was justified by the need to maintain the military, and taxpayers sometimes got a refund if the army captured a surplus of booty. In-kind taxes were accepted from less-monetized areas, particularly those who could supply grain or goods to army camps.\nThe primary source of direct tax revenue was individuals, who paid a poll tax and a tax on their land, construed as a tax on its produce or productive capacity. Supplemental forms could be filed by those eligible for certain exemptions; for example, Egyptian farmers could register fields as fallow and tax-exempt depending on flood patterns of the Nile. Tax obligations were determined by the census, which required each head of household to appear before the presiding official and provide a head count of his household, as well as an accounting of property he owned that was suitable for agriculture or habitation.\n\nA major source of indirect-tax revenue was the \"portoria\", customs and tolls on imports and exports, including among provinces. Special taxes were levied on the slave trade. Towards the end of his reign, Augustus instituted a 4% tax on the sale of slaves, which Nero shifted from the purchaser to the dealers, who responded by raising their prices. An owner who manumitted a slave paid a \"freedom tax\", calculated at 5% of value.\n\nAn inheritance tax of 5% was assessed when Roman citizens above a certain net worth left property to anyone but members of their immediate family. Revenues from the estate tax and from a 1% sales tax on auctions went towards the veterans' pension fund \"(aerarium militare)\".\n\nLow taxes helped the Roman aristocracy increase their wealth, which equalled or exceeded the revenues of the central government. An emperor sometimes replenished his treasury by confiscating the estates of the \"super-rich\", but in the later period, the resistance of the wealthy to paying taxes was one of the factors contributing to the collapse of the Empire.\n\nMoses Finley was the chief proponent of the primitivist view that the Roman economy was \"underdeveloped and underachieving,\" characterized by subsistence agriculture; urban centres that consumed more than they produced in terms of trade and industry; low-status artisans; slowly developing technology; and a \"lack of economic rationality.\" Current views are more complex. Territorial conquests permitted a large-scale reorganization of land use that resulted in agricultural surplus and specialization, particularly in north Africa. Some cities were known for particular industries or commercial activities, and the scale of building in urban areas indicates a significant construction industry. Papyri preserve complex accounting methods that suggest elements of economic rationalism, and the Empire was highly monetized. Although the means of communication and transport were limited in antiquity, transportation in the 1st and 2nd centuries expanded greatly, and trade routes connected regional economies. The supply contracts for the army, which pervaded every part of the Empire, drew on local suppliers near the base \"(castrum)\", throughout the province, and across provincial borders. The Empire is perhaps best thought of as a network of regional economies, based on a form of \"political capitalism\" in which the state monitored and regulated commerce to assure its own revenues. Economic growth, though not comparable to modern economies, was greater than that of most other societies prior to industrialization.\n\nSocially, economic dynamism opened up one of the avenues of social mobility in the Roman Empire. Social advancement was thus not dependent solely on birth, patronage, good luck, or even extraordinary ability. Although aristocratic values permeated traditional elite society, a strong tendency towards plutocracy is indicated by the wealth requirements for census rank. Prestige could be obtained through investing one's wealth in ways that advertised it appropriately: grand country estates or townhouses, durable luxury items such as jewels and silverware, public entertainments, funerary monuments for family members or coworkers, and religious dedications such as altars. Guilds \"(collegia)\" and corporations \"(corpora)\" provided support for individuals to succeed through networking, sharing sound business practices, and a willingness to work.\n\nThe early Empire was monetized to a near-universal extent, in the sense of using money as a way to express prices and debts. The \"sestertius\" (plural \"sestertii,\" English \"sesterces\", symbolized as \"HS\") was the basic unit of reckoning value into the 4th century, though the silver \"denarius\", worth four sesterces, was used also for accounting beginning in the Severan dynasty. The smallest coin commonly circulated was the bronze \"as\" (plural \"asses\"), one-fourth \"sestertius\". Bullion and ingots seem not to have counted as \"pecunia\", \"money,\" and were used only on the frontiers for transacting business or buying property. Romans in the 1st and 2nd centuries counted coins, rather than weighing them—an indication that the coin was valued on its face, not for its metal content. This tendency towards fiat money led eventually to the debasement of Roman coinage, with consequences in the later Empire. The standardization of money throughout the Empire promoted trade and market integration. The high amount of metal coinage in circulation increased the money supply for trading or saving.\n\nRome had no central bank, and regulation of the banking system was minimal. Banks of classical antiquity typically kept less in reserves than the full total of customers' deposits. A typical bank had fairly limited capital, and often only one principal, though a bank might have as many as six to fifteen principals. Seneca assumes that anyone involved in commerce needs access to credit.\nA professional deposit banker (\"argentarius,\" \"coactor argentarius\", or later \"nummularius\") received and held deposits for a fixed or indefinite term, and lent money to third parties. The senatorial elite were involved heavily in private lending, both as creditors and borrowers, making loans from their personal fortunes on the basis of social connections. The holder of a debt could use it as a means of payment by transferring it to another party, without cash changing hands. Although it has sometimes been thought that ancient Rome lacked \"paper\" or documentary transactions, the system of banks throughout the Empire also permitted the exchange of very large sums without the physical transfer of coins, in part because of the risks of moving large amounts of cash, particularly by sea. Only one serious credit shortage is known to have occurred in the early Empire, a credit crisis in 33 AD that put a number of senators at risk; the central government rescued the market through a loan of 100 million \"HS\" made by the emperor Tiberius to the banks \"(mensae)\". Generally, available capital exceeded the amount needed by borrowers. The central government itself did not borrow money, and without public debt had to fund deficits from cash reserves.\n\nEmperors of the Antonine and Severan dynasties overall debased the currency, particularly the denarius, under the pressures of meeting military payrolls. Sudden inflation during the reign of Commodus damaged the credit market. In the mid-200s, the supply of specie contracted sharply. Conditions during the Crisis of the Third Century—such as reductions in long-distance trade, disruption of mining operations, and the physical transfer of gold coinage outside the empire by invading enemies—greatly diminished the money supply and the banking sector by the year 300. Although Roman coinage had long been fiat money or fiduciary currency, general economic anxieties came to a head under Aurelian, and bankers lost confidence in coins legitimately issued by the central government. Despite Diocletian's introduction of the gold \"solidus\" and monetary reforms, the credit market of the Empire never recovered its former robustness.\n\nThe main mining regions of the Empire were the Iberian Peninsula (gold, silver, copper, tin, lead); Gaul (gold, silver, iron); Britain (mainly iron, lead, tin), the Danubian provinces (gold, iron); Macedonia and Thrace (gold, silver); and Asia Minor (gold, silver, iron, tin). Intensive large-scale mining—of alluvial deposits, and by means of open-cast mining and underground mining—took place from the reign of Augustus up to the early 3rd century AD, when the instability of the Empire disrupted production. The gold mines of Dacia, for instance, were no longer available for Roman exploitation after the province was surrendered in 271. Mining seems to have resumed to some extent during the 4th century.\n\nHydraulic mining, which Pliny referred to as \"ruina montium\" (\"ruin of the mountains\"), allowed base and precious metals to be extracted on a proto-industrial scale. The total annual iron output is estimated at 82,500 tonnes. Copper was produced at an annual rate of 15,000 t, and lead at 80,000 t, both production levels unmatched until the Industrial Revolution; Hispania alone had a 40% share in world lead production. The high lead output was a by-product of extensive silver mining which reached 200 t per annum. At its peak around the mid-2nd century AD, the Roman silver stock is estimated at 10,000 t, five to ten times larger than the combined silver mass of medieval Europe and the Caliphate around 800 AD. As an indication of the scale of Roman metal production, lead pollution in the Greenland ice sheet quadrupled over its prehistoric levels during the Imperial era, and dropped again thereafter.\n\nThe Roman Empire completely encircled the Mediterranean, which they called \"our sea\" \"(mare nostrum)\". Roman sailing vessels navigated the Mediterranean as well as the major rivers of the Empire, including the Guadalquivir, Ebro, Rhône, Rhine, Tiber and Nile. Transport by water was preferred where possible, and moving commodities by land was more difficult. Vehicles, wheels, and ships indicate the existence of a great number of skilled woodworkers.\n\nLand transport utilized the advanced system of Roman roads. The in-kind taxes paid by communities included the provision of personnel, animals, or vehicles for the \"cursus publicus\", the state mail and transport service established by Augustus. Relay stations were located along the roads every seven to twelve Roman miles, and tended to grow into a village or trading post. A \"mansio\" (plural \"mansiones\") was a privately run service station franchised by the imperial bureaucracy for the \"cursus publicus\". The support staff at such a facility included muleteers, secretaries, blacksmiths, cartwrights, a veterinarian, and a few military police and couriers. The distance between \"mansiones\" was determined by how far a wagon could travel in a day. Mules were the animal most often used for pulling carts, travelling about 4 mph. As an example of the pace of communication, it took a messenger a minimum of nine days to travel to Rome from Mainz in the province of Germania Superior, even on a matter of urgency. In addition to the \"mansiones\", some taverns offered accommodations as well as food and drink; one recorded tab for a stay showed charges for wine, bread, mule feed, and the services of a prostitute.\n\nRoman provinces traded among themselves, but trade extended outside the frontiers to regions as far away as China and India. The main commodity was grain. Chinese trade was mostly conducted overland through middle men along the Silk Road; Indian trade, however, also occurred by sea from Egyptian ports on the Red Sea. Also traded were olive oil, various foodstuffs, \"garum\" (fish sauce), slaves, ore and manufactured metal objects, fibres and textiles, timber, pottery, glassware, marble, papyrus, spices and \"materia medica\", ivory, pearls, and gemstones.\n\nThough most provinces were capable of producing wine, regional varietals were desirable and wine was a central item of trade. Shortages of \"vin ordinaire\" were rare. The major suppliers for the city of Rome were the west coast of Italy, southern Gaul, the Tarraconensis region of Hispania, and Crete. Alexandria, the second-largest city, imported wine from Laodicea in Syria and the Aegean. At the retail level, taverns or speciality wine shops \"(vinaria)\" sold wine by the jug for carryout and by the drink on premises, with price ranges reflecting quality.\n\nInscriptions record 268 different occupations in the city of Rome, and 85 in Pompeii. Professional associations or trade guilds \"(collegia)\" are attested for a wide range of occupations, including fishermen \"(piscatores)\", salt merchants \"(salinatores)\", olive oil dealers \"(olivarii)\", entertainers \"(scaenici)\", cattle dealers \"(pecuarii)\", goldsmiths \"(aurifices)\", teamsters \"(asinarii\" or \"muliones)\", and stonecutters \"(lapidarii)\". These are sometimes quite specialized: one \"collegium\" at Rome was strictly limited to craftsmen who worked in ivory and citrus wood.\n\nWork performed by slaves falls into five general categories: domestic, with epitaphs recording at least 55 different household jobs; imperial or public service; urban crafts and services; agriculture; and mining. Convicts provided much of the labour in the mines or quarries, where conditions were notoriously brutal. In practice, there was little division of labour between slave and free, and most workers were illiterate and without special skills. The greatest number of common labourers were employed in agriculture: in the Italian system of industrial farming \"(latifundia)\", these may have been mostly slaves, but throughout the Empire, slave farm labour was probably less important than other forms of dependent labour by people who were technically not enslaved.\n\nTextile and clothing production was a major source of employment. Both textiles and finished garments were traded among the peoples of the Empire, whose products were often named for them or a particular town, rather like a fashion \"label\". Better ready-to-wear was exported by businessmen (\"negotiatores\" or \"mercatores\") who were often well-to-do residents of the production centres. Finished garments might be retailed by their sales agents, who travelled to potential customers, or by \"vestiarii,\" clothing dealers who were mostly freedmen; or they might be peddled by itinerant merchants. In Egypt, textile producers could run prosperous small businesses employing apprentices, free workers earning wages, and slaves. The fullers (\"fullones\") and dye workers (\"coloratores\") had their own guilds. \"Centonarii\" were guild workers who specialized in textile production and the recycling of old clothes into pieced goods.\n\nEconomic historians vary in their calculations of the gross domestic product of the Roman economy during the Principate. In the sample years of 14, 100, and 150 AD, estimates of per capita GDP range from 166 to 380 \"HS\". The GDP per capita of Italy is estimated as 40 to 66% higher than in the rest of the Empire, due to tax transfers from the provinces and the concentration of elite income in the heartland.\n\nIn the Scheidel–Friesen economic model, the total annual income generated by the Empire is placed at nearly 20 billion \"HS\", with about 5% extracted by central and local government. Households in the top 1.5% of income distribution captured about 20% of income. Another 20% went to about 10% of the population who can be characterized as a non-elite middle. The remaining \"vast majority\" produced more than half of the total income, but lived near subsistence.\n\nThe chief Roman contributions to architecture were the arch, vault and the dome. Even after more than 2,000 years some Roman structures still stand, due in part to sophisticated methods of making cements and concrete. Roman roads are considered the most advanced roads built until the early 19th century. The system of roadways facilitated military policing, communications, and trade. The roads were resistant to floods and other environmental hazards. Even after the collapse of the central government, some roads remained usable for more than a thousand years.\n\nRoman bridges were among the first large and lasting bridges, built from stone with the arch as the basic structure. Most utilized concrete as well. The largest Roman bridge was Trajan's bridge over the lower Danube, constructed by Apollodorus of Damascus, which remained for over a millennium the longest bridge to have been built both in terms of overall span and length.\n\nThe Romans built many dams and reservoirs for water collection, such as the Subiaco Dams, two of which fed the Anio Novus, one of the largest aqueducts of Rome. They built 72 dams just on the Iberian peninsula, and many more are known across the Empire, some still in use. Several earthen dams are known from Roman Britain, including a well-preserved example from Longovicium (Lanchester).\nThe Romans constructed numerous aqueducts. A surviving treatise by Frontinus, who served as \"curator aquarum\" (water commissioner) under Nerva, reflects the administrative importance placed on ensuring the water supply. Masonry channels carried water from distant springs and reservoirs along a precise gradient, using gravity alone. After the water passed through the aqueduct, it was collected in tanks and fed through pipes to public fountains, baths, toilets, or industrial sites. The main aqueducts in the city of Rome were the Aqua Claudia and the Aqua Marcia. The complex system built to supply Constantinople had its most distant supply drawn from over 120 km away along a sinuous route of more than 336 km. Roman aqueducts were built to remarkably fine tolerance, and to a technological standard that was not to be equalled until modern times. The Romans also made use of aqueducts in their extensive mining operations across the empire, at sites such as Las Medulas and Dolaucothi in South Wales.\n\nInsulated glazing (or \"double glazing\") was used in the construction of public baths. Elite housing in cooler climates might have hypocausts, a form of central heating. The Romans were the first culture to assemble all essential components of the much later steam engine, when Hero built the aeolipile. With the crank and connecting rod system, all elements for constructing a steam engine (invented in 1712)—Hero's aeolipile (generating steam power), the cylinder and piston (in metal force pumps), non-return valves (in water pumps), gearing (in water mills and clocks)—were known in Roman times.\n\nIn the ancient world, a city was viewed as a place that fostered civilization by being \"properly designed, ordered, and adorned.\" Augustus undertook a vast building programme in Rome, supported public displays of art that expressed the new imperial ideology, and reorganized the city into neighbourhoods \"(vici)\" administered at the local level with police and firefighting services. A focus of Augustan monumental architecture was the Campus Martius, an open area outside the city centre that in early times had been devoted to equestrian sports and physical training for youth. The Altar of Augustan Peace \"(Ara Pacis Augustae)\" was located there, as was an obelisk imported from Egypt that formed the pointer \"(gnomon)\" of a horologium. With its public gardens, the Campus became one of the most attractive places in the city to visit.\n\nCity planning and urban lifestyles had been influenced by the Greeks from an early period, and in the eastern Empire, Roman rule accelerated and shaped the local development of cities that already had a strong Hellenistic character. Cities such as Athens, Aphrodisias, Ephesus and Gerasa altered some aspects of city planning and architecture to conform to imperial ideals, while also expressing their individual identity and regional preeminence. In the areas of the western Empire inhabited by Celtic-speaking peoples, Rome encouraged the development of urban centres with stone temples, forums, monumental fountains, and amphitheatres, often on or near the sites of the preexisting walled settlements known as \"oppida\". Urbanization in Roman Africa expanded on Greek and Punic cities along the coast.\nThe network of cities throughout the Empire (\"coloniae\", \"municipia\", \"civitates\" or in Greek terms \"poleis\") was a primary cohesive force during the Pax Romana. Romans of the 1st and 2nd centuries AD were encouraged by imperial propaganda to \"inculcate the habits of peacetime\". As the classicist Clifford Ando has noted:\n\nMost of the cultural appurtenances popularly associated with imperial culture—public cult and its games and civic banquets, competitions for artists, speakers, and athletes, as well as the funding of the great majority of public buildings and public display of art—were financed by private individuals, whose expenditures in this regard helped to justify their economic power and legal and provincial privileges.\n\nEven the Christian polemicist Tertullian declared that the world of the late 2nd century was more orderly and well-cultivated than in earlier times: \"Everywhere there are houses, everywhere people, everywhere the \"res publica\", the commonwealth, everywhere life.\" The decline of cities and civic life in the 4th century, when the wealthy classes were unable or disinclined to support public works, was one sign of the Empire's imminent dissolution.\nIn the city of Rome, most people lived in multistory apartment buildings \"(insulae)\" that were often squalid firetraps. Public facilities—such as baths \"(thermae)\", toilets that were flushed with running water \"(latrinae)\", conveniently located basins or elaborate fountains \"(nymphea)\" delivering fresh water, and large-scale entertainments such as chariot races and gladiator combat—were aimed primarily at the common people who lived in the \"insulae\". Similar facilities were constructed in cities throughout the Empire, and some of the best-preserved Roman structures are in Spain, southern France, and northern Africa.\n\nThe public baths served hygienic, social and cultural functions. Bathing was the focus of daily socializing in the late afternoon before dinner. Roman baths were distinguished by a series of rooms that offered communal bathing in three temperatures, with varying amenities that might include an exercise and weight-training room, sauna, exfoliation spa (where oils were massaged into the skin and scraped from the body with a strigil), ball court, or outdoor swimming pool. Baths had hypocaust heating: the floors were suspended over hot-air channels that circulated warmth. Mixed nude bathing was not unusual in the early Empire, though some baths may have offered separate facilities or hours for men and women. Public baths were a part of urban culture throughout the provinces, but in the late 4th century, individual tubs began to replace communal bathing. Christians were advised to go to the baths for health and cleanliness, not pleasure, but to avoid the games \"(ludi)\", which were part of religious festivals they considered \"pagan\". Tertullian says that otherwise Christians not only availed themselves of the baths, but participated fully in commerce and society.\nRich families from Rome usually had two or more houses, a townhouse \"(domus,\" plural \"domūs)\" and at least one luxury home \"(villa)\" outside the city. The \"domus\" was a privately owned single-family house, and might be furnished with a private bath \"(balneum)\", but it was not a place to retreat from public life. Although some neighbourhoods of Rome show a higher concentration of well-to-do houses, the rich did not live in segregated enclaves. Their houses were meant to be visible and accessible. The atrium served as a reception hall in which the \"paterfamilias\" (head of household) met with clients every morning, from wealthy friends to poorer dependents who received charity. It was also a centre of family religious rites, containing a shrine and the images of family ancestors. The houses were located on busy public roads, and ground-level spaces facing the street were often rented out as shops \"(tabernae)\". In addition to a kitchen garden—windowboxes might substitute in the \"insulae\"—townhouses typically enclosed a peristyle garden that brought a tract of nature, made orderly, within walls.\nThe villa by contrast was an escape from the bustle of the city, and in literature represents a lifestyle that balances the civilized pursuit of intellectual and artistic interests \"(otium)\" with an appreciation of nature and the agricultural cycle. Ideally a villa commanded a view or vista, carefully framed by the architectural design. It might be located on a working estate, or in a \"resort town\" situated on the seacoast, such as Pompeii and Herculaneum.\n\nThe programme of urban renewal under Augustus, and the growth of Rome's population to as many as 1 million people, was accompanied by a nostalgia for rural life expressed in the arts. Poetry praised the idealized lives of farmers and shepherds. The interiors of houses were often decorated with painted gardens, fountains, landscapes, vegetative ornament, and animals, especially birds and marine life, rendered accurately enough that modern scholars can sometimes identify them by species. The Augustan poet Horace gently satirized the dichotomy of urban and rural values in his fable of the city mouse and the country mouse, which has often been retold as a children's story.\n\nOn a more practical level, the central government took an active interest in supporting agriculture. Producing food was the top priority of land use. Larger farms \"(latifundia)\" achieved an economy of scale that sustained urban life and its more specialized division of labour. Small farmers benefited from the development of local markets in towns and trade centres. Agricultural techniques such as crop rotation and selective breeding were disseminated throughout the Empire, and new crops were introduced from one province to another, such as peas and cabbage to Britain.\n\nMaintaining an affordable food supply to the city of Rome had become a major political issue in the late Republic, when the state began to provide a grain dole \"(annona)\" to citizens who registered for it. About 200,000–250,000 adult males in Rome received the dole, amounting to about 33 kg. per month, for a per annum total of about 100,000 tons of wheat primarily from Sicily, north Africa, and Egypt. The dole cost at least 15% of state revenues, but improved living conditions and family life among the lower classes, and subsidized the rich by allowing workers to spend more of their earnings on the wine and olive oil produced on the estates of the landowning class.\nThe grain dole also had symbolic value: it affirmed both the emperor's position as universal benefactor, and the right of all citizens to share in \"the fruits of conquest\". The \"annona\", public facilities, and spectacular entertainments mitigated the otherwise dreary living conditions of lower-class Romans, and kept social unrest in check. The satirist Juvenal, however, saw \"bread and circuses\" \"(panem et circenses)\" as emblematic of the loss of republican political liberty:\n\nThe public has long since cast off its cares: the people that once bestowed commands, consulships, legions and all else, now meddles no more and longs eagerly for just two things: bread and circuses.\n\nMost apartments in Rome lacked kitchens, though a charcoal brazier could be used for rudimentary cookery. Prepared food was sold at pubs and bars, inns, and food stalls \"(tabernae, cauponae, popinae, thermopolia)\". Carryout and restaurant dining were for the lower classes; fine dining could be sought only at private dinner parties in houses with a chef \"(archimagirus)\" and trained kitchen staff, or at banquets hosted by social clubs \"(collegia)\".\n\nMost people would have consumed at least 70% of their daily calories in the form of cereals and legumes. \"Puls\" (pottage) was considered the aboriginal food of the Romans. The basic grain pottage could be elaborated with chopped vegetables, bits of meat, cheese, or herbs to produce dishes similar to polenta or risotto.\nUrban populations and the military preferred to consume their grain in the form of bread. Mills and commercial ovens were usually combined in a bakery complex. By the reign of Aurelian, the state had begun to distribute the \"annona\" as a daily ration of bread baked in state factories, and added olive oil, wine, and pork to the dole.\n\nThe importance of a good diet to health was recognized by medical writers such as Galen (2nd century AD), whose treatises included one \"On Barley Soup\". Views on nutrition were influenced by schools of thought such as humoral theory.\n\nRoman literature focuses on the dining habits of the upper classes, for whom the evening meal \"(cena)\" had important social functions. Guests were entertained in a finely decorated dining room \"(triclinium)\", often with a view of the peristyle garden. Diners lounged on couches, leaning on the left elbow. By the late Republic, if not earlier, women dined, reclined, and drank wine along with men.\n\nThe most famous description of a Roman meal is probably Trimalchio's dinner party in the \"Satyricon\", a fictional extravaganza that bears little resemblance to reality even among the most wealthy. The poet Martial describes serving a more plausible dinner, beginning with the \"gustatio\" (\"tasting\" or \"appetizer\"), which was a composed salad of mallow leaves, lettuce, chopped leeks, mint, arugula, mackerel garnished with rue, sliced eggs, and marinated sow udder. The main course was succulent cuts of kid, beans, greens, a chicken, and leftover ham, followed by a dessert of fresh fruit and vintage wine. The Latin expression for a full-course dinner was \"ab ovo usque mala\", \"from the egg to the apples,\" equivalent to the English \"from soup to nuts.\"\nA book-length collection of Roman recipes is attributed to Apicius, a name for several figures in antiquity that became synonymous with \"gourmet.\" Roman \"foodies\" indulged in wild game, fowl such as peacock and flamingo, large fish (mullet was especially prized), and shellfish. Luxury ingredients were brought by the fleet from the far reaches of empire, from the Parthian frontier to the Straits of Gibraltar.\n\nRefined cuisine could be moralized as a sign of either civilized progress or decadent decline. The early Imperial historian Tacitus contrasted the indulgent luxuries of the Roman table in his day with the simplicity of the Germanic diet of fresh wild meat, foraged fruit, and cheese, unadulterated by imported seasonings and elaborate sauces. Most often, because of the importance of landowning in Roman culture, produce—cereals, legumes, vegetables, and fruit—was considered a more civilized form of food than meat. The Mediterranean staples of bread, wine, and oil were sacralized by Roman Christianity, while Germanic meat consumption became a mark of paganism, as it might be the product of animal sacrifice.\n\nSome philosophers and Christians resisted the demands of the body and the pleasures of food, and adopted fasting as an ideal. Food became simpler in general as urban life in the West diminished, trade routes were disrupted, and the rich retreated to the more limited self-sufficiency of their country estates. As an urban lifestyle came to be associated with decadence, the Church formally discouraged gluttony, and hunting and pastoralism were seen as simple, virtuous ways of life.\n\nWhen Juvenal complained that the Roman people had exchanged their political liberty for \"bread and circuses\", he was referring to the state-provided grain dole and the \"circenses\", events held in the entertainment venue called a \"circus\" in Latin. The largest such venue in Rome was the Circus Maximus, the setting of horse races, chariot races, the equestrian Troy Game, staged beast hunts \"(venationes)\", athletic contests, gladiator combat, and historical re-enactments. From earliest times, several religious festivals had featured games \"(ludi)\", primarily horse and chariot races \"(ludi circenses)\". Although their entertainment value tended to overshadow ritual significance, the races remained part of archaic religious observances that pertained to agriculture, initiation, and the cycle of birth and death.\n\nUnder Augustus, public entertainments were presented on 77 days of the year; by the reign of Marcus Aurelius, the number of days had expanded to 135. Circus games were preceded by an elaborate parade \"(pompa circensis)\" that ended at the venue. Competitive events were held also in smaller venues such as the amphitheatre, which became the characteristic Roman spectacle venue, and stadium. Greek-style athletics included footraces, boxing, wrestling, and the pancratium. Aquatic displays, such as the mock sea battle \"(naumachia)\" and a form of \"water ballet\", were presented in engineered pools. State-supported theatrical events \"(ludi scaenici)\" took place on temple steps or in grand stone theatres, or in the smaller enclosed theatre called an \"odeum\".\nCircuses were the largest structure regularly built in the Roman world, though the Greeks had their own architectural traditions for the similarly purposed hippodrome. The Flavian Amphitheatre, better known as the Colosseum, became the regular arena for blood sports in Rome after it opened in 80 AD. The circus races continued to be held more frequently. The Circus Maximus could seat around 150,000 spectators, and the Colosseum about 50,000 with standing room for about 10,000 more. Many Roman amphitheatres, circuses and theatres built in cities outside Italy are visible as ruins today. The local ruling elite were responsible for sponsoring spectacles and arena events, which both enhanced their status and drained their resources.\n\nThe physical arrangement of the amphitheatre represented the order of Roman society: the emperor presiding in his opulent box; senators and equestrians watching from the advantageous seats reserved for them; women seated at a remove from the action; slaves given the worst places, and everybody else packed in-between. The crowd could call for an outcome by booing or cheering, but the emperor had the final say. Spectacles could quickly become sites of social and political protest, and emperors sometimes had to deploy force to put down crowd unrest, most notoriously at the Nika riots in the year 532, when troops under Justinian slaughtered thousands.\nThe chariot teams were known by the colours they wore, with the Blues and Greens the most popular. Fan loyalty was fierce and at times erupted into sports riots. Racing was perilous, but charioteers were among the most celebrated and well-compensated athletes. One star of the sport was Diocles, from Lusitania (present-day Portugal), who raced chariots for 24 years and had career earnings of 35 million sesterces. Horses had their fans too, and were commemorated in art and inscriptions, sometimes by name. The design of Roman circuses was developed to assure that no team had an unfair advantage and to minimize collisions (\"naufragia,\" \"shipwrecks\"), which were nonetheless frequent and spectacularly satisfying to the crowd. The races retained a magical aura through their early association with chthonic rituals: circus images were considered protective or lucky, curse tablets have been found buried at the site of racetracks, and charioteers were often suspected of sorcery. Chariot racing continued into the Byzantine period under imperial sponsorship, but the decline of cities in the 6th and 7th centuries led to its eventual demise.\n\nThe Romans thought gladiator contests had originated with funeral games and sacrifices in which select captive warriors were forced to fight to expiate the deaths of noble Romans. Some of the earliest styles of gladiator fighting had ethnic designations such as \"Thracian\" or \"Gallic\". The staged combats were considered \"munera\", \"services, offerings, benefactions\", initially distinct from the festival games \"(ludi)\".\n\nThroughout his 40-year reign, Augustus presented eight gladiator shows in which a total of 10,000 men fought, as well as 26 staged beast hunts that resulted in the deaths of 3,500 animals. To mark the opening of the Colosseum, the emperor Titus presented 100 days of arena events, with 3,000 gladiators competing on a single day. Roman fascination with gladiators is indicated by how widely they are depicted on mosaics, wall paintings, lamps, and even graffiti drawings.\n\nGladiators were trained combatants who might be slaves, convicts, or free volunteers. Death was not a necessary or even desirable outcome in matches between these highly skilled fighters, whose training represented a costly and time-consuming investment. By contrast, \"noxii\" were convicts sentenced to the arena with little or no training, often unarmed, and with no expectation of survival. Physical suffering and humiliation were considered appropriate retributive justice for the crimes they had committed. These executions were sometimes staged or ritualized as re-enactments of myths, and amphitheatres were equipped with elaborate stage machinery to create special effects. Tertullian considered deaths in the arena to be nothing more than a dressed-up form of human sacrifice.\n\nModern scholars have found the pleasure Romans took in the \"theatre of life and death\" to be one of the more difficult aspects of their civilization to understand and explain. The younger Pliny rationalized gladiator spectacles as good for the people, a way \"to inspire them to face honourable wounds and despise death, by exhibiting love of glory and desire for victory even in the bodies of slaves and criminals\". Some Romans such as Seneca were critical of the brutal spectacles, but found virtue in the courage and dignity of the defeated fighter rather than in victory—an attitude that finds its fullest expression with the Christians martyred in the arena. Even martyr literature, however, offers \"detailed, indeed luxuriant, descriptions of bodily suffering\", and became a popular genre at times indistinguishable from fiction.\n\nIn the plural, \"ludi\" almost always refers to the large-scale spectator games. The singular \"ludus\", \"play, game, sport, training,\" had a wide range of meanings such as \"word play,\" \"theatrical performance,\" \"board game,\" \"primary school,\" and even \"gladiator training school\" (as in \"Ludus Magnus\", the largest such training camp at Rome).\n\nActivities for children and young people included hoop rolling and knucklebones (\"astragali\" or \"jacks\"). The sarcophagi of children often show them playing games. Girls had dolls, typically 15–16 cm tall with jointed limbs, made of materials such as wood, terracotta, and especially bone and ivory. Ball games include trigon, which required dexterity, and harpastum, a rougher sport. Pets appear often on children's memorials and in literature, including birds, dogs, cats, goats, sheep, rabbits and geese.\nAfter adolescence, most physical training for males was of a military nature. The Campus Martius originally was an exercise field where young men developed the skills of horsemanship and warfare. Hunting was also considered an appropriate pastime. According to Plutarch, conservative Romans disapproved of Greek-style athletics that promoted a fine body for its own sake, and condemned Nero's efforts to encourage gymnastic games in the Greek manner.\n\nSome women trained as gymnasts and dancers, and a rare few as female gladiators. The famous \"bikini girls\" mosaic shows young women engaging in apparatus routines that might be compared to rhythmic gymnastics. Women in general were encouraged to maintain their health through activities such as playing ball, swimming, walking, reading aloud (as a breathing exercise), riding in vehicles, and travel.\nPeople of all ages played board games pitting two players against each other, including \"latrunculi\" (\"Raiders\"), a game of strategy in which opponents coordinated the movements and capture of multiple game pieces, and \"XII scripta\" (\"Twelve Marks\"), involving dice and arranging pieces on a grid of letters or words. A game referred to as \"alea\" (dice) or \"tabula\" (the board), to which the emperor Claudius was notoriously addicted, may have been similar to backgammon, using a dice-cup \"(pyrgus)\". Playing with dice as a form of gambling was disapproved of, but was a popular pastime during the December festival of the Saturnalia with its carnival, norms-overturned atmosphere.\n\nIn a status-conscious society like that of the Romans, clothing and personal adornment gave immediate visual clues about the etiquette of interacting with the wearer. Wearing the correct clothing was supposed to reflect a society in good order. The toga was the distinctive national garment of the Roman male citizen, but it was heavy and impractical, worn mainly for conducting political business and religious rites, and for going to court. The clothing Romans wore ordinarily was dark or colourful, and the most common male attire seen daily throughout the provinces would have been tunics, cloaks, and in some regions trousers. The study of how Romans dressed in daily life is complicated by a lack of direct evidence, since portraiture may show the subject in clothing with symbolic value, and surviving textiles from the period are rare.\nThe basic garment for all Romans, regardless of gender or wealth, was the simple sleeved tunic. The length differed by wearer: a man's reached mid-calf, but a soldier's was somewhat shorter; a woman's fell to her feet, and a child's to its knees. The tunics of poor people and labouring slaves were made from coarse wool in natural, dull shades, with the length determined by the type of work they did. Finer tunics were made of lightweight wool or linen. A man who belonged to the senatorial or equestrian order wore a tunic with two purple stripes \"(clavi)\" woven vertically into the fabric: the wider the stripe, the higher the wearer's status. Other garments could be layered over the tunic.\n\nThe Imperial toga was a \"vast expanse\" of semi-circular white wool that could not be put on and draped correctly without assistance. In his work on oratory, Quintilian describes in detail how the public speaker ought to orchestrate his gestures in relation to his toga. In art, the toga is shown with the long end dipping between the feet, a deep curved fold in front, and a bulbous flap at the midsection. The drapery became more intricate and structured over time, with the cloth forming a tight roll across the chest in later periods. The \"toga praetexta\", with a purple or purplish-red stripe representing inviolability, was worn by children who had not come of age, curule magistrates, and state priests. Only the emperor could wear an all-purple toga \"(toga picta)\".\nIn the 2nd century, emperors and men of status are often portrayed wearing the pallium, an originally Greek mantle \"(himation)\" folded tightly around the body. Women are also portrayed in the pallium. Tertullian considered the pallium an appropriate garment both for Christians, in contrast to the toga, and for educated people, since it was associated with philosophers. By the 4th century, the toga had been more or less replaced by the pallium as a garment that embodied social unity.\n\nRoman clothing styles changed over time, though not as rapidly as fashions today. In the Dominate, clothing worn by both soldiers and government bureaucrats became highly decorated, with woven or embroidered stripes \"(clavi)\" and circular roundels \"(orbiculi)\" applied to tunics and cloaks. These decorative elements consisted of geometrical patterns, stylized plant motifs, and in more elaborate examples, human or animal figures. The use of silk increased, and courtiers of the later Empire wore elaborate silk robes. The militarization of Roman society, and the waning of cultural life based on urban ideals, affected habits of dress: heavy military-style belts were worn by bureaucrats as well as soldiers, and the toga was abandoned.\n\nPeople visiting or living in Rome or the cities throughout the Empire would have seen art in a range of styles and media on a daily basis. Public or official art—including sculpture, monuments such as victory columns or triumphal arches, and the iconography on coins—is often analysed for its historical significance or as an expression of imperial ideology. At Imperial public baths, a person of humble means could view wall paintings, mosaics, statues, and interior decoration often of high quality. In the private sphere, objects made for religious dedications, funerary commemoration, domestic use, and commerce can show varying degrees of aesthetic quality and artistic skill. A wealthy person might advertise his appreciation of culture through painting, sculpture, and decorative arts at his home—though some efforts strike modern viewers and some ancient connoisseurs as strenuous rather than tasteful. Greek art had a profound influence on the Roman tradition, and some of the most famous examples of Greek statues are known only from Roman Imperial versions and the occasional description in a Greek or Latin literary source.\n\nDespite the high value placed on works of art, even famous artists were of low social status among the Greeks and Romans, who regarded artists, artisans, and craftsmen alike as manual labourers. At the same time, the level of skill required to produce quality work was recognized, and even considered a divine gift.\n\nPortraiture, which survives mainly in the medium of sculpture, was the most copious form of imperial art. Portraits during the Augustan period utilize youthful and classical proportions, evolving later into a mixture of realism and idealism. Republican portraits had been characterized by a \"warts and all\" verism, but as early as the 2nd century BC, the Greek convention of heroic nudity was adopted sometimes for portraying conquering generals. Imperial portrait sculptures may model the head as mature, even craggy, atop a nude or seminude body that is smooth and youthful with perfect musculature; a portrait head might even be added to a body created for another purpose. Clothed in the toga or military regalia, the body communicates rank or sphere of activity, not the characteristics of the individual.\n\nWomen of the emperor's family were often depicted dressed as goddesses or divine personifications such as Pax (\"Peace\"). Portraiture in painting is represented primarily by the Fayum mummy portraits, which evoke Egyptian and Roman traditions of commemorating the dead with the realistic painting techniques of the Empire. Marble portrait sculpture would have been painted, and while traces of paint have only rarely survived the centuries, the Fayum portraits indicate why ancient literary sources marvelled at how lifelike artistic representations could be.\n\nExamples of Roman sculpture survive abundantly, though often in damaged or fragmentary condition, including freestanding statues and statuettes in marble, bronze and terracotta, and reliefs from public buildings, temples, and monuments such as the Ara Pacis, Trajan's Column, and the Arch of Titus. Niches in amphitheatres such as the Colosseum were originally filled with statues, and no formal garden was complete without statuary.\n\nTemples housed the cult images of deities, often by famed sculptors. The religiosity of the Romans encouraged the production of decorated altars, small representations of deities for the household shrine or votive offerings, and other pieces for dedicating at temples. Divine and mythological figures were also given secular, humorous, and even obscene depictions. \n\nElaborately carved marble and limestone sarcophagi are characteristic of the 2nd to the 4th centuries with at least 10,000 examples surviving. Although mythological scenes have been most widely studied, sarcophagus relief has been called the \"richest single source of Roman iconography,\" and may also depict the deceased's occupation or life course, military scenes, and other subject matter. The same workshops produced sarcophagi with Jewish or Christian imagery.\n\nMuch of what is known of Roman painting is based on the interior decoration of private homes, particularly as preserved at Pompeii and Herculaneum by the eruption of Vesuvius in 79 AD. In addition to decorative borders and panels with geometric or vegetative motifs, wall painting depicts scenes from mythology and the theatre, landscapes and gardens, recreation and spectacles, work and everyday life, and frank pornography. Birds, animals, and marine life are often depicted with careful attention to realistic detail. \n\nA unique source for Jewish figurative painting under the Empire is the Dura-Europos synagogue, dubbed \"the Pompeii of the Syrian Desert,\" buried and preserved in the mid-3rd century after the city was destroyed by Persians.\n\nMosaics are among the most enduring of Roman decorative arts, and are found on the surfaces of floors and other architectural features such as walls, vaulted ceilings, and columns. The most common form is the tessellated mosaic, formed from uniform pieces \"(tesserae)\" of materials such as stone and glass. Mosaics were usually crafted on site, but sometimes assembled and shipped as ready-made panels. A mosaic workshop was led by the master artist \"(pictor)\" who worked with two grades of assistants.\n\nFigurative mosaics share many themes with painting, and in some cases portray subject matter in almost identical compositions. Although geometric patterns and mythological scenes occur throughout the Empire, regional preferences also find expression. In North Africa, a particularly rich source of mosaics, homeowners often chose scenes of life on their estates, hunting, agriculture, and local wildlife. Plentiful and major examples of Roman mosaics come also from present-day Turkey, Italy, southern France, Spain, and Portugal. More than 300 Antioch mosaics from the 3rd century are known. \n\n\"Opus sectile\" is a related technique in which flat stone, usually coloured marble, is cut precisely into shapes from which geometric or figurative patterns are formed. This more difficult technique was highly prized, and became especially popular for luxury surfaces in the 4th century, an abundant example of which is the Basilica of Junius Bassus.\n\nDecorative arts for luxury consumers included fine pottery, silver and bronze vessels and implements, and glassware. The manufacture of pottery in a wide range of quality was important to trade and employment, as were the glass and metalworking industries. Imports stimulated new regional centres of production. Southern Gaul became a leading producer of the finer red-gloss pottery \"(terra sigillata)\" that was a major item of trade in 1st-century Europe. Glassblowing was regarded by the Romans as originating in Syria in the 1st century BC, and by the 3rd century Egypt and the Rhineland had become noted for fine glass.\nIn Roman tradition, borrowed from the Greeks, literary theatre was performed by all-male troupes that used face masks with exaggerated facial expressions that allowed audiences to \"see\" how a character was feeling. Such masks were occasionally also specific to a particular role, and an actor could then play multiple roles merely by switching masks. Female roles were played by men in drag (\"travesti\"). Roman literary theatre tradition is particularly well represented in Latin literature by the tragedies of Seneca. The circumstances under which Seneca's tragedies were performed are however unclear; scholarly conjectures range from minimally staged readings to full production pageants. More popular than literary theatre was the genre-defying \"mimus\" theatre, which featured scripted scenarios with free improvisation, risqué language and jokes, sex scenes, action sequences, and political satire, along with dance numbers, juggling, acrobatics, tightrope walking, striptease, and dancing bears. Unlike literary theatre, \"mimus\" was played without masks, and encouraged stylistic realism in acting. Female roles were performed by women, not by men. \"Mimus\" was related to the genre called \"pantomimus\", an early form of story ballet that contained no spoken dialogue. \"Pantomimus\" combined expressive dancing, instrumental music and a sung libretto, often mythological, that could be either tragic or comic.\nAlthough sometimes regarded as foreign elements in Roman culture, music and dance had existed in Rome from earliest times. Music was customary at funerals, and the \"tibia\" (Greek \"aulos\"), a woodwind instrument, was played at sacrifices to ward off ill influences. Song \"(carmen)\" was an integral part of almost every social occasion. The \"Secular Ode\" of Horace, commissioned by Augustus, was performed publicly in 17 BC by a mixed children's choir. Music was thought to reflect the orderliness of the cosmos, and was associated particularly with mathematics and knowledge.\n\nVarious woodwinds and \"brass\" instruments were played, as were stringed instruments such as the \"cithara\", and percussion. The \"cornu\", a long tubular metal wind instrument that curved around the musician's body, was used for military signals and on parade. These instruments are found in parts of the Empire where they did not originate, and indicate that music was among the aspects of Roman culture that spread throughout the provinces. Instruments are widely depicted in Roman art. \n\nThe hydraulic pipe organ \"(hydraulis)\" was \"one of the most significant technical and musical achievements of antiquity\", and accompanied gladiator games and events in the amphitheatre, as well as stage performances. It was among the instruments that the emperor Nero played.\n\nAlthough certain forms of dance were disapproved of at times as non-Roman or unmanly, dancing was embedded in religious rituals of archaic Rome, such as those of the dancing armed Salian priests and of the Arval Brothers, priesthoods which underwent a revival during the Principate. Ecstatic dancing was a feature of the international mystery religions, particularly the cult of Cybele as practised by her eunuch priests the Galli and of Isis. In the secular realm, dancing girls from Syria and Cadiz were extremely popular.\n\nLike gladiators, entertainers were \"infames\" in the eyes of the law, little better than slaves even if they were technically free. \"Stars\", however, could enjoy considerable wealth and celebrity, and mingled socially and often sexually with the upper classes, including emperors. Performers supported each other by forming guilds, and several memorials for members of the theatre community survive. Theatre and dance were often condemned by Christian polemicists in the later Empire, and Christians who integrated dance traditions and music into their worship practices were regarded by the Church Fathers as shockingly \"pagan.\" St. Augustine is supposed to have said that bringing clowns, actors, and dancers into a house was like inviting in a gang of unclean spirits.\n\nEstimates of the average literacy rate in the Empire range from 5 to 30% or higher, depending in part on the definition of \"literacy\". The Roman obsession with documents and public inscriptions indicates the high value placed on the written word. The Imperial bureaucracy was so dependent on writing that the Babylonian Talmud declared \"if all seas were ink, all reeds were pen, all skies parchment, and all men scribes, they would be unable to set down the full scope of the Roman government's concerns.\" Laws and edicts were posted in writing as well as read out. Illiterate Roman subjects would have someone such as a government scribe \"(scriba)\" read or write their official documents for them. Public art and religious ceremonies were ways to communicate imperial ideology regardless of ability to read. Although the Romans were not a \"People of the Book\", they had an extensive priestly archive, and inscriptions appear throughout the Empire in connection with statues and small votives dedicated by ordinary people to divinities, as well as on binding tablets and other \"magic spells\", with hundreds of examples collected in the Greek Magical Papyri. The military produced a vast amount of written reports and service records, and literacy in the army was \"strikingly high\". Urban graffiti, which include literary quotations, and low-quality inscriptions with misspellings and solecisms indicate casual literacy among non-elites. In addition, numeracy was necessary for any form of commerce. Slaves were numerate and literate in significant numbers, and some were highly educated.\n\nBooks were expensive, since each copy had to be written out individually on a roll of papyrus \"(volumen)\" by scribes who had apprenticed to the trade. The codex—a book with pages bound to a spine—was still a novelty in the time of the poet Martial (1st century AD), but by the end of the 3rd century was replacing the \"volumen\" and was the regular form for books with Christian content. Commercial production of books had been established by the late Republic, and by the 1st century AD certain neighbourhoods of Rome were known for their bookshops \"(tabernae librariae)\", which were found also in Western provincial cities such as Lugdunum (present-day Lyon, France). The quality of editing varied wildly, and some ancient authors complain about error-ridden copies, as well as plagiarism or forgery, since there was no copyright law. A skilled slave copyist \"(servus litteratus)\" could be valued as highly as 100,000 sesterces.\nCollectors amassed personal libraries, such as that of the Villa of the Papyri in Herculaneum, and a fine library was part of the cultivated leisure \"(otium)\" associated with the villa lifestyle. Significant collections might attract \"in-house\" scholars; Lucian mocked mercenary Greek intellectuals who attached themselves to philistine Roman patrons. An individual benefactor might endow a community with a library: Pliny the Younger gave the city of Comum a library valued at 1 million sesterces, along with another 100,000 to maintain it. Imperial libraries housed in state buildings were open to users as a privilege on a limited basis, and represented a literary canon from which disreputable writers could be excluded. Books considered subversive might be publicly burned, and Domitian crucified copyists for reproducing works deemed treasonous.\n\nLiterary texts were often shared aloud at meals or with reading groups. Scholars such as Pliny the Elder engaged in \"multitasking\" by having works read aloud to them while they dined, bathed or travelled, times during which they might also dictate drafts or notes to their secretaries. The multivolume \"Attic Nights\" of Aulus Gellius is an extended exploration of how Romans constructed their literary culture. The reading public expanded from the 1st through the 3rd century, and while those who read for pleasure remained a minority, they were no longer confined to a sophisticated ruling elite, reflecting the social fluidity of the Empire as a whole and giving rise to \"consumer literature\" meant for entertainment. Illustrated books, including erotica, were popular, but are poorly represented by extant fragments.\n\nTraditional Roman education was moral and practical. Stories about great men and women, or cautionary tales about individual failures, were meant to instil Roman values \"(mores maiorum)\". Parents and family members were expected to act as role models, and parents who worked for a living passed their skills on to their children, who might also enter apprenticeships for more advanced training in crafts or trades. Formal education was available only to children from families who could pay for it, and the lack of state intervention in access to education contributed to the low rate of literacy.\n\nYoung children were attended by a \"pedagogus,\" or less frequently a female \"pedagoga\", usually a Greek slave or former slave. The pedagogue kept the child safe, taught self-discipline and public behaviour, attended class and helped with tutoring. The emperor Julian recalled his pedagogue Mardonius, a eunuch slave who reared him from the age of 7 to 15, with affection and gratitude. Usually, however, pedagogues received little respect.\n\nPrimary education in reading, writing, and arithmetic might take place at home for privileged children whose parents hired or bought a teacher. Others attended a school that was \"public,\" though not state-supported, organized by an individual schoolmaster \"(ludimagister)\" who accepted fees from multiple parents. \"Vernae\" (homeborn slave children) might share in home- or public-schooling. Schools became more numerous during the Empire, and increased the opportunities for children to acquire an education. School could be held regularly in a rented space, or in any available public niche, even outdoors. Boys and girls received primary education generally from ages 7 to 12, but classes were not segregated by grade or age. For the socially ambitious, bilingual education in Greek as well as Latin was a must.\n\nQuintilian provides the most extensive theory of primary education in Latin literature. According to Quintilian, each child has in-born \"ingenium,\" a talent for learning or linguistic intelligence that is ready to be cultivated and sharpened, as evidenced by the young child's ability to memorize and imitate. The child incapable of learning was rare. To Quintilian, \"ingenium\" represented a potential best realized in the social setting of school, and he argued against homeschooling. He also recognized the importance of play in child development, and disapproved of corporal punishment because it discouraged love of learning—in contrast to the practice in most Roman primary schools of routinely striking children with a cane \"(ferula)\" or birch rod for being slow or disruptive.\n\nAt the age of 14, upperclass males made their rite of passage into adulthood, and began to learn leadership roles in political, religious, and military life through mentoring from a senior member of their family or a family friend. Higher education was provided by \"grammatici\" or \"rhetores\". The \"grammaticus\" or \"grammarian\" taught mainly Greek and Latin literature, with history, geography, philosophy or mathematics treated as explications of the text. With the rise of Augustus, contemporary Latin authors such as Vergil and Livy also became part of the curriculum. The \"rhetor\" was a teacher of oratory or public speaking. The art of speaking \"(ars dicendi)\" was highly prized as a marker of social and intellectual superiority, and \"eloquentia\" (\"speaking ability, eloquence\") was considered the \"glue\" of a civilized society. Rhetoric was not so much a body of knowledge (though it required a command of references to the literary canon) as it was a mode of expression and decorum that distinguished those who held social power. The ancient model of rhetorical training—\"restraint, coolness under pressure, modesty, and good humour\"—endured into the 18th century as a Western educational ideal.\n\nIn Latin, \"illiteratus\" (Greek \"agrammatos\") could mean both \"unable to read and write\" and \"lacking in cultural awareness or sophistication.\" Higher education promoted career advancement, particularly for an equestrian in Imperial service: \"eloquence and learning were considered marks of a well-bred man and worthy of reward\". The poet Horace, for instance, was given a top-notch education by his father, a prosperous former slave.\n\nUrban elites throughout the Empire shared a literary culture embued with Greek educational ideals \"(paideia)\". Hellenistic cities sponsored schools of higher learning as an expression of cultural achievement. Young men from Rome who wished to pursue the highest levels of education often went abroad to study rhetoric and philosophy, mostly to one of several Greek schools in Athens. The curriculum in the East was more likely to include music and physical training along with literacy and numeracy. On the Hellenistic model, Vespasian endowed chairs of grammar, Latin and Greek rhetoric, and philosophy at Rome, and gave teachers special exemptions from taxes and legal penalties, though primary schoolmasters did not receive these benefits. Quintilian held the first chair of grammar. In the eastern empire, Berytus (present-day Beirut) was unusual in offering a Latin education, and became famous for its school of Roman law. The cultural movement known as the Second Sophistic (1st–3rd century AD) promoted the assimilation of Greek and Roman social, educational, and aesthetic values, and the Greek proclivities for which Nero had been criticized were regarded from the time of Hadrian onward as integral to Imperial culture.\n\nLiterate women ranged from cultured aristocrats to girls trained to be calligraphers and scribes. The \"girlfriends\" addressed in Augustan love poetry, although fictional, represent an ideal that a desirable woman should be educated, well-versed in the arts, and independent to a frustrating degree. Education seems to have been standard for daughters of the senatorial and equestrian orders during the Empire. A highly educated wife was an asset for the socially ambitious household, but one that Martial regards as an unnecessary luxury.\n\nThe woman who achieved the greatest prominence in the ancient world for her learning was Hypatia of Alexandria, who educated young men in mathematics, philosophy, and astronomy, and advised the Roman prefect of Egypt on politics. Her influence put her into conflict with the bishop of Alexandria, Cyril, who may have been implicated in her violent death in 415 at the hands of a Christian mob.\n\nLiteracy began to decline, perhaps dramatically, during the socio-political Crisis of the Third Century. Although the Church Fathers were well-educated, they regarded Classical literature as dangerous, if valuable, and reconstrued it through moralizing and allegorical readings. Julian, the only emperor after the conversion of Constantine to reject Christianity, banned Christians from teaching the Classical curriculum, on the grounds that they might corrupt the minds of youth.\n\nWhile the book roll had emphasized the continuity of the text, the codex format encouraged a \"piecemeal\" approach to reading by means of citation, fragmented interpretation, and the extraction of maxims. In the 5th and 6th centuries, reading became rarer even for those within the Church hierarchy.\n\nIn the traditional literary canon, literature under Augustus, along with that of the late Republic, has been viewed as the \"Golden Age\" of Latin literature, embodying the classical ideals of \"unity of the whole, the proportion of the parts, and the careful articulation of an apparently seamless composition.\" The three most influential Classical Latin poets—Vergil, Horace, and Ovid—belong to this period. Vergil wrote the \"Aeneid\", creating a national epic for Rome in the manner of the Homeric epics of Greece. Horace perfected the use of Greek lyric metres in Latin verse. Ovid's erotic poetry was enormously popular, but ran afoul of the Augustan moral programme; it was one of the ostensible causes for which the emperor exiled him to Tomis (present-day Constanța, Romania), where he remained to the end of his life. Ovid's \"Metamorphoses\" was a continuous poem of fifteen books weaving together Greco-Roman mythology from the creation of the universe to the deification of Julius Caesar. Ovid's versions of Greek myths became one of the primary sources of later classical mythology, and his work was so influential in the Middle Ages that the 12th and 13th centuries have been called the \"Age of Ovid.\"\n\nThe principal Latin prose author of the Augustan age is the historian Livy, whose account of Rome's founding and early history became the most familiar version in modern-era literature. Vitruvius's book \"De Architectura\", the only complete work on architecture to survive from antiquity, also belongs to this period.\n\nLatin writers were immersed in the Greek literary tradition, and adapted its forms and much of its content, but Romans regarded satire as a genre in which they surpassed the Greeks. Horace wrote verse satires before fashioning himself as an Augustan court poet, and the early Principate also produced the satirists Persius and Juvenal. The poetry of Juvenal offers a lively curmudgeon's perspective on urban society.\n\nThe period from the mid-1st century through the mid-2nd century has conventionally been called the \"Silver Age\" of Latin literature. Under Nero, disillusioned writers reacted to Augustanism. The three leading writers—Seneca the philosopher, dramatist, and tutor of Nero; Lucan, his nephew, who turned Caesar's civil war into an epic poem; and the novelist Petronius \"(Satyricon)\"—all committed suicide after incurring the emperor's displeasure. Seneca and Lucan were from Hispania, as was the later epigrammatist and keen social observer Martial, who expressed his pride in his Celtiberian heritage. Martial and the epic poet Statius, whose poetry collection \"Silvae\" had a far-reaching influence on Renaissance literature, wrote during the reign of Domitian.\n\nThe so-called \"Silver Age\" produced several distinguished writers, including the encyclopedist Pliny the Elder; his nephew, known as Pliny the Younger; and the historian Tacitus. The \"Natural History\" of the elder Pliny, who died during disaster relief efforts in the wake of the eruption of Vesuvius, is a vast collection on flora and fauna, gems and minerals, climate, medicine, freaks of nature, works of art, and antiquarian lore. Tacitus's reputation as a literary artist matches or exceeds his value as a historian; his stylistic experimentation produced \"one of the most powerful of Latin prose styles.\" \"The Twelve Caesars\" by his contemporary Suetonius is one of the primary sources for imperial biography.\n\nAmong Imperial historians who wrote in Greek are Dionysius of Halicarnassus, the Jewish historian Josephus, and the senator Cassius Dio. Other major Greek authors of the Empire include the biographer and antiquarian Plutarch, the geographer Strabo, and the rhetorician and satirist Lucian. Popular Greek romance novels were part of the development of long-form fiction works, represented in Latin by the \"Satyricon\" of Petronius and \"The Golden Ass\" of Apuleius.\n\nFrom the 2nd to the 4th centuries, the Christian authors who would become the Latin Church Fathers were in active dialogue with the Classical tradition, within which they had been educated. Tertullian, a convert to Christianity from Roman Africa, was the contemporary of Apuleius and one of the earliest prose authors to establish a distinctly Christian voice. After the conversion of Constantine, Latin literature is dominated by the Christian perspective. When the orator Symmachus argued for the preservation of Rome's religious traditions, he was effectively opposed by Ambrose, the bishop of Milan and future saint—a debate preserved by their missives.\nIn the late 4th century, Jerome produced the Latin translation of the Bible that became authoritative as the Vulgate. Augustine, another of the Church Fathers from the province of Africa, has been called \"one of the most influential writers of western culture\", and his \"Confessions\" is sometimes considered the first autobiography of Western literature. In \"The City of God against the Pagans,\" Augustine builds a vision of an eternal, spiritual Rome, a new \"imperium sine fine\" that will outlast the collapsing Empire.\n\nIn contrast to the unity of Classical Latin, the literary aesthetic of late antiquity has a tessellated quality that has been compared to the mosaics characteristic of the period. A continuing interest in the religious traditions of Rome prior to Christian dominion is found into the 5th century, with the \"Saturnalia\" of Macrobius and \"The Marriage of Philology and Mercury\" of Martianus Capella. Prominent Latin poets of late antiquity include Ausonius, Prudentius, Claudian, and Sidonius. Ausonius (d. ca. 394), the Bordelaise tutor of the emperor Gratian, was at least nominally a Christian, though throughout his occasionally obscene mixed-genre poems, he retains a literary interest in the Greco-Roman gods and even druidism. The imperial panegyrist Claudian (d. 404) was a \"vir illustris\" who appears never to have converted. Prudentius (d. ca. 413), born in Hispania Tarraconensis and a fervent Christian, was thoroughly versed in the poets of the Classical tradition, and transforms their vision of poetry as a monument of immortality into an expression of the poet's quest for eternal life culminating in Christian salvation. Sidonius (d. 486), a native of Lugdunum, was a Roman senator and bishop of Clermont who cultivated a traditional villa lifestyle as he watched the Western empire succumb to barbarian incursions. His poetry and collected letters offer a unique view of life in late Roman Gaul from the perspective of a man who \"survived the end of his world\".\n\nReligion in the Roman Empire encompassed the practices and beliefs the Romans regarded as their own, as well as the many cults imported to Rome or practised by peoples throughout the provinces. The Romans thought of themselves as highly religious, and attributed their success as a world power to their collective piety \"(pietas)\" in maintaining good relations with the gods \"(pax deorum)\". The archaic religion believed to have been handed down from the earliest kings of Rome was the foundation of the \"mos maiorum\", \"the way of the ancestors\" or \"tradition\", viewed as central to Roman identity. There was no principle analogous to \"separation of church and state\". The priesthoods of the state religion were filled from the same social pool of men who held public office, and in the Imperial era, the Pontifex Maximus was the emperor.\n\nRoman religion was practical and contractual, based on the principle of \"do ut des\", \"I give that you might give.\" Religion depended on knowledge and the correct practice of prayer, ritual, and sacrifice, not on faith or dogma, although Latin literature preserves learned speculation on the nature of the divine and its relation to human affairs. For ordinary Romans, religion was a part of daily life. Each home had a household shrine at which prayers and libations to the family's domestic deities were offered. Neighbourhood shrines and sacred places such as springs and groves dotted the city. Apuleius (2nd century) described the everyday quality of religion in observing how people who passed a cult place might make a vow or a fruit offering, or merely sit for a while. The Roman calendar was structured around religious observances. In the Imperial era, as many as 135 days of the year were devoted to religious festivals and games (\"ludi)\". Women, slaves, and children all participated in a range of religious activities.\n\nIn the wake of the Republic's collapse, state religion had adapted to support the new regime of the emperors. As the first Roman emperor, Augustus justified the novelty of one-man rule with a vast programme of religious revivalism and reform. Public vows formerly made for the security of the republic now were directed at the wellbeing of the emperor. So-called \"emperor worship\" expanded on a grand scale the traditional Roman veneration of the ancestral dead and of the \"Genius\", the divine tutelary of every individual. Upon death, an emperor could be made a state divinity (\"divus\") by vote of the Senate. Imperial cult, influenced by Hellenistic ruler cult, became one of the major ways Rome advertised its presence in the provinces and cultivated shared cultural identity and loyalty throughout the Empire. Cultural precedent in the Eastern provinces facilitated a rapid dissemination of Imperial cult, extending as far as the Augustan military settlement at Najran, in present-day Saudi Arabia. Rejection of the state religion became tantamount to treason against the emperor. This was the context for Rome's conflict with Christianity, which Romans variously regarded as a form of atheism and novel \"superstitio\".\nThe Romans are known for the great number of deities they honoured, a capacity that earned the mockery of early Christian polemicists. As the Romans extended their dominance throughout the Mediterranean world, their policy in general was to absorb the deities and cults of other peoples rather than try to eradicate them. One way that Rome promoted stability among diverse peoples was by supporting their religious heritage, building temples to local deities that framed their theology within the hierarchy of Roman religion. Inscriptions throughout the Empire record the side-by-side worship of local and Roman deities, including dedications made by Romans to local gods. By the height of the Empire, numerous cults of pseudo-foreign gods (Roman reinventions of foreign gods) were cultivated at Rome and in the provinces, among them cults of Cybele, Isis, Epona, and of solar gods such as Mithras and Sol Invictus, found as far north as Roman Britain. Because Romans had never been obligated to cultivate one god or one cult only, religious tolerance was not an issue in the sense that it is for competing monotheistic systems.\n\nMystery religions, which offered initiates salvation in the afterlife, were a matter of personal choice for an individual, practised in addition to carrying on one's family rites and participating in public religion. The mysteries, however, involved exclusive oaths and secrecy, conditions that conservative Romans viewed with suspicion as characteristic of \"magic\", conspiracy (\"coniuratio\"), and subversive activity. Sporadic and sometimes brutal attempts were made to suppress religionists who seemed to threaten traditional morality and unity. In Gaul, the power of the druids was checked, first by forbidding Roman citizens to belong to the order, and then by banning druidism altogether. At the same time, however, Celtic traditions were reinterpreted (\"interpretatio romana\") within the context of Imperial theology, and a new Gallo-Roman religion coalesced, with its capital at the Sanctuary of the Three Gauls in Lugdunum (present-day Lyon, France). The sanctuary established precedent for Western cult as a form of Roman-provincial identity.\n\nThe monotheistic rigour of Judaism posed difficulties for Roman policy that led at times to compromise and the granting of special exemptions. Tertullian noted that the Jewish religion, unlike that of the Christians, was considered a \"religio licita\", \"legitimate religion.\" Wars between the Romans and the Jews occurred when conflict, political as well as religious, became intractable. When Caligula wanted to place a golden statue of his deified self in the Temple in Jerusalem, the potential sacrilege and likely war were prevented only by his timely death. The Siege of Jerusalem in 70 AD led to the sacking of the temple and the dispersal of Jewish political power (see Jewish diaspora).\n\nChristianity emerged in Roman Judea as a Jewish religious sect in the 1st century AD. The religion gradually spread out of Jerusalem, initially establishing major bases in first Antioch, then Alexandria, and over time throughout the Empire as well as beyond. Imperially authorized persecutions were limited and sporadic, with martyrdoms occurring most often under the authority of local officials.\n\nThe first persecution by an emperor occurred under Nero, and was confined to the city of Rome. Tacitus reports that after the Great Fire of Rome in AD 64, some among the population held Nero responsible and that the emperor attempted to deflect blame onto the Christians. After Nero, a major persecution occurred under the emperor Domitian and a persecution in 177 took place at Lugdunum, the Gallo-Roman religious capital. A surviving letter from Pliny the Younger, governor of Bythinia, to the emperor Trajan describes his persecution and executions of Christians. The Decian persecution of 246–251 was a serious threat to the Church, but ultimately strengthened Christian defiance. Diocletian undertook what was to be the most severe persecution of Christians, lasting from 303 to 311.\n\nIn the early 4th century, Constantine I became the first emperor to convert to Christianity. During the rest of the fourth century Christianity became the dominant religion of the Empire. The emperor Julian made a short-lived attempt to revive traditional and Hellenistic religion and to affirm the special status of Judaism, but in 380 (Edict of Thessalonica), under Theodosius I Christianity became the official state church of the Roman Empire, to the exclusion of all others. From the 2nd century onward, the Church Fathers had begun to condemn the diverse religions practised throughout the Empire collectively as \"pagan.\" Pleas for religious tolerance from traditionalists such as the senator Symmachus (d. 402) were rejected, and Christian monotheism became a feature of Imperial domination. Christian heretics as well as non-Christians were subject to exclusion from public life or persecution, but Rome's original religious hierarchy and many aspects of its ritual influenced Christian forms, and many pre-Christian beliefs and practices survived in Christian festivals and local traditions.\n\nSeveral states claimed to be the Roman Empire's successors after the fall of the Western Roman Empire. The Holy Roman Empire, an attempt to resurrect the Empire in the West, was established in 800 when Pope Leo III crowned Frankish King Charlemagne as Roman Emperor on Christmas Day, though the empire and the imperial office did not become formalized for some decades. After the fall of Constantinople, the Russian Tsardom, as inheritor of the Byzantine Empire's Orthodox Christian tradition, counted itself the Third Rome (Constantinople having been the second). These concepts are known as Translatio imperii.\n\nWhen the Ottomans, who based their state on the Byzantine model, took Constantinople in 1453, Mehmed II established his capital there and claimed to sit on the throne of the Roman Empire. He even went so far as to launch an invasion of Italy with the purpose of re-uniting the Empire and invited European artists to his capital, including Gentile Bellini.\n\nIn the medieval West, \"Roman\" came to mean the church and the Pope of Rome. The Greek form Romaioi remained attached to the Greek-speaking Christian population of the Eastern Roman Empire, and is still used by Greeks in addition to their common appellation.\n\nThe Roman Empire's territorial legacy of controlling the Italian peninsula would influence Italian nationalism and the unification of Italy (\"Risorgimento\") in 1861.\nIn the United States, the founders were educated in the classical tradition, and used classical models for landmarks and buildings in Washington, D.C., to avoid the feudal and religious connotations of European architecture such as castles and cathedrals. In forming their theory of the mixed constitution, the founders looked to Athenian democracy and Roman republicanism for models, but regarded the Roman emperor as a figure of tyranny. They nonetheless adopted Roman Imperial forms such as the dome, as represented by the US Capitol and numerous state capitol buildings, to express classical ideals through architecture. Thomas Jefferson saw the Empire as a negative political lesson, but was a chief proponent of its architectural models. Jefferson's design for the Virginia State Capitol, for instance, is modelled directly from the Maison Carrée, a Gallo-Roman temple built under Augustus. The renovations of the National Mall at the beginning of the 20th century have been viewed as expressing a more overt imperialist kinship with Rome.\n\n\n\n"}
{"id": "25508", "url": "https://en.wikipedia.org/wiki?curid=25508", "title": "Riga", "text": "Riga\n\nRiga (; , ) is the capital and the largest city of Latvia. With 639,630 inhabitants (2016), Riga is the largest city in the Baltic states, home to one third of Latvia's population and one tenth of the Baltic states' population. The city lies on the Gulf of Riga, at the mouth of the Daugava. Riga's territory covers and lies between above sea level, on a flat and sandy plain.\n\nRiga was founded in 1201 and is a former Hanseatic League member. Riga's historical centre is a UNESCO World Heritage Site, noted for its Art Nouveau/Jugendstil architecture and 19th century wooden architecture. Riga was the European Capital of Culture during 2014, along with Umeå in Sweden. Riga hosted the 2006 NATO Summit, the Eurovision Song Contest 2003, the 2006 IIHF Men's World Ice Hockey Championships and the 2013 World Women's Curling Championship. It is home to the European Union's office of European Regulators for Electronic Communications (BEREC). \n\nIn 2016, Riga received 2.3 million visitors. It is served by Riga International Airport, the largest and busiest airport in the Baltic states. Riga is a member of Eurocities, the Union of the Baltic Cities (UBC) and Union of Capitals of the European Union (UCEU).\n\nOne theory about the origin of the name \"Riga\" is that it is a corrupted borrowing from the Liv \"ringa\" meaning loop, referring to the ancient natural harbour formed by the tributary loop of the Daugava River. The other is that \"Riga\" owes its name to this already-established role in commerce between East and West, as a borrowing of the Latvian \"rija\", for threshing barn, the \"j\" becoming a \"g\" in German — notably, Riga is called \"Rie\" by English geographer Richard Hakluyt (1589), and German historian Dionysius Fabricius (1610) confirms the origin of \"Riga\" from \"rija\". Another theory could be that Riga was named after Riege, the German name for the River Rīdzene, a tributary of the Daugava.\n\nThe river Daugava has been a trade route since antiquity, part of the Vikings' Dvina-Dnieper navigation route to Byzantium. A sheltered natural harbour upriver from the mouth of the Daugava — the site of today's Riga — has been recorded, as \"Duna Urbs\", as early as the 2nd century. It was settled by the Livs, an ancient Finnic tribe.\n\nRiga began to develop as a centre of Viking trade during the early Middle Ages.\nRiga's inhabitants occupied themselves mainly with fishing, animal husbandry, and trading, later developing crafts (in bone, wood, amber, and iron).\n\nThe Livonian Chronicle of Henry testifies to Riga having long been a trading centre by the 12th century, referring to it as \"portus antiquus\" (ancient port), and describes dwellings and warehouses used to store mostly corn, flax, and hides. German traders began visiting Riga, establishing a nearby outpost in 1158.\n\nAlong with German traders also arrived the monk Meinhard of Segeberg to convert the Livonian pagans to Christianity. Catholic and Orthodox Christianity had already arrived in Latvia more than a century earlier, and many Latvians baptised. Meinhard settled among the Livs, building a castle and church at Ikšķile, upstream from Riga, and established his bishopric there. The Livs, however, continued to practice paganism and Meinhard died in Ikšķile in 1196, having failed his mission. In 1198, the Bishop Berthold arrived with a contingent of crusaders and commenced a campaign of forced Christianization. Berthold was killed soon afterwards and his forces defeated.\n\nThe Church mobilised to avenge. Pope Innocent III issued a bull declaring a crusade against the Livonians. Bishop Albert was proclaimed Bishop of Livonia by his uncle Hartwig of Uthlede, Prince-Archbishop of Bremen and Hamburg in 1199. Albert landed in Riga in 1200 with 23 ships and 500 Westphalian crusaders. In 1201, he transferred the seat of the Livonian bishopric from Ikšķile to Riga, extorting agreement to do so from the elders of Riga by force.\n\nThe year 1201 also marked the first arrival of German merchants in Novgorod, via the Dvina. To defend territory and trade, Albert established the Order of Livonian Brothers of the Sword in 1202, open to nobles and merchants.\n\nChristianization of the Livs continued. In 1207, Albert started on fortification of the town. Emperor Philip invested Albert with Livonia as a fief and principality of the Holy Roman Empire. To promote a permanent military presence, territorial ownership was divided between the Church and the \"Order\", with the Church taking Riga and two-thirds of all lands conquered and granting the \"Order\" a third. Until then, it had been customary for crusaders to serve for a year and then return home.\n\nAlbert had ensured Riga's commercial future by obtaining papal bulls which decreed that all German merchants had to carry on their Baltic trade through Riga. In 1211, Riga minted its first coinage, and Albert laid the cornerstone for the Riga Dom. Riga was not yet secure as an alliance of tribes failed to take Riga. In 1212, Albert led a campaign to compel Polotsk to grant German merchants free river passage. Polotsk conceded Kukenois (Koknese) and Jersika to Albert, also ending the Livs' tribute to Polotsk.\n\nRiga's merchant citizenry chafed and sought greater autonomy from the Church. In 1221, they acquired the right to independently self-administer Riga and adopted a city constitution.\n\nThat same year Albert was compelled to recognise Danish rule over lands they had conquered in Estonia and Livonia. Albert had sought the aid of King Valdemar of Denmark to protect Riga and Livonian lands against Liv insurrection when reinforcements could not reach Riga. The Danes landed in Livonia, built a fortress at Reval (Tallinn) and set about conquering Estonian and Livonian lands. The Germans attempted, but failed, to assassinate Valdemar. Albert was able to reach an accommodation with them a year later, however and, in 1222, Valdemar returned all Livonian lands and possessions to Albert's control.\n\nAlbert's difficulties with Riga's citizenry continued; with papal intervention, a settlement was reached in 1225 whereby they no longer had to pay tax to the Bishop of Riga, and Riga's citizens acquired the right to elect their magistrates and town councillors. In 1226, Albert consecrated the Dom Cathedral, built St. James's Church, (now a cathedral) and founding a parochial school at the Church of St. George.\n\nIn 1227, Albert conquered Oesel and the city of Riga concluded a treaty with the Principality of Smolensk giving Polotsk to Riga.\n\nAlbert died in January 1229. He failed in his aspiration to be anointed archbishop but the German hegemony he established over the Baltic would last for seven centuries.\n\nIn 1282, Riga became a member of the Hanseatic League. The Hansa was instrumental in giving Riga economic and political stability, thus providing the city with a strong foundation which endured the political conflagrations that were to come, down to modern times.\nAs the influence of the Hanseatic League waned, Riga became the object of foreign military, political, religious and economic aspirations. Riga accepted the Reformation in 1522, ending the power of the archbishops. In 1524, iconoclasts targeted a statue of the Virgin Mary in the Cathedral to make a statement against religious icons. It was accused of being a witch, and given a trial by water in the Daugava River. The statue floated, so it was denounced as a witch and burnt at Kubsberg. With the demise of the Livonian Order during the Livonian War, Riga for twenty years had the status of a Free Imperial City of the Holy Roman Empire before it came under the influence of the Polish–Lithuanian Commonwealth by the Treaty of Drohiczyn, which ended the war for Riga in 1581. In 1621, during the Polish–Swedish War (1621–1625), Riga and the outlying fortress of Daugavgriva came under the rule of Gustavus Adolphus, King of Sweden, who intervened in the Thirty Years' War not only for political and economic gain but also in favour of German Lutheran Protestantism. During the Russo-Swedish War (1656–1658), Riga withstood a siege by Russian forces.\n\nRiga remained the largest city in Sweden until 1710, a period during which the city retained a great deal of autonomous self-government. In that year, in the course of the Great Northern War, Russia under Tsar Peter the Great besieged plague-stricken Riga. Along with the other Livonian towns and gentry, Riga capitulated to Russia, but largely retained their privileges. Riga was made the capital of the Governorate of Riga (later: Livonia). Sweden's northern dominance had ended, and Russia's emergence as the strongest Northern power was formalised through the Treaty of Nystad in 1721. Riga became an industrialised port city of the Russian empire, in which it remained until World War I. By 1900, Riga was the third largest city in Russia after Moscow and Saint Petersburg in terms of the number of industrial workers and number of theatres.\n\nDuring these many centuries of war and changes of power in the Baltic, and despite demographic changes, the Baltic Germans in Riga had maintained a dominant position. By 1867, Riga's population was 42.9% German. Riga employed German as its official language of administration until the installation of Russian in 1891 as the official language in the Baltic provinces, as part of the policy of Russification of the non-Russian speaking territories of the Russian Empire, including Congress Poland, Finland and the Baltics, undertaken by Tsar Alexander III. More and more Latvians started moving to the city during the mid-19th century. The rise of a Latvian bourgeoisie made Riga a centre of the Latvian National Awakening with the founding of the Riga Latvian Association in 1868 and the organisation of the first national song festival in 1873. The nationalist movement of the Young Latvians was followed by the socialist New Current during the city's rapid industrialisation, culminating in the 1905 Revolution led by the Latvian Social Democratic Workers' Party.\n\nThe 20th century brought World War I and the impact of the Russian Revolution of 1917 to Riga. In consequence of the battle of Jugla, the German army marched into Riga on 3 September 1917. On 3 March 1918, the Treaty of Brest-Litovsk was signed, giving the Baltic countries to Germany. Because of the Armistice with Germany of 11 November 1918, Germany had to renounce that treaty, as did Russia, leaving Latvia and the other Baltic States in a position to claim independence. Latvia, with Riga as its capital city, thus declared its independence on 18 November 1918.\nBetween World War I and World War II (1918–1940), Riga and Latvia shifted their focus from Russia to the countries of Western Europe. The United Kingdom and Germany replaced Russia as Latvia's major trade partners. The majority of the Baltic Germans were resettled in late 1939, prior to the occupation of Estonia and Latvia by the Soviet Union in June 1940.\n\nDuring World War II, Latvia was occupied by the Soviet Union in June 1940 and then was occupied by Nazi Germany in 1941–1944. The city's Jewish community was forced into the Riga Ghetto and a Nazi concentration camp was constructed in Kaiserwald. On 25 October 1941, the Nazis relocated all Jews from Riga and the vicinity to the ghetto. Most of Latvia's Jews (about 24,000) were killed on 30 November and 8 December 1941 in the Rumbula massacre. By the end of the war, the remaining Baltic Germans were expelled to Germany.\n\nThe Soviet Red Army re-entered Riga on 13 October 1944. In the following years the massive influx of labourers, administrators, military personnel, and their dependents from Russia and other Soviet republics started. Microdistricts of the large multi-storied housing blocks were built to house immigrant workers. By 1989, the percentage of Latvians in Riga had fallen to 36.5%.\n\nIn 2004, the arrival of low-cost airlines resulted in cheaper flights from other European cities such as London and Berlin and consequently a substantial increase in numbers of tourists.\n\nIn November 2013, the roof of a supermarket collapsed, possibly as a result of the weight of materials used in the construction of a garden on the roof. At least 54 people were killed. The Latvian President Andris Berzins described the disaster as \"a large scale murder of many defenceless people\".\n\nRiga was the European Capital of Culture in 2014.\nDuring the Latvia's Presidency of the Council of the European Union in 2015 the 4th Eastern Partnership Summit took place in Riga.\n\n\nRiga's administrative divisions consist of six administrative entities: Central, Kurzeme and Northern Districts and the Latgale, Vidzeme and Zemgale Suburbs. Three entities were established on 1 September 1941, and the other three were established in October 1969. There are no official lower level administrative units, but the Riga City Council Development Agency is working on a plan, which officially makes Riga consist of 58 neighbourhoods. The current names were confirmed on 28 December 1990.\n\nThe climate of Riga is humid continental (Köppen \"Dfb\"). The coldest months are January and February, when the average temperature is but temperatures as low as can be observed almost every year on the coldest days. The proximity of the sea causes frequent autumn rains and fogs. Continuous snow cover may last eighty days. The summers in Riga are cool and humid with the average temperature of , while the temperature on the hottest days can exceed .\n\nRiga is one of the key economic and financial centres of the Baltic States. Roughly half of all the jobs in Latvia are in Riga and the city generates more than 50% of Latvia's GDP as well as around half of Latvia's exports. The biggest exporters are in wood products, IT, food and beverage manufacturing, pharmaceuticals, transport and metallurgy. Riga Port is one of the largest in the Baltics. It handled a record 34 million tons of cargo in 2011 and has potential for future growth with new port developments on Krievu Sala. Tourism is also a large industry in Riga and after a slowdown during the recent global economic recessions, grew 22% in 2011 alone.\n\nRiga, with its central geographic position and concentration of population, has always been the infrastructural hub of Latvia. Several national roads begin in Riga, and European route E22 crosses Riga from the east and west, while the Via Baltica crosses Riga from the south and north.\n\nAs a city situated by a river, Riga also has several bridges. The oldest standing bridge is the Railway Bridge, which is also the only railroad-carrying bridge in Riga. The Stone Bridge (\"Akmens tilts\") connects Old Riga and Pārdaugava; the Island Bridge (\"Salu tilts\") connects Maskavas Forštate and Pārdaugava via Zaķusala; and the Shroud Bridge (\"Vanšu tilts\") connects Old Riga and Pārdaugava via Ķīpsala. In 2008, the first stage of the new Southern Bridge (\"Dienvidu tilts\") route across the Daugava was completed, and was opened to traffic on 17 November.\n\nThe Southern Bridge was the biggest construction project in the Baltic states in 20 years, and its purpose was to reduce traffic congestion in the city centre. Another major construction project is the planned Riga Northern Transport Corridor; its first segment detailed project was completed in 2015.\n\nThe Freeport of Riga facilitates cargo and passenger traffic by sea. Sea ferries currently connect Riga Passenger Terminal to Stockholm operated by Tallink.\n\nRiga has one active airport that serves commercial airlines—the Riga International Airport (RIX), built in 1973. Renovation and modernization of the airport was completed in 2001, coinciding with the 800th anniversary of the city. In 2006, a new terminal extension was opened. Extension of the runway was completed in October 2008, and the airport is now able to accommodate large aircraft such as the Airbus A340, Boeing 747, 757, 767 and 777. Another terminal extension is under construction . The annual number of passengers has grown from 310,000 in 1993 to 4.7 million in 2014, making Riga International Airport the largest in the Baltic States.\n\nThe former international airport of Riga, Spilve Airport, located from Riga city centre, is currently used for small aircraft, pilot training and recreational aviation. Riga was also home to a military air base during the Cold War — Rumbula Air Base.\n\nPublic transportation in the city is provided by Rīgas Satiksme which operates a large number of trams, buses and trolleybuses on an extensive network of routes across the city. In addition, up until 2012 many private owners operated minibus services, after which the City Council established the unified transport company \"Rīgas mikroautobusu satiksme\", establishing a monopoly over the service.\n\nRiga is connected to the rest of Latvia by trains operated by the national carrier Passenger Train, whose headquarters are in Riga. There are also international rail services to Russia and Belarus, and plans to revive passenger rail traffic with Estonia. A TEN-T project called Rail Baltica envisages building a high-speed railway line via Riga connecting Tallinn to Warsaw using standard gauge, expected to be put into operation in 2024.\n\nRiga International Coach Terminal provides domestic and international connections by coach.\n\nThe head of the city government in Riga is the mayor. Incumbent mayor Nils Ušakovs, who is a member of the \"Harmony\" party, took office on 1 July 2009.\n\nThe city council is a democratically elected institution and is the final decision-making authority in the city. The Council consists of 60 members who are elected every four years. The Presidium of the Riga City Council consists of the Chairman of the Riga City Council and the representatives delegated by the political parties or party blocks elected to the City Council.\n\nWith 639,630 inhabitants in 2016 as according to the Central statistical administration of Latvia, Riga is the largest city in the Baltic States, though its population has decreased from just over 900,000 in 1991. Notable causes include emigration and low birth rates. Some have estimated that the population may fall by as much as 50% by 2050. According to the 2017 data, ethnic Latvians made up 44.03% of the population of Riga, with the percentage of ethnic Russians at 37.88%, Belarusians at 3.72%, Ukrainians at 3.66%, Poles at 1.83% and other ethnicities at 9.10%. By comparison, 60.1% of Latvia's total population are ethnic Latvians, 26.2% are Russians, 3.3% are Belarusians, 2.4% are Ukrainians, 2.1% are Polish, 1.2% are Lithuanians and the remaining 4.7% are accounted for by other ethnicities.\n\nUpon the restoration of Latvia's independence in 1991, Soviet era immigrants (and any of their offspring born before 1991) were not automatically granted Latvian citizenship because they had migrated to the territory of Latvia during the years when Latvia was part of the Soviet Union. In 2013 citizens of Latvia made up 73.1%, non-citizens 21.9% and citizens of other countries 4.9% of the population of Riga.\nThe proportion of ethnic Latvians in Riga increased from 36.5% in 1989 to 42.4% in 2010. In contrast, the percentage of Russians fell from 47.3% to 40.7% in the same time period. Latvians overtook Russians as the largest ethnic group in 2006. Further projections show that the ethnic Russian population will continue a steady decline, despite higher birth rates, due to emigration.\n\nThe radio and TV tower of Riga is the tallest structure in Latvia and the Baltic States, and one of the tallest in the European Union, reaching . Riga centre also has many great examples of Art Nouveau architecture, as well as a medieval old town.\n\nIt is generally recognized that Riga has the finest and the largest collection of art nouveau buildings in the world. This is due to the fact that at the end of the 19th and beginning of the 20th centuries, when Art Nouveau was at the height of its popularity, Riga experienced an unprecedented financial and demographic boom. In the period from 1857 to 1914 its population grew from 282,000 (256,200 in Riga itself and another 26,200 inhabitants beyond the city limits in patrimonial district and military town of Ust-Dvinsk) to 558,000 making it the 4th largest city in the Russian Empire (after Saint-Petersburg, Moscow and Warsaw) and its largest port. The bourgeoisie of Riga used their wealth to build imposing apartment blocks around the former city walls. Local architects, mostly graduates of Riga Technical University, adopted current European movements, and in particular Art Nouveau. In that period around 800 Art Nouveau buildings were erected. The majority of them are concentrated in the central part of Riga and a few more in the Old Town.\n\n\nRiga hosted the biannual 2014 World Choir Games from 9–19 July 2014 which coincided with the city being named European Capital of Culture for 2014. The event, organised by the choral foundation, Interkultur, takes place at various host cities every two years and was originally known as the \"Choir Olympics\". The event regularly sees over 15'000 choristers in over 300 choirs from over 60 nations compete for gold, silver and bronze medals in over 20 categories. The competition is further divided into a Champions Competition and an Open Competition to allow choirs from all backgrounds to enter. Choral workshops and festivals are also witnessed in the host cities and are usually open to the public.\n\nRiga has a rich basketball history. In the 1950s ASK Riga became the best club in the Soviet Union and also in Europe, winning the first three editions of the European Cup for Men's Champions Clubs from 1958 to 1960.\n\nIn 1960, ASK was not the only team from Riga to take the European crown. TTT Riga clinched their first title in the European Cup for Women's Champion Clubs, turning Riga into the capital city of European basketball because for the first and, so far, only time in the history of European basketball, clubs from the same city were concurrent European Men's and Women's club champions.\n\nIn 2015, Riga was one of the hosts for EuroBasket 2015.\n\n\n\n\nRiga maintains sister city relationships with the following cities:\n\n"}
{"id": "25519", "url": "https://en.wikipedia.org/wiki?curid=25519", "title": "Reich", "text": "Reich\n\nReich (; ) is a German word literally meaning \"realm\". The terms ' (literally \"realm of an emperor\") and ' (literally \"realm of a king\") are used in German to refer to empires and kingdoms respectively.\n\nAs such, the term \"Deutsches Reich\" (often translated to \"German Empire\") continued to be used even after the collapse of the German Empire and abolition of the monarchy in 1918, without any imperial connotations.\n\nThe term derives from the Germanic word meaning \"realm\" in general, but is typically used in German to designate a kingdom or an empire, especially the Roman Empire. The terms ' (roughly \"Emperordom\") and ' are used in German to more specifically define an empire ruled by an emperor.\n\n\"Reich\" is comparable in meaning and development (as well as descending from the same Proto-Indo-European root) to the English word \"realm\" (via French \"reaume\" \"kingdom\" from Latin \"regalis\" \"royal\"). It is used for historical empires in general, such as the Roman Empire ('), Persian Empire ('), and both the Tsardom of Russia and the Russian Empire (', literally \"Tsar realm\"). The Eastern Realm (') of the Holy Roman Empire is still the name used today for Austria.\n\nIn the history of Germany specifically, it is used to refer to:\n\nThe term \"Third Reich\" was adopted by the Nazis as propaganda to legitimize their government as a successor to the retroactively renamed \"First\" and \"Second\" Reichs. The terms \"First Reich\" and \"Second Reich\" are not used by historians, whilst the term \"Fourth Reich\" is used mainly in fiction and for political humour, however it also used by those who subscribe to the belief of Neo-Nazism or the belief of \"\"Aryan Supremacy\".\"\n\nThe Latin equivalent of \"Reich\" is ' or rather with a king '. Both terms translate to \"rule, sovereignty, government\", usually of monarchs (kings or emperors), but also of gods, and of the Christian God. The German version of the Lord's Prayer uses the words \"\" for \"\" (usually translated as \"thy kingdom come\" in English). \n\"Himmelreich\" is the German term for the concept of \"kingdom of heaven\".\n\nThe German noun \"Reich\" is derived from Old High German \"rīhhi\", which together with its cognates in Old English \"rīce\" Old Norse \"rîki\" (modern Scandinavian \"rike\"/\"rige\") and Gothic \"reiki\" is from a Common Germanic \"*rīkijan\".\nThe English noun is extinct, but persists in composition, in \"bishopric\".\n\nThe German adjective \"\", on the other hand, has an exact cognate in English rich. Both the noun (\"*rīkijan\") and the adjective (\"*rīkijaz\") are derivations based on a Common Germanic \"*rīks\" \"ruler, king\", reflected in Gothic as \"reiks\", glossing \"leader, ruler, chieftain\".\n\nIt is probable that the Germanic word was not inherited from pre-Proto-Germanic, but rather loaned from Celtic (i.e. Gaulish \"rīx\", Welsh \"rhi\", both meaning 'king') at an early time.\n\nThe word has many cognates outside of Germanic and Celtic, notably Latin \"rex\" and Sanskrit \"raja\" \"king\". It is ultimately from a Proto-Indo-European root \"*reg-\", meaning \"to straighten out or rule\".\n\n\"Frankenreich\" or \"Fränkisches Reich\" is the German name given to the Frankish Kingdom of Charlemagne. \n\"Frankenreich\" came to be used of Western Francia and medieval France after the development of Eastern Francia into the Holy Roman Empire.\nThe German name of France, \"Frankreich\", is a contraction of \"Frankenreich\" used in reference to the kingdom of France from the late medieval period.\n\nThe term \"Reich\" was part of the German names for Germany for much of its history. Reich was used by itself in the common German variant of the Holy Roman Empire, ('). \"Der rîche\" was a title for the Emperor. However, Latin, not German, was the formal legal language of the medieval Empire ('), so English-speaking historians are more likely to use Latin ' than German ' as a term for this period of German history. The common contemporary Latin legal term used in documents of the Holy Roman Empire was for a long time \"regnum\" (\"rule, domain, empire\", such as in \"Regnum Francorum\" for the Frankish Kingdom) before \"imperium\" was in fact adopted, the latter first attested in 1157, whereas the parallel use of \"regnum\" never fell out of use during the Middle Ages.\n\nAt the beginning of the modern age, some circles redubbed the HRE into the \"Holy Roman Empire of the German Nation\" (\"), a symptom of the formation of a German nation state as opposed to the multinational state the Empire was throughout its history. Austria-Hungary and Prussia opposed this movement.\n\nResistance against the French revolution with its concept of the state brought a new movement to create a German \"ethnical state\", especially after the Napoleonic wars. Ideal for this state was the Holy Roman Empire; the legend arose that Germany were \"un-defeated when unified\", especially after the Franco-Prussian War (\", lit. \"German-French war\"). Before that, the German question ruptured this \"German unity\" after the 1848 Revolution before it was achieved, however; Austria-Hungary as a multinational state could not become part of the new \"German empire\", and nationality conflicts in Prussia with the Prussian Poles arose (\"We can never be Germans – Prussians, every time!\").\n\nThe advent of national feeling and the movement to create an ethnically German Empire did lead directly to nationalism in 1871. Ethnic minorities declined since the beginning of the modern age; the Polabs, Sorbs and even the once important Low Germans had to assimilate themselves. This marked the transition between Antijudaism, where converted Jews were accepted as full citizens (in theory), to Antisemitism, where Jews were thought to be from a different ethnicity that could never become German. Apart from all those ethnic minorities being de facto extinct, even today the era of national feeling is taught in history in German schools as an important stepping-stone on the road to a German nation.\n\nThe term royal reich, or reich royale, was coined to describe a monarchy or royalty-backed network that characterizes many of the same attributes that Nazi Germany possessed, notably privilege of royal rank, repression and silencing of expression.\n\nIn the case of the Hohenzollern Empire (1871–1918), the official name of the country was \"Deutsches Reich\" (\"German Realm\"), because under the Constitution of the German Empire, it was legally a confederation of German states under the permanent presidency of the King of Prussia. The constitution granted the King of Prussia the title of \"German Emperor\" (\"Deutscher Kaiser\"), but this referred to the German nation rather than directly to the \"\"country\"\" of Germany.\n\nThe exact translation of the term \"German Empire\" would be \"Deutsches Kaiserreich\". This name was sometimes used informally for Germany between 1871 and 1918, but it was disliked by the first German Emperor, Wilhelm I, and never became official.\n\nThe unified Germany which arose under Chancellor Otto von Bismarck in 1871 was the first entity that was officially called in German \"\". \"Deutsches Reich\" remained the official name of Germany until 1945, although these years saw three very different political systems more commonly referred to in English as: \"the German Empire\" (1871–1918), the Weimar Republic (1919–1933; this term is a pre-World War II coinage not used at the time), and Nazi Germany (1933–1945).\n\nAfter 1918 \"Reich\" was usually not translated as \"Empire\" in English-speaking countries, and the title was instead simply used in its original German. During the Weimar Republic the term ' and the prefix ' referred not to the idea of empire but rather to the institutions, officials, affairs etc. of the whole country as opposed to those of one of its constituent federal states ('), in the same way that the terms ' (federation) and \"\" (federal) are used in Germany today, and comparable to \"The Crown\" in Commonwealth countries and \"The Union\" in the United States.\n\nThe Nazis sought to legitimize their power historiographically by portraying their ascendancy to rule as the direct continuation of an ancient German past. They adopted the term \"\" (\"Third Empire\" – usually rendered in English in the partial-translation \"the Third Reich\"), first used in a 1923 book entitled \"Das Dritte Reich\" by Arthur Moeller van den Bruck, that counted the medieval Holy Roman Empire as the first and the 1871–1918 monarchy as the second, which was then to be followed by a \"reinvigorated\" third one. This ignored the previous 1918–1933 Weimar period, which the Nazis denounced as a historical aberration, contemptuously referring to it as \"the System\". In the summer of 1939 the Nazis themselves actually banned the continued use of the term in the press, ordering it to use expressions such as \"nationalsozialistisches Deutschland\" (\"National Socialist Germany\"), \"Großdeutsches Reich\" (\"Greater German Reich\"), or simply \"Deutsches Reich\" (German Reich) to refer to the German state instead. It was Adolf Hitler's personal desire that \"Großdeutsches Reich\" and \"nationalsozialistischer Staat\" (\"[the] National Socialist State\") would be used in place of \"Drittes Reich\". \"Reichskanzlei Berchtesgaden\" (\"Reich Chancellery Berchtesgaden\"), another nickname of the regime (named after the eponymous town located in the vicinity of Hitler's mountain residence where he spent much of his time in office) was also banned at the same time, despite the fact that a sub-section of the Chancellery was in fact installed there to serve Hitler's needs.\n\nAlthough the term \"Third Reich\" is still in common use to refer to this historical period, the terms \"First Reich\" and \"Second Reich\" for the earlier periods are seldom found outside Nazi propaganda. To use the terms \"First Reich\" and \"Second Reich\", as some commentators did in the post-war years, is generally frowned upon as accepting Nazi historiography. During and following the Anschluss (annexation) of Austria in 1938 Nazi propaganda also used the political slogan \"Ein Volk, ein Reich, ein Führer\" (\"One people, one \"Reich\", one leader\"), in order to enforce pan-German sentiment. The term ' (\"old Reich\"; cf. French \"ancien regime\" for monarchical France) is sometimes used to refer to the Holy Roman Empire. The term ' was also used after the Anschluss to denote Germany with its pre-1938 post-World War I borders. Another name that was popular during this period was the term \"Tausendjähriges Reich\" (\"Thousand-Year Reich\"), the millennial connotations of which suggested that Nazi Germany would last for a thousand years.\n\nThe Nazis also spoke of enlarging the then-established Greater German Reich into a \"Greater Germanic Reich of the German Nation\" (\"Großgermanisches Reich Deutscher Nation\") by gradually annexing all the historically Germanic countries and regions of Europe (Flanders, the Netherlands, Denmark, Norway, Sweden etc.) directly into the Nazi state.\n\nA number of previously neutral words used by the Nazis have later taken on negative connotations in German (e.g. ' or '); while in many contexts ' is not one of them (\"Frankreich\", France; \"Römisches Reich\", Roman Empire), it can imply German imperialism or strong nationalism if it is used to describe a political or governmental entity. ' has thus not been used in official terminology since 1945, though it is still found in the name of the Reichstag building, which since 1999 has housed the German federal parliament, the Bundestag. The decision not to rename the Reichstag building was taken only after long debate in the Bundestag; even then, it is described officially as \"\" (Reichstag, seat of the Bundestag). As seen in this example, the term \"Bund\" (federation) has replaced \"Reich\" in the names of various state institutions such as the army (\"Bundeswehr\"). The term \"Reichstag\" also remains in use in the German language as the term for the parliaments of some foreign monarchies, such as Sweden's Riksdag and Japan's pre-war Imperial Diet.\n\nThe exception is that during the Cold War, the East German railway incongruously continued to use the name \"Deutsche Reichsbahn\" (German Reich Railways), which had been the name of the national railway during the Weimar Republic and the Nazi era. Even after German reunification in October 1990, the Reichsbahn continued to exist for over three years as the operator of the railroad in eastern Germany, ending finally on 1 January 1994 when the Reichsbahn and the western Deutsche Bundesbahn were merged to form the privatized Deutsche Bahn AG.\n\nDue to the importance of this word it is a popular conjunction in names. Many German names contain the word reich in modified forms. Such as Dietrich, Heinrich, Friedrich, Richard , and so on.\n\nRike is the Swedish and Norwegian word for \"realm\", in Danish spelled \"rige,\" of similar meaning as German \"Reich.\" The word is traditionally used for sovereign entities; a country with a King or Queen as head of state, such as the United Kingdom or Sweden itself, is a \"(kunga)rike\", literally a \"royal realm\". Two regions in Norway that were petty kingdoms before the unification of Norway around 900 AD have retained the word in the names (see Ringerike and Romerike). \"Riik\" is an Estonian word for country and realm.\n\nThe word is used in \"Svea rike\", with the current spelling \"Sverige,\" the name of Sweden in Swedish. The derived prefix \"riks-\" implies nationwide or under central jurisdiction such as in \"riksväg\", the Swedish name for a national road. It is also present in the names of institutions such as the Riksdag, Sveriges Riksbank, Riksåklagaren, Rikspolisstyrelsen, Riksteatern, riksdaler, etc. \"Riksförbund\" is used as a denomination by many national central organizations. \"Rike\" in Swedish is also used in \"utrikes\" (relating to foreign countries and other things from abroad) such as \"Utrikesdepartementet\" (Ministry for Foreign Affairs) and \"utrikesnyheter\" (news from abroad). The opposite of \"utrikes\" is \"inrikes\" (relating to the home country).\n\nThe Lord's Prayer uses the word in the Swedish, Norwegian and Danish versions: \"Tillkomme ditt rike\", \"Komme ditt rike\", \"Komme dit rige\" ('Thy kingdom come' – old versions). \"Låt ditt rike komma!\", \"La ditt rike komme\", \"Komme dit rige\" ('Let your kingdom come' – new versions).\n\n\"Rike\" is also a now-archaic English word cognate with \"reich\".\n\nRijk is the Dutch and ryk the Afrikaans equivalent of German \"Reich\".\n\nIn a political sense in the Netherlands and Belgium the word \"rijk\" often connotes a connection with the Kingdom of the Netherlands and Belgium as opposed to the European part of the country or as opposed to provincial or municipal governments; the \"ministerraad\" is the executive body of the Netherlands' government and the \"rijksministerraad\" that of the Kingdom of the Netherlands, a similar distinction is found in \"wetten\" (laws) versus \"rijkswetten\" (kingdom laws), or the now-abolished \"rijkswacht\" for gendarmerie in Belgium. The word \"rijk\" can also be found in institutions like Rijkswaterstaat, Rijksinstituut voor Volksgezondheid en Milieu, and Rijksuniversiteit Groningen.\n\nIn Afrikaans, \"ryk\" refers to rulership and area of governance (mostly a kingdom), but in a modern sense the term is used in a much more figurative sense (e.g. \"Die Hemelse Ryk\" (the heavenly kingdom, China)), as the sphere under one's control or influence, such as:\n\nLike in German, the adjective \"rijk\"/\"ryk\" means \"rich\".\n\n"}
{"id": "25520", "url": "https://en.wikipedia.org/wiki?curid=25520", "title": "Reggae", "text": "Reggae\n\nReggae () is a music genre that originated in Jamaica in the late 1960s. The term also denotes the modern popular music of Jamaica and its diaspora. A 1968 single by Toots and the Maytals, \"Do the Reggay\" was the first popular song to use the word \"reggae,\" effectively naming the genre and introducing it to a global audience. While sometimes used in a broad sense to refer to most types of popular Jamaican dance music, the term \"reggae\" more properly denotes a particular music style that was strongly influenced by traditional mento as well as American jazz and rhythm and blues, especially the New Orleans R&B practiced by Fats Domino and Allen Toussaint, and evolved out of the earlier genres ska and rocksteady. Reggae usually relates news, social gossip, and political comment. Reggae spread into a commercialized jazz field, being known first as ‘Rudie Blues’, then ‘Ska’, later ‘Blue Beat’, and ‘Rock Steady’. It is instantly recognizable from the counterpoint between the bass and drum downbeat, and the offbeat rhythm section. The immediate origins of reggae were in ska and rock steady; from the latter, reggae took over the use of the bass as a percussion instrument.\n\nStylistically, reggae incorporates some of the musical elements of rhythm and blues, jazz, mento (a celebratory, rural folk form that served its largely rural audience as dance music and an alternative to the hymns and adapted chanteys of local church singing), calypso, African music, as well as other genres. One of the most easily recognizable elements is offbeat rhythms; staccato chords played by a guitar or piano (or both) on the offbeats of the measure. The tempo of reggae is usually slower paced than ska but faster than rocksteady. The concept of call and response can be found throughout reggae music.\n\nThe genre of reggae music is led by the drum and bass. Some key players in this sound are Jackie Jackson from Toots and the Maytals, Carlton Barrett from Bob Marley and the Wailers, Lloyd Brevett from The Skatalites, Paul Douglas from Toots and the Maytals, Lloyd Knibb from The Skatalites, Winston Grennan, Sly Dunbar, and Anthony \"Benbow\" Creary from The Upsetters. The bass guitar often plays the dominant role in reggae. The bass sound in reggae is thick and heavy, and equalized so the upper frequencies are removed and the lower frequencies emphasized. The guitar in reggae usually plays on the off beat of the rhythm. It is common for reggae to be sung in Jamaican Patois, Jamaican English, and Iyaric dialects. Reggae is noted for its tradition of social criticism and religion in its lyrics, although many reggae songs discuss lighter, more personal subjects, such as love and socializing.\n\nReggae has spread to many countries across the world, often incorporating local instruments and fusing with other genres. Reggae en Español spread from the mainland South America countries of Venezuela and Guyana to the rest of South America. Caribbean music in the United Kingdom, including reggae, has been popular since the late 1960s, and has evolved into several subgenres and fusions. Many reggae artists began their careers in the UK, and there have been a number of European artists and bands drawing their inspiration directly from Jamaica and the Caribbean community in Europe. Reggae in Africa was boosted by the visit of Bob Marley to Zimbabwe in 1980. In Jamaica, authentic reggae is one of the biggest sources of income.\n\nThe 1967 edition of the \"Dictionary of Jamaican English\" lists \"reggae\" as \"a recently estab. sp. for \"rege\"\", as in \"rege-rege\", a word that can mean either \"rags, ragged clothing\" or \"a quarrel, a row\". \"Reggae\" as a musical term first appeared in print with the 1968 rocksteady hit \"Do the Reggay\" by The Maytals which named the genre of Reggae for the world.\n\nReggae historian Steve Barrow credits Clancy Eccles with altering the Jamaican patois word \"streggae\" (loose woman) into \"reggae\". However, Toots Hibbert said:\n\nThere's a word we used to use in Jamaica called 'streggae'. If a girl is walking and the guys look at her and say 'Man, she's streggae' it means she don't dress well, she look raggedy. The girls would say that about the men too. This one morning me and my two friends were playing and I said, 'OK man, let's do the reggay.' It was just something that came out of my mouth. So we just start singing 'Do the reggay, do the reggay' and created a beat. People tell me later that we had given the sound its name. Before that people had called it blue-beat and all kind of other things. Now it's in the Guinness World of Records.\n\nBob Marley is said to have claimed that the word \"reggae\" came from a Spanish term for \"the king's music\". The liner notes of \"To the King\", a compilation of Christian gospel reggae, suggest that the word \"reggae\" was derived from the Latin \"regi\" meaning \"to the king\".\n\nAlthough strongly influenced by traditional mento and calypso music, as well as American jazz and rhythm and blues, reggae owes its direct origins to the ska and rocksteady of 1960s Jamaica. The generic title for Jamaican music recorded between 1961 and 1967, ska emerged from Jamaican R&B, which itself was largely based on American R&B and doo-wop. Rastafari entered some countries primarily through reggae music; thus, the movement in these places is more particularly stamped by its origins in reggae music and social milieu. The Rastafari movement was a significant influence on reggae, with Rasta drummers like Count Ossie taking part in seminal recordings. One of the predecessors of reggae drumming is the Nyabinghi rhythm, a style of ritual drumming performed as a communal meditative practice in the Rastafarian life.\n\nSka arose in Jamaican studios in the late 1950s, developing from American R&B, mento and calypso music. Ska is characterized by a quarter note walking bass line, guitar and piano offbeats, and a drum pattern with cross-stick snare and bass drum on the backbeat and open hi-hat on the offbeats (with nothing on beats one and three). It is also notable for its jazz-influenced horn riffs. Jamaica gained its independence in 1962, and ska became the music of choice for Jamaican youths seeking music that was their own. Ska also became popular among mods in Britain.\n\nIn the mid-1960s, Rocksteady emerged, a genre slower than ska featuring more romantic lyrics and less prominent horns. The name was later solidified after the release of a single by Alton Ellis. There are many theories as to why Jamaican musicians slowed the ska tempo to create rocksteady; one is that the singer Hopeton Lewis was unable to sing his hit song \"Take It Easy\" at a ska tempo. Many rocksteady rhythms were later used as the basis of reggae recordings. The \"double skank\" guitar strokes on the offbeat were also part of the new reggae style.\n\nReggae developed from ska and rocksteady in the 1960s. Larry And Alvin’s ‘Nanny Goat’ and the Beltones’ ‘No More Heartaches’ competed for the status of first reggae record. The beat was distinctive from rocksteady in that it dropped any of the pretensions to the smooth, soulful sound that characterized slick American R&B, and instead was closer in kinship to US southern funk, being heavily dependent on the rhythm section to drive it along.Reggae’s great advantage was its almost limitless flexibility: from the early, jerky sound of Lee Perry’s ‘People Funny Boy’, to the uptown sounds of Third World’s ‘Now That We’ve Found Love’, it was an enormous leap through the years and styles, yet both are instantly recognizable as reggae. The shift from rocksteady to reggae was illustrated by the organ shuffle pioneered by Jamaican musicians like Jackie Mittoo and Winston Wright and featured in transitional singles \"Say What You're Saying\" (1968) by Eric \"Monty\" Morris and \"People Funny Boy\" (1968) by Lee \"Scratch\" Perry. The Pioneers' 1968 track \"Long Shot (Bus' Me Bet)\" has been identified as the earliest recorded example of the new rhythm sound that became known as reggae.\n\nEarly 1968 was when the first \"bona fide\" reggae records were released: \"Nanny Goat\" by Larry Marshall and \"No More Heartaches\" by The Beltones. That same year, the newest Jamaican sound began to spawn big-name imitators in other countries. American artist Johnny Nash's 1968 hit \"Hold Me Tight\" has been credited with first putting reggae in the American listener charts. Around the same time, reggae influences were starting to surface in rock and pop music, one example being 1968's \"Ob-La-Di, Ob-La-Da\" by The Beatles.\n\nThe Wailers, a band started by Bob Marley, Peter Tosh and Bunny Wailer in 1963, is perhaps the most recognized band that made the transition through all three stages of early Jamaican popular music: ska, rocksteady and reggae. Over a dozen Wailers songs are based on or use a line from Jamaican mento songs. In 1951, recordings of mento music began to be released. These recordings showcased two styles of mento: an acoustic, rural style and a jazzy, popular style. Other significant reggae pioneers include Prince Buster, Desmond Dekker and Ken Boothe.\n\nHowever, another pioneer was Millie Small (born 6 October 1946), a Jamaican singer-songwriter, best known for her 1964 blue-beat/ska cover version of \"My Boy Lollipop\" which was a smash hit internationally.\n\nNotable Jamaican producers influential in the development of ska into rocksteady and reggae include: Coxsone Dodd, Lee \"Scratch\" Perry, Leslie Kong, Duke Reid, Joe Gibbs and King Tubby. Chris Blackwell, who founded Island Records in Jamaica in 1960, relocated to England in 1962, where he continued to promote Jamaican music. He formed a partnership with Lee Gopthal's Trojan Records in 1968, which released reggae in the UK until bought by Saga records in 1974.\n\nReggae's influence bubbled to the top of the U.S. \"Billboard\" Hot 100 charts in late 1972. First Three Dog Night hit #1 in September with a cover of the Maytones' version of \"Black and White\". Then Johnny Nash was at #1 for four weeks in November with \"I Can See Clearly Now\". Paul Simon's single \"Mother And Child Reunion\" - a track which he recorded in Kingston, Jamaica with Jimmy Cliff's backing group - was ranked by Billboard as the No. 57 song of 1972.\n\nIn 1973, the film \"The Harder They Come\" starring Jimmy Cliff was released and introduced Jamaican music to cinema audiences outside of Jamaica. Though the film achieved cult status its limited appeal meant that it had a smaller impact than Eric Clapton's 1974 cover of Bob Marley's \"I Shot the Sheriff\" which made it onto the playlists of mainstream rock and pop radio stations worldwide. Clapton's \"I Shot The Sheriff\" used modern rock production and recording techniques and faithfully retained most of the original reggae elements; it was a breakthrough pastiche devoid of any parody and played an important part in bringing the music of Bob Marley to a wider rock audience. By the mid-1970s, authentic reggae dub plates and specials were getting some exposure in the UK on John Peel's radio show, who promoted the genre for the rest of his career. Around the same time, British filmmaker Jeremy Marre documented the Jamaican music scene in \"Roots Rock Reggae\", capturing the heyday of Roots reggae.\n\nIn the late 1970s and early 1980s, the UK punk rock scene flourished, and reggae was a notable influence. The DJ Don Letts would play reggae and punk tracks at clubs such as The Roxy. Punk bands such as The Clash, The Ruts, The Members and The Slits played many reggae-influenced songs. Around the same time, reggae music took a new path in the UK; one that was created by the multiracial makeup of England's inner cities and exemplified by groups like Steel Pulse, Aswad and UB40, as well as artists such as Smiley Culture and Carroll Thompson. The Jamaican ghetto themes in the lyrics were replaced with UK inner city themes, and Jamaican patois became intermingled with Cockney slang. In South London around this time, a new subgenre of Lovers Rock, was being created. Unlike the Jamaican music of the same name which was mainly dominated by male artists such as Gregory Isaacs, the South London genre was led by female singers like Thompson and Janet Kay. The UK Lovers Rock had a softer and more commercial sound.Other reggae artists who enjoyed international appeal in the early 1980s include Third World, Black Uhuru and Sugar Minott. The Grammy Awards introduced the Grammy Award for Best Reggae Album category in 1985.\n\nFemales also play a role in the reggae music industry personnel such as Olivia Grange, president of Specs-Shang Musik; Trish Farrell, president of Island/Jamaica; Lisa Cortes, president of Loose Cannon; Jamaican-American Sharon Gordon, who has worked in the independent reggae music industry.\n\nJamaican Prime Minister Bruce Golding made February 2008 the first annual Reggae Month in Jamaica. To celebrate, the Recording Industry Association of Jamaica (RIAJam) held its first Reggae Academy Awards on February 24, 2008. In addition, Reggae Month included a six-day Global Reggae conference, a reggae film festival, two radio station award functions, and a concert tribute to the late Dennis Brown, who Bob Marley cited as his favorite singer. On the business side, RIAJam held events focused on reggae's employment opportunities and potential international revenue.\n\nStylistically, reggae incorporates some of the musical elements of rhythm and blues (R&B), jazz, mento, calypso, African, and Latin American music, as well as other genres. Reggae scenes consist of two guitars, one for rhythm and one for lead—drums, congas, and keyboards, with a couple vocalists.\n\nReggae is played in time because the symmetrical rhythmic pattern does not lend itself to other time signatures such as . One of the most easily recognizable elements is offbeat rhythms; staccato chords played by a guitar or piano (or both) on the offbeats of the measure, often referred to as the skank.\n\nThis rhythmic pattern accents the second and fourth beats in each bar and combines with the drum's emphasis on beat three to create a unique sense of phrasing. The reggae offbeat can be counted so that it falls between each count as an \"and\" (example: 1 and 2 and 3 and 4, etc.) or counted as a half-time feel at twice the tempo so it falls on beats 2 and 4. This is in contrast to the way most other popular genres focus on beat one, the \"downbeat\".\n\nThe tempo of reggae is usually slower than ska but faster than rocksteady. It is this slower tempo, the guitar/piano offbeats, the emphasis on the third beat, and the use of syncopated, melodic bass lines that differentiate reggae from other music, although other musical styles have incorporated some of these innovations.\n\nHarmonically the music is essentially the same as any other modern popular genre with a tendency to make use of simple chord progressions. Reggae sometimes uses the dominant chord in its minor form therefore never allowing a perfect cadence to be sounded; this lack of resolution between the tonic and the dominant imparts a sense of movement \"without rest\" and harmonic ambiguity. Extended chords like the major seventh chord (\"Waiting in Vain\" by Bob Marley) and minor seventh chord are used though suspended chords or diminished chords are rare. Minor keys are commonly used especially with the minor chord forms of the subdominant and dominant chord (for example in the key of G minor the progression may be played Gm – Dm – Gm – Dm – Cm – Dm – Cm – Dm). A simple progression borrowed from rhythm and blues and soul music is the tonic chord followed by the minor supertonic chord with the two chords repeated continuously to form a complete verse (\"Just My Imagination\" by The Temptations C – Dm).\n\nThe concept of \"call and response\" can be found throughout reggae music, in the vocals but also in the way parts are composed and arranged for each instrument. The emphasis on the \"third beat\" of the bar also results in a different sense of musical phrasing, with bass lines and melody lines often emphasizing what might be considered \"pick up notes\" in other genres.\n\nA standard drum kit is generally used in reggae, but the snare drum is often tuned very high to give it a timbales-type sound. Some reggae drummers use an additional timbale or high-tuned snare to get this sound. Cross-stick technique on the snare drum is commonly used, and tom-tom drums are often incorporated into the drumbeat itself.\n\nReggae drumbeats fall into three main categories: \"One drop\", \"Rockers\", and \"Steppers\". With the \"One drop\", the emphasis is entirely on the backbeat (usually on the snare, or as a rim shot combined with bass drum). Beat one is empty except for a closed high hat commonly used, which is unusual in popular music. There is some controversy about whether reggae should be counted so that this beat falls on two and four, or whether it should be counted twice as fast, so it falls on three. An example played by Barrett can be heard in the Bob Marley and the Wailers song \"One Drop\". Barrett often used an unusual triplet cross-rhythm on the hi-hat, which can be heard on many recordings by Bob Marley and the Wailers, such as \"Running Away\" on the \"Kaya\" album.\nAn emphasis on the backbeat is found in all reggae drumbeats, but with the \"Rockers\" beat, the emphasis is on all four beats of the bar (usually on bass drum). This beat was pioneered by Sly and Robbie, who later helped create the \"Rub-a-Dub\" sound that greatly influenced dancehall. Sly has stated he was influenced to create this style by listening to American drummer Earl Young as well as other disco and R&B drummers in the early to mid-1970s, as stated in the book \"Wailing Blues\". The prototypical example of the style is found in Sly Dunbar's drumming on \"Right Time\" by the Mighty Diamonds. The \"Rockers\" beat is not always straightforward, and various syncopations are often included. An example of this is the Black Uhuru song \"Sponji Reggae\".\n\nIn \"Steppers\", the bass drum plays every quarter beat of the bar, giving the beat an insistent drive. An example is \"Exodus\" by Bob Marley and the Wailers. Another common name for the \"Steppers\" beat is the \"four on the floor\". Burning Spear's 1975 song \"Red, Gold, and Green\" (with Leroy Wallace on drums) is one of the earliest examples. The \"Steppers\" beat was adopted (at a much higher tempo) by some 2 Tone ska revival bands of the late 1970s and early 1980s.\n\nAn unusual characteristic of reggae drumming is that the drum fills often do not end with a climactic cymbal. A wide range of other percussion instrumentation are used in reggae. Bongos are often used to play free, improvised patterns, with heavy use of African-style cross-rhythms. Cowbells, claves and shakers tend to have more defined roles and a set pattern.\n\nReggae drummers often involved these three tips for other reggae performers: (1) go for open, ringing tones when playing ska and rocksteady, (2) use any available material to stuff the bass drum so that it tightens up the kick to a deep, punchy thud, and (3) go without a ride cymbal, focusing on the hi-hat for timekeeping and thin crashes with fast decay for accents.\n\nThe bass guitar often plays the dominant role in reggae, and the drum and bass is often the most important part of what is called, in Jamaican music, a \"riddim\" (rhythm), a (usually simple) piece of music that's used repeatedly by different artists to write and record songs with. Literally hundreds of reggae singers have released different songs recorded over the same rhythm. The central role of the bass can be particularly heard in dub music — which gives an even bigger role to the drum and bass line, reducing the vocals and other instruments to peripheral roles.\n\nThe bass sound in reggae is thick and heavy, and equalized so the upper frequencies are removed and the lower frequencies emphasized. The bass line is often a repeated two or four bar riff when simple chord progressions are used. The simplest example of this might be Robbie Shakespeare's bass line for the Black Uhuru hit \"Shine Eye Gal\". In the case of more complex harmonic structures, such as John Holt's version of \"Stranger In Love\", these simpler patterns are altered to follow the chord progression either by directly moving the pattern around or by changing some of the interior notes in the phrase to better support the chords.\n\nThe guitar in reggae usually plays on the off beat of the rhythm. So if one is counting in time and counting 1 + 2 + 3 + 4 +, one would play a downstroke on the \"and\" part of the beat. A musical figure known as skank or the 'bang\" has a very dampened, short and scratchy chop sound, almost like a percussion instrument. Sometimes a double chop is used when the guitar still plays the off beats, but also plays the following eighth-note beats on the up-stroke. An example is the intro to \"Stir It Up\" by The Wailers. Artist and producer Derrick Harriott says, “What happened was the musical thing was real widespread, but only among a certain sort of people. It was always a down-town thing, but more than just hearing the music. The equipment was so powerful and the vibe so strong that we feel it.”\n\nFrom the earliest days of Ska recordings, a piano was used to double the rhythm guitar's skank, playing the chords in a \"staccato\" style to add body, and playing occasional extra beats, runs and riffs. The piano part was widely taken over by synthesizers during the 1980s, although synthesizers have been used in a peripheral role since the 1970s to play incidental melodies and countermelodies. Larger bands may include either an additional keyboardist, to cover or replace horn and melody lines, or the main keyboardist filling these roles on two or more keyboards.\n\nThe reggae organ-shuffle is unique to reggae. In the original version of reggae, the drummer played a reggae groove that was used in the four bar introduction, allowing the piano to serve as a percussion instrument. Typically, a Hammond organ-style sound is used to play chords with a choppy feel. This is known as the \"bubble\". This may be the most difficult reggae keyboard rhythm. The organ bubble can be broken down into 2 basic patterns. In the first, the 8th beats are played with a space-left-right-left-space-left-right-left pattern, where the spaces represent downbeats not played—that and the left-right-left falls on the ee-and-a, or and-2-and if counted at double time. In the second basic pattern, the left hand plays a double chop as described in the guitar section while the right hand plays longer notes on beat 2 (or beat 3 if counted at double time) or a syncopated pattern between the double chops. Both these patterns can be expanded on and improvised embellishments are sometimes used.\n\nHorn sections are frequently used in reggae, often playing introductions and counter-melodies. Instruments included in a typical reggae horn section include saxophone, trumpet or trombone. In more recent times, real horns are sometimes replaced in reggae by synthesizers or recorded samples. The horn section is often arranged around the first horn, playing a simple melody or counter melody. The first horn is usually accompanied by the second horn playing the same melodic phrase in unison, one octave higher. The third horn usually plays the melody an octave and a fifth higher than the first horn. The horns are generally played fairly softly, usually resulting in a soothing sound. However, sometimes punchier, louder phrases are played for a more up-tempo and aggressive sound.\n\nThe vocals in reggae are less of a defining characteristic of the genre than the instrumentation and rhythm, as almost any song can be performed in a reggae style. However, it is very common for reggae to be sung in Jamaican Patois, Jamaican English, and Iyaric dialects. Vocal harmony parts are often used, either throughout the melody (as with vocal groups such as the Mighty Diamonds), or as a counterpoint to the main vocal line (as with the backing vocalists, the I-Threes). More complex vocal arrangements can be found in the works of groups like The Abyssinians and British reggae band Steel Pulse.\n\nAn unusual aspect of reggae singing is that many singers use \"tremolo\" (volume oscillation) rather than \"vibrato\" (pitch oscillation). Notable exponents of this technique include Horace Andy and vocal group Israel Vibration. The toasting vocal style is unique to reggae, originating when DJs improvised spoken introductions to songs (or \"toasts\") to the point where it became a distinct rhythmic vocal style, and is generally considered to be a precursor to rap. It differs from rap mainly in that it is generally melodic, while rap is generally more a spoken form without melodic content.\n\nReggae is noted for its tradition of social criticism in its lyrics, although many reggae songs discuss lighter, more personal subjects, such as love and socializing. Many early reggae bands covered Motown or Atlantic soul and funk songs. Some reggae lyrics attempt to raise the political consciousness of the audience, such as by criticizing materialism, or by informing the listener about controversial subjects such as Apartheid. Many reggae songs promote the use of cannabis (also known as \"herb\", \"ganja\", or \"sinsemilla\"), considered a sacrament in the Rastafari movement. There are many artists who utilize religious themes in their music — whether it be discussing a specific religious topic, or simply giving praise to God (Jah). Other common socio-political topics in reggae songs include black nationalism, anti-racism, anti-colonialism, anti-capitalism and criticism of political systems and \"Babylon\".\n\nIn recent years, Jamaican (and non-Jamaican) reggae musicians have used more positive themes in reggae music. The music is widely considered a treasured cultural export for Jamaica, so musicians who still desire progress for their island nation have begun focusing on themes of hopefulness, faith, and love. For elementary children, reggae songs such as \"Give a Little Love,\" \"One Love,\" or \"Three Little Birds,\" all written by Bob Marley, can be sung and enjoyed for their optimism and cheerful lyrics.\n\nThe wide cultural exposure which has enhanced the recognizability of reggae has been achieved primarily through a corporate commercialization effected at the expense of both the lyrical and instrumental essence of the music. This process has involved coerced or voluntary assimilation of more commercially compatible characteristics, appropriation by white mainstream artists, and an overall dispersal of ideological and musical meaning and creative value.The mainstream Euro-American audience has continually demonstrated a propensity for adopting reggae-oriented material on the basis of its aesthetically pleasing surface qualities rather than for explicitly political or deeper musical content, causing authenticity problems for reggae fans.\n\nSome dancehall and ragga artists have been criticised for homophobia, including threats of violence. Buju Banton's song \"Boom Bye-Bye\" states that gays \"haffi dead\". Other notable dancehall artists who have been accused of homophobia include Elephant Man, Bounty Killer and Beenie Man. The controversy surrounding anti-gay lyrics has led to the cancellation of UK tours by Beenie Man and Sizzla. Toronto, Canada has also seen the cancellation of concerts due to artists such as Elephant Man and Sizzla refusing to conform to similar censorship pressures.\n\nAfter lobbying from the Stop Murder Music coalition, the dancehall music industry agreed in 2005 to stop releasing songs that promote hatred and violence against gay people. In June 2007, Beenie Man, Sizzla and Capleton signed up to the Reggae Compassionate Act, in a deal brokered with top dancehall promoters and Stop Murder Music activists. They renounced homophobia and agreed to \"not make statements or perform songs that incite hatred or violence against anyone from any community\". Five artists targeted by the anti-homophobia campaign did not sign up to the act, including Elephant Man, TOK, Bounty Killa and Vybz Kartel. Buju Banton and Beenie Man both gained positive press coverage around the world for publicly renouncing homophobia by signing the Reggae Compassion Act. However, both of these artists have since denied any involvement in anti-homophobia work and both deny having signed any such act.\n\nFor many years vinyl has been of central importance to the Jamaican music industry, playing a significant cultural and economic role in the development of reggae music. \"In the early 1950's, Jamaican entrepreneurs began issuing 78s\" but this format would soon be superseded by the 7\" single, first released in 1949. The first 7\" singles to appear in Jamaica around this time were often covers of popular American RnB hits, made by Kingston sound system operators to be played in the dance. \"Meanwhile, Jamaican expatriates started issuing 45s on small UK independents, typically featuring graphics-free logos. Though the quality of foreign pressing was typically better, some were actually mastered from Jamaican 45s and many were totally unauthorised\".\n\nOil Crisis\n\nThe quality of 7\" singles produced in Jamaica took a dramatic turn for the worse following the oil crisis of the 1970s.\n\n45 rpm adapter\n\nThe 45 rpm adapter is crucial when playing 7\" singles which feature a cut out middle.\n\nReggae has spread to many countries across the world, often incorporating local instruments and fusing with other genres.\n\nReggae en Español spread from mainland South American Caribbean from Venezuela and Guyana to the rest of South America. It does not have any specific characteristics other than being sung in Spanish, usually by artists of Latin American origin. Samba reggae originated in Brazil as a blend of samba with Jamaican reggae. Reggae also has a presence in Veracruz, Mexico. The most notable Jarocho reggae group being Los Aguas Aguas from Xalapa. Some of the most popular reggae groups across Latin America come from the Southern Cone, such as the Chilean band Gondwana, and the Argentinian band Los Cafres. The Puerto Rican band Cultura Profética is also widely recognized in the region. Hispanic reggae includes three elements: the incorporation of the Spanish language; the use of translations and versions based on known riddims and background music; and regional consciousness. It is a medium of rebellious contestation rising from the underground. Hispanic reggae is related to rap, sharing characteristics that can be found not only in the social conditions in which they developed in the region but also in the characteristics of social sectors and classes that welcome them.\n\nBrazilian samba-reggae utilized themes such as the U.S. African-American civil rights movement and the Black Soul movement, and especially the Jamaican independence movement since the 1960s and its messages in reggae and Rastafarianism. Thus, the sudden popularity of reggae music and musicians in Bahia, Brazil, was not the result of the effects of the transnational music industry, but of the need to establish cultural and political links with black communities across the Americas that had faced and were facing similar sociopolitical situations.\n\nMusically, it was the bloco afro Olodum and its lead percussionist, Neguinho do Samba, that began to combine the basic samba beat of the blocos with merengue, salsa, and reggae rhythms and debuted their experimentations in the carnival of 1986. The new toques (drumming patterns) were labeled \"samba-reggae\" and consisted basically of a pattern in which the surdo bass drums (four of them at the minimum) divided themselves into four or five interlocking parts.\n\nIn the United States, bands like Rebelution, Slightly Stoopid, and SOJA are considered progressive reggae bands sometimes referred to as Cali Reggae or Pacific Dub. The American reggae scene is heavily centred in Southern California, with large scenes also in New York City, Washington, D.C., Chicago, Miami, and Honolulu. For decades, Hawaiian reggae has had a big following on the Hawaiian islands and the West coast of the US. On the east coast upstate NY has seen a rise in original roots reggae bands such as Giant Panda Guerilla Dub Squad and John Brown's Body who were inspired by Jamaican reggae bands that performed in the area back in the 80s and 90s. Matisyahu gained prominence by blending traditional Jewish themes with reggae. Compounding his use of the hazzan style, Matisyahu's lyrics are mostly English with more than occasional use of Hebrew and Yiddish. There is a large Caribbean presence in Toronto and Montreal, Canada, with English and French influences on the reggae genre.\n\nIn 2017, Toots and the Maytals became the second reggae-based group to ever perform at the Coachella festival, after Chronixx in 2016.\n\nThe UK was a primary destination for Caribbean people looking to emigrate as early as the 1950s. Because of this, Caribbean music in the United Kingdom, including reggae, has been popular since the late 1960s, and has evolved into several subgenres and fusions. Most notable of these is lovers rock, but this fusion of Jamaican music into English culture was seminal in the formation of other musical forms like drum and bass and dubstep. The UK became the base from which many Jamaican artists toured Europe and due to the large number of Jamaican musicians emigrating there, the UK is the root of the larger European scene that exists today. Many of the world's most famous reggae artists began their careers in UK. Singer and Grammy Award-winning reggae artist Maxi Priest began his career with seminal British sound system Saxon Studio International.\n\nThree reggae-tinged singles from the Police's 1978 debut album, \"Outlandos d'Amour,\" laid down the template for the basic structure of a lot of rock/reggae songwriting: a reggae-infused verse containing upstrokes on guitar or keyboards and a more aggressive, on-the-beat punk/rock attack during the chorus. The end of the 1970s featured a ska revival in the UK. By the end of the '70s, a revival movement had begun in England, with such bands as the Specials, Madness, the (English) Beat, and the Selecter. The Specials' leader and keyboardist, Jerry Dammers, founded the 2 Tone record label, which released albums from the aforementioned racially integrated groups and was instrumental in creating a new social and cultural awareness. The 2 Tone movement referenced reggae's godfathers, popular styles (including the genre's faster and more dance-oriented precursors, ska and rocksteady), and previous modes of dress (such as black suits and porkpie hats) but updated the sound with a faster tempo, more guitar, and more attitude.\n\nBirmingham based reggae/pop music band UB40 were main contributors to the British reggae scene throughout the 1980s and 1990s. The achieved international success with hits such as \"Red Red Wine,\" \"Kingston Town\" and \"(I can't Help) Falling in Love with You.\"\n\nOther UK based artists that had international impact include Aswad, Misty In Roots, Steel Pulse, Janet Kay, Tippa Irie, Smiley Culture and more recently Bitty McLean. There have been a number of European artists and bands drawing their inspiration directly from Jamaica and the Caribbean community in Europe, whose music and vocal styles are almost identical to contemporary Jamaican music. The best examples might be Alborosie (Italy) and Gentleman (Germany). Both Gentleman and Alborosie have had a significant chart impact in Jamaica, unlike many European artists. They have both recorded and released music in Jamaica for Jamaican labels and producers and are popular artists, likely to appear on many riddims. Alborosie has lived in Jamaica since the late 1990s and has recorded at Bob Marley's famous Tuff Gong Studios. Since the early 1990s, several Italian reggae bands have emerged, including Africa Unite, Reggae National Tickets, Sud Sound System, Pitura Freska and B.R. Stylers. Another Italian famous reggae singer was Rino Gaetano.\n\nReggae appeared on the Yugoslav popular music scene in the late 1970s, through sporadic songs by popular rock acts. Reggae saw an expansion with the emergence of Yugoslav new wave scene. The bands like Haustor, Šarlo Akrobata, Aerodrom, Laboratorija Zvuka, Piloti, Du Du A and others recorded reggae and reggae-influence songs. In the mid-1980s appeared Del Arno Band, often considered the first real reggae band in Yugoslavia. Throughout the following decades they remained one of the most popular and influential reggae bands in the region. In the 1990s and early 2000s, after the breakup of Yugoslavia, appeared a new generation of reggae bands, like Serbian band Eyesburn, which gained popularity with their combination of reggae with hardcore punk and crossover thrash, and Croatian band Radikal Dub Kolektiv, alongside bands which incorporated reggae into their sound, like Darkwood Dub, Kanda, Kodža i Nebojša and Lira Vega in Serbia and Dubioza Kolektiv in Bosnia and Herzegovina. Late 2000s and 2010s brought a new generation of reggae acts in the region.\n\nThe first homegrown Polish reggae bands started in the 1980s with groups like Izraelario. Singer and songwriter Alexander Barykin was considered as the father of Russian reggae. In Sweden, Uppsala Reggae Festival attracts attendees from across Northern Europe, and features Swedish reggae bands such as Rootvälta and Svenska Akademien as well as many popular Jamaican artists. Summerjam, Europe's biggest reggae festival, takes place in Cologne, Germany and sees crowds of 25,000 or more. Rototom Sunsplash, a week-long festival which used to take place in Osoppo, Italy, until 2009, is now held in Benicassim, Spain and gathers up to 150,000 visitors every year.\n\nIn Iceland reggae band Hjálmar is well established having released six CDs in Iceland. They were the first reggae band in Iceland, but few Icelandic artists had written songs in the reggae style before their showing up at the Icelandic music scene. The Icelandic reggae scene is expanding and growing at a fast rate. RVK Soundsystem is the first Icelandic sound system, counting 5 DJ's. They hold reggae nights in Reykjavík every month at clubs Hemmi og Valdi and more recently in Faktorý as the crowd has grown so much.\n\nIn Germany, the three successful Reggae JSnrfti mer Jam open-air fastivals were crucial parts of the renaissance of Caribbean music in Germany but at that year (1990) war broke out between the two main German promoters who had cooperated so well during the previous seasons. With a lot of infighting and personal quarrels, each of them pursued his own preparations for a big summer festival. The result was that two open-air events look place on the same day.\n\nThe Reggae Sammer Jam '90 was staged as usual, but this year for only one day. The event took place at the Lorelei Rock amphit heater with artists like Mad Professor's Ariwa Posse with Macka B and Kofi, Mutabaruka, the Mighty Diamonds, the Twinkle Brothers, Manu Dibango and Fela Kuti.\n\nThe other, ex-partner of the onceunited promoters succeeded in bringing the original Sunsplash package to Germany for the first time. Close to the Main River in the little village of Gemaunden deep down in rural southcentral Germany, they staged a two-day festival that drew the bigger crowd. About 10,000 people came from all over the country as well as from neighboring states like trance and, for the first time, East Germany to see the lineup of top reggae artists.\n\nReggae in Africa was much boosted by the visit of Bob Marley to Zimbabwe on Independence Day 18 April 1980. Nigerian reggae had developed in the 1970s with artists such as Majek Fashek proving popular. In South Africa, reggae music has played a unifying role amongst cultural groups in Cape Town. During the years of Apartheid, the music bonded people from all demographic groups. Lucky Dube recorded 25 albums, fusing reggae with Mbaqanga. The Marcus Garvey Rasta camp in Phillipi is regarded by many to be the reggae and Rastafari center of Cape Town. Reggae bands play regularly at community centres such as the Zolani center in Nyanga.\n\nIn Uganda musician Papa Cidy is very popular. In Ethiopia, Dub Colossus and Invisible System emerged in 2008 sharing core members, and have received wide acclaim. In Mali, Askia Modibo fuses reggae with Malian music. In Malawi, Black Missionaries produced nine albums. In Ivory Coast a country where reggae music is extremely popular, Tiken Jah Fakoly fuses reggae with traditional music. Alpha Blondy from Ivory Coast sings reggae with religious lyrics. In Sudan, beats, drums and bass guitar from reggae music has been adopted into their music as reggae is a very popular among the generations from young to old, some spiritual (religious) groups grow their dreadlocks and have some reggae beats in their chants.\n\nIn the Philippines, several bands and sound systems play reggae and dancehall music. Their music is called Pinoy reggae. Japanese reggae emerged in the early 1980s. Reggae is becoming more prevalent in Thailand as well. Reggae music is quite popular in Sri Lanka. Aside from the reggae music and Rastafari influences seen ever more on Thailand's islands and beaches, a true reggae sub-culture is taking root in Thailand's cities and towns. Many Thai artists, such as Job 2 Do, keep the tradition of reggae music and ideals alive in Thailand. By the end of the 1980s, the local music scene in Hawaii was dominated by Jawaiian music, a local form of reggae.\n\nFamous Indian singer Kailash Kher and music producer Clinton Cerejo created \"Kalapi\", a rare fusion piece of Reggae and Indian music for Coke Studio India. Other than this high-profile piece, Reggae is confined to a small, emerging scene in India. Thaikkudam Bridge, a neo-Indian band based in Kerala, India is known for inducing Reggae into Indian regional blues.\n\nReggae in Australia originated in the 1980s. Desert Reggae is a developing contemporary style possibly originating in Central Australia. Lyrics are often sung in Australian Aboriginal languages. However, possibly the best known Australian reggae groups are Sticky Fingers (band), Blue King Brown and Astronomy Class, who both use English language lyrics.\n\nNew Zealand reggae was heavily inspired by Bob Marley's 1979 tour of the country, and early reggae groups such as Herbs. The genre has seen many bands like Fat Freddy's Drop, Salmonella Dub, The Black Seeds and Katchafire emerging in more recent times, often involving fusion with electronica.\n\n\n\n\n"}
{"id": "25521", "url": "https://en.wikipedia.org/wiki?curid=25521", "title": "Relay league", "text": "Relay league\n\nA relay league is a chain of message forwarding stations in a system of optical telegraphs, radio telegraph stations, or riding couriers.\n\nAn interesting description of these early 19th century methods and its evolution into the electrical telegraph networks of the mid-to-late 19th century is found in \"The Victorian Internet\", a book by Tom Standage .\n\nRadio amateurs have been early in arranging relay leagues, as is reflected in the name of the organization of American Radio Relay League (ARRL), http://www.arrl.org/.\n\nRadio amateur message relay operations were originally conducted using Morse code in the first two decades of the 20th century using spark-gap transmitters. As vacuum tubes became affordable operations shifted to more efficient manual telegraphy transmitters, referred to as CW (Continuous wave). Messages were relayed station to station typically covering four or more re-transmission cycles to cover the continental United States, in an organized system of amateur radio networks. After World War II, voice and radioteletype implementations of the message relay system were employed.\n\n"}
{"id": "25522", "url": "https://en.wikipedia.org/wiki?curid=25522", "title": "History of radio", "text": "History of radio\n\nThe early history of radio is the history of technology that produce and use radio instruments that use radio waves. Within the timeline of radio, many people contributed theory and inventions in what became radio. Radio development began as \"wireless telegraphy\". Later radio history increasingly involves matters of broadcasting.\n\nThe idea of wireless communication predates the discovery of \"radio\" with experiments in \"wireless telegraphy\" via inductive and capacitive induction and transmission through the ground, water, and even train tracks from the 1830s on. James Clerk Maxwell showed in theoretical and mathematical form in 1864 that electromagnetic waves could propagate through free space. It is likely that the first intentional transmission of a signal by means of electromagnetic waves was performed in an experiment by David Edward Hughes around 1880, although this was considered to be induction at the time. In 1888 Heinrich Rudolf Hertz was able to conclusively prove transmitted airborne electromagnetic waves in an experiment confirming Maxwell's theory of electromagnetism.\n\nAfter the discovery of these \"Hertzian waves\" (it would take almost 20 years for the term \"radio\" to be universally adopted for this type of electromagnetic radiation) many scientists and inventors experimented with wireless transmission, some trying to develop a system of communication, some intentionally using these new Hertzian waves, some not. Maxwell's theory showing that light and Hertzian electromagnetic waves were the same phenomenon at different wavelengths led \"Maxwellian\" scientist such as John Perry, Frederick Thomas Trouton and Alexander Trotter to assume they would be analogous to optical signaling and the Serbian American engineer Nikola Tesla to consider them relatively useless for communication since \"light\" could not transmit further than line of sight. In 1892 the physicist William Crookes wrote on the possibilities of wireless telegraphy based on Hertzian waves and in 1893 Tesla proposed a system for transmitting intelligence and wireless power using the earth as the medium. Others, such as Amos Dolbear, Sir Oliver Lodge, Reginald Fessenden, and Alexander Popov were involved in the development of components and theory involved with the transmission and reception of airborne electromagnetic waves for their own theoretical work or as a potential means of communication.\n\nOver several years starting in 1894 the Italian inventor Guglielmo Marconi built the first complete, commercially successful wireless telegraphy system based on airborne Hertzian waves (radio transmission). Marconi demonstrated application of radio in military and marine communications and started a company for the development and propagation of radio communication services and equipment.\n\nThe meaning and usage of the word \"radio\" has developed in parallel with developments within the field of communications and can be seen to have three distinct phases: electromagnetic waves and experimentation; wireless communication and technical development; and radio broadcasting and commercialization. In an 1864 presentation, published in 1865, James Clerk Maxwell proposed his theories and mathematical proofs on electromagnetism that showed that light and other phenomena were all types of electromagnetic waves propagating through free space. In 1886–88 Heinrich Rudolf Hertz conducted a series of experiments that proved the existence of Maxwell's electromagnetic waves, using a frequency in what would later be called the \"radio\" spectrum. Many individuals—inventors, engineers, developers and businessmen—constructed systems based on their own understanding of these and other phenomena, some predating Maxwell and Hertz's discoveries. Thus \"wireless telegraphy\" and radio wave-based systems can be attributed to multiple \"inventors\". Development from a laboratory demonstration to a commercial entity spanned several decades and required the efforts of many practitioners.\n\nIn 1878, David E. Hughes noticed that sparks could be heard in a telephone receiver when experimenting with his carbon microphone. He developed this carbon-based detector further and eventually could detect signals over a few hundred yards. He demonstrated his discovery to the Royal Society in 1880, but was told it was merely induction, and therefore abandoned further research. Thomas Edison came across the electromagnetic phenomenon while experimenting with a telegraph at Menlo Park. He noted an unexplained transmission effect while experimenting with a telegraph. He referred to this as etheric force in an announcement on November 28, 1875. Elihu Thomson published his findings on Edison's new \"force\", again attributing it to induction, an explanation that Edison accepted. Edison would go on the next year to take out on a system of electrical wireless communication between ships based on electrostatic coupling using the water and elevated terminals. Although this was not a radio system the Marconi Company would purchase the rights in 1903 to protect them legally from lawsuits.\n\nBetween 1886 and 1888 Heinrich Rudolf Hertz published the results of his experiments where he was able to transmit electromagnetic waves (radio waves) through the air, proving Maxwell's electromagnetic theory. Early on after their discovery, radio waves were referred to as \"Hertzian waves\". Between 1890 and 1892 physicists such as John Perry, Frederick Thomas Trouton and William Crookes proposed electromagnetic or Hertzian waves as a navigation aid or means of communication, with Crookes writing on the possibilities of wireless telegraphy based on Hertzian waves in 1892.\n\nAfter learning of Hertz demonstrations of wireless transmission, inventor Nikola Tesla began developing his own system based on Hertz and Maxwell's ideas, primarily as a means of wireless lighting and power distribution. Tesla, concluding that Hertz had not demonstrated airborne electromagnetic waves (radio transmission), went on to develop a system based on what he thought was the primary conductor, the earth. In 1893 demonstrations of his ideas, in St. Louis, Missouri and at the \"Franklin Institute\" in Philadelphia, Tesla proposed this wireless power technology could also incorporate a system for the telecommunication of information.\n\nIn a lecture on the work of Hertz, shortly after his death, Professor Oliver Lodge and Alexander Muirhead demonstrated wireless signaling using Hertzian (radio) waves in the lecture theater of the Oxford University Museum of Natural History on August 14, 1894. During the demonstration a radio signal was sent from the neighboring Clarendon Laboratory building, and received by apparatus in the lecture theater.\n\nBuilding on the work of Lodge, the Indian Bengali physicist Jagadish Chandra Bose ignited gunpowder and rang a bell at a distance using millimeter range wavelength microwaves in a November 1894 public demonstration at the Town Hall of Kolkata. Bose wrote in a Bengali essay, Adrisya Alok (Invisible Light), \"The invisible light can easily pass through brick walls, buildings etc. Therefore, messages can be transmitted by means of it without the mediation of wires.\" Bose’s first scientific paper, \"On polarisation of electric rays by double-refracting crystals\" was communicated to the Asiatic Society of Bengal in May 1895. His second paper was communicated to the Royal Society of London by Lord Rayleigh in October 1895. In December 1895, the London journal The Electrician (Vol. 36) published Bose’s paper, \"On a new electro-polariscope\". At that time, the word 'coherer', coined by Lodge, was used in the English-speaking world for Hertzian wave receivers or detectors. The Electrician readily commented on Bose’s coherer. (December 1895). The Englishman (18 January 1896) quoted from the Electrician and commented as follows: \"Should Professor Bose succeed in perfecting and patenting his ‘Coherer’, we may in time see the whole system of coast lighting throughout the navigable world revolutionised by an Indian Bengali scientist working single handed in our Presidency College Laboratory.\" Bose planned to \"perfect his coherer\", but never thought of patenting it.\n\nIn 1895, conducting experiments along the lines of Hertz's research, Alexander Stepanovich Popov built his first radio receiver, which contained a coherer. Further refined as a lightning detector, it was presented to the Russian Physical and Chemical Society on May 7, 1895. A depiction of Popov's lightning detector was printed in the Journal of the Russian Physical and Chemical Society the same year (publication of the minutes 15/201 of this session — December issue of the journal RPCS). An earlier description of the device was given by Dmitry Aleksandrovich Lachinov in July 1895 in the 2nd edition of his course \"Fundamentals of Meteorology and climatology\" — the first in Russia. Popov's receiver was created on the improved basis of Lodge's receiver, and originally intended for reproduction of its experiments.\n\nIn 1894 the young Italian inventor Guglielmo Marconi began working on the idea of building a commercial wireless telegraphy system based on the use of Hertzian waves (radio waves), a line of inquiry that he noted other inventors did not seem to be pursuing. Marconi read through the literature and used the ideas of others who were experimenting with radio waves but did a great deal to develop devices such as portable transmitters and receiver systems that could work over long distances, turning what was essentially a laboratory experiment into a useful communication system. By August 1895 Marconi was field testing his system but even with improvements he was only able to transmit signals up to one-half mile, a distance Oliver Lodge had predicted in 1894 as the maximum transmission distance for radio waves. Marconi raised the height of his antenna and hit upon the idea of grounding his transmitter and receiver. With these improvements the system was capable of transmitting signals up to and over hills. Marconi's experimental apparatus proved to be the first engineering-complete, commercially successful radio transmission system. Marconi’s apparatus is also credited with saving the 700 people who survived the tragic \"Titanic\" disaster.\n\nIn 1896, Marconi was awarded British patent 12039, \"Improvements in transmitting electrical impulses and signals and in apparatus there-for\", the first patent ever issued for a Hertzian wave (radio wave) base wireless telegraphic system. In 1897, he established a radio station on the Isle of Wight, England. Marconi opened his \"wireless\" factory in the former silk-works at Hall Street, Chelmsford, England in 1898, employing around 60 people. Shortly after the 1900s, Marconi held the patent rights for radio. Marconi would go on to win the Nobel Prize in Physics in 1909 and be more successful than any other inventor in his ability to \"commercialize\" radio and its associated equipment into a global business. In the US some of his subsequent patented refinements (but not his original radio patent) would be overturned in a 1935 court case (upheld by the US Supreme Court in 1943).\n\nIn 1900, Brazilian priest Roberto Landell de Moura transmitted the human voice wirelessly. According to the newspaper \"Jornal do Comercio\" (June 10, 1900), he conducted his first public experiment on June 3, 1900, in front of journalists and the General Consul of Great Britain, C.P. Lupton, in São Paulo, Brazil, for a distance of approximately . The points of transmission and reception were Alto de Santana and Paulista Avenue.\n\nOne year after that experiment, he received his first patent from the Brazilian government. It was described as \"equipment for the purpose of phonetic transmissions through space, land and water elements at a distance with or without the use of wires.\" Four months later, knowing that his invention had real value, he left Brazil for the United States with the intent of patenting the machine at the US Patent Office in Washington, DC.\n\nHaving few resources, he had to rely on friends to push his project. Despite great difficulty, three patents were awarded: \"The Wave Transmitter\" (October 11, 1904), which is the precursor of today's radio transceiver; \"The Wireless Telephone\" and the \"Wireless Telegraph\", both dated November 22, 1904.\nThe next advancement was the vacuum tube detector, invented by Westinghouse engineers. On Christmas Eve 1906, Reginald Fessenden used a synchronous rotary-spark transmitter for the first radio program broadcast, from Ocean Bluff-Brant Rock, Massachusetts. Ships at sea heard a broadcast that included Fessenden playing \"O Holy Night\" on the violin and reading a passage from the Bible. This was, for all intents and purposes, the first transmission of what is now known as amplitude modulation or AM radio.\n\nIn June 1912 Marconi opened the world's first purpose-built radio factory at New Street Works in Chelmsford, England.\n\nThe first radio news program was broadcast August 31, 1920 by station 8MK in Detroit, Michigan, which survives today as all-news format station WWJ under ownership of the CBS network. The first college radio station began broadcasting on October 14, 1920 from Union College, Schenectady, New York under the personal call letters of Wendell King, an African-American student at the school.\n\nThat month 2ADD (renamed WRUC in 1947), aired what is believed to be the first public entertainment broadcast in the United States, a series of Thursday night concerts initially heard within a radius and later for a radius. In November 1920, it aired the first broadcast of a sporting event. At 9 pm on August 27, 1920, Sociedad Radio Argentina aired a live performance of Richard Wagner's opera \"Parsifal\" from the Coliseo Theater in downtown Buenos Aires. Only about twenty homes in the city had receivers to tune in this radio program. Meanwhile, regular entertainment broadcasts commenced in 1922 from the Marconi Research Centre at Writtle, England.\n\nSports broadcasting began at this time as well, including the college football on radio broadcast of a 1921 West Virginia vs. Pittsburgh football game.\nOne of the first developments in the early 20th century was that aircraft used commercial AM radio stations for navigation. This continued until the early 1960s when VOR systems became widespread. In the early 1930s, single sideband and frequency modulation were invented by amateur radio operators. By the end of the decade, they were established commercial modes. Radio was used to transmit pictures visible as television as early as the 1920s. Commercial television transmissions started in North America and Europe in the 1940s.\n\nIn 1947 AT&T commercialized the Mobile Telephone Service. From its start in St. Louis in 1946, AT&T then introduced Mobile Telephone Service to one hundred towns and highway corridors by 1948. Mobile Telephone Service was a rarity with only 5,000 customers placing about each week. Because only three radio channels were available, only three customers in any given city could make mobile telephone calls at one time. Mobile Telephone Service was expensive, costing per month, plus 0.30 to 0.40 USD per local call, equivalent to about per month and 3.50 to 4.75 per call in 2012 USD. The Advanced Mobile Phone System analog mobile cell phone system, developed by Bell Labs, was introduced in the Americas in 1978, gave much more capacity. It was the primary analog mobile phone system in North America (and other locales) through the 1980s and into the 2000s.\nIn 1954, the Regency company introduced a pocket transistor radio, the TR-1, powered by a \"standard 22.5 V Battery.\" In 1955, the newly formed Sony company introduced its first transistorized radio. It was small enough to fit in a vest pocket, powered by a small battery. It was durable, because it had no vacuum tubes to burn out. Over the next 20 years, transistors replaced tubes almost completely except for high-power transmitters.\n\nBy 1963, color television was being broadcast commercially (though not all broadcasts or programs were in color), and the first (radio) communication satellite, \"Telstar\", was launched. In the late 1960s, the U.S. long-distance telephone network began to convert to a digital network, employing digital radios for many of its links. In the 1970s, LORAN became the premier radio navigation system.\n\nSoon, the U.S. Navy experimented with satellite navigation, culminating in the launch of the Global Positioning System (GPS) constellation in 1987. In the early 1990s, amateur radio experimenters began to use personal computers with audio cards to process radio signals. In 1994, the U.S. Army and DARPA launched an aggressive, successful project to construct a software-defined radio that can be programmed to be virtually any radio by changing its software program. Digital transmissions began to be applied to broadcasting in the late 1990s.\n\nAround the start of the 20th century, the Slaby-Arco wireless system was developed by Adolf Slaby and Georg von Arco. In 1900, Reginald Fessenden made a weak transmission of voice over the airwaves. In 1901, Marconi conducted the first successful transatlantic experimental radio communications. In 1904, The U.S. Patent Office reversed its decision, awarding Marconi a patent for the invention of radio, possibly influenced by Marconi's financial backers in the States, who included Thomas Edison and Andrew Carnegie. This also allowed the U.S. government (among others) to avoid having to pay the royalties that were being claimed by Tesla for use of his patents. For more information see Marconi's radio work. In 1907, Marconi established the first commercial transatlantic radio communications service, between Clifden, Ireland and Glace Bay, Newfoundland.\n\nJulio Cervera Baviera developed radio in Spain around 1902. Cervera Baviera obtained patents in England, Germany, Belgium, and Spain. In May–June 1899, Cervera had, with the blessing of the Spanish Army, visited Marconi's radiotelegraphic installations on the English Channel, and worked to develop his own system. He began collaborating with Marconi on resolving the problem of a wireless communication system, obtaining some patents by the end of 1899. Cervera, who had worked with Marconi and his assistant George Kemp in 1899, resolved the difficulties of wireless telegraph and obtained his first patents prior to the end of that year. On March 22, 1902, Cervera founded the Spanish Wireless Telegraph and Telephone Corporation and brought to his corporation the patents he had obtained in Spain, Belgium, Germany and England. He established the second and third regular radiotelegraph service in the history of the world in 1901 and 1902 by maintaining regular transmissions between Tarifa and Ceuta (across the Straits of Gibraltar) for three consecutive months, and between Javea (Cabo de la Nao) and Ibiza (Cabo Pelado). This is after Marconi established the radiotelegraphic service between the Isle of Wight and Bournemouth in 1898. In 1906, Domenico Mazzotto wrote: \"In Spain the Minister of War has applied the system perfected by the commander of military engineering, Julio Cervera Baviera (English patent No. 20084 (1899)).\" Cervera thus achieved some success in this field, but his radiotelegraphic activities ceased suddenly, the reasons for which are unclear to this day.\n\nUsing various patents, the British Marconi company was established in 1897 and began communication between coast radio stations and ships at sea. This company, along with its subsidiaries Canadian Marconi and American Marconi, had a stranglehold on ship-to-shore communication. It operated much the way American Telephone and Telegraph operated until 1983, owning all of its equipment and refusing to communicate with non-Marconi equipped ships. In June 1912, after the RMS \"Titanic\" disaster, due to increased production Marconi opened the world's first purpose-built radio factory at New Street Works in Chelmsford, and in 1932 the Marconi Research Laboratory. Many inventions improved the quality of radio, and amateurs experimented with uses of radio, thus planting the first seeds of broadcasting.\n\nThe company Telefunken was founded on May 27, 1903, as \"Telefunken society for wireless telefon\" of Siemens & Halske (S & H) and the Allgemeine Elektrizitäts-Gesellschaft (\"General Electricity Company\") as joint undertakings for radio engineering in Berlin. It continued as a joint venture of AEG and Siemens AG, until Siemens left in 1941. In 1911, Kaiser Wilhelm II sent Telefunken engineers to West Sayville, New York to erect three 600-foot (180-m) radio towers there. Nikola Tesla assisted in the construction. A similar station was erected in Nauen, creating the only wireless communication between North America and Europe.\n\nThe invention of amplitude-modulated (AM) radio, so that more than one station can send signals (as opposed to spark-gap radio, where one transmitter covers the entire bandwidth of the spectrum) is attributed to Reginald Fessenden and Lee de Forest. On Christmas Eve 1906, Reginald Fessenden used an Alexanderson alternator and rotary spark-gap transmitter to make the first radio audio broadcast, from Brant Rock, Massachusetts. Ships at sea heard a broadcast that included Fessenden playing \"O Holy Night\" on the violin and reading a passage from the Bible.\n\nIn 1909, Marconi and Karl Ferdinand Braun were awarded the Nobel Prize in Physics for \"contributions to the development of wireless telegraphy\".\n\nIn April 1909 Charles David Herrold, an electronics instructor in San Jose, California constructed a broadcasting station. It used spark gap technology, but modulated the carrier frequency with the human voice, and later music. The station \"San Jose Calling\" (there were no call letters), continued to eventually become today's KCBS in San Francisco. Herrold, the son of a Santa Clara Valley farmer, coined the terms \"narrowcasting\" and \"broadcasting\", respectively to identify transmissions destined for a single receiver such as that on board a ship, and those transmissions destined for a general audience. (The term \"broadcasting\" had been used in farming to define the tossing of seed in all directions.) Charles Herrold did not claim to be the first to transmit the human voice, but he claimed to be the first to conduct \"broadcasting\". To help the radio signal to spread in all directions, he designed some omnidirectional antennas, which he mounted on the rooftops of various buildings in San Jose. Herrold also claims to be the first broadcaster to accept advertising (he exchanged publicity for a local record store for records to play on his station), though this dubious honour usually is foisted on WEAF (1922).\n\nIn 1912, the RMS \"Titanic\" sank in the northern Atlantic Ocean. After this, wireless telegraphy using spark-gap transmitters quickly became universal on large ships. In 1913, the International Convention for the Safety of Life at Sea was convened and produced a treaty requiring shipboard radio stations to be manned 24 hours a day. A typical high-power spark gap was a rotating commutator with six to twelve contacts per wheel, nine inches (229 mm) to a foot wide, driven by about 2,000 volts DC. As the gaps made and broke contact, the radio wave was audible as a tone in a magnetic detector at a remote location. The telegraph key often directly made and broke the 2,000 volt supply. One side of the spark gap was directly connected to the antenna. Receivers with thermionic valves became commonplace before spark-gap transmitters were replaced by continuous wave transmitters.\n\nOn March 8, 1916, Harold Power with his radio company American Radio and Research Company (AMRAD), broadcast the first continuous broadcast in the world from Tufts University under the call sign 1XE (it lasted 3 hours). The company later became the first to broadcast on a daily schedule, and the first to broadcast radio dance programs, university professor lectures, the weather, and bedtime stories.\n\nInventor Edwin Howard Armstrong is credited with developing many of the features of radio as it is known today. Armstrong patented three important inventions that made today's radio possible. Regeneration, the superheterodyne circuit and wide-band frequency modulation or FM. Regeneration or the use of positive feedback greatly increased the amplitude of received radio signals to the point where they could be heard without headphones. The superhet simplified radio receivers by doing away with the need for several tuning controls. It made radios more sensitive and selective as well. FM gave listeners a static-free experience with better sound quality and fidelity than AM.\n\nThe most common type of receiver before vacuum tubes was the crystal set, although some early radios used some type of amplification through electric current or battery. Inventions of the triode amplifier, motor-generator, and detector enabled audio radio. The use of amplitude modulation (AM), with which more than one station can simultaneously send signals (as opposed to spark-gap radio, where one transmitter covers the entire bandwidth of spectra) was pioneered by Fessenden and Lee de Forest.\n\nThe art and science of crystal sets is still pursued as a hobby in the form of simple un-amplified radios that 'runs on nothing, forever'. They are used as a teaching tool by groups such as the Boy Scouts of America to introduce youngsters to electronics and radio. As the only energy available is that gathered by the antenna system, loudness is necessarily limited.\n\nDuring the mid-1920s, amplifying vacuum tubes (or \"thermionic valves\" in the UK) revolutionized radio receivers and transmitters. John Ambrose Fleming developed a vacuum tube diode. Lee de Forest placed a screen, added a \"grid\" electrode, creating the triode. The Dutch company \"Nederlandsche Radio-Industrie\" and its owner engineer, Hanso Idzerda, made the first regular wireless broadcast for entertainment from its workshop in The Hague on 6 November 1919. The company manufactured both transmitters and receivers. Its popular program was broadcast four nights per week on AM 670 metres, until 1924 when the company ran into financial troubles.\n\nOn 27 August 1920, regular wireless broadcasts for entertainment began in Argentina, pioneered by the group around Enrique Telémaco Susini, and spark gap telegraphy stopped. On 31 August 1920 the first known radio news program was broadcast by station 8MK, the unlicensed predecessor of WWJ (AM) in Detroit, Michigan. In 1922 regular wireless broadcasts for entertainment began in the UK from the Marconi Research Centre 2MT at Writtle near Chelmsford, England. Early radios ran the entire power of the transmitter through a carbon microphone. In the 1920s, the Westinghouse company bought Lee de Forest's and Edwin Armstrong's patent. During the mid-1920s, Amplifying vacuum tubes (US)/thermionic valves (UK) revolutionized radio receivers and transmitters. Westinghouse engineers developed a more modern vacuum tube.\n\nThe British government and the state-owned postal services found themselves under massive pressure from the wireless industry (including telegraphy) and early radio adopters to open up to the new medium. In an internal confidential report from February 25, 1924, the \"Imperial Wireless Telegraphy Committee\" stated:\n\nThe question of the 'first' publicly targeted licensed radio station in the U.S. has more than one answer and depends on semantics. Settlement of this 'first' question may hang largely upon what constitutes 'regular' programming.\n\"There is the history noted above of Charles David Herrold's radio services as early as 1909 with call signs FN, SJN, 6XF, and 6XE until 1921 when it became WKQW and then finally KCBS in 1949.\n\nOutside the United States there are also claims for the first radio stations:\n\nBroadcasting was not yet supported by advertising or listener sponsorship. The stations owned by manufacturers and department stores were established to sell radios and those owned by newspapers to sell newspapers and express the opinions of the owners. In the 1920s, radio was first used to transmit pictures visible as television. During the early 1930s, single sideband (SSB) and frequency modulation (FM) were invented by amateur radio operators. By 1940, they were established commercial modes.\n\nWestinghouse was brought into the patent allies group, General Electric, American Telephone and Telegraph, and Radio Corporation of America, and became a part owner of RCA. All radios made by GE and Westinghouse were sold under the RCA label 60% GE and 40% Westinghouse. ATT's Western Electric would build radio transmitters. The patent allies attempted to set up a monopoly, but they failed due to successful competition. Much to the dismay of the patent allies, several of the contracts for inventor's patents held clauses protecting \"amateurs\" and allowing them to use the patents. Whether the competing manufacturers were really amateurs was ignored by these competitors.\n\nThese features arose:\n\nIn 1933, FM radio was patented by inventor Edwin H. Armstrong. FM uses frequency modulation of the radio wave to reduce static and interference from electrical equipment and the atmosphere. In 1937, W1XOJ, the first experimental FM radio station, was granted a construction permit by the US Federal Communications Commission (FCC). In the 1930s, regular analog television broadcasting began in some parts of Europe and North America. By the end of the decade there were roughly 25,000 all-electronic television receivers in existence worldwide, the majority of them in the UK. In the US, Armstrong's FM system was designated by the FCC to transmit and receive television sound.\n\nAfter World War II, FM radio broadcasting was introduced in Germany. At a meeting in Copenhagen in 1948, a new wavelength plan was set up for Europe. Because of the recent war, Germany (which did not exist as a state and so was not invited) was only given a small number of medium-wave frequencies, which were not very good for broadcasting. For this reason Germany began broadcasting on UKW (\"Ultrakurzwelle\", i.e. ultra short wave, nowadays called VHF) which was not covered by the Copenhagen plan. After some amplitude modulation experience with VHF, it was realized that FM radio was a much better alternative for VHF radio than AM. Because of this history FM Radio is still referred to as \"UKW Radio\" in Germany. Other European nations followed a bit later, when the superior sound quality of FM and the ability to run many more local stations because of the more limited range of VHF broadcasts were realized.\n\nIn 1954 Regency introduced a pocket transistor radio, the TR-1, powered by a \"standard 22.5V Battery\". In the early 1960s, VOR systems finally became widespread for aircraft navigation; before that, aircraft used commercial AM radio stations for navigation. (AM stations are still marked on U.S. aviation charts). In 1960 Sony introduced their first transistorized radio, small enough to fit in a vest pocket, and able to be powered by a small battery. It was durable, because there were no tubes to burn out. Over the next twenty years, transistors displaced tubes almost completely except for picture tubes and very high power or very high frequency uses.\n\n\nTelegraphy did not go away on radio. Instead, the degree of automation increased. On land-lines in the 1930s, teletypewriters automated encoding, and were adapted to pulse-code dialing to automate routing, a service called telex. For thirty years, telex was the absolute cheapest form of long-distance communication, because up to 25 telex channels could occupy the same bandwidth as one voice channel. For business and government, it was an advantage that telex directly produced written documents.\n\nTelex systems were adapted to short-wave radio by sending tones over single sideband. CCITT R.44 (the most advanced pure-telex standard) incorporated character-level error detection and retransmission as well as automated encoding and routing. For many years, telex-on-radio (TOR) was the only reliable way to reach some third-world countries. TOR remains reliable, though less-expensive forms of e-mail are displacing it. Many national telecom companies historically ran nearly pure telex networks for their governments, and they ran many of these links over short wave radio.\n\nDocuments including maps and photographs went by radiofax, or wireless photoradiogram, invented in 1924 by Richard H. Ranger of Radio Corporation of America (RCA). This method prospered in the mid-20th century and faded late in the century.\n\nIn 1947 AT&T commercialized the Mobile Telephone Service. From its start in St. Louis in 1946, AT&T then introduced Mobile Telephone Service to one hundred towns and highway corridors by 1948. Mobile Telephone Service was a rarity with only 5,000 customers placing about each week. Because only three radio channels were available, only three customers in any given city could make mobile telephone calls at one time. Mobile Telephone Service was expensive, costing per month, plus 0.30 to 0.40 USD per local call, equivalent to about per month and 3.50 to 4.75 per call in 2012 USD. The Advanced Mobile Phone System analog mobile cell phone system, developed by Bell Labs, was introduced in the Americas in 1978, gave much more capacity. It was the primary analog mobile phone system in North America (and other locales) through the 1980s and into the 2000s.\n\nWhen radio was introduced in the 1920s many predicted the end of records. Radio was a free medium for the public to hear music for which they would normally pay. While some companies saw radio as a new avenue for promotion, others feared it would cut into profits from record sales and live performances. Many companies had their major stars sign agreements that they would not appear on radio.\n\nIndeed, the music recording industry had a severe drop in profits after the introduction of the radio. For a while, it appeared as though radio was a definite threat to the record industry. Radio ownership grew from two out of five homes in 1931 to four out of five homes in 1938. Meanwhile, record sales fell from $75 million in 1929 to $26 million in 1938 (with a low point of $5 million in 1933), though the economics of the situation were also affected by the Great Depression.\n\nThe copyright owners were concerned that they would see no gain from the popularity of radio and the ‘free’ music it provided. Luckily, what they needed to make this new medium work for them already existed in previous copyright law. The copyright holder for a song had control over all public performances ‘for profit.’ The problem now was proving that the radio industry, which was just figuring out for itself how to make money from advertising and currently offered free music to anyone with a receiver, was making a profit from the songs.\n\nThe test case was against Bamberger's Department Store in Newark, New Jersey in 1922. The store was broadcasting music throughout its store on the radio station WOR. No advertisements were heard, except at the beginning of the broadcast which announced \"L. Bamberger and Co., One of America's Great Stores, Newark, New Jersey.\" It was determined through this and previous cases (such as the lawsuit against Shanley's Restaurant) that Bamberger was using the songs for commercial gain, thus making it a public performance for profit, which meant the copyright owners were due payment.\n\nWith this ruling the American Society of Composers, Authors and Publishers (ASCAP) began collecting licensing fees from radio stations in 1923. The beginning sum was $250 for all music protected under ASCAP, but for larger stations the price soon ballooned to $5,000. Edward Samuels reports in his book \"The Illustrated Story of Copyright\" that \"radio and TV licensing represents the single greatest source of revenue for ASCAP and its composers […] and [a]n average member of ASCAP gets about $150–$200 per work per year, or about $5,000-$6,000 for all of a member's compositions.\" Not long after the Bamberger ruling, ASCAP had to once again defend their right to charge fees, in 1924. The Dill Radio Bill would have allowed radio stations to play music without paying and licensing fees to ASCAP or any other music-licensing corporations. The bill did not pass.\n\n\n\n\nMany contributed to wireless. Individuals that helped to further the science include, among others:\n\n\n\n\n"}
{"id": "25523", "url": "https://en.wikipedia.org/wiki?curid=25523", "title": "Richard Feynman", "text": "Richard Feynman\n\nRichard Phillips Feynman (; May 11, 1918 – February 15, 1988) was an American theoretical physicist known for his work in the path integral formulation of quantum mechanics, the theory of quantum electrodynamics, and the physics of the superfluidity of supercooled liquid helium, as well as in particle physics for which he proposed the parton model. For his contributions to the development of quantum electrodynamics, Feynman, jointly with Julian Schwinger and Shin'ichirō Tomonaga, received the Nobel Prize in Physics in 1965.\n\nFeynman developed a widely used pictorial representation scheme for the mathematical expressions governing the behavior of subatomic particles, which later became known as Feynman diagrams. During his lifetime, Feynman became one of the best-known scientists in the world. In a 1999 poll of 130 leading physicists worldwide by the British journal \"Physics World\" he was ranked as one of the ten greatest physicists of all time.\n\nHe assisted in the development of the atomic bomb during World War II and became known to a wide public in the 1980s as a member of the Rogers Commission, the panel that investigated the Space Shuttle Challenger disaster. Along with his work in theoretical physics, Feynman has been credited with pioneering the field of quantum computing and introducing the concept of nanotechnology. He held the Richard C. Tolman professorship in theoretical physics at the California Institute of Technology.\n\nFeynman was a keen popularizer of physics through both books and lectures, including a 1959 talk on top-down nanotechnology called \"There's Plenty of Room at the Bottom\", and the three-volume publication of his undergraduate lectures, \"The Feynman Lectures on Physics\". Feynman also became known through his semi-autobiographical books \"Surely You're Joking, Mr. Feynman!\" and \"What Do You Care What Other People Think?\" and books written about him, such as \"Tuva or Bust!\" and \"Genius: The Life and Science of Richard Feynman\" by James Gleick.\n\nRichard Phillips Feynman was born on May 11, 1918, in Queens, New York City, to Lucille , a homemaker, and Melville Arthur Feynman, a sales manager, originally from Minsk in Belarus, in those days part of the Russian Empire; both were Lithuanian Jews. They were not religious, and by his youth, Feynman described himself as an \"avowed atheist\". Many years later, in a letter to Tina Levitan, declining a request for information for her book on Jewish Nobel Prize winners, he stated, \"To select, for approbation the peculiar elements that come from some supposedly Jewish heredity is to open the door to all kinds of nonsense on racial theory\", adding, \"at thirteen I was not only converted to other religious views, but I also stopped believing that the Jewish people are in any way 'the chosen people'. (He was not included in the book.)\" Later in his life, during a visit to the Jewish Theological Seminary, he encountered the Talmud for the first time and remarked that it contained a medieval kind of reasoning and was a wonderful book.\n\nLike Albert Einstein and Edward Teller, Feynman was a late talker, and by his third birthday had yet to utter a single word. He retained a Brooklyn accent as an adult. That accent was thick enough to be perceived as an affectation or exaggeration – so much so that his good friends Wolfgang Pauli and Hans Bethe once commented that Feynman spoke like a \"bum\". The young Feynman was heavily influenced by his father, who encouraged him to ask questions to challenge orthodox thinking, and who was always ready to teach Feynman something new. From his mother, he gained the sense of humor that he had throughout his life. As a child, he had a talent for engineering, maintained an experimental laboratory in his home, and delighted in repairing radios. When he was in grade school, he created a home burglar alarm system while his parents were out for the day running errands.\n\nWhen Richard was five years old, his mother gave birth to a younger brother, Henry Philips, who died at four weeks of age on February 25, 1924. Four years later, Richard's sister Joan was born, and the family moved to Far Rockaway, Queens. Though separated by nine years, Joan and Richard were close, as they both shared a natural curiosity about the world. Their mother thought that women did not have the cranial capacity to comprehend such things. Despite their mother's disapproval of Joan's desire to study astronomy, Richard encouraged his sister to explore the universe. Joan eventually became an astrophysicist specializing in interactions between the Earth and the solar wind.\n\nFeynman attended Far Rockaway High School, a school in Far Rockaway, Queens, which was also attended by fellow Nobel laureates Burton Richter and Baruch Samuel Blumberg. Upon starting high school, Feynman was quickly promoted into a higher math class. A high-school-administered IQ test estimated his IQ at 125—high, but \"merely respectable\" according to biographer James Gleick. His sister Joan did better, allowing her to claim that she was smarter. Years later he declined to join Mensa International, saying that his IQ was too low. Physicist Steve Hsu stated of the test: \n\nWhen Feynman was 15, he taught himself trigonometry, advanced algebra, infinite series, analytic geometry, and both differential and integral calculus. Before entering college, he was experimenting with and deriving mathematical topics such as the half-derivative using his own notation. He created special symbols for logarithm, sine, cosine and tangent functions so they didn't look like three variables multiplied together, and for the derivative, to remove the temptation of canceling out the d's. A member of the Arista Honor Society, in his last year in high school he won the New York University Math Championship. His habit of direct characterization sometimes rattled more conventional thinkers; for example, one of his questions, when learning feline anatomy, was \"Do you have a map of the cat?\" (referring to an anatomical chart).\n\nFeynman applied to Columbia University but was not accepted because of their quota for the number of Jews admitted. Instead, he attended the Massachusetts Institute of Technology, where he joined the Phi Beta Delta fraternity. Although he originally majored in mathematics, he later switched to electrical engineering, as he considered mathematics to be too abstract. Noticing that he \"had gone too far,\" he then switched to physics, which he claimed was \"somewhere in between.\" As an undergraduate, he published two papers in the \"Physical Review\". One, co-written with Manuel Vallarta, was on \"The Scattering of Cosmic Rays by the Stars of a Galaxy\". \n\nThe other was his senior thesis, on \"The Forces in Molecules\", based on an idea by John C. Slater, who was sufficiently impressed by the paper to have it published. Today, it is known as the Hellmann–Feynman theorem.\n\nIn 1939, Feynman received a bachelor's degree, and was named a Putnam Fellow. He attained a perfect score on the graduate school entrance exams to Princeton University in physics—an unprecedented feat—and an outstanding score in mathematics, but did poorly on the history and English portions. The head of the physics department there, Henry D. Smyth, had another concern, writing to Philip M. Morse to ask: \"Is Feynman Jewish? We have no definite rule against Jews but like to keep their proportion in our department reasonably small\". Morse conceded that Feynman was indeed Jewish, but reassured Smyth that Feynman's \"physiognomy and manner, however, show no trace of this characteristic\".\n\nAttendees at Feynman's first seminar, which was on the classical version of the Wheeler-Feynman absorber theory, included Albert Einstein, Wolfgang Pauli, and John von Neumann. Pauli made the prescient comment that the theory would be extremely difficult to quantize, and Einstein said that one might try to apply this method to gravity in general relativity, which Sir Fred Hoyle and Jayant Narlikar did much later as the Hoyle–Narlikar theory of gravity. Feynman received a PhD from Princeton in 1942; his thesis advisor was John Archibald Wheeler. His doctoral thesis applied the principle of stationary action to problems of quantum mechanics, inspired by a desire to quantize the Wheeler–Feynman absorber theory of electrodynamics, laying the groundwork for the path integral formulation and Feynman diagrams, and was titled \"The Principle of Least Action in Quantum Mechanics\". A key insight was that positrons behaved like electrons moving backwards in time. James Gleick wrote:\nOne of the conditions of Feynman's scholarship to Princeton was that he could not be married; but he continued to see his high school sweetheart, Arline Greenbaum, and was determined to marry her once he had been awarded his Ph.D. despite the knowledge that she was seriously ill with tuberculosis. This was an incurable disease at the time, and she was not expected to live more than two years. On June 29, 1942, they took the Staten Island Ferry to Staten Island, where they were married in the city office. The ceremony was attended by neither family nor friends and was witnessed by a pair of strangers. Feynman could only kiss Arline on the cheek. After the ceremony he took her to Deborah Hospital, where he visited her on weekends.\n\nIn 1941, with World War II raging in Europe but the United States not yet at war, Feynman spent the summer working on ballistics problems at the Frankford Arsenal in Pennsylvania. After the attack on Pearl Harbor had brought the United States into the war, Feynman was recruited by Robert R. Wilson, who was working on means to produce enriched uranium for use in an atomic bomb, as part of what would become the Manhattan Project. Wilson's team at Princeton was working on a device called an isotron, which would electromagnetically separate uranium-235 from uranium-238. This was done in a quite different manner from that used by the calutron that was under development by a team under Wilson's former mentor, Ernest O. Lawrence, at the Radiation Laboratory of the University of California. On paper, the isotron was many times more efficient than the calutron, but Feynman and Paul Olum struggled to determine whether or not it was practical. Ultimately, on Lawrence's recommendation, the isotron project was abandoned.\n\nAt this juncture, in early 1943, Robert Oppenheimer was establishing the Los Alamos Laboratory, a secret laboratory on a remote mesa in New Mexico where atomic bombs would be designed and built. An offer was made to the Princeton team to be redeployed there. \"Like a bunch of professional soldiers,\" Wilson later recalled, \"we signed up, en masse, to go to Los Alamos.\" Like many other young physicists, Feynman soon fell under the spell of the charismatic Oppenheimer, who telephoned Feynman long distance from Chicago to inform him that he had found a sanatorium in Albuquerque, New Mexico, for Arline. They were among the first to depart for New Mexico, leaving on a train on March 28, 1943. The railroad supplied Arline with a wheelchair, and Feynman paid extra for a private room for her.\n\nAt Los Alamos, Feynman was assigned to Hans Bethe's Theoretical (T) Division, and impressed Bethe enough to be made a group leader. He and Bethe developed the Bethe–Feynman formula for calculating the yield of a fission bomb, which built upon previous work by Robert Serber. As a junior physicist, he was not central to the project. He administered the computation group of human computers in the theoretical division. With Stanley Frankel and Nicholas Metropolis, he assisted in establishing a system for using IBM punched cards for computation. He invented a new method of computing logarithms that he later used on the Connection Machine. Other work at Los Alamos included calculating neutron equations for the Los Alamos \"Water Boiler\", a small nuclear reactor, to measure how close an assembly of fissile material was to criticality.\n\nOn completing this work, Feynman was sent to the Clinton Engineer Works in Oak Ridge, Tennessee, where the Manhattan Project had its uranium enrichment facilities. He aided the engineers there in devising safety procedures for material storage so that criticality accidents could be avoided, especially when enriched uranium came into contact with water, which acted as a neutron moderator. He insisted on giving the rank and file a lecture on nuclear physics so that they would realize the dangers. He explained that while any amount of unenriched uranium could be safely stored, the enriched uranium had to be carefully handled. He developed a series of safety recommendations for the various grades of enrichments. He was told that if the people at Oak Ridge gave him any difficulty with his proposals, he was to inform them that Los Alamos \"could not be responsible for their safety otherwise\".\nReturning to Los Alamos, Feynman was put in charge of the group responsible for the theoretical work and calculations on the proposed uranium hydride bomb, which ultimately proved to be infeasible. He was sought out by physicist Niels Bohr for one-on-one discussions. He later discovered the reason: most of the other physicists were too much in awe of Bohr to argue with him. Feynman had no such inhibitions, vigorously pointing out anything he considered to be flawed in Bohr's thinking. He said he felt as much respect for Bohr as anyone else, but once anyone got him talking about physics, he would become so focused he forgot about social niceties. Perhaps because of this, Bohr never warmed to Feynman.\n\nDue to the top secret nature of the work, the Los Alamos Laboratory was isolated. Feynman indulged his curiosity by discovering the combination locks on cabinets and desks used to secure papers. He found that people tended to leave their safes unlocked, or leave them on the factory settings, or write the combinations down, or use easily guessable combinations like dates. Feynman played jokes on colleagues. In one case he found the combination to a locked filing cabinet by trying the numbers he thought a physicist would use (it proved to be 27–18–28 after the base of natural logarithms, \"e\" = 2.71828...), and found that the three filing cabinets where a colleague kept a set of atomic bomb research notes all had the same combination. He left a series of notes in the cabinets as a prank, which initially spooked his colleague, Frederic de Hoffmann, into thinking a spy or saboteur had gained access to atomic bomb secrets.\n\nFeynman's salary was $380 a month, about half what he needed to cover his modest living expenses and Arline's medical bills. The rest came from her $3,300 in savings. On weekends, Feynman drove to Albuquerque to see his ailing wife in a car borrowed from his good friend Klaus Fuchs. Asked who at Los Alamos was most likely to be a spy, Fuchs speculated that Feynman, with his safe cracking and frequent trips to Albuquerque, was the most likely candidate. When Fuchs confessed to being a spy for the Soviet Union in 1950, this would be seen in a different light. The FBI would compile a bulky file on Feynman.\nFeynman was working in the computing room when he was informed that Arline was dying. He borrowed Fuchs' car and drove to Albuquerque where he sat with her for hours until she died on June 16, 1945. He immersed himself in work on the project and was present at the Trinity nuclear test. Feynman claimed to be the only person to see the explosion without the very dark glasses or welder's lenses provided, reasoning that it was safe to look through a truck windshield, as it would screen out the harmful ultraviolet radiation. On witnessing the blast, Feynman ducked towards the floor of his truck because of the immense brightness of the explosion, where he saw a temporary \"purple splotch\" afterimage of the event.\n\nFeynman nominally held an appointment at the University of Wisconsin–Madison as an assistant professor of physics, but was on unpaid leave during his involvement in the Manhattan project. In 1945, he received a letter from Dean Mark Ingraham of the College of Letters and Science requesting his return to the university to teach in the coming academic year. His appointment was not extended when he did not commit to returning. In a talk given there several years later, Feynman quipped, \"It's great to be back at the only university that ever had the good sense to fire me.\"\n\nAs early as October 30, 1943, Bethe had written to the chairman of the physics department of his university, Cornell, to recommend that Feynman be hired. On February 28, 1944, this was endorsed by Robert Bacher, also from Cornell, and one of the most senior scientists at Los Alamos. This led to an offer being made in August 1944, which Feynman accepted. Oppenheimer had also hoped to recruit Feynman to the University of California, but the head of the physics department, Raymond T. Birge was reluctant. Eventually, he made Feynman an offer in May 1945, but Feynman turned it down. Cornell did, however, match its salary offer of $3,900 per annum. Feynman became one of the first of the Los Alamos Laboratory's group leader to depart, leaving for Ithaca, New York, in October 1945.\n\nSince Feynman was no longer working at the Los Alamos Laboratory, he was no longer exempt from the draft and was called up by the Army in the fall of 1946. He avoided this by faking mental illness, and the Army gave him a 4-F exemption on mental grounds. This may not have been an incorrect assessment; his father died suddenly on October 8, 1946, and Feynman suffered from depression. On October 17, 1946, he wrote a letter to Arline, expressing his deep love and heartbreak. This letter was sealed and only opened after his death. \"Please excuse my not mailing this,\" the letter concluded, \"but I don't know your new address.\"\n\nUnable to focus on research problems, Feynman began tackling physics problems, not for utility, but for self-satisfaction. One of these involved analyzing the physics of a twirling, nutating disk as it is moving through the air, inspired by an incident in the cafeteria at Cornell when someone tossed a dinner plate in the air. He read the work of Sir William Rowan Hamilton on quaternions, and attempted unsuccessfully to use them to formulate a relativistic theory of electrons. His work during this period, which used equations of rotation to express various spinning speeds, ultimately proved important to his Nobel Prize–winning work, yet because he felt burned out and had turned his attention to less immediately practical problems, he was surprised by the offers of professorships from other renowned universities, including the Institute for Advanced Study, the University of California, Los Angeles, and the University of California, Berkeley.\nFeynman was not the only frustrated theoretical physicist in the early post-war years. Quantum electrodynamics suffered from infinite integrals in perturbation theory. These were clear mathematical flaws in the theory, which Feynman and Wheeler had unsuccessfully attempted to work around. \"Theoreticians\", noted Murray Gell-Mann, \"were in disgrace.\" In June 1947, leading American physicists met at the Shelter Island Conference. For Feynman, it was his \"first big conference with big men ... I had never gone to one like this one in peacetime.\" The problems plaguing quantum electrodynamics were discussed, but the theoreticians were completely overshadowed by the achievements of the experimentalists, who reported the discovery of the Lamb shift, the measurement of the magnetic moment of the electron, and Robert Marshak's two-meson hypothesis.\n\nBethe took the lead from the work of Hans Kramers, and derived a renormalized non-relativistic quantum equation for the Lamb shift. The next step was to create a relativistic version. Feynman thought that he could do this, but when he went back to Bethe with his solution, it did not converge. Feynman carefully worked through the problem again, applying the path integral formulation that he had used in his thesis. Like Bethe, he made the integral finite by applying a cut-off term. The result corresponded to Bethe's version. Feynman presented his work to his peers at the Pocono Conference in 1948. It did not go well. Julian Schwinger gave a long presentation of his work in quantum electrodynamics, and Feynman then offered his version, titled \"Alternative Formulation of Quantum Electrodynamics\". The unfamiliar Feynman diagrams, used for the first time, puzzled the audience. Feynman failed to get his point across, and Paul Dirac, Edward Teller and Niels Bohr all raised objections.\n\nTo Freeman Dyson, one thing at least was clear: Sin'ichirō Tomonaga, Schwinger and Feynman understood what they were talking about even if no one else did, but had not published anything. Moreover, he was convinced that Feynman's formulation was easier to understand, and ultimately managed to convince Oppenheimer that this was the case. Dyson published a paper in 1949, which added new rules to Feynman's that told how to implement renormalization. Feynman was prompted to publish his ideas in the \"Physical Review\" in a series of papers over three years. His 1948 papers on \"A Relativistic Cut-Off for Classical Electrodynamics\" attempted to explain what he had been unable to get across at Pocono. His 1949 paper on \"The Theory of Positrons\" addressed the Schrödinger equation and Dirac equation, and introduced what is now called the Feynman propagator. Finally, in papers on the \"Mathematical Formulation of the Quantum Theory of Electromagnetic Interaction\" in 1950 and \"An Operator Calculus Having Applications in Quantum Electrodynamics\" in 1951, he developed the mathematical basis of his ideas, derived familiar formulae and advanced new ones.\n\nWhile papers by others initially cited Schwinger, papers citing Feynman and employing Feynman diagrams appeared in 1950, and soon became prevalent. Students learned and used the powerful new tool that Feynman had created. Eventually, computer programs were written to compute Feynman diagrams, providing a tool of unprecedented power. It is possible to write such programs because the Feynman diagrams constitute a formal language with a formal grammar. Marc Kac provided the formal proofs of the summation under history, showing that the parabolic partial differential equation can be re-expressed as a sum under different histories (that is, an expectation operator), what is now known as the Feynman–Kac formula, the use of which extends beyond physics to many applications of stochastic processes. To Schwinger, the Feynman diagram was \"pedagogy, not physics\".\n\nBy 1949, Feynman was becoming restless at Cornell. He never settled into a particular house or apartment, living in guest houses or student residences, or with married friends \"until these arrangements became sexually volatile\". He liked to date undergraduates, hire prostitutes, and sleep with the wives of friends. He was not fond of Ithaca's cold winter weather, and pined for a warmer climate. Above all, at Cornell, he was always in the shadow of Hans Bethe. Feynman did, however, look back favorably on the Telluride House, where he resided for a large period of his Cornell career. In an interview, he described the House as \"a group of boys have been specially selected because of their scholarship, because of their cleverness or whatever it is, to be given free board and lodging and so on, because of their brains\". He enjoyed the house's convenience and said that \"it's there that I did the fundamental work\" for which he won the Nobel Prize.\n\nFeynman spent several weeks in Rio de Janeiro in July 1949, and brought back a woman called Clotilde from Copacabana who lived with him in Ithaca for a time. As well as the cold weather, there was also the Cold War. The Soviet Union detonated its first atomic bomb in 1949, generating anti-communist hysteria. Fuchs was arrested as a Soviet spy in 1950, and the FBI questioned Bethe about Feynman's loyalty. Physicist David Bohm was arrested on December 4, 1950, and emigrated to Brazil in October 1951. A girlfriend told Feynman that he should consider moving to South America. He had a sabbatical coming for 1951–52, and elected to spend it in Brazil, where he gave courses at the Centro Brasileiro de Pesquisas Físicas. In Brazil, Feynman was particularly impressed with the \"Samba\" music, and learned to play a metal percussion instrument, the \"frigideira\". He was an enthusiastic amateur player of bongo drums and often played them in the pit orchestra in musicals. He spent time in Rio with his good friend Bohm, but Bohm could not convince Feynman to take up investigating Bohm's ideas on physics.\n\nFeynman did not return to Cornell. Bacher, who had been instrumental in bringing Feynman to Cornell, had lured him to the California Institute of Technology (Caltech). Part of the deal was that he could spend his first year on sabbatical in Brazil. He had become smitten by Mary Louise Bell, a platinum blonde from Neodesha, Kansas. They had met in a cafeteria in Cornell, where she had studied the history of Mexican art and textiles. She later followed him to Caltech, where he gave a lecture. While he was in Brazil, she had taught classes on the history of furniture and interiors at Michigan State University. He proposed to her by mail from Rio de Janeiro, and they married in Boise, Idaho, on June 28, 1952, shortly after he returned. They frequently quarreled and she was frightened by his violent temper. Their politics were different; although he registered and voted as a Republican, she was more conservative, and her opinion on the 1954 Oppenheimer security hearing (\"Where there's smoke there's fire\") offended him. They separated on May 20, 1956. An interlocutory decree of divorce was entered on June 19, 1956, on the grounds of \"extreme cruelty\". The divorce became final on May 5, 1958.\n\nIn the wake of the 1957 Sputnik crisis, the U.S. government's interest in science rose for a time. Feynman was considered for a seat on the President's Science Advisory Committee, but was not appointed. At this time the FBI interviewed a woman close to Feynman, possibly Mary Lou, who sent a written statement to J. Edgar Hoover on August 8, 1958:\n\nThe government nevertheless sent Feynman to Geneva for the September 1958 Atoms for Peace Conference. On the beach on Lake Geneva, he met Gweneth Howarth, who was from Ripponden, Yorkshire, and working in Switzerland as an \"au pair\". Feynman's love life had been turbulent since his divorce; his previous girlfriend had walked off with his Albert Einstein Award medal and, on the advice of an earlier girlfriend, had feigned pregnancy and blackmailed him into paying for an abortion, then used the money to buy furniture. When Feynman found that Howarth was being paid only $25 a month, he offered her $20 a week to be his live-in maid. That this sort of behavior was illegal was not overlooked; Feynman had a friend, Matthew Sands, act as her sponsor. Howarth pointed out that she already had two boyfriends, but eventually decided to take Feynman up on his offer, and arrived in Altadena, California, in June 1959. She made a point of dating other men but Feynman proposed in the spring of 1960. They were married on September 24, 1960, at the Huntington Hotel in Pasadena. They had a son, Carl, in 1962, and adopted a daughter, Michelle, in 1968. Besides their home in Altadena, they had a beach house in Baja California, purchased with the money from Feynman's Nobel Prize.\n\nFeynman tried LSD during his professorship at Caltech. He also tried marijuana and ketamine experiences at John Lilly's famed sensory deprivation tanks, as a way of studying consciousness. He gave up alcohol when he began to show vague, early signs of alcoholism, as he did not want to do anything that could damage his brain.\n\nAt Caltech, Feynman investigated the physics of the superfluidity of supercooled liquid helium, where helium seems to display a complete lack of viscosity when flowing. Feynman provided a quantum-mechanical explanation for the Soviet physicist Lev D. Landau's theory of superfluidity. Applying the Schrödinger equation to the question showed that the superfluid was displaying quantum mechanical behavior observable on a macroscopic scale. This helped with the problem of superconductivity, but the solution eluded Feynman. It was solved with the BCS theory of superconductivity, proposed by John Bardeen, Leon Neil Cooper, and John Robert Schrieffer.\nWith Murray Gell-Mann, Feynman developed a model of weak decay, which showed that the current coupling in the process is a combination of vector and axial currents (an example of weak decay is the decay of a neutron into an electron, a proton, and an antineutrino). Although E. C. George Sudarshan and Robert Marshak developed the theory nearly simultaneously, Feynman's collaboration with Murray Gell-Mann was seen as seminal because the weak interaction was neatly described by the vector and axial currents. It thus combined the 1933 beta decay theory of Enrico Fermi with an explanation of parity violation.\n\nFrom his diagrams of a few particles interacting in spacetime, Feynman could then model all of physics in terms of the spins of those particles and the range of coupling of the fundamental forces. Feynman attempted an explanation of the strong interactions governing nucleons scattering called the parton model. The parton model emerged as a complement to the quark model developed by Gell-Mann. The relationship between the two models was murky; Gell-Mann referred to Feynman's partons derisively as \"put-ons\". In the mid-1960s, physicists believed that quarks were just a bookkeeping device for symmetry numbers, not real particles; the statistics of the Omega-minus particle, if it were interpreted as three identical strange quarks bound together, seemed impossible if quarks were real.\n\nThe SLAC National Accelerator Laboratory deep inelastic scattering experiments of the late 1960s showed that nucleons (protons and neutrons) contained point-like particles that scattered electrons. It was natural to identify these with quarks, but Feynman's parton model attempted to interpret the experimental data in a way that did not introduce additional hypotheses. For example, the data showed that some 45% of the energy momentum was carried by electrically neutral particles in the nucleon. These electrically neutral particles are now seen to be the gluons that carry the forces between the quarks, and their three-valued color quantum number solves the Omega-minus problem. Feynman did not dispute the quark model; for example, when the fifth quark was discovered in 1977, Feynman immediately pointed out to his students that the discovery implied the existence of a sixth quark, which was discovered in the decade after his death.\n\nAfter the success of quantum electrodynamics, Feynman turned to quantum gravity. By analogy with the photon, which has spin 1, he investigated the consequences of a free massless spin 2 field and derived the Einstein field equation of general relativity, but little more. The computational device that Feynman discovered then for gravity, \"ghosts\", which are \"particles\" in the interior of his diagrams that have the \"wrong\" connection between spin and statistics, have proved invaluable in explaining the quantum particle behavior of the Yang–Mills theories, for example, quantum chromodynamics and the electro-weak theory. He did work on all four of the forces of nature: electromagnetic, the weak force, the strong force and gravity. John and Mary Gribbin say in their book on Feynman: \"Nobody else has made such influential contributions to the investigation of all four of the interactions\".\n\nPartly as a way to bring publicity to progress in physics, Feynman offered $1,000 prizes for two of his challenges in nanotechnology; one was claimed by William McLellan and the other by Tom Newman. He was also one of the first scientists to conceive the possibility of quantum computers. In 1984–86, he developed a variational method for the approximate calculation of path integrals, which has led to a powerful method of converting divergent perturbation expansions into convergent strong-coupling expansions (variational perturbation theory) and, as a consequence, to the most accurate determination of critical exponents measured in satellite experiments.\n\nIn the early 1960s, Feynman acceded to a request to \"spruce up\" the teaching of undergraduates at Caltech. After three years devoted to the task, he produced a series of lectures that eventually became \"The Feynman Lectures on Physics\". He wanted a picture of a drumhead sprinkled with powder to show the modes of vibration at the beginning of the book. Concerned over the connections to drugs and rock and roll that could be made from the image, the publishers changed the cover to plain red, though they included a picture of him playing drums in the foreword. \"The Feynman Lectures on Physics\" occupied two physicists, Robert B. Leighton and Matthew Sands, as part-time co-authors for several years. Even though the books were not adopted by universities as textbooks, they continue to sell well because they provide a deep understanding of physics. Many of his lectures and miscellaneous talks were turned into other books, including \"The Character of Physical Law\", \"\", \"Statistical Mechanics\", \"Lectures on Gravitation\", and the \"Feynman Lectures on Computation\".\n\nFeynman wrote about his experiences teaching physics undergraduates in Brazil. The students' study habits and the Portuguese language textbooks were so bad that they were not, in his opinion, learning physics at all. At the end of the year, he was invited to give a lecture on his teaching experiences, and he agreed to do so, provided he could speak frankly and didn't pull any punches.\nFeynman opposed rote learning or unthinking memorization and other teaching methods that emphasized form over function. \"Clear thinking\" and \"clear presentation\" were fundamental prerequisites for his attention. It could be perilous even to approach him when unprepared, and he did not forget the fools or pretenders. In 1964, he served on the California State Curriculum Commission, which was responsible for approving textbooks to be used by schools in California. He was not impressed with what he found. Many of the mathematics texts covered subjects of use only to pure mathematicians as part of the \"New Math\". Elementary students were taught about sets, but:\n\nIn April 1966, Feynman delivered an address to the National Science Teachers Association, in which he suggested how students could be made to think like scientists, be open-minded, curious, and especially, to doubt. In the course of the lecture, he gave a definition of science, which he said came about by several stages. The evolution of intelligent life on planet Earth—creatures such as cats that play and learn from experience. The evolution of humans, who came to use language to pass knowledge from one individual to the next, so that the knowledge was not lost when an individual died. Unfortunately, incorrect knowledge could be passed down as well as correct knowledge, so another step was needed. Galileo and others started doubting the truth of what was passed down and to investigate \"ab initio\", from experience, what the true situation was—this was science.\n\nIn 1974, Feynman delivered the Caltech commencement address on the topic of \"cargo cult science\", which has the semblance of science, but is only pseudoscience due to a lack of \"a kind of scientific integrity, a principle of scientific thought that corresponds to a kind of utter honesty\" on the part of the scientist. He instructed the graduating class that \"The first principle is that you must not fool yourself—and you are the easiest person to fool. So you have to be very careful about that. After you've not fooled yourself, it's easy not to fool other scientists. You just have to be honest in a conventional way after that.\"\n\nFeynman served as doctoral advisor to 31 students.\n\nIn the 1960s, Feynman began thinking of writing an autobiography, and he began granting interviews to historians. In the 1980s, working with Ralph Leighton (Robert Leighton's son), he recorded chapters on audio tape that Robert transcribed. The book was published in 1985 as \"Surely You're Joking, Mr. Feynman!\" and became a best-seller. The publication of the book brought a new wave of protest about Feynman's attitude toward women. There had been protests over his alleged sexism in 1968, and again in 1972. It did not help that Jenijoy La Belle, who had been hired as Caltech's first female professor in 1969, was refused tenure in 1974. She filed suit with the Equal Employment Opportunity Commission, which ruled against Caltech in 1977, adding that she had been paid less than male colleagues. La Belle finally received tenure in 1979. Many of Feynman's colleagues were surprised that he took her side. He had gotten to know her, and both liked and admired her.\n\nGell-Mann was upset by Feynman's account in the book of the weak interaction work, and threatened to sue, resulting in a correction being inserted in later editions. This incident was just the latest provocation in a decades-long bad feeling between the two scientists. Gell-Mann often expressed frustration at the attention Feynman received; he remarked: \"[Feynman] was a great scientist, but he spent a great deal of his effort generating anecdotes about himself.\" He noted that Feynman's eccentricities included a refusal to brush his teeth, which he advised others not to do on national television, despite dentists showing him scientific studies that supported the practice.\n\nFeynman played an important role on the Presidential Rogers Commission, which investigated the \"Challenger\" disaster. During a televised hearing, Feynman demonstrated that the material used in the shuttle's O-rings became less resilient in cold weather by compressing a sample of the material in a clamp and immersing it in ice-cold water. The commission ultimately determined that the disaster was caused by the primary O-ring not properly sealing in unusually cold weather at Cape Canaveral.\n\nFeynman devoted the latter half of his book \"What Do You Care What Other People Think?\" to his experience on the Rogers Commission, straying from his usual convention of brief, light-hearted anecdotes to deliver an extended and sober narrative. Feynman's account reveals a disconnect between NASA's engineers and executives that was far more striking than he expected. His interviews of NASA's high-ranking managers revealed startling misunderstandings of elementary concepts. For instance, NASA managers claimed that there was a 1 in 100,000 chance of a catastrophic failure aboard the shuttle, but Feynman discovered that NASA's own engineers estimated the chance of a catastrophe at closer to 1 in 200. He concluded that NASA management's estimate of the reliability of the space shuttle was unrealistic, and he was particularly angered that NASA used it to recruit Christa McAuliffe into the Teacher-in-Space program. He warned in his appendix to the commission's report (which was included only after he threatened not to sign the report), \"For a successful technology, reality must take precedence over public relations, for nature cannot be fooled.\"\n\nThe first public recognition of Feynman's work came in 1954, when Lewis Strauss, the chairman of the Atomic Energy Commission (AEC) notified him that he had won the Albert Einstein Award, which was worth $15,000 and came with a gold medal. Because of Strauss' actions in stripping Oppenheimer of his security clearance, Feynman was reluctant to accept the award, but Isidor Isaac Rabi cautioned him: \"You should never turn a man's generosity as a sword against him. Any virtue that a man has, even if he has many vices, should not be used as a tool against him.\" It was followed by the AEC's Ernest Orlando Lawrence Award in 1962. Schwinger, Tomonaga and Feynman shared the 1965 Nobel Prize in Physics \"for their fundamental work in quantum electrodynamics, with deep-ploughing consequences for the physics of elementary particles\". He was elected a Foreign Member of the Royal Society in 1965, received the Oersted Medal in 1972, and the National Medal of Science in 1979. He was elected a member of the National Academy of Sciences, but ultimately resigned and is no longer listed by them.\n\nIn 1978, Feynman sought medical treatment for abdominal pains and was diagnosed with liposarcoma, a rare form of cancer. Surgeons removed a tumor the size of a football that had crushed one kidney and his spleen. Further operations were performed in October 1986 and October 1987. He was again hospitalized at the UCLA Medical Center on February3, 1988. A ruptured duodenal ulcer caused kidney failure, and he declined to undergo the dialysis that might have prolonged his life for a few months. Watched over by his wife Gweneth, sister Joan, and cousin Frances Lewine, he died on February15, 1988.\n\nWhen the end was near, Feynman asked Danny Hillis why he was so sad. Hillis replied that he thought Feynman was going to die soon. Feynman said that that sometimes bothered him, too, adding, when you get to be as old as he was, and have told so many stories to so many people, even when he was dead he wouldn't be completely gone.\n\nNear the end of his life, Feynman attempted to visit the Russian land of Tuva, a dream thwarted by Cold War bureaucratic issuesthe letter from the Soviet government authorizing the trip was not received until the day after he died. His daughter Michelle later undertook the journey. His burial was at Mountain View Cemetery and Mausoleum in Altadena. His last words were: \"I'd hate to die twice. It's so boring.\"\n\nAspects of Feynman's life have been portrayed in various media. Actor Alan Alda commissioned playwright Peter Parnell to write a two-character play about a fictional day in the life of Feynman set two years before Feynman's death. The play, \"QED\", which was based on writings about Richard Feynman's life, premiered at the Mark Taper Forum in Los Angeles in 2001. The play was then presented at the Vivian Beaumont Theater on Broadway, with both presentations starring Alda as Richard Feynman. Real Time Opera premiered its opera \"Feynman\" at the Norfolk (CT) Chamber Music Festival in June 2005. In 2013, Feynman's role on the Rogers Commission was dramatised by the BBC in \"The Challenger\" (US title: \"The Challenger Disaster\"), with William Hurt playing Feynman. In 2011, Feynman was the subject of a biographical graphic novel entitled simply \"Feynman\", written by Jim Ottaviani and illustrated by Leland Myrick. Feynman was also portrayed by Matthew Broderick in the 1996 biopic \"Infinity\".\n\nFeynman is commemorated in various ways. On May 4, 2005, the United States Postal Service issued the \"American Scientists\" commemorative set of four 37-cent self-adhesive stamps in several configurations. The scientists depicted were Richard Feynman, John von Neumann, Barbara McClintock, and Josiah Willard Gibbs. Feynman's stamp, sepia-toned, features a photograph of a 30-something Feynman and eight small Feynman diagrams. The stamps were designed by Victor Stabin under the artistic direction of Carl T. Herrman. The main building for the Computing Division at Fermilab is named the \"Feynman Computing Center\" in his honor. A photograph of Richard Feynman giving a lecture was part of the 1988 poster series commissioned by Apple Inc. for their \"Think Different\" advertising campaign. The Sheldon Cooper character in \"The Big Bang Theory\" is a Feynman fan who emulates him by playing the bongo drums. On January 27, 2016, Bill Gates wrote an article \"The Best Teacher I Never Had\" describing Feynman's talents as a teacher which inspired Gates to create Project Tuva to place the filmed Feynman Messenger Lectures The Character of Physical Law videos on a website for public viewing. In 2015 Gates also made a video giving his thoughts why Feynman was special. The video was made for the 50th anniversary of Feynman's 1965 Nobel Prize, in response to Caltech's request for thoughts on Feynman.\n\n\n\"The Feynman Lectures on Physics\" is perhaps his most accessible work for anyone with an interest in physics, compiled from lectures to Caltech undergraduates in 1961–64. As news of the lectures' lucidity grew, professional physicists and graduate students began to drop in to listen. Co-authors Robert B. Leighton and Matthew Sands, colleagues of Feynman, edited and illustrated them into book form. The work has endured and is useful to this day. They were edited and supplemented in 2005 with \"Feynman's Tips on Physics: A Problem-Solving Supplement to the Feynman Lectures on Physics\" by Michael Gottlieb and Ralph Leighton (Robert Leighton's son), with support from Kip Thorne and other physicists.\n\n\n\n\n\n\n\n"}
{"id": "25524", "url": "https://en.wikipedia.org/wiki?curid=25524", "title": "Research", "text": "Research\n\nResearch comprises \"creative work undertaken on a systematic basis in order to increase the stock of knowledge, including knowledge of humans, culture and society, and the use of this stock of knowledge to devise new applications.\" It is used to establish or confirm facts, reaffirm the results of previous work, solve new or existing problems, support theorems, or develop new theories. A research project may also be an expansion on past work in the field. Research projects can be used to develop further knowledge on a topic, or in the example of a school research project, they can be used to further a student's research prowess to prepare them for future jobs or reports. To test the validity of instruments, procedures, or experiments, research may replicate elements of prior projects or the project as a whole. The primary purposes of basic research (as opposed to applied research) are documentation, discovery, interpretation, or the research and development (R&D) of methods and systems for the advancement of human knowledge. Approaches to research depend on epistemologies, which vary considerably both within and between humanities and sciences. There are several forms of research: scientific, humanities, artistic, economic, social, business, marketing, practitioner research, life, technological, etc.\n\nThe word \"research\" is derived from the Middle French \"\"recherche\"\", which means \"to go about seeking\", the term itself being derived from the Old French term \"\"recerchier\"\" a compound word from \"re-\" + \"cerchier\", or \"sercher\", meaning 'search'. The earliest recorded use of the term was in 1577.\n\nResearch has been defined in a number of different ways.\n\nA broad definition of research is given by Godwin Colibao: \"In the broadest sense of the word, the definition of research includes any gathering of data, information, and facts for the advancement of knowledge.\"\n\nAnother definition of research is given by John W. Creswell, who states that \"[r]esearch is a process of steps used to collect and analyze information to increase our understanding of a topic or issue\". It consists of three steps: pose a question, collect data to answer the question, and present an answer to the question.\n\nThe Merriam-Webster Online Dictionary defines research in more detail as \"a studious inquiry or examination; especially investigation or experimentation aimed at the discovery and interpretation of facts, revision of accepted theories or laws in the light of new facts, or practical application of such new or revised theories or laws\".\n\nOriginal research is research that is not exclusively based on a summary, review or synthesis of earlier publications on the subject of research. This material is of a primary source character. The purpose of the original research is to produce new knowledge, rather than to present the existing knowledge in a new form (\"e.g.\", summarized or classified).\n\nOriginal research can take a number of forms, depending on the discipline it pertains to. In experimental work, it typically involves direct or indirect observation of the researched subject(s), e.g., in the laboratory or in the field, documents the methodology, results, and conclusions of an experiment or set of experiments, or offers a novel interpretation of previous results. In analytical work, there are typically some new (for example) mathematical results produced, or a new way of approaching an existing problem. In some subjects which do not typically carry out experimentation or analysis of this kind, the originality is in the particular way existing understanding is changed or re-interpreted based on the outcome of the work of the researcher.\n\nThe degree of originality of the research is among major criteria for articles to be published in academic journals and usually established by means of peer review. Graduate students are commonly required to perform original research as part of a dissertation.\n\nScientific research is a systematic way of gathering data and harnessing curiosity. This research provides scientific information and theories for the explanation of the nature and the properties of the world. It makes practical applications possible. Scientific research is funded by public authorities, by charitable organizations and by private groups, including many companies. Scientific research can be subdivided into different classifications according to their academic and application disciplines. Scientific research is a widely used criterion for judging the standing of an academic institution, but some argue that such is an inaccurate assessment of the institution, because the quality of research does not tell about the quality of teaching (these do not necessarily correlate).\n\nResearch in the humanities involves different methods such as for example hermeneutics and semiotics. Humanities scholars usually do not search for the ultimate correct answer to a question, but instead, explore the issues and details that surround it. Context is always important, and context can be social, historical, political, cultural, or ethnic. An example of research in the humanities is historical research, which is embodied in historical method. Historians use primary sources and other evidence to systematically investigate a topic, and then to write histories in the form of accounts of the past. Other studies aim to merely examine the occurrence of behaviours in societies and communities, without particularly looking for reasons or motivations to explain these. These studies may be qualitative or quantitative, and can use a variety of approaches, such as queer theory or feminist theory.\n\nArtistic research, also seen as 'practice-based research', can take form when creative works are considered both the research and the object of research itself. It is the debatable body of thought which offers an alternative to purely scientific methods in research in its search for knowledge and truth.\n\nGenerally, research is understood to follow a certain structural process. Though step order may vary depending on the subject matter and researcher, the following steps are usually part of most formal research, both basic and applied:\n\nA common misconception is that a hypothesis will be proven (see, rather, null hypothesis). Generally, a hypothesis is used to make predictions that can be tested by observing the outcome of an experiment. If the outcome is inconsistent with the hypothesis, then the hypothesis is rejected (see falsifiability). However, if the outcome is consistent with the hypothesis, the experiment is said to support the hypothesis. This careful language is used because researchers recognize that alternative hypotheses may also be consistent with the observations. In this sense, a hypothesis can never be proven, but rather only supported by surviving rounds of scientific testing and, eventually, becoming widely thought of as true.\n\nA useful hypothesis allows prediction and within the accuracy of observation of the time, the prediction will be verified. As the accuracy of observation improves with time, the hypothesis may no longer provide an accurate prediction. In this case, a new hypothesis will arise to challenge the old, and to the extent that the new hypothesis makes more accurate predictions than the old, the new will supplant it. Researchers can also use a null hypothesis, which states no relationship or difference between the independent or dependent variables.\n\nThe historical method comprises the techniques and guidelines by which historians use historical sources and other evidence to research and then to write history. There are various history guidelines that are commonly used by historians in their work, under the headings of external criticism, internal criticism, and synthesis. This includes lower criticism and sensual criticism. Though items may vary depending on the subject matter and researcher, the following concepts are part of most formal historical research:\n\nThe controversial trend of artistic teaching becoming more academics-oriented is leading to artistic research being accepted as the primary mode of enquiry in art as in the case of other disciplines. One of the characteristics of artistic research is that it must accept subjectivity as opposed to the classical scientific methods. As such, it is similar to the social sciences in using qualitative research and intersubjectivity as tools to apply measurement and critical analysis.\n\nArtistic research has been defined by the University of Dance and Circus (Dans och Cirkushögskolan, DOCH), Stockholm in the following manner - \"Artistic research is to investigate and test with the purpose of gaining knowledge within and for our artistic disciplines. It is based on artistic practices, methods, and criticality. Through presented documentation, the insights gained shall be placed in a context.\" Artistic research aims to enhance knowledge and understanding with presentation of the arts. For a survey of the central problematics of today's Artistic Research, see Giaco Schiesser.\n\nAccording to artist Hakan Topal, in artistic research, \"perhaps more so than other disciplines, intuition is utilized as a method to identify a wide range of new and unexpected productive modalities\". Most writers, whether of fiction or non-fiction books, also have to do research to support their creative work. This may be factual, historical, or background research. Background research could include, for example, geographical or procedural research.\n\nThe Society for Artistic Research (SAR) publishes the triannual \"Journal for Artistic Research\" (JAR), an international, online, open access, and peer-reviewed journal for the identification, publication, and dissemination of artistic research and its methodologies, from all arts disciplines and it runs the \"Research Catalogue\" (RC), a searchable, documentary database of artistic research, to which anyone can contribute.\n\nPatricia Leavy addresses eight arts-based research (ABR) genres: narrative inquiry, fiction-based research, poetry, music, dance, theatre, film, and visual art.\n\nIn 2016 ELIA (European League of the Institutes of the Arts) launched \"The Florence Principles' on the Doctorate in the Arts\". The Florence Principles relating to the Salzburg Principles and the Salzburg Recommendations of EUA (European University Association) name seven points of attention to specify the Doctorate / Ph.D. in the Arts compared to a scientific doctorate / Ph.D. The Florence Principles have been endorsed and are supported also by AEC, CILECT, CUMULUS and SAR.\n\nResearch is often conducted using the hourglass model structure of research. The hourglass model starts with a broad spectrum for research, focusing in on the required information through the method of the project (like the neck of the hourglass), then expands the research in the form of discussion and results. The major steps in conducting research are:\n\nThe steps generally represent the overall process; however, they should be viewed as an ever-changing iterative process rather than a fixed set of steps. Most research begins with a general statement of the problem, or rather, the purpose for engaging in the study. The literature review identifies flaws or holes in previous research which provides justification for the study. Often, a literature review is conducted in a given subject area before a research question is identified. A gap in the current literature, as identified by a researcher, then engenders a research question. The research question may be parallel to the hypothesis. The hypothesis is the supposition to be tested. The researcher(s) collects data to test the hypothesis. The researcher(s) then analyzes and interprets the data via a variety of statistical methods, engaging in what is known as empirical research. The results of the data analysis in rejecting or failing to reject the null hypothesis are then reported and evaluated. At the end, the researcher may discuss avenues for further research. However, some researchers advocate for the reverse approach: starting with articulating findings and discussion of them, moving \"up\" to identification of a research problem that emerges in the findings and literature review. The reverse approach is justified by the transactional nature of the research endeavor where research inquiry, research questions, research method, relevant research literature, and so on are not fully known until the findings have fully emerged and been interpreted.\n\nRudolph Rummel says, \"... no researcher should accept any one or two tests as definitive. It is only when a range of tests are consistent over many kinds of data, researchers, and methods can one have confidence in the results.\"\n\nPlato in Meno talks about an inherent difficulty, if not a paradox, of doing research that can be paraphrased in the following way, \"If you know what you're searching for, why do you search for it?! [i.e., you have already found it] If you don't know what you're searching for, what are you searching for?!\"\n\nThe goal of the research process is to produce new knowledge or deepen understanding of a topic or issue. This process takes three main forms (although, as previously discussed, the boundaries between them may be obscure):\nThere are two major types of empirical research design: qualitative research and quantitative research. Researchers choose qualitative or quantitative methods according to the nature of the research topic they want to investigate and the research questions they aim to answer:\n\n\n\nThe quantitative data collection methods rely on random sampling and structured data collection instruments that fit diverse experiences into predetermined response categories. These methods produce results that are easy to summarize, compare, and generalize. Quantitative research is concerned with testing hypotheses derived from theory and/or being able to estimate the size of a phenomenon of interest.\n\nIf the research question is about people, participants may be randomly assigned to different treatments (this is the only way that a quantitative study can be considered a true experiment). If this is not feasible, the researcher may collect data on participant and situational characteristics in order to statistically control for their influence on the dependent, or outcome, variable. If the intent is to generalize from the research participants to a larger population, the researcher will employ probability sampling to select participants.\n\nIn either qualitative or quantitative research, the researcher(s) may collect primary or secondary data. Primary data is data collected specifically for the research, such as through interviews or questionnaires. Secondary data is data that already exists, such as census data, which can be re-used for the research. It is good ethical research practice to use secondary data wherever possible.\n\nMixed-method research, i.e. research that includes qualitative and quantitative elements, using both primary and secondary data, is becoming more common.\n\nBig data has brought big impacts on research methods so that now many researchers do not put much effort into data collection; furthermore, methods to analyze easily available huge amounts of data have also been developed.\n\nNon-empirical (theoretical) research is an approach that involves the development of theory as opposed to using observation and experimentation. As such, non-empirical research seeks solutions to problems using existing knowledge as its source. This, however, does not mean that new ideas and innovations cannot be found within the pool of existing and established knowledge. Non-empirical research is not an absolute alternative to empirical research because they may be used together to strengthen a research approach. Neither one is less effective than the other since they have their particular purpose in science. Typically empirical research produces observations that need to be explained; then theoretical research tries to explain them, and in so doing generates empirically testable hypotheses; these hypotheses are then tested empirically, giving more observations that may need further explanation; and so on. See Scientific method.\n\nA simple example of a non-empirical task is the prototyping of a new drug using a differentiated application of existing knowledge; another is the development of a business process in the form of a flow chart and texts where all the ingredients are from established knowledge. Much of cosmological research is theoretical in nature. Mathematics research does not rely on externally available data; rather, it seeks to prove theorems about mathematical objects.\n\nResearch ethics involves the application of fundamental ethical principles to a variety of topics involving research, including scientific research. These include the design and implementation of research involving human experimentation, animal experimentation, various aspects of academic scandal, including scientific misconduct (such as fraud, fabrication of data and plagiarism), whistleblowing; regulation of research, etc. Research ethics is most developed as a concept in medical research. The key agreement here is the 1964 Declaration of Helsinki. The Nuremberg Code is a former agreement, but with many still important notes. Research in the social sciences presents a different set of issues than those in medical research.\n\nIn many disciplines, Western methods of conducting research are predominant. Researchers are overwhelmingly taught Western methods of data collection and study. The increasing participation of indigenous peoples as researchers has brought increased attention to the lacuna in culturally-sensitive methods of data collection. Non-Western methods of data collection may not be the most accurate or relevant for research on non-Western societies. For example, “Hua Oranga” was created as a criterion for psychological evaluation in Māori populations, and is based on dimensions of mental health important to the Māori people — \"taha wairua (the spiritual dimension), taha hinengaro (the mental dimension), taha tinana (the physical dimension), and taha whanau (the family dimension)”.\n\nPeriphery scholars face the challenges of exclusion and linguicism in research and academic publication. As the great majority of mainstream academic journals are written in English, multilingual periphery scholars often must translate their work in order to be accepted to elite Western-dominated journals. Multilingual scholars’ influences from their native communicative styles can be assumed to be incompetence instead of difference.\n\nPeer Review is a form of self-regulation by qualified members of a profession within the relevant field. Peer review methods are employed to maintain standards of quality, improve performance, and provide credibility. In academia, scholarly peer review is often used to determine an academic paper's suitability for publication. Usually, the peer review process involves experts in the same field who are consulted by editors to give a review of the scholarly works produced by a colleague of theirs from an unbiased and impartial point of view, and this is usually done free of charge. The tradition of peer reviews being done for free has however brought many pitfalls which are also indicative of why most peer reviewers decline many invitations to review. It was observed that publications from periphery countries rarely rise to the same elite status as those of North America and Europe, because limitations on the availability of resources including high-quality paper and sophisticated image-rendering software and printing tools render these publications less able to satisfy standards currently carrying formal or informal authority in the publishing industry. These limitations in turn result in the under-representation of scholars from periphery nations among the set of publications holding prestige status relative to the quantity and quality of those scholars' research efforts, and this under-representation in turn results in disproportionately reduced acceptance of the results of their efforts as contributions to the body of knowledge available worldwide.\n\nThe open access movement assumes that all information generally deemed useful should be free and belongs to a “public domain”, that of “humanity”. This idea gained prevalence as a result of Western colonial history and ignores alternative conceptions of knowledge circulation. For instance, most indigenous communities consider that access to certain information proper to the group should be determined by relationships.\n\nThere is alleged to be a double standard in the Western knowledge system. On the one hand, “digital right management” used to restrict access to personal information on social networking platforms is celebrated as a protection of privacy, while simultaneously when similar functions are utilised by cultural groups (i.e. indigenous communities) this is denounced as “access control” and reprehended as censorship.\n\nEven though Western dominance seems to be prominent in research, some scholars, such as Simon Marginson, argue for “the need [for] a plural university world”. Marginson argues that the East Asian Confucian model could take over the Western model.\n\nThis could be due to changes in funding for research both in the East and the West. Focussed on emphasizing educational achievement, East Asian cultures, mainly in China and South Korea, have encouraged the increase of funding for research expansion. In contrast, in the Western academic world, notably in the United Kingdom as well as in some state governments in the United States, funding cuts for university research have occurred, which some say may lead to the future decline of Western dominance in research.\n\nIn several national and private academic systems, the professionalisation of research has resulted in formal job titles.\n\nIn present-day Russia, the former Soviet Union and in some post-Soviet states the term \"researcher\" (, \"nauchny sotrudnik\") is both a generic term for a person who carried out scientific research, as well as a job position within the frameworks of the USSR Academy of Sciences, Soviet universities, and in other research-oriented establishments. The term is also sometimes translated as \"research fellow\", \"research associate\", etc.\n\nThe following ranks are known:\n\n\nAcademic publishing is a system that is necessary in order for academic scholars to peer review the work and make it available for a wider audience. The system varies widely by field and is also always changing, if often slowly. Most academic work is published in journal article or book form. There is also a large body of research that exists in either a thesis or dissertation form. These forms of research can be found in databases explicitly for theses and dissertations. In publishing, STM publishing is an abbreviation for academic publications in science, technology, and medicine.\n\nMost established academic fields have their own scientific journals and other outlets for publication, though many academic journals are somewhat interdisciplinary, and publish work from several distinct fields or subfields. The kinds of publications that are accepted as contributions of knowledge or research vary greatly between fields, from the print to the electronic format. A study suggests that researchers should not give great consideration to findings that are not replicated frequently. It has also been suggested that all published studies should be subjected to some measure for assessing the validity or reliability of its procedures in order to prevent the publication of unproven findings. Business models are different in the electronic environment. Since about the early 1990s, licensing of electronic resources, particularly journals, has been very common. Presently, a major trend, particularly with respect to scholarly journals, is open access. There are two main forms of open access: open access publishing, in which the articles or the whole journal is freely available from the time of publication, and self-archiving, where the author makes a copy of their own work freely available on the web.\n\nMost funding for scientific research comes from three major sources: corporate research and development departments; private foundations, for example, the Bill and Melinda Gates Foundation; and government research councils such as the National Institutes of Health in the USA and the Medical Research Council in the UK. These are managed primarily through universities and in some cases through military contractors. Many senior researchers (such as group leaders) spend a significant amount of their time applying for grants for research funds. These grants are necessary not only for researchers to carry out their research but also as a source of merit.\n\nThe Social Psychology Network provides a comprehensive list of U.S. Government and private foundation funding sources.\n\n\n\n"}
{"id": "25525", "url": "https://en.wikipedia.org/wiki?curid=25525", "title": "René Descartes", "text": "René Descartes\n\nRené Descartes (; ; Latinized: Renatus Cartesius; adjectival form: \"Cartesian\"; 31 March 159611 February 1650) was a French philosopher, mathematician, and scientist. Dubbed the father of modern western philosophy, much of subsequent Western philosophy is a response to his writings, which are studied closely to this day. A native of the Kingdom of France, he spent about 20 years (1629–49) of his life in the Dutch Republic after serving for a while in the Dutch States Army of Maurice of Nassau, Prince of Orange and the Stadtholder of the United Provinces. He is generally considered one of the most notable intellectual representatives of the Dutch Golden Age.\n\nDescartes's \"Meditations on First Philosophy\" continues to be a standard text at most university philosophy departments. Descartes's influence in mathematics is equally apparent; the Cartesian coordinate system (see below) was named after him. He is credited as the father of analytical geometry, the bridge between algebra and geometry, used in the discovery of infinitesimal calculus and analysis. Descartes was also one of the key figures in the scientific revolution.\n\nDescartes refused to accept the authority of previous philosophers. He frequently set his views apart from those of his predecessors. In the opening section of the \"Les passions de l'âme\", a treatise on the early modern version of what are now commonly called emotions, Descartes goes so far as to assert that he will write on this topic \"as if no one had written on these matters before\". His best known philosophical statement is \"\"Cogito ergo sum\"\" (; \"I think, therefore I am\"), found in part IV of \"Discours de la méthode\" (1637; written in French but with inclusion of \"\"Cogito ergo sum\"\") and §7 of part I of \"Principles of Philosophy\" (1644; written in Latin).\n\nMany elements of his philosophy have precedents in late Aristotelianism, the revived Stoicism of the 16th century, or in earlier philosophers like Augustine. In his natural philosophy, he differed from the schools on two major points: first, he rejected the splitting of corporeal substance into matter and form; second, he rejected any appeal to final ends, divine or natural, in explaining natural phenomena. In his theology, he insists on the absolute freedom of God's act of creation.\n\nDescartes laid the foundation for 17th-century continental rationalism, later advocated by Baruch Spinoza and Gottfried Leibniz, and opposed by the empiricist school of thought consisting of Hobbes, Locke, Berkeley, and Hume. Leibniz, Spinoza and Descartes were all well-versed in mathematics as well as philosophy, and Descartes and Leibniz contributed greatly to science as well.\n\nDescartes was born in La Haye en Touraine (now Descartes, Indre-et-Loire), France, on 31 March 1596. When he was one year old, his mother Jeanne Brochard died after trying to give birth to another child who also died. His father Joachim was a member of the Parlement of Brittany at Rennes. René lived with his grandmother and with his great-uncle. Although the Descartes family was Roman Catholic, the Poitou region was controlled by the Protestant Huguenots. In 1607, late because of his fragile health, he entered the Jesuit Collège Royal Henry-Le-Grand at La Flèche, where he was introduced to mathematics and physics, including Galileo's work. After graduation in 1614, he studied two years (1615–16) at the University of Poitiers, earning a \"Baccalauréat\" and \"Licence\" in Canon and Civil Law, in accordance with his father's wishes that he should become a lawyer. From there he moved to Paris.\n\nIn his book \"Discourse on the Method\", Descartes recalls,\nI entirely abandoned the study of letters. Resolving to seek no knowledge other than that of which could be found in myself or else in the great book of the world, I spent the rest of my youth traveling, visiting courts and armies, mixing with people of diverse temperaments and ranks, gathering various experiences, testing myself in the situations which fortune offered me, and at all times reflecting upon whatever came my way so as to derive some profit from it.\n\nGiven his ambition to become a professional military officer, in 1618, Descartes joined, as a mercenary, the Protestant Dutch States Army in Breda under the command of Maurice of Nassau, and undertook a formal study of military engineering, as established by Simon Stevin. Descartes, therefore, received much encouragement in Breda to advance his knowledge of mathematics. In this way, he became acquainted with Isaac Beeckman, principal of a Dordrecht school, for whom he wrote the Compendium of Music (written 1618, published 1650). Together they worked on free fall, catenary, conic section, and fluid statics. Both believed that it was necessary to create a method that thoroughly linked mathematics and physics.\n\nWhile in the service of the Catholic Duke Maximilian of Bavaria since 1619, Descartes was present at the Battle of the White Mountain outside Prague, in November 1620. He visited the labs of Tycho Brahe in Prague and Johannes Kepler in Regensburg.\n\nAccording to Adrien Baillet, on the night of 10–11 November 1619 (St. Martin's Day), while stationed in Neuburg an der Donau, Descartes shut himself in a room with an \"oven\" (probably a \"Kachelofen\" or masonry heater) to escape the cold. While within, he had three visions and believed that a divine spirit revealed to him a new philosophy. Upon exiting, he had formulated analytical geometry and the idea of applying the mathematical method to philosophy. He concluded from these visions that the pursuit of science would prove to be, for him, the pursuit of true wisdom and a central part of his life's work. Descartes also saw very clearly that all truths were linked with one another so that finding a fundamental truth and proceeding with logic would open the way to all science. Descartes discovered this basic truth quite soon: his famous \"I think, therefore I am\".\n\nIn 1620 Descartes left the army. He visited Basilica della Santa Casa in Loreto, then visited various countries before returning to France, and during the next few years spent time in Paris. It was there that he composed his first essay on method: \"Regulae ad Directionem Ingenii\" (Rules for the Direction of the Mind). He arrived in La Haye in 1623, selling all of his property to invest in bonds, which provided a comfortable income for the rest of his life. Descartes was present at the siege of La Rochelle by Cardinal Richelieu in 1627. In the fall of the same year, in the residence of the papal nuncio Guidi di Bagno, where he came with Mersenne and many other scholars to listen to a lecture given by the alchemist Nicolas de Villiers, Sieur de Chandoux on the principles of a supposed new philosophy, Cardinal Bérulle urged him to write an exposition of his own new philosophy.\n\nDescartes returned to the Dutch Republic in 1628. In April 1629 he joined the University of Franeker, studying under Adriaan Metius, living either with a Catholic family, or renting the Sjaerdemaslot, where he invited in vain a French cook and an optician. The next year, under the name \"Poitevin\", he enrolled at the Leiden University to study mathematics with Jacobus Golius, who confronted him with Pappus's hexagon theorem, and astronomy with Martin Hortensius. In October 1630 he had a falling-out with Beeckman, whom he accused of plagiarizing some of his ideas. In Amsterdam, he had a relationship with a servant girl, Helena Jans van der Strom, with whom he had a daughter, Francine, who was born in 1635 in Deventer.\nUnlike many moralists of the time, Descartes was not devoid of passions but rather defended them; he wept upon Francine's death in 1640. \"Descartes said that he did not believe that one must refrain from tears to prove oneself a man.\" Russell Shorto postulated that the experience of fatherhood and losing a child formed a turning point in Descartes' work, changing its focus from medicine to a quest for universal answers.\n\nDespite frequent moves, he wrote all his major work during his 20+ years in the Netherlands, where he managed to revolutionize mathematics and philosophy. In 1633, Galileo was condemned by the Catholic Church, and Descartes abandoned plans to publish \"Treatise on the World\", his work of the previous four years. Nevertheless, in 1637 he published part of this work in three essays: \"Les Météores\" (The Meteors), \"La Dioptrique\" (Dioptrics) and \"La Géométrie\" (Geometry), preceded by an introduction, his famous \"Discours de la méthode\" (Discourse on the Method). In it, Descartes lays out four rules of thought, meant to ensure that our knowledge rests upon a firm foundation.\n\nDescartes continued to publish works concerning both mathematics and philosophy for the rest of his life. In 1641 he published a metaphysics work, \"Meditationes de Prima Philosophia\" (Meditations on First Philosophy), written in Latin and thus addressed to the learned. It was followed, in 1644, by \"Principia Philosophiæ\" (Principles of Philosophy), a kind of synthesis of the \"Discourse on the Method\" and \"Meditations on First Philosophy\". In 1643, Cartesian philosophy was condemned at the University of Utrecht, and Descartes was obliged to flee to the Hague, but settled in Egmond-Binnen, where he married his servant Helena (see above) the son of the innkeeper.\n\nDescartes began (through Alfonso Polloti, an Italian general in Dutch service) a long correspondence with Princess Elisabeth of Bohemia, devoted mainly to moral and psychological subjects. Connected with this correspondence, in 1649 he published \"Les Passions de l'âme\" (Passions of the Soul), that he dedicated to the Princess. In 1647, he was awarded a pension by the Louis XIV of France, though it was never paid. A French translation of \"Principia Philosophiæ\", prepared by Abbot Claude Picot, was published in 1647. This edition Descartes also dedicated to Princess Elisabeth. In the preface to the French edition, Descartes praised true philosophy as a means to attain wisdom. He identifies four ordinary sources to reach wisdom and finally says that there is a fifth, better and more secure, consisting in the search for first causes.\n\nQueen Christina of Sweden invited Descartes to her court in 1649 to organize a new scientific academy and tutor her in his ideas about love. She was interested in and stimulated Descartes to publish the \"Passions of the Soul\", a work based on his correspondence with Princess Elisabeth.\n\nHe was a guest at the house of Pierre Chanut, living on Västerlånggatan, less than 500 meters from Tre Kronor in Stockholm. There, Chanut and Descartes made observations with a Torricellian barometer, a tube with mercury. Challenging Blaise Pascal, Descartes took the first set of barometric readings in Stockholm to see if atmospheric pressure could be used in forecasting the weather.\n\nDescartes apparently started giving lessons to Queen Christina after her birthday, three times a week, at 5 a.m, in her cold and draughty castle. Soon it became clear they did not like each other; she did not like his mechanical philosophy, nor did he appreciate her interest in Ancient Greek. By 15 January 1650, Descartes had seen Christina only four or five times. On 1 February he caught a cold which quickly turned into a serious respiratory infection, and he died on 11 February. The cause of death was pneumonia according to Chanut, but peripneumonia according to the doctor Van Wullen who was not allowed to bleed him. (The winter seems to have been mild, except for the second half of January which was harsh as described by Descartes himself; however, \"this remark was probably intended to be as much Descartes' take on the intellectual climate as it was about the weather.\")\n\nIn 1996 E. Pies, a German scholar, published a book questioning this account, based on a letter by Johann van Wullen, who had been sent by Christina to treat him, something Descartes refused, and more arguments against its veracity have been raised since. Descartes might have been assassinated as he asked for an emetic: wine mixed with tobacco.\nAs a Catholic in a Protestant nation, he was interred in a graveyard used mainly for orphans in Adolf Fredriks kyrka in Stockholm. His manuscripts came into the possession of Claude Clerselier, Chanut's brother-in-law, and \"a devout Catholic who has begun the process of turning Descartes into a saint by cutting, adding and publishing his letters selectively.\" In 1663, the Pope placed his works on the Index of Prohibited Books. In 1666 his remains were taken to France and buried in the Saint-Étienne-du-Mont. In 1671 Louis XIV prohibited all the lectures in Cartesianism. Although the National Convention in 1792 had planned to transfer his remains to the Panthéon, he was reburied in the Abbey of Saint-Germain-des-Prés in 1819, missing a finger and skull. His skull is on display in the Musee de l'Homme in Paris.\n\nDescartes is often regarded as the first thinker to emphasize the use of reason to develop the natural sciences. For him the philosophy was a thinking system that embodied all knowledge, and expressed it in this way:\n\nIn his \"Discourse on the Method\", he attempts to arrive at a fundamental set of principles that one can know as true without any doubt. To achieve this, he employs a method called hyperbolical/metaphysical doubt, also sometimes referred to as methodological skepticism: he rejects any ideas that can be doubted and then reestablishes them in order to acquire a firm foundation for genuine knowledge.\n\nDescartes built his ideas from scratch. He relates this to architecture: the top soil is taken away to create a new building or structure. Descartes calls his doubt the soil and new knowledge the buildings. To Descartes, Aristotle’s foundationalism is incomplete and his method of doubt enhances foundationalism.\n\nInitially, Descartes arrives at only a single principle: thought exists. Thought cannot be separated from me, therefore, I exist (\"Discourse on the Method\" and \"Principles of Philosophy\"). Most famously, this is known as \"cogito ergo sum\" (English: \"I think, therefore I am\"). Therefore, Descartes concluded, if he doubted, then something or someone must be doing the doubting, therefore the very fact that he doubted proved his existence. \"The simple meaning of the phrase is that if one is skeptical of existence, that is in and of itself proof that he does exist.\"\n\nDescartes concludes that he can be certain that he exists because he thinks. But in what form? He perceives his body through the use of the senses; however, these have previously been unreliable. So Descartes determines that the only indubitable knowledge is that he is a \"thinking thing\". Thinking is what he does, and his power must come from his essence. Descartes defines \"thought\" (\"cogitatio\") as \"what happens in me such that I am immediately conscious of it, insofar as I am conscious of it\". Thinking is thus every activity of a person of which the person is immediately conscious.\n\nTo further demonstrate the limitations of these senses, Descartes proceeds with what is known as the \"Wax Argument\". Descartes concludes that his senses are similar to wax. Wax changes its characteristics when exposed to flame, but it is still the same. He compares himself to this wax and rejects his senses and considers his mind the only thing he can trust. It is the never changing characteristics.\n\nTherefore, to properly grasp the nature of the wax, he should put aside the senses. He must use his mind. Descartes concludes:\nIn this manner, Descartes proceeds to construct a system of knowledge, discarding perception as unreliable and, instead, admitting only deduction as a method. In the third and fifth \"Meditation\", he offers an ontological proof of a benevolent God (through both the ontological argument and trademark argument). Because God is benevolent, he can have some faith in the account of reality his senses provide him, for God has provided him with a working mind and sensory system and does not desire to deceive him. From this supposition, however, he finally establishes the possibility of acquiring knowledge about the world based on deduction \"and\" perception. Regarding epistemology, therefore, he can be said to have contributed such ideas as a rigorous conception of foundationalism and the possibility that reason is the only reliable method of attaining knowledge. He, nevertheless, was very much aware that experimentation was necessary to verify and validate theories.\n\nDescartes also wrote a response to External world scepticism. Through this method of scepticism, he does not doubt for the sake of doubting but to achieve concrete and reliable information. In other words, certainty. He argues that sensory perceptions come to him involuntarily, and are not willed by him. They are external to his senses, and according to Descartes, this is evidence of the existence of something outside of his mind, and thus, an external world. Descartes goes on to show that the things in the external world are material by arguing that God would not deceive him as to the ideas that are being transmitted, and that God has given him the \"propensity\" to believe that such ideas are caused by material things. Descartes also believes a substance is something that does not need any assistance to function or exist. Descartes further explains how only God can be a true “substance”. But minds are substances, meaning they need only God for it to function. The mind is a thinking substance. The means for a thinking substance stem from ideas.\n\nHe gave reasons for thinking that waking thoughts are distinguishable from dreams, and that one's mind cannot have been \"hijacked\" by an evil demon placing an illusory external world before one's senses. The Evil Genius Doubt that arises from doubting simple concepts like basic mathematics and geometry. The Evil Genius or evil demon doubt is an external force who is capable of deception.\n\nThere are three kinds of ideas, explained Descartes, Fabricated, Innate and Adventitious. Fabricated ideas are inventions made by the mind. For example, a person has never eaten moose but assumes it tastes like cow. Adventitious ideas are ideas that cannot be manipulated or changed by the mind. For example, a person stands in a cold room, they can only think of the feeling as cold and nothing else. Innate ideas are set ideas made by God in a person’s mind. For example, The features of a shape can be examined and set aside, but its content can never be manipulated to cause it not to be a three sided object.\n\nDescartes, influenced by the Automatons on display throughout the city of Paris, began to investigate the connection between the mind and body. The main influences for Dualism were theology and physics and how the two interact. Descartes in his \"Passions of the Soul\" and \"The Description of the Human Body\" suggested that the body works like a machine, that it has material properties. The mind (or soul), on the other hand, was described as a nonmaterial and does not follow the laws of nature. Descartes argued that the mind interacts with the body at the pineal gland. This form of dualism or duality proposes that the mind controls the body, but that the body can also influence the otherwise rational mind, such as when people act out of passion. Most of the previous accounts of the relationship between mind and body had been uni-directional.\n\nDescartes suggested that the pineal gland is \"the seat of the soul\" for several reasons. First, the soul is unitary, and unlike many areas of the brain the pineal gland appeared to be unitary (though subsequent microscopic inspection has revealed it is formed of two hemispheres). Second, Descartes observed that the pineal gland was located near the ventricles. He believed the cerebrospinal fluid of the ventricles acted through the nerves to control the body, and that the pineal gland influenced this process. Sensations delivered by the nerves to the pineal, he believed, caused it to vibrate in some sympathetic manner, which in turn gave rise to the emotions and caused the body to act. Cartesian dualism set the agenda for philosophical discussion of the mind–body problem for many years after Descartes' death.\n\nDescartes denied that animals had reason or intelligence, but did not lack sensations or perceptions, but these could be explained mechanistically. Descartes argued the theory of Innate knowledge and that all humans were born with knowledge through a higher power (religion). It was this theory of Innate knowledge that later led philosopher John Locke (1632-1704) to combat this theory of empiricism (that all knowledge is acquired through experience).\n\nFor Descartes, ethics was a science, the highest and most perfect of them. Like the rest of the sciences, ethics had its roots in metaphysics. In this way, he argues for the existence of God, investigates the place of man in nature, formulates the theory of mind-body dualism, and defends free will. However, as he was a convinced rationalist, Descartes clearly states that reason is sufficient in the search for the goods that we should seek, and virtue consists in the correct reasoning that should guide our actions. Nevertheless, the quality of this reasoning depends on knowledge, because a well-informed mind will be more capable of making good choices, and it also depends on mental condition. For this reason, he said that a complete moral philosophy should include the study of the body. He discussed this subject in the correspondence with Princess Elisabeth of Bohemia, and as a result wrote his work \"The Passions of the Soul\", that contains a study of the psychosomatic processes and reactions in man, with an emphasis on emotions or passions.\n\nHumans should seek the sovereign good that Descartes, following Zeno, identifies with virtue, as this produces a solid blessedness or pleasure. For Epicurus the sovereign good was pleasure, and Descartes says that, in fact, this is not in contradiction with Zeno's teaching, because virtue produces a spiritual pleasure, that is better than bodily pleasure. Regarding Aristotle's opinion that happiness depends on the goods of fortune, Descartes does not deny that this good contributes to happiness but remarks that they are in great proportion outside one's own control, whereas one's mind is under one's complete control.\n\nThe moral writings of Descartes came at the last part of his life, but earlier, in his \"Discourse on the Method\" he adopted three maxims to be able to act while he put all his ideas into doubt. This is known as his .\n\nIn his \"Meditations on First Philosophy\" Descartes sets forth two proofs for God's existence. One of these is founded upon the possibility of thinking the \"idea of a being that is supremely perfect and infinite,\" and suggests that \"of all the ideas that are in me, the idea that I have of God is the most true, the most clear and distinct.\" Descartes considered himself to be a devout Catholic and one of the purposes of the \"Meditations\" was to defend the Catholic faith. His attempt to ground theological beliefs on reason encountered intense opposition in his time, however: Pascal regarded Descartes' views as rationalist and mechanist, and accused him of deism: \"I cannot forgive Descartes; in all his philosophy, Descartes did his best to dispense with God. But Descartes could not avoid prodding God to set the world in motion with a snap of his lordly fingers; after that, he had no more use for God,\" while a powerful contemporary, Martin Schoock, accused him of atheist beliefs, though Descartes had provided an explicit critique of atheism in his \"Meditations\". The Catholic Church prohibited his books in 1663.\n\nDescartes has often been dubbed the father of modern Western philosophy, the thinker whose approach has profoundly changed the course of Western philosophy and set the basis for modernity. The first two of his \"Meditations on First Philosophy\", those that formulate the famous methodic doubt, represent the portion of Descartes' writings that most influenced modern thinking. It has been argued that Descartes himself didn't realize the extent of this revolutionary move. In shifting the debate from \"what is true\" to \"of what can I be certain?,\" Descartes arguably shifted the authoritative guarantor of truth from God to humanity (even though Descartes himself claimed he received his visions from God) – while the traditional concept of \"truth\" implies an external authority, \"certainty\" instead relies on the judgment of the individual.\n\nIn an anthropocentric revolution, the human being is now raised to the level of a subject, an agent, an emancipated being equipped with autonomous reason. This was a revolutionary step that established the basis of modernity, the repercussions of which are still being felt: the emancipation of humanity from Christian revelational truth and Church doctrine; humanity making its own law and taking its own stand. In modernity, the guarantor of truth is not God anymore but human beings, each of whom is a \"self-conscious shaper and guarantor\" of their own reality. In that way, each person is turned into a reasoning adult, a subject and agent, as opposed to a child obedient to God. This change in perspective was characteristic of the shift from the Christian medieval period to the modern period, a shift that had been anticipated in other fields, and which was now being formulated in the field of philosophy by Descartes.\n\nThis anthropocentric perspective of Descartes' work, establishing human reason as autonomous, provided the basis for the Enlightenment's emancipation from God and the Church. It also provided the basis for all subsequent anthropology. Descartes' philosophical revolution is sometimes said to have sparked modern anthropocentrism and subjectivism.\n\nOne of Descartes' most enduring legacies was his development of Cartesian or analytic geometry, which uses algebra to describe geometry. He \"invented the convention of representing unknowns in equations by \"x\", \"y\", and \"z\", and knowns by \"a\", \"b\", and \"c\"\". He also \"pioneered the standard notation\" that uses superscripts to show the powers or exponents; for example, the 4 used in x to indicate squaring of squaring. He was first to assign a fundamental place for algebra in our system of knowledge, using it as a method to automate or mechanize reasoning, particularly about abstract, unknown quantities. European mathematicians had previously viewed geometry as a more fundamental form of mathematics, serving as the foundation of algebra. Algebraic rules were given geometric proofs by mathematicians such as Pacioli, Cardan, Tartaglia and Ferrari. Equations of degree higher than the third were regarded as unreal, because a three-dimensional form, such as a cube, occupied the largest dimension of reality. Descartes professed that the abstract quantity \"a\" could represent length as well as an area. This was in opposition to the teachings of mathematicians, such as Vieta, who argued that it could represent only area. Although Descartes did not pursue the subject, he preceded Leibniz in envisioning a more general science of algebra or \"universal mathematics,\" as a precursor to symbolic logic, that could encompass logical principles and methods symbolically, and mechanize general reasoning.\n\nDescartes' work provided the basis for the calculus developed by Newton and Leibniz, who applied infinitesimal calculus to the tangent line problem, thus permitting the evolution of that branch of modern mathematics. His rule of signs is also a commonly used method to determine the number of positive and negative roots of a polynomial.\n\nDescartes discovered an early form of the law of conservation of mechanical momentum (a measure of the motion of an object), and envisioned it as pertaining to motion in a straight line, as opposed to perfect circular motion, as Galileo had envisioned it. He outlined his views on the universe in his \"Principles of Philosophy\".\n\nDescartes also made contributions to the field of optics. He showed by using geometric construction and the law of refraction (also known as Descartes' law or more commonly Snell's law) that the angular radius of a rainbow is 42 degrees (i.e., the angle subtended at the eye by the edge of the rainbow and the ray passing from the sun through the rainbow's centre is 42°). He also independently discovered the law of reflection, and his essay on optics was the first published mention of this law.\n\nCurrent opinion is that Descartes had the most influence of anyone on the young Newton, and this is arguably one of Descartes' most important contributions. Newton continued Descartes' work on cubic equations, which freed the subject from the fetters of the Greek perspectives. The most important concept was his very modern treatment of independent variables.\n\nAlthough Descartes was well known in academic circles towards the end of his life, the teaching of his works in schools was controversial. Henri de Roy (Henricus Regius, 1598–1679), Professor of Medicine at the University of Utrecht, was condemned by the Rector of the University, Gijsbert Voet (Voetius), for teaching Descartes' physics.\n\n\nIn January 2010, a previously unknown letter from Descartes, dated 27 May 1641, was found by the Dutch philosopher Erik-Jan Bos when browsing through Google. Bos found the letter mentioned in a summary of autographs kept by Haverford College in Haverford, Pennsylvania. The College was unaware that the letter had never been published. This was the third letter by Descartes found in the last 25 years.\n\n\n\n\n\n\nGeneral\n\nBibliographies\n\nStanford Encyclopedia of Philosophy\n\nInternet Encyclopedia of Philosophy\n\nOther\n"}
{"id": "25529", "url": "https://en.wikipedia.org/wiki?curid=25529", "title": "Romansh language", "text": "Romansh language\n\nRomansh\n(also spelled Romansch, Rumantsch, or Romanche; Romansh: , \"rumàntsch\", or ) is a Romance language spoken predominantly in the southeastern Swiss canton of Grisons (Graubünden), where it has official status alongside German and Italian and is used as the medium of instruction in schools in Romansh-speaking areas. Romansh has also been recognized as a national language of Switzerland since 1938 and as an official language along with German, French and Italian since 1996. It is sometimes grouped with Ladin and Friulian as a Rhaeto-Romance language, though this is disputed.\n\nRomansh is a descendant of the spoken Latin language of the Roman Empire, which by the 5th century AD replaced the Celtic and Raetic languages previously spoken in the area, although Romansh retains a small number of words from these languages. Romansh has also been heavily influenced by German in vocabulary and morphosyntax. The language gradually retreated to its current area over the centuries, being replaced by Alemannic and Bavarian dialects. The earliest writing identified as Romansh dates from the 10th or 11th century, although major works do not appear until the 16th century when several regional written varieties began to develop. The 19th century saw a further shrinkage of the language area but also a literary revival and the start of a language movement dedicated to halting the decline of the language.\n\nIn the 2000 Swiss census, 35,095 people (of whom 27,038 live in the canton of Grisons) indicated Romansh as the language of \"best command\", and 61,815 as a \"regularly spoken\" language. In 2010, Switzerland switched to a yearly system which uses a combination of municipal citizen records and a limited number of surveys. Based on this yearly system, the number of people aged 15 and above reporting Romansh as their main language was 36,622 in 2012. Spoken by around 0.9% of Switzerland's 7.7 million inhabitants, Romansh is Switzerland's least-used national language in terms of number of speakers and the eleventh most spoken language in Switzerland overall. The language area and number of speakers of Romansh have been continually shrinking, though language use remains vigorous in certain areas.\n\nRomansh is divided into five different regional dialects (Sursilvan, Sutsilvan, Surmiran, Putèr, and Vallader), each with its own standardized written language. In addition, a pan-regional variety called Rumantsch Grischun was introduced in 1982, which is controversial among Romansh speakers.\n\nRomansh is a Romance language descending from Vulgar Latin, the spoken language of the Roman Empire. Within the Romance languages, Romansh stands out because of its peripheral location, which manifests itself through several archaic features. Another distinguishing feature is the centuries-long language contact with German, which is most noticeable in the vocabulary and to a lesser extent the syntax of Romansh. Romansh belongs to the Gallo-Romance branch of the Romance languages, which includes languages such as French, Occitan, and Lombard. The main feature placing Romansh within the Gallo-Romance languages is the fronting of Latin to or , as seen in Latin \"muru(m)\" 'wall', which is or in Romansh. The main features distinguishing Romansh from the Gallo-Italic languages to the south are:\nAnother defining feature of the Romansh language is the use of unstressed vowels. All unstressed vowels (except /a/) disappeared.\nWhether or not Romansh, Friulan and Ladin should compose a separate \"Rhaeto-Romance\" subgroup within Gallo-Romance is an unresolved issue, known as the \"Questione ladina\". Some linguists posit that these languages are descended from a common language, which was then fractured geographically through the spread of German and Italian. This position goes back to the Italian linguist Graziadio Ascoli, who first made the claim in 1873.\n\nThe other position holds that any similarities between these three languages can be explained through their relative geographic isolation, which shielded them from certain linguistic changes, whereas the Gallo-Italic varieties of Northern Italy were more open to linguistic influences from the South. Linguists who take this position often point out that the similarities between the languages are comparatively few. This position was first introduced by the Italian dialectologist Carlo Battisti. This linguistic dispute became politically relevant for the Italian irredentist movement. Italian nationalists interpreted Battisti's hypothesis as implying that Romansh, Friulan and Ladin were not separate languages but rather Italian dialects. They used this as an argument to claim the territories where these languages were spoken for Italy. From a sociolinguistic perspective, however, this question is largely irrelevant, since the speakers of Romansh have always identified as speaking a language distinct from both Italian and other Romance varieties.\n\nRomansh comprises a group of closely related dialects, which are most commonly divided into five different varieties, each of which has developed a standardized form. These standardized regional standards are referred to as \"idioms\" in Romansh to distinguish them from the local vernaculars, which are referred to as \"dialects\". These dialects form a dialect continuum without clear-cut divisions. Historically a continuous speech area, this continuum has now been ruptured by the spread of German, so that Romansh is now geographically divided into at least two non-adjacent parts.\n\nAside from these five major dialects, two additional varieties are often distinguished. One is the dialect of the Val Müstair, which is closely related to Vallader but often separately referred to as \"Jauer\" (derived from the personal pronoun \"jau\" 'I', i.e. 'the \"jau\"-sayers'). Less commonly distinguished is the dialect of Tujetsch and the Val Medel, which is markedly different from Sursilvan and is referred to as \"Tuatschin\". Additionally, the standardized variety Rumantsch Grischun intended for pan-regional use has been introduced since 1982. The dialect of the Val Bregaglia is usually considered a variety of Lombard and speakers use Italian as their written language, even though the dialect shares many features with the neighboring Putèr dialect of Romansh.\n\nAs these varieties form a continuum with small transitions from each village to the next, there is no straightforward internal grouping of the Romansh dialects. The Romansh language area can be described best as consisting of two widely divergent varieties, Sursilvan in the west and the dialects of the Engadine in the east, with Sutsilvan and Surmiran forming a transition zone between them. The Engadinese varieties \"Putèr\" and \"Vallader\" are often referred to as one specific variety known as \"Ladin\" (rm. ), which is not to be confused with the closely related language in Italy's Dolomite mountains also known as Ladin. Sutsilvan and Surmiran are sometimes grouped together as Central Romansh (rm. \"Grischun central\"), and then grouped together with Sursilvan as \"Rhenish Romansh\".\n\nOne feature that separates the Rhenish varieties from Ladin is the retention of the rounded front vowels and (written \"ü\" and \"ö\") in Ladin, which have been unrounded in the other dialects, as in Ladin , Sursilvan , Surmiran \"meir\" ‘wall’ or Ladin to Rhenish ‘cheese’. Another is the development of Latin -CT-, which has developed into /tɕ/ in the Rhenish varieties as in \"détg\" ‘said’ or \"fatg\" ‘did’, while developing into /t/ in Ladin (\"dit\" and \"fat\"). A feature separating Sursilvan from Central Romansh however, involves the extent of palatalization of Latin K in front of A, which is rare in Sursilvan but common in the other varieties: Sursilvan , Sutsilvan \"tgea\", Surmiran \"tgesa\", Putèr , and Vallader 'house'. Overall however, the Central Romansh varieties do not share many unique features, but rather connect Sursilvan and Ladin through a succession of numerous small dialect differences from one village to the next.\nThe dialects of Romansh are not always mutually comprehensible. Speakers of Sursilvan and Ladin in particular, are usually unable to understand each other initially. Because speakers usually identify themselves primarily with their regional dialect, many do not take the effort to attempt to understand unfamiliar dialects, and prefer to speak Swiss German with speakers of other varieties. A common Romansh identity is not widespread outside of intellectual circles, even though this has been changing among the younger generation.\n\nRomansh originates from the spoken Latin brought to the region by Roman soldiers, merchants, and officials following the conquest of the modern-day Grisons area by the Romans in 15 BC. Before that, the inhabitants spoke Celtic and Raetic languages, with Raetic apparently being spoken mainly in the Lower Engadine valley. Traces of these languages survive mainly in toponyms, including village names such as Tschlin, Scuol, Savognin, Glion, Breil/Brigels, Brienz/Brinzauls, Purtenza, and Trun. Additionally, a small number of pre-Latin words have survived in Romansh, mainly concerning animals, plants, and geological features unique to the Alps, such as \"camutsch\" 'chamois' and \"grava\" 'scree'.\n\nIt is unknown how rapidly the Celtic and Raetic inhabitants were Romanized following the conquest of Raetia. Some linguists assume that the area was rapidly Romanized following the Roman conquest, whereas others think that this process did not end until the 4th or 5th century, when more thoroughly Romanized Celts from farther north fled south to avoid invasions by Germanic tribes. The process was certainly complete and the pre-Roman languages extinct by the 5th–6th century, when Raetia became part of the Ostrogothic Kingdom. Around 537 AD, the Ostrogoths handed over the province of Raetia Prima to the Frankish Empire, which continued to have local rulers administering the so-called Duchy of Chur. However, after the death of the last Victorid ruler, Bishop Tello, around 765, Charlemagne assigned a Germanic duke to administer the region. Additionally, the Diocese of Chur was transferred by the Roman Catholic Church from the Archdiocese of Milan to the Diocese of Mainz in 843. The combined effect was a cultural reorientation towards the German-speaking north, especially as the ruling élite now comprised almost entirely speakers of German.\n\nAt the time, Romansh was spoken over a much wider area, stretching north into the present-day cantons of Glarus and St. Gallen, to the Walensee in the northwest, and Rüthi and the Alpine Rhine Valley in the northeast. In the east, parts of modern-day Vorarlberg were Romansh-speaking, as were parts of Tyrol. The northern areas, called Lower Raetia, became German-speaking by the 12th century; and by the 15th century, the Rhine Valley of St. Gallen and the areas around the Wallensee were entirely German-speaking. This language shift was a long, drawn-out process, with larger, central towns adopting German first, while the more peripheral areas around them remained Romansh-speaking longer. The shift to German was caused in particular by the influence of the local German-speaking élites and by German-speaking immigrants from the north, with the lower and rural classes retaining Romansh longer.\n\nIn addition, beginning around 1270, the German-speaking Walser began settling in sparsely populated or uninhabited areas within the Romansh-speaking heartland. The Walser sometimes expanded into Romansh-speaking areas from their original settlements, which then often became German-speaking, such as Davos, Schanfigg, the Prättigau, Schams, and Valendas, which became German-speaking by the 14th century. In rare cases, these Walser settlements were eventually assimilated by their Romansh-speaking neighbors, for instance, Oberhalbstein and Medel and Tujetsch in the Surselva region.\n\nThe Germanization of Chur had particular long-term consequences. Even though the city had long before ceased to be a cultural center of Romansh, the spoken language of the capital of the Diocese of Chur continued to be Romansh until the 15th century. After a fire in 1465 which virtually destroyed the city, many German-speaking artisans who had been called in to help repair the damage settled there, causing German to become the majority language. In a chronicle written in 1571-72, Durich Chiampell mentions that Romansh was still spoken in Chur roughly a hundred years before, but had since then rapidly given way to German and was now not much appreciated by the inhabitants of the city. Many linguists regard the loss of Chur to German as a crucial event. According to Sylvia Osswald, for example, it occurred precisely at a time when the introduction of the printing press could have led to the adoption of the Romansh dialect of the capital as a common written language for all Romansh speakers. Other linguists such as Jachen Curdin Arquint remain skeptical of this view, however, and assume that the various Romansh-speaking regions would still have developed their own separate written standards.\n\nInstead, several regional written varieties of Romansh began appearing during the 16th century. Gian Travers wrote the first surviving work in Romansh, the \"Chianzun dalla guerra dagl Chiaste da Müs\", in the Putèr dialect. This epic poem, written in 1527, describes the first Musso war, in which Travers himself had taken part. Travers also translated numerous biblical plays into Romansh, though only the titles survive for many of them. Another early writer, Giachem Bifrun, who also wrote in Putèr, penned the first printed book in Romansh, a catechism published in 1552. In 1560 he published a translation of the New Testament: \"L'g Nuof Sainc Testamaint da nos Signer Jesu Christ\".\n\nTwo years later, in 1562, another writer from the Engadine, Durich Chiampel, published the \"Cudesch da Psalms\", a collection of church songs in the Vallader dialect. These early works are generally well written and show that the authors had a large amount of Romansh vocabulary at their disposal, contrary to what one might expect of the first pieces of writing in a language. Because of this, the linguist Ricarda Liver assumes that these written works built on an earlier, pre-literature tradition of using Romansh in administrative and legal situations, of which no evidence survives. In their prefaces, the authors themselves often mention the novelty of writing Romansh, and discuss an apparently common prejudice that Romansh was a language that could not be written.\nThe first writing in the Sursilvan and Sutsilvan dialects appears in the 17th century. As in the Engadine, these early works usually focused on religious themes, in particular the struggles between Protestants and Counter-Reformers. Daniel Bonifaci produced the first surviving work in this category, the catechism \"Curt mussameint dels principals punctgs della Christianevla Religiun\", published in 1601 in the Sutsilvan dialect. A second edition, published in 1615, is closer to Sursilvan, however, and writings in Sutsilvan do not appear again until the 20th century. In 1611, \"Igl Vêr Sulaz da pievel giuvan\" (\"The true joys of young people\"), a series of religious instructions for Protestant youths, was published by Steffan Gabriel. Four years later, in 1615, a Catholic catechism, \"Curt Mussament\", was published in response, written by Gion Antoni Calvenzano. The first translation of the New Testament into Sursilvan was published in 1648 by the son of Steffan Gabriel, Luci Gabriel.\n\nThe first complete translation of the Bible, the \"Bibla da Cuera\", was published between 1717 and 1719. The Sursilvan dialect thus had two separate written varieties, one used by the Protestants with its cultural center around Ilanz, and a Catholic variety with the Disentis Abbey as its center. The Engadine dialect was also written in two varieties: Putèr in the Upper Valley and Vallader in the Lower Valley. The Sutsilvan areas either used the Protestant variety of Sursilvan, or simply used German as their main written language. The Surmiran region began developing its own variety in the early 18th century, with a catechism being published in 1703, though either the Catholic variety of Sursilvan or Putèr was more commonly used there until the 20th century.\n\nIn the 16th century, the language border between Romansh and German largely stabilized, and it remained almost unchanged until the late 19th century. During this period, only isolated areas became German-speaking, mainly a few villages around Thusis and the village of Samnaun. In the case of Samnaun, the inhabitants adopted the Bavarian dialect of neighboring Tyrol, making Samnaun the only municipality of Switzerland where a Bavarian dialect is spoken. The Vinschgau in South Tyrol was still Romansh-speaking in the 17th century, after which it became entirely German-speaking because of the Counter-Reformation denunciation of Romansh as a \"Protestant language\".\n\nWhen Grisons became part of Switzerland in 1803, it had a population of roughly 73,000, of whom around 36,600 were Romansh speakers—many of them monolingual—living mostly within the Romansh-speaking valleys. The language border with German, which had mostly been stable since the 16th century, now began moving again as more and more villages shifted to German. One cause was the admission of Grisons as a Swiss canton, which brought Romansh-speakers into more frequent contact with German-speakers. Another factor was the increased power of the central government of Grisons, which had always used German as its administrative language. In addition, many Romansh-speakers migrated to the larger cities, which were German-speaking, while speakers of German settled in Romansh villages. Moreover, economic changes meant that the Romansh-speaking villages, which had mostly been self-sufficient, engaged in more frequent commerce with German-speaking regions. Also, improvements in the infrastructure made travel and contact with other regions much easier than it had been.\n\nFinally, the rise of tourism made knowledge of German an economic necessity in many areas, while the agricultural sector, which had been a traditional domain of Romansh, became less important. All this meant that knowledge of German became more and more of a necessity for Romansh speakers and that German became more and more a part of daily life. For the most part, German was seen not as a threat but rather as an important asset for communicating outside one's home region. The common people frequently demanded better access to learning German. When public schools began to appear, many municipalities decided to adopt German as the medium of instruction, as in the case of Ilanz, where German became the language of schooling in 1833, when the town was still largely Romansh-speaking.\n\nSome people even welcomed the disappearance of Romansh, in particular among progressives. In their eyes, Romansh was an obstacle to the economic and intellectual development of the Romansh people. For instance, the priest Heinrich Bansi from Ardez wrote in 1797: \"The biggest obstacle to the moral and economical improvement of these regions is the language of the people, Ladin [...] The German language could certainly be introduced with ease into the Engadine, as soon as one could convince the people of the immense advantages of it\". Others however, saw Romansh as an economic asset, since it gave the Romansh an advantage when learning other Romance languages. In 1807, for example, the priest Mattli Conrad wrote an article listing the advantages and disadvantages of Romansh: \nIn response however, the editor of the newspaper added that: According to the testimony of experienced and vigilant language teachers, while the one who is born Romansh can easily learn to understand these languages and make himself understood in them, he has great difficulties in learning them properly, since precisely because of the similarity, he mixes them so easily with his own bastardized language. [...] in any case, the conveniences named hold no weight against all the disadvantages that come from such an isolated and uneducated language. According to Mathias Kundert, this quote is a good example of the attitude of many German-speakers towards Romansh at the time. According to Mathias Kundert, while there was never a plan to Germanize the Romansh areas of Grisons, many German-speaking groups wished that the entire canton would become German-speaking. They were careful however, to avoid any drastic measures to that extent, in order not to antagonize the influential Romansh minority.\n\nThe decline of Romansh over the 20th century can be seen through the results of the Swiss censuses. The decline in percentages is only partially due to the Germanization of Romansh areas, since the Romansh-speaking valleys always had a lower overall population growth than other parts of the canton.\n\nStarting in the mid-19th century however, a revival movement began, often called the \"Rhaeto-Romansh renaissance\". This movement involved an increased cultural activity, as well as the foundation of several organizations dedicated to protecting the Romansh language. In 1863, the first of several attempts was made to found an association for all Romansh regions, which eventually led to the foundation of the \"Società Retorumantscha\" in 1885. In 1919, the Lia Rumantscha was founded to serve as an umbrella organization for the various regional language societies. Additionally, the role of Romansh in schooling was strengthened, with the first Romansh school books being published in the 1830s and 1840s. Initially, these were merely translations of the German editions, but by the end of the 19th century teaching materials were introduced which took the local Romansh culture into consideration. Additionally, Romansh was introduced as a subject in teacher's college in 1860 and was recognized as an official language by the canton in 1880.\nAround the same time, grammar and spelling guidelines began to be developed for the regional written dialects. One of the earliest was the \"Ortografia et ortoëpia del idiom romauntsch d'Engiadin'ota\" by Zaccaria Pallioppi, published in 1857. For Sursilvan, a first attempt to standardize the written language was the \"Ortografia gienerala, speculativa ramontscha\" by Baseli Carigiet, published in 1858, followed by a Sursilvan-German dictionary in 1882, and the \"Normas ortografias\" by Giachen Caspar Muoth in 1888. Neither of these guidelines managed to gather much support however. At the same time, the Canton published school books in its own variety. Sursilvan was then definitely standardized through the works of Gion Cahannes, who published \"Grammatica Romontscha per Surselva e Sutselva\" in 1924, followed by \"Entruidament devart nossa ortografia\" in 1927. The Surmiran dialect had its own norms established in 1903, when the Canton agreed to finance the school book \"Codesch da lectura per las scolas primaras de Surmeir\", though a definite guideline, the \"Normas ortograficas per igl rumantsch da Surmeir\" was not published until 1939. In the meantime, the norms of Pallioppi had come under criticism in the Engadine due to the strong influence of Italian in them. This led to an orthographic reform which was concluded by 1928, when the \"Pitschna introducziun a la nouva ortografia ladina ufficiala\" by Cristoffel Bardola was published. A separate written variety for Sutsilvan was developed in 1944 by Giuseppe Gangale.\n\nAround 1880, the entire Romansh-speaking area still formed a continuous geographical unit. But by the end of the century, the so-called \"Central-Grisons language bridge\" began to disappear. From Thusis, which had become German-speaking in the 16th/17th century, the Heinzenberg and Domleschg valleys were gradually Germanized over the next decades. Around the turn of the century, the inner Heinzenberg and Cazis became German-speaking, followed by Rothenbrunnen, Rodels, Almens, and Pratval, splitting the Romansh area into two geographically non-connected parts. In the 1920s and 1930s the rest of the villages in the valley became mainly German-speaking, sealing the split.\n\nIn order to halt the decline of Romansh, the Lia Rumantscha began establishing Romansh day care schools, called \"Scoletas\", beginning in the 1940s with the aim of reintroducing Romansh to children. Although the \"Scoletas\" had some success – of the ten villages where Scoletas were established, the children began speaking Romansh amongst themselves in four, with the children in four others acquiring at least some knowledge of Romansh – the program ultimately failed to preserve the language in the valley.\n\nA key factor was the disinterest of the parents, whose main motivation for sending their children to the Scoletas appears to have been that they were looked after for a few hours and given a meal every day, rather than an interest in preserving Romansh. The other factor was that after entering primary school, the children received a few hours a week of Romansh instruction at best. As a result, the last Scoletas were closed in the 1960s with the exception of Präz, where the Scoleta remained open until 1979.\n\nIn other areas, such as the Engadine and the Surselva, where the pressure of German was equally strong, Romansh was maintained much better and remained a commonly spoken language. According to the linguist Mathias Kundert, one important factor was the different social prestige of Romansh. In the Heinzenberg and Domleschg valleys, the elite had been German-speaking for centuries, so that German was associated with power and education, even though most people did not speak it, whereas Romansh was associated with peasant life. In the Engadine and the Surselva by contrast, the elite was itself Romansh-speaking, so that Romansh there was \"not only the language spoken to children and cows, but also that of the village notable, the priest, and the teacher.\" Additionally, Romansh schools had been common for several years before German had become a necessity, so that Romansh was firmly established as a medium of education.\n\nIn Central Grisons by contrast, German had been a central part of schooling since the beginning, and virtually all schools switched entirely to German as the language of instruction by 1900, with children in many schools being punished for speaking Romansh well into the 1930s. In the Upper Engadine by contrast, where factors such as increased mobility and immigration by German speakers were even stronger, Romansh was more firmly established as a language of education and administration, so that the language was maintained to a much greater extent.\n\nEarly attempts to create a unified written language for Romansh include the \"Romonsch fusionau\" of Gion Antoni Bühler in 1867 and the \"Interrumantsch\" by Leza Uffer in 1958. Neither was able to gain much support, and their creators were largely the only ones actively using them. In the meantime, the Romansh movement sought to promote the different regional varieties while promoting a gradual convergence of the five varieties, called the \"\"avischinaziun\"\". In 1982, however, the then secretary of the Lia Rumantscha, a sociolinguist named Bernard Cathomas, launched a project for designing a pan-regional variety. The linguist Heinrich Schmid presented to the Lia Rumantscha the same year the rules and directives for this standard language under the name Rumantsch Grischun. Schmid's approach consisted of creating a language as equally acceptable as possible to speakers of the different dialects, by choosing those forms which were found in a majority of the three strongest varieties: Sursilvan, Surmiran, and Vallader. The elaboration of the new standard was endorsed by the Swiss National Fund and carried out by a team of young Romansh linguists under the guidance of Georges Darms and Anna-Alice Dazzi-Gross.\n\nThe Lia Rumantscha then began introducing Rumantsch Grischun to the public, announcing that it would be chiefly introduced into domains where only German was being used, such as official forms and documents, billboards, and commercials. In 1984, the assembly of delegates of the head organization Lia Rumantscha decided to use the new standard language when addressing all Romansh-speaking areas of the Grisons. From the very start, Rumansh Grischun has been implemented only on the basis of a decision of the particular institutions. In 1986, the federal administration began to use Rumantsch Grischun for single texts. The same year, however, several influential figures began to criticize the introduction of Rumantsch Grischun. Donat Cadruvi, at the time the president of the cantonal government, claimed that the Lia Rumantscha was trying to force the issue. Romansh writer Theo Candinas also called for a public debate on the issue, calling Rumantsch Grischun a \"plague\" and \"death blow\" to Romansh and its introduction a \"Romansh Kristallnacht\", thus launching a highly emotional and bitter debate which would continue for several years. The following year, Theo Candinas published another article titled \"Rubadurs Garmadis\" in which he compared the proponents of Rumantsch Grischun to Nazi thugs raiding a Romansh village and desecrating, destroying, and burning the Romansh cultural heritage.\n\nThe proponents responded by labeling the opponents as a small group of archconservative and narrow-minded Sursilvans and CVP politicians among other things. The debate was characterized by a heavy use of metaphors, with opponents describing Rumantsch Grischun as a \"test-tube baby\" or \"castrated language\". They argued that it was an artificial and infertile creation which lacked a heart and soul, in contrast to the traditional dialects. On the other side, proponents called on the Romansh people to nurture the \"new-born\" to allow it to grow, with Romansh writer Ursicin Derungs calling Rumantsch Grischun a \"\"lungatg virginal\"\" 'virgin language' that now had to be seduced and turned into a blossoming woman.\n\nThe opposition to Rumantsch Grischun also became clear in the Swiss census of 1990, in which certain municipalities refused to distribute questionnaires in Rumantsch Grischun, requesting the German version instead. Following a survey on the opinion of the Romansh population on the issue, the government of Grisons decided in 1996 that Rumantsch Grischun would be used when addressing all Romansh speakers, but the regional varieties could continue to be used when addressing a single region or municipality. In schools, Rumantsch Grischun was not to replace the regional dialects but only be taught passively.\n\nThe compromise was largely accepted by both sides. A further recommendation in 1999, known as the \"Haltinger concept\", also proposed that the regional varieties should remain the basis of the Romansh schools, with Rumantsch Grischun being introduced in middle school and secondary school.\n\nThe government of Grisons then took steps to strengthen the role of Rumantsch Grischun as an official language. Since the cantonal constitution explicitly named Sursilvan and Engadinese as the language of ballots, a referendum was launched to amend the relevant article. In the referendum, which took place on June 10, 2001, 65% voted in favor of naming Rumantsch Grischun the only official Romansh variety of the Canton. Opponents of Rumantsch Grischun such as Renata Coray and Matthias Grünert argue, however, that if only those municipalities with at least 30% Romansh speakers were considered, the referendum would have been rejected by 51%, with an even larger margin if only those with at least 50% Romansh speakers were considered. They thus interpret the results as the Romansh minority having been overruled by the German-speaking majority of the canton.\nA major change in policy came in 2003, when the cantonal government proposed a number of spending cuts, including a proposal according to which new Romansh teaching materials would not be published except in Rumantsch Grischun from 2006 onwards, the logical result of which would be to abolish the regional varieties as languages of instruction. The cantonal parliament passed the measure in August 2003, even advancing the deadline to 2005. The decision was met by strong opposition, in particular in the Engadine, where teachers collected over 4,300 signatures opposing the measure, followed by a second petition signed by around 180 Romansh writers and cultural figures, including many who were supportive of Rumantsch Grischun but opposed its introduction as a language of instruction.\n\nOpponents argued that Romansh culture and identity was transmitted through the regional varieties and not through Rumantsch Grischun and that Rumantsch Grischun would serve to weaken rather than strengthen Romansh, possibly leading to a switch to German-language schools and a swift Germanization of Romansh areas.\n\nThe cantonal government refused to debate the issue again however, instead deciding on a three-step plan in December 2004 to introduce Rumantsch Grischun as the language of schooling, allowing the municipalities to choose when they would make the switch. The decision not to publish any new teaching materials in the regional varieties was not overturned, however, raising the question of what would happen with those municipalities refused to introduce Rumantsch Grischun at all as the language of schooling is decided by the municipalities themselves in Grisons.\n\nThe teachers of the Engadine in particular were outraged over the decision, but those in the Surmeir were mostly satisfied. Few opinions were heard from the Surselva, which was interpreted either as support or resignation, depending in the viewpoint of the observer.\n\nIn 2007–2008, 23 so called \"pioneer-municipalities\" introduced Rumantsch Grischun as the language of instruction in 1st grade, followed by an additional 11 the following year and another 6 in 2009-2010. However, other municipalities, including the entire Engadine valley and most of the Surselva, continued to use their regional variety. The cantonal government aimed to introduce Rumantsch Grischun as the sole language of instruction in Romansh schools by 2020.\n\nIn early 2011, however, a group of opponents in the Surselva and the Engadine founded the association Pro Idioms, demanding the overturning of the government decision of 2003 and launching numerous local initiatives to return to the regional varieties as the language of instruction. In April 2011, Riein became the first municipality to vote to return to teaching in Sursilvan, followed by an additional 4 in December, and a further 10 in early 2012, including Val Müstair, which had been the first to introduce Rumantsch Grischun. As of September 2013, all municipalities in the Surselva, with the exception of Pitasch, have decided to return to teaching in Sursilvan.\n\nSupporters of Rumantsch Grischun then announced that they would take the issue to the Federal Supreme Court of Switzerland and announced their intention to launch a cantonal referendum to enshrine Rumantsch Grischun as the language of instruction.\n\nThe Lia Rumantscha opposes these moves and now supports a model of coexistence in which Rumantsch Grischun will supplement but not replace the regional varieties in school. It cites the need for keeping linguistic peace among Romansh speakers, as it says that the decades-long debate over the issue has torn friends and even families apart. The 2003 decision, in December 2011, has been overturned so the canton will again finance school books in the regional varieties.\n\nRumantsch Grischun is still a project in progress. At the start of 2014, it is in use as a school language in the central part of Grisons and in the bilingual classes in the region of Chur. It is taught in upper-secondary schools, in the university of teacher education in Chur and at the universities of Zürich and Fribourg, along with the Romansh idioms. It remains an official and administrative language in the Swiss Confederation and the Canton of Grisons as well as in public and private institutions for all kinds of texts intended for the whole Romansh-speaking territory.\n\nRumantsch Grischun is read in the news of Radiotelevisiun Svizra Rumantscha and written in the daily newspaper \"La Quotidiana\", along with the Romansh idioms. Thanks to many new texts in a wide variety of political and social functions, the Romansh vocabulary has been decisively broadened.\n\nThe \"Pledari Grond\" dictionary with more than 215 000 entries German Rumantsch Grischun is the most comprehensive collection of Romansh words, which can also be used in the idioms with the necessary phonetic shifts. The signatories of \"Pro Rumantsch\" stress that Romansh needs both the idioms and Rumantsch Grischun if it is to improve its chances in today's communication society.\n\nIn Switzerland, official language use is governed by the \"territorial principle\": Cantonal law determines which of the four national languages enjoys official status in which part of the territory. Only the federal administration is officially quadrilingual. Romansh is an official language at the federal level, one of the three official languages of the Canton of Grisons, and is a working language in various districts and numerous municipalities within the canton.\n\nThe first Swiss constitution of 1848, as well as the subsequent revision of 1872, make no mention of Romansh, which at the time was not a working language of the Canton of Grisons either. The federal government did finance a translation of the constitution into the two Romansh varieties Sursilvan and Vallader in 1872, noting however that these did not carry the force of law. Romansh became a national language of Switzerland in 1938, following a referendum. However, a distinction was introduced between \"national languages\" and \"official languages\". The status of a national language was largely symbolic, whereas only official languages were to be used in official documents, a status reserved for German, French, and Italian. The recognition of Romansh as the fourth national language is best seen within the context of the \"Spiritual defence\" preceding World War II, which aimed to underline the special status of Switzerland as a multinational country. Additionally, this was supposed to discredit the efforts of Italian nationalists to claim Romansh as a dialect of Italian and establish a claim to parts of Grisons. The Romansh language movement led by the Lia Rumantscha was mostly satisfied with the status as a national but not official language. Their aims at the time were to secure a symbolic \"right of residence\" for Romansh, and not actual use in official documents.\nThis status did have disadvantages however. For instance, official name registers and property titles had to be in either German, French, or Italian. This meant that Romansh-speaking parents were often forced to register their children under German or Italian versions of their Romansh names. As late as 1984, the Canton of Grisons was ordered not to make entries into its corporate registry in Romansh. The Swiss National Bank first planned to include Romansh on its bills in 1956, when a new series was introduced. Due to disputes within the Lia Rumantscha over whether the bills were to feature the Sursilvan version \"\"Banca nazionala svizra\"\" or the Vallader version \"\"Banca naziunala svizzra\"\", the bills eventually featured the Italian version twice, alongside French and German. When new bills were again introduced in 1976/77, a Romansh version was added by finding a compromise between the two largest varieties Sursilvan and Vallader, which read \"\"Banca naziunala svizra\"\". The numbers on the bills were printed in Surmiran, a minor intermediate dialect.\n\nFollowing a referendum on March 10, 1996, Romansh was recognized as a partial official language of Switzerland alongside German, French, and Italian in article 70 of the federal constitution. According to the article, German, French, Italian, and Rhaeto-Romansh are national languages of Switzerland. The official languages are declared to be German, French, and Italian, and Rhaeto-Romansh is an official language for correspondence with Romansh-speaking people. This means that in principle, it is possible to address the federal administration in Romansh and receive an answer in the same language. In what the Federal Culture Office itself admits is \"more a placatory and symbolic use\" of Romansh, the federal authorities occasionally translate some official texts into Romansh. In general, though, demand for Romansh-language services is low because, according to the Federal Culture Office, Romansh speakers may either dislike the official Rumantsch Grischun idiom or prefer to use German in the first place, as most are perfectly bilingual. Without a unified standard language, the status of an official language of the Swiss Confederation would not have been conferred to Romansh. It takes time and needs to be promoted to get implemented in this new function.\n\nThe Swiss Armed Forces attempted to introduce Romansh as an official language of command between 1988 and 1992. Attempts were made to form four entirely Romansh-speaking companies, but these efforts were abandoned in 1992 due to a lack of sufficient Romansh-speaking non-commissioned officers. Official use of Romansh as a language of command was discontinued in 1995 as part of a reform of the Swiss military.\n\nGrisons is the only canton of Switzerland where Romansh is recognized as an official language. The only working language of the Three Leagues was German until 1794, when the assembly of the leagues declared German, Italian, Sursilvan, and Ladin (Putèr and Vallader) to have equal official standing. No explicit mention of any official language was made in the cantonal constitutions of 1803, 1814, and 1854. The constitution of 1880 declared that \"The three languages of the Canton are guaranteed as national languages, without specifying anywhere which three languages are meant. The new cantonal constitution of 2004 recognizes German, Italian, and Romansh as equal national and official languages of the canton. The canton used the Romansh varieties Sursilvan and Vallader up until 1997, when Rumantsch Grischun was added and use of Sursilvan and Vallader was discontinued in 2001.\nThis means that any citizen of the canton may request service and official documents such as ballots in their language of choice, that all three languages may be used in court, and that a member of the cantonal parliament is free to use any of the three languages. Since 1991, all official texts of the cantonal parliament must be translated into Romansh and offices of the cantonal government must include signage in all three languages. In practice, the role of Romansh within the cantonal administration is limited and often symbolic and the working language is mainly German. This is usually justified by cantonal officials on the grounds that all Romansh speakers are perfectly bilingual and able to understand and speak German. Up until the 1980s it was usually seen as a provocation when a deputy in the cantonal parliament used Romansh during a speech.\n\nCantonal law leaves it to the districts and municipalities to specify their own language of administration and schooling. According to Article 3 of the cantonal constitution however, the municipalities are to \"take into consideration the traditional linguistic composition and respect the autochthonous linguistic minorities\". This means that the language area of Romansh has never officially been defined, and that any municipality is free to change its official language. In 2003, Romansh was the sole official language in 56 municipalities of Grisons, and 19 were bilingual in their administrative business. In practice, even those municipalities which only recognize Romansh as an official working language, readily offer services in German as well. Additionally, since the working language of the canton is mainly German and many official publications of the canton are available only in German, it is virtually impossible for a municipal administration to operate only in Romansh.\n\nWithin the Romansh-speaking areas, three different types of educational models can be found: Romansh schools, bilingual schools, and German schools with Romansh as a subject.\n\nIn the Romansh schools, Romansh is the primary language of instruction during the first 3–6 years of the nine years of compulsory schooling, and German during the last 3–9 years. Due to this, this school type is often called the \"so-called Romansh school\". In practice, the amount of Romansh schooling varies between half and 4/5 of the compulsory school term, often depending on how many Romansh-speaking teachers are available. This \"so-called Romansh school\" is found in 82 municipalities of Grisons as of 2001. The bilingual school is found only in Samedan, Pontresina, and Ilanz/Schnaus. In 15 municipalities, German is the sole medium of instruction as of 2001, with Romansh being taught as a subject.\n\nOutside of areas where Romansh is traditionally spoken, Romansh is not offered as a subject and as of 2001, 17 municipalities within the historical language area of Romansh do not teach Romansh as a subject. On the secondary level, the language of instruction is mainly German, with Romansh as a subject in Romansh-speaking regions.\n\nOutside of the traditional Romansh-speaking areas, the capital of Grisons, Chur, runs a bilingual Romansh-German elementary school.\n\nOn the tertiary level, the University of Fribourg offers Bachelor- and Master programs for Romansh language and literature. The Romansh department there has been in existence since 1991. The University of Zürich also maintains a partial chair for Romansh language and literature together with the ETH Zürich since 1985.\n\nWhereas Romansh was spoken as far north as Lake Constance in the early Middle Ages, the language area of Romansh is today limited to parts of the Swiss canton of Grisons; the last areas outside the canton to speak Romansh, the Vinschgau in South Tyrol, became German-speaking in the 17th century. Inside Grisons, the language borders largely stabilized in the 16th century and remained almost unchanged until the 19th century. This language area is often called the \"Traditional Romansh-speaking territory\", a term introduced by the statistician Jean-Jacques Furer based on the results of the Swiss censuses. Furer defines this language area as those municipalities in which a majority declared Romansh as their mother tongue in any of the first four Swiss censuses between 1860 and 1888. In addition, he includes Fürstenau. This represented 121 municipalities at the time, corresponding to 116 present-day municipalities. The villages of Samnaun, Sils im Domleschg, Masein, and Urmein, which were still Romansh-speaking in the 17th century, had lost their Romansh majority by 1860, and are not included in this definition. This historical definition of the language area has been taken up in many subsequent publications, but the Swiss Federal Statistical Office for instance defines the language area of Romansh as those municipalities, where a majority declared to habitually use Romansh in the census of 2000.\n\nThe presence of Romansh within its traditional language area varies from region to region. In 2000, 66 municipalities still had a Romansh majority, an additional 32 had at least 20% who declared Romansh as their language of best command or as a habitually spoken language, while Romansh is either extinct or only spoken by a small minority in the remaining 18 municipalities within the traditional language area. In the Surselva region, it is the habitually spoken language of 78.5% and the language of best command of 66%. In the Sutselva region by contrast, Romansh is extinct or only spoken by a small number of older people, with the exception of Schams, where it is still transmitted to children and where some villages still have a Romansh majority, notably in the vicinity of the Schamserberg. In the Surmiran region, it is the main language in the Surses region, but no longer widely spoken in the Albula Valley.\n\nIn the Upper Engadine valley, it is a habitually spoken language for 30.8% and the language of best command for 13%. However, most children still acquire Romansh through the school system, which has retained Romansh as the primary language of instruction, even though Swiss German is more widely spoken inside the home. In the Lower Engadine, Romansh speakers form the majority in virtually all municipalities, with 60.4% declaring Romansh as their language of best command in 2000, and 77.4% declaring it as a habitually spoken language.\n\nOutside of the traditional Romansh language area, Romansh is spoken by the so-called \"Romansh diaspora\", meaning people who have moved out of the Romansh-speaking valleys. A significant number are found in the capital of Grisons, Chur, as well as in Swiss cities outside of Grisons.\n\nThe current situation of Romansh is quite well researched. The number of speakers is known through the Swiss censuses, with the most recent having taken place in 2000, in addition to surveys by the Radio e Televisiun Rumantscha. The quantitative data from these surveys was summed up by statistician Jean-Jacques Furer in 2005. In addition, linguist Regula Cathomas performed a detailed survey of everyday language use, published in 2008.\n\nVirtually all Romansh-speakers today are bilingual in Romansh and German. Whereas monolingual Romansh were still common at the beginning of the twentieth century, they are now only found among pre-school children. As Romansh linguist Ricarda Liver writes:\nThe language situation today consists of a complex relationship between several diglossia, since there is a functional distribution within Romansh itself between the local dialect, the regional standard variety, and nowadays the pan-regional variety Rumantsch Grischun as well; and German is also acquired in two varieties: Swiss German and Standard German. Additionally, in Val Müstair many people also speak Bavarian German as a second language. Aside from German, many Romansh also speak additional languages such as French, Italian, or English, learned at school or acquired through direct contact.\n\nThe Swiss census of 1990 and 2000 asked for the \"language of best command\" as well as for the languages habitually used in the family, at work, and in school. Previous censuses had only asked for the \"mother tongue\". In 1990, Romansh was named as the \"language of best command\" by 39,632 people, with a decrease to 35,095 in 2000. As a family language, Romansh is more widespread, with 55,707 having named it in 1990, and 49,134 in 2000. As a language used at work, Romansh was more widely used in 2000 with 20,327 responses than in 1990 with 17,753, as it was as a language used at school, with 6,411 naming it in 2000 as compared to 5,331 in 1990. Overall, a total of 60,561 people reported that they used Romansch of some sort on a habitual basis, representing 0.83% of the Swiss population. As the language of best command, Romansh comes in 11th in Switzerland with 0.74%, with the non-national languages Serbian, Croatian, Albanian, Portuguese, Spanish, English, and Turkish all having more speakers than Romansh.\n\nIn the entire Canton of Grisons, where about two-thirds of all speakers live, roughly a sixth report it as the language of best command (29,679 in 1990 and 27,038 in 2000). As a family language it was used by 19.5% in 2000 (33,707), as a language used on the job by 17.3% (15,715), and as a school language by 23.3% (5,940). Overall, 21.5% (40,168) of the population of Grisons reported to be speaking Romansh habitually in 2000. Within the traditional Romansh-speaking areas, where 56.1% (33,991) of all speakers lived in 2000, it is the majority language in 66 municipalities.\n\nThe status of Romansh differs widely within this traditional area however. Whereas in some areas Romansh is used by virtually the entire population, in others the only speakers are people who have moved there from elsewhere. Overall, Romansh dominates in most of the Surselva and the Lower Engadine as well as parts of the Surses, whereas German is the dominant daily language in most other areas, though Romansh is often still used and transmitted in a limited manner regardless.\n\nIn general, Romansh is the dominant language in most of the Surselva. In the western areas, the Cadi and the Lumnezia, it is the language of a vast majority, with around 80% naming it as their language of best command, and it often being a daily language for virtually the entire population. In the eastern areas of the Gruob around Ilanz, German is significantly more dominant in daily life, though most people still use Romansh regularly. Romansh is still acquired by most children in the Cadi and Gruob even in villages where Romansh speakers are in the minority, since it is usually the language of instruction in primary education there. Even in villages where Romansh dominates, newcomers rarely learn Romansh however, as Sursilvan speakers quickly accommodate by switching to German, so that there is often little opportunity to practice Romansh even when people are willing to learn it. Some pressure is often exerted by children, who will sometimes speak Romansh even with their non-Romansh-speaking parents.\n\nIn the Imboden District by contrast, it is only used habitually by 22%, and is the language of best command for only 9.9%. Even within this district however, the presence of Romansh varies, with 41.3% in Trin reporting to speak it habitually. In the Sutselva, the local Romansh dialects are extinct in most villages, with a few elder speakers remaining in places such as Präz, Scharans, Feldis/Veulden, and Scheid, though passive knowledge is slightly more common. Some municipalities still offer Romansh as a foreign language subject in school, though it is often under pressure of being replaced by Italian. The notably exception is Schams, where it is still regularly transmitted to children and where the language of instruction is Romansh. In the Surmeir region, it is still the dominant every day language in the Surses, but has mostly disappeared from the Albula Valley. The highest proportion of habitual speakers is found in Salouf with 86.3%, the lowest in Obervaz with 18.9%. In these areas, many Romansh speakers only speak German with their spouses as an accommodation or because of a habit, though they sometimes speak Romansh to their children. In most cases, this is not because of a will to preserve the language, but because of other reasons such as Romansh having been their own childhood language or a belief that their children will later find it easier to learn additional languages.\n\nIn the Upper Engadine, it is used habitually by 30.8% and the language of best command for 13%, with only S-chanf having a Romansh majority. Even though the main every-day and family language is German, Romansh is not in imminent danger of disappearing in the Upper Engadine, due to the strong emotional attachment to the language and in particular the Romansh-language school, which means that a Romansh-speaking core always exists in some form. Romansh is often a sign of being one of the locals, and used to distinguish oneself from tourists or temporary residents, so that outsiders will sometimes acquire Romansh in order to fit in. In the Lower Engadine by contrast, Romansh is the majority language virtually everywhere, with over 80% reporting it as a habitually spoken language in most villages. The status of Romansh is even stronger in the Val Müstair, where 86.4% report to speak it habitually, and 74.1% as their language of best command. In the Lower Engadine, outsiders are generally expected to learn Romansh if they wish to be integrated into the local community and take part in social life. In addition, there is often pressure from inside the family to learn Romansh.\n\nOverall, Jean-Jacques Furer concludes that the shrinkage of the Romansh-speaking areas is continuing, though at different rates depending on the region. At the same time, he notes that Romansh is still very much alive, a fact that is obvious in those areas where it retains a strong presence, such as most parts of the Surselva and the Lower Engadine. It is also assured that Romansh will continue to be transmitted for several more generations, even though each succeeding generation will be more and more rooted in German as well as Romansh. As a result, if the overall linguistic situation does not change, speakers will slowly become fewer and fewer with each generation. He also concludes however, that there are still enough speakers to ensure that Romansh will survive in the long term at least in certain regions. He considers the Romansh-language school system to be the single most crucial factor in this.\n\nRomansh has up to 26 consonant phonemes. Two are only found in some varieties, and one is found only in loanwords borrowed from German.\nNotes:\nThe voiced obstruents are fully voiced in Romansh and voiceless ones are non-aspirated, in contrast to Swiss German with which Romansh is in extensive contact. Voiced obstruents are devoiced word-finally, however, as in \"buob\" 'boy' > , \"chöd\" 'warm' > , \"saung\" 'blood' > , or \"clav\" 'key' > .\nThe vowel inventory varies somewhat between dialects, as the front rounded vowels and and are found only in Putèr and Vallader. They have historically been unrounded in the other varieties and are found only in recent loans from German there. They are not found in the pan-regional variety Rumantsch Grischun either. The now nearly extinct Sutsilvan dialects of the Heinzenberg have as in \"plànta\" 'plant, tree', but this is etymologically unrelated to the found in Putèr and Vallader. The exact realization of the phoneme varies from to depending on the dialect: / 'book'. It is regarded as either a marginal phoneme or not a separate phoneme from by some linguists.\n\nWord stress generally falls either on the last or the penult syllable of a word. Unstressed vowels are generally reduced to a schwa, whose exact pronunciation varies between or as in 'song'. Vowel length is predictable:\n\nThe amount of diphthongs varies significantly between dialects. Sursilvan dialects contain eleven diphthongs and four triphthongs (, , , and ).\n\nOther dialects have different inventories; Putèr for instance lacks , , and as well as the triphthongs but has , which is missing in Sursilvan. A phenomenon known as \"hardened diphthongs\", in which the second vowel of a falling Diphthong is pronounced as , was once common in Putèr as well, but is nowadays limited to Surmiran: \"strousch\" 'barely > .\n\nRomansh is written in the Latin alphabet, and mostly follows a phonemic orthography, with a high correspondence between letters and sounds. The orthography varies slightly depending on the variety.\n\nThe vowel inventories of the five regional written varieties differ widely (in particular in regards to diphthongs), and the pronunciation often differs depending on the dialect even within them. The orthography of Sutsilvan is particularly complex, allowing for different pronunciations of the vowels depending on the regional dialect, and is not treated in this table.\n\nThe following description deals mainly with the Sursilvan dialect, which is the best-studied so far. The dialects Putèr and Vallader of the Engadine valley in particular diverge considerably from Sursilvan in many points. When possible, such differences are described.\n\nNouns are not inflected for case in Romansh; the grammatical category is expressed through word order instead. As in most other Romance languages, Romansh nouns belong to two grammatical genders: masculine and feminine. A definite article (masc. \"il\" or \"igl\" before a vowel; fem. \"la\") is distinguished from an indefinite article (masc. \"in\", \"egn\", \"en\" or \"ün\", depending on the dialect; fem. \"ina\", \"egna\", \"ena\" or \"üna\"). The plural is usually formed by adding the suffix -s. In Sursilvan, masculine nouns are sometimes irregular, with the stem vowel alternating:\n\nA particularity of Romansh is the so-called \"collective plural\" to refer to a mass of things as a whole:\n\nAdjectives are declined according to gender and number. Feminine forms are always regular, but the stem vowel sometimes alternates in the masculine forms:\n\nSursilvan also distinguishes an attributive and predicative form of adjectives in the singular. This is not found in some of the other dialects however:\n\nThere are three singular and three plural pronouns in Romansh (Sursilvan forms shown below):\nThere is a T–V distinction between familiar \"ti\" and polite \"vus\". Putèr and Vallader distinguish between familiar \"tü\" and \"vus\" and polite \"El/Ella\" and \"Els/Ellas\". Pronouns for the polite forms in Putèr and Vallader are always capitalized to distinguish them from third person pronouns: \"Eau cugnuosch a Sia sour\" \"I know your sister\" and \"Eau cugnuosch a sia sour\" \"I know his/her sister\".\n\nThe 1st and 2nd person pronouns for a direct object have two distinct forms, with one occurring following the preposition \"a\": \"dai a mi tiu codisch\" 'give me your book'.\n\nA particularity of Sursilvan is that reflexive verbs are all formed with the reflexive pronoun \"se-\", which was originally only the third person pronoun:\n\nThe other Romansh dialects distinguish different reflexive pronouns however.\n\nPossessive pronouns occur in a pronominal and a predicative form that differ only in the masculine form, however:\nThe feminine remains the same: \"sia casa\" 'her/his house' – \"quella casa ei sia\" 'this house is hers/his'\n\nThree different demonstrative pronouns \"quel\", \"tschel\", and \"lez\" are distinguished: \"A quel fidel jeu, a tschel buc\" 'I trust that one, but not that other one' or \"Ed il bab, tgei vegn lez a dir?\" 'and the father, what is he going to say?'.\n\nVerb tenses are divided into synthetic forms (present, imperfect) and analytic forms (perfect, pluperfect, future, passive) distinguished by the grammatical moods indicative, subjunctive, conditional, and imperative. These are most common forms in Sursilvan:\n\nThe syntax of Romansh has not been thoroughly investigated so far. Regular word order is subject–verb–object, but subject-auxiliary inversion occurs in several cases, placing the verb at the beginning of a sentence:\n\nThis feature might be a result of contact with German, or it might be an archaic feature no longer found in other Romance languages.\n\nA sentence is negated by adding a negative particle. In Sursilvan, this is \"buc\", placed after the verb, while in other dialects such as Putèr and Vallader, it is \"nu\", placed before the verb:\n\nA feature found only in Putèr and Vallader (as it is in Castilian Spanish) is the preposition of a direct object, when that direct object is a person or an animal, with \"a\", as in \"test vis a Peider?\" \"did you see Peter?\", \"eau d'he mno a spass al chaun\" \"I took the dog out for a walk\", but \"hest vis la baselgia?\" \"did you see the church?\".\n\nNo systematic synchronic description of Romansh vocabulary has been carried out so far. Existing studies usually approach the subject from a historical perspective, taking particular interest in pre-Roman substratum, archaic words preserved only in Romansh, or in loan words from German. A project to compile together all known historic and modern Romansh vocabulary is the Dicziunari Rumantsch Grischun, first published in 1904, with the 13th edition currently in preparation.\n\nThe influence of the languages (Raetic and Celtic) spoken in Grisons before the arrival of the Romans is most obvious in placenames, which are often pre-Roman. Since very little is known about the Celtic language once spoken in Grisons, and almost nothing about Raetic, words or placenames thought to come from them are usually simply referred to as \"pre-Roman\". Apart from placenames, such words are found in landscape features, plant and animal names unique to the Alps, and tools and methods related to alpine transhumance. Such words include:\n\nLike all languages, Romansh has its own archaisms, that is, words derived from Latin that have fallen out of use in most other Romance languages. Examples include \"baselgia\" 'church' (Vegliote \"bašalka\", Romanian \"biserică\"), \"nuidis\" 'grudgingly, reluctantly' from Latin \"invitus\", \"urar\" 'to pray' (Portuguese \"orar\", Romanian \"a ura\" - to wish), \"aura\" 'weather' (Old French \"ore\", Aromanian \"avrî\"), \"scheiver\" 'carnival', \"cudesch\" 'book', the last two of which are only found in Romansh. The non-Engadinese dialects retain \"anceiver\" ~ \"entschaiver\" 'to begin', from Latin \"incipere\", otherwise found only in Romanian \"începere\", whereas Surmiran and Engadinese (Putèr, Vallader) and all other Romance languages retain a reflex of Latin *\"cuminitiāre\", e.g. Engadinese \"(s)cumanzar\", Italian \"cominciare\", French \"commencer\". Other examples are \"memia\" (adv.) 'too much' from Latin \"nimia\" (adj., fem.), only found in Old Occitan, \"vess\" 'difficult' from Latin \"vix\" 'seldom' (cf. Old Spanish \"abés\", Romanian \"abia\" < \"ad vix\"), and Engadinese \"encleger\" 'to understand' (vs. non-Engadinese \"capir\"), also found in Romanian \"înțelege\" and Albanian \"(n)dëgjoj\", from Latin \"intellegere\". Some unique innovations include \"tedlar\" 'to listen' from Latin \"titulare\" and \"patertgar\" 'to think' from \"pertractare\".\n\nAnother distinguishing characteristic of Romansh vocabulary is its numerous Germanic loanwords.\n\nSome Germanic loan words already entered the language in Late Antiquity or the Early Middle Ages, and they are often found in other Romance languages as well. Words more particular to Romansh include Surs./ Suts. \"tschadun\", Surm. \"sdom\"/\"sdong\", Engad. \"sdun\" 'spoon', which is also found in Ladin as \"sciadon\" and Friaulian as \"sedòn\" and is thought to go back to Ostrogothic *skeitho, and it was once probably common throughout Northern Italy. Another such early loan is \"bletsch\" 'wet', which probably goes back to Old Frankish \"blettjan\" 'to squeeze', from where French \"blesser\" 'to wound' is also derived. The change in meaning probably occurred by the way of 'bruised fruit', as is still found in French \"blet\". Early Germanic loans found more commonly in the other Romance languages includes Surs./Vall. \"blau\", Suts. \"blo\"/\"blova\", Surm. \"blo\"/\"blava\", Put. \"blov\" 'blue', which is derived from Germanic \"blao\" and also found for instance in French as \"bleu\" and Italian as \"blu\".\n\nOthers were borrowed into Romansh during the Old High German period, such as \"glieud\" 'people' from OHG \"liut\" or Surs. \"uaul\", Suts. \"gòld\", Surm. \"gôt\", eng. \"god\" 'forest' from OHG \"wald\". Surs. \"baul\", Suts. \"bòld\", Engad. \"bod\" 'soon, early, nearly' is likely derived from Middle High German \"bald, balde\" 'keen, fast' as are Surs. \"nez\", Engad. \"nüz\" 'use' from Middle High German \"nu(t)z\", or \"losch\" 'proud' likely from Middle High German \"lôs\". Other examples include Surs. \"schuber\" 'clean' from Swiss German \"suuber\", Surs. \"schumber\" 'drum' from Swiss German or Middle High German \"sumber\", and Surs. \"schufar\" 'to drink greedily' from Swiss German \"suufe\".\n\nSome words were adapted into Romansh through different dialects of German, such as the word for 'farmer', borrowed as \"paur\" from Bavarian in Vallader and Putèr, but from Alemannic as \"pur\" in the other dialects.\n\nIn addition, many German words entered Romansh beginning in the 19th century, when numerous new objects and ideas were introduced. Romansh speakers often simply adopted the German words, such as \"il zug\" 'the train' or \"il banhof\" 'the train station'. Language purists attempted to coin new Romansh words instead, which were occasionally successful in entering popular usage. Whereas \"il tren\" and \"la staziun\" managed to replace \"il zug\" and \"il banhof\", other German words have become established in Romansh usage, such as \"il schalter\" 'the switch', \"il hebel\" 'the lever', \"la schlagbohrmaschina\" 'the hammer drill', or \"in schluc\" 'a sip'. Especially noticeable are interjections such as \"schon\", \"aber\" or \"halt\", which have become established in everyday language.\n\nRomansh speakers have been in close contact with speakers of German dialects such as Alemannic and Bavarian for centuries, as well as speakers of various Italian dialects and Standard German more recently. These languages have influenced Romansh, most strongly the vocabulary, whereas the German and Italian influences on morphology and syntax are much more limited. This means that despite German influence, Romansh has remained a Romance language in its core structure. Romansh linguist Ricarda Liver also notes that an influence of Swiss German on intonation is obvious, in particular in the Sursilvan dialect, even though this has so far not been linguistically studied. The influence of German is generally strongest in the Rhenish varieties Sursilvan, Sutsilvan, and Sursilvan, where French loanwords (frequently not borrowed directly but transmitted through German) are also more numerous. In the dialects of the Engadine, by contrast, the influence of Italian is stronger.\n\nIn the Engadinese written languages, Putèr and Vallader, Italian-influenced spellings, learned words, and derivations were previously abundant, for instance in Zaccaria Pallioppi's 1895 dictionary, but came under scrutiny at the start of the 20th century and were gradually eliminated from the written language. Following reforms of the written languages of the Engadine, many of these Italian words fell out of usage (such as \"contadin\" 'farmer' instead of \"paur\", \"nepotin\" 'nephew' rather than \"abiadi\", \"ogni\" 'everyone' instead of \"inmincha\", \"saimper\" 'always' instead of \"adüna\", and \"abbastanza\" 'enough' instead of \"avuonda\"), while others persisted as synonyms of more traditional Ladin words (such as \"tribunal\" 'court' alongside \"drettüra\", \"chapir\" alongside \"incleger\", and \"testimoni\" 'witness' alongside \"perdütta\").\n\nAside from the written language, everyday Romansh was also influenced by Italian through the large number of emigrants, especially from the Engadine, to Italy, the so-called Randulin. These emigrants often returned with their Romansh speech influenced by Italian.\n\nGerman loan words entered Romansh as early as the Old High German period in the Early Middle Ages, and German has remained an important source of vocabulary since. Many of these words have been in use in Romansh for long enough that German speakers no longer recognize them as German, and for morphological derivations of them to have appeared, in particular through the suffix \"-egiar ~ iar\", as in Surs. \"baghegiar\", sut. \"biagear\", Surm. \"biagier\", Put. \"biager\", Vall. \"bear\" 'to build', derived from Middle High German \"bûwen\". Other examples include \"malegiar\" 'to paint' (← \"malen\"), \"schenghegiar\" 'to give (a present)' (← \"schenken\"), \"schazegiar\" 'to estimate' (← \"schätzen\"), or Surs. \"betlegiar\" (sut. \"batlagear\", Surm./Put. \"batlager\", Vall. \"supetliar\") 'to beg', derived from Swiss German \"bettle\" with the same meaning. Nouns derived from these verbs include \"maletg\" 'painting', \"schenghetg\" 'gift', \"schazetg\" 'estimation', or \"bagetg\" 'building'. The adjective \"flissi\" 'hard-working' has given rise to the noun \"flissiadad\" 'industriousness'. The word \"pur\" has given rise to derived words such as \"pura\" 'farmwife, female farmer' or \"puranchel\" 'small-time farmer', as has \"buob\" ‘boy’ from Swiss German \"bueb\" ‘boy’, with the derivations \"buoba\" ‘girl’ and \"buobanaglia\" ‘crowd of children’.\n\nCommon nouns of Italian origin include \"resposta/risposta\" 'answer', \"vista/vesta\" 'view', \"proposta\" 'proposal', \"surpresa/surpraisa\" 'surprise', and \"offaisa/offesa\" 'insult'. In Ladin, many such nouns are borrowed or derived from Italian and end in –a, whereas the same group of nouns in Sursilvan frequently ends in –iun and where borrowed either from French or formed through analogy with Latin. Examples include \"pretensiun\" ‘opinion, claim’ vs. \"pretaisa\", \"defensiun\" ‘defense’ vs. \"defaisa\", or \"confirmaziun\" ‘confirmation’ vs. \"conferma\".\n\nOther Italian words used throughout Romansh include the words for 'nail', which are derived from Italian \"acuto\" 'sharp', which has yielded Sur. \"guota\", Sut. \"guta\", Surm. \"gotta\", and Ladin \"guotta/aguotta\", whereas the Romansh word for 'sharp' itself (Rhenish: \"git\", Ladin \"agüz\") is derived from the same Latin source ACUTUM. Words from various Italian dialects related to crafts include Ladin \"marangun\" 'carpenter' (← Venetian \"marangon\"), as opposed to \"lennari\" in other Romansh dialects, \"chazzoula\" 'trowel' (← Lombard \"cazzola\"), or \"filadè\" 'spinning wheel' (← Lombard \"filadel\"). Other words include culinary items such as \"macaruns\" 'macaroni' (← \"maccheroni\"); \"tschiculatta/tschugalata\" 'chocolate' (← \"cioccolata\" or Lombard \"ciculata/cicolata\"), Ladin and Surmiran \"limun/limung\" 'lemon' as opposed to Sursilvan \"citrona\" (← \"limone\"), \"giabus/baguos\" 'cabbage' (← Lombard \"gabüs\"), \"chanella/canella\" 'cinnamon' (← \"cannella\"). In Sursilvan, the word \"ogna\" 'flat cake' can be found, which is derived from Italian \"lasagna\", with the initial \"las-\" having been mistaken for the plural article, and the vowel having been adapted to Sursilvan sound patterns through analogy with words such as \"muntogna\" 'mountain'. Others are words for animals such as \"lodola\" 'lark' (← \"lodola\") or \"randulina\" 'swallow' (← Lombard \"randulina\"), as well as Ladin \"scarafagi/scarvatg\" 'beetle' (← \"scarafaggio\"). Other Italian words include \"impostas\" 'taxes' (← \"imposte\"; as opposed to Rhenish \"taglia\"), \"radunanza/radunonza\" 'assembly' (← \"radunanza\"), Ladin \"ravarenda\" '(Protestant) priest' (← \"reverendo\"), 'bambin 'Christmas child (giftbringer)' (← \"Gesù Bambino\"), \"marchadant/marcadont\" 'merchant' (← \"mercatante\") or \"butia/buteia\" 'shop' (← \"bottega\").\n\nIn Ladin, Italian borrowings also include words groups not usually borrowed readily. Examples include pronouns such as \"qualchosa\" 'something' (← \"qualcosa\"), \"listess\" 'the same one' (← Lombard or Venetian \"l'istess\"), adverbs such as \"apunta\" 'exactly' (← \"appunto\"), \"magara/magari\" 'fairly/quite' (← \"magari\"), prepositions like \"dürant/duront\" 'during' (← \"durante\") and \"malgrà/malgrad\" 'despite' (← \"malgrado\"), and conjunctions such as \"però\" 'but' (← \"però\") and \"fin cha\" 'until' (← \"finché\"). Most of these are confined to Ladin, with some exceptions such as Sursilvan \"magari\", \"duront\", and \"malgrad\".\n\nAside from outright loan words, the German influence on Romansh often takes the form of calques, where Romanic vocabulary has taken on the meaning of German words, summed up by Italian dialectologist Graziadio Isaia Ascoli in 1880 as \"\"materia romana e spirito tedesco\"\" (\"Roman body and German soul). The earliest examples go back to Carolingian times and show the influence of Germanic law. Such words include \"tschentament\" 'statute', a derivation of the verb \"tschentar\" (from Latin *\"sedentare\" 'to sit') as an analogy to Middle High German \"satzunge\" or Surs./sut./Surm. \"lètg\", Put. \"alach\", Vall. \"lai\" 'marriage', derived from Latin \"legem\" (accusative singular of \"lēx\" 'law'), with the meaning of Middle High German \"ê, ewe\". A more recent example of a loan translation is the verb \"tradir\" 'to betray', which has taken on the additional meaning of German \"verraten\" of 'to give away' as in \"tradir in secret\" 'to give away a secret', originally covered by the verb \"revelar\".\n\nParticularly common are combinations of verbs with locative adverbs, such as \"vegnir cun\" 'to accompany' (literally 'to come with'), \"vegnir anavos\" 'to come back', \"far cun\" 'to participate' (literally 'to do with'), \"far giu\" 'to agree on' (literally 'to do down'), or \"grodar tras\" 'to fail' (literally 'to fall through'). Whereas such verbs also occur sporadically in other Romance languages as in French \"prendre avec\" 'to take along' or Italian \"andare via\" 'to go away', the large number in Romansh suggests an influence of German, where this pattern is common. However, prepositional verbs are also common in the (Romance) Lombard language spoken in the bordering Swiss and Italian regions. The verbs \"far cun\" 'to participate' or \"grodar tras\" 'to fail' for example, are direct equivalents of German \"mitmachen\" (from \"mit\" 'with' and \"machen\" 'to do) and \"durchfallen\" (from \"durch\" 'through' and \"fallen\" 'to fall').\n\nLess integrated into the Romansh verbal system are constructions following the pattern of \"far il\" ('doing the') + a German infinitive. Examples include \"far il löten\" 'to solder', \"far il würzen\" 'to season', or \"far il vermissen\" 'to miss, to feel the absence of'.\n\nGerman also often serves as a model for the creation of new words. An example is Surs. \"tschetapuorla\" 'vacuum cleaner', a compound of \"tschitschar\" 'to suck' and \"puorla\" 'dust', following the model of German \"Staubsauger\" – the Italian word, \"aspirapolvere\" possibly being itself a calque on the German word. The Engadinese dialects on the other hand have adopted \"aspiradur\" from Italian \"aspiratore\", which, however, does not mean \"vacuum cleaner\". The Engadinese dialects on the other hand have adopted \"aspiradur\" from Italian \"aspiratore\". A skyscraper, which is a direct loan translation from English in many Romance languages (as in French \"gratte-en-ciel\", Italian \"grattacielo\"), is a loan translation of German \"Wolkenkratzer\" (literally 'cloud-scraper') in Sursilvan: \"il sgrattaneblas\" (from \"sgrattar\" 'to scratch' and \"neblas\" 'clouds'). The Engadinese varieties again follow the Italian pattern of \"sgrattatschêl\" (from \"tschêl\" 'sky'). A more recent word is \"la natelnumra\" 'the cell phone number', which follows the word order of Swiss German \"Natelnummer\", and is found alongside \"la numra da natel\".\n\nExamples of idiomatic expressions include Surs. \"dar in canaster\", Engad. \"dar ün dschierl\", a direct translation of German 'einen Korb geben', literally meaning 'to hand a basket', but used in the sense of 'turning down a marriage proposal' or \"esser ligiongia ad enzatgi\", a loan translation of the German expression \"jemandem Wurst sein\", literally meaning 'to be sausage to someone' but meaning 'not cared about, to be unimportant'.\n\nApart from vocabulary, the influence of German is noticeable in grammatical constructions, which are sometimes closer to German than to other Romance languages.\n\nFor instance, Romansh is the only Romance language in which indirect speech is formed using the subjunctive mood, as in Sursilvan \"El di ch'el seigi malsauns\", Putèr \"El disch ch'el saja amalo\", 'He says that he is sick', as compared to Italian \"Dice che è malato\" or French \"Il dit qu'il est malade\". Ricarda Liver attributes this to the influence of German. Limited to Sursilvan is the insertion of entire phrases between auxiliary verbs and participles as in \"Cun Mariano Tschuor ha Augustin Beeli discurriu\" 'Mariano Tschuor has spoken with Augustin Beeli' as compared to Engadinese \"Cun Rudolf Gasser ha discurrü Gion Peider Mischol\" 'Rudolf Gasser has spoken with Gion Peider Mischol'.\n\nIn contemporary spoken language, adjective forms are often not distinguished from adverbs, as in Sursilvan \"Jeu mon direct\" 'I am going directly', rather than \"Jeu mon directamein\". This usage is rare in most other Romance languages with a few sporadic exceptions as in French \"parler haut\" or Italian \"vosà fort\" 'speak aloud', and the common usage in colloquial Romansh is likely an influence from German.\n\nEspecially noticeable and often criticized by language purists are particles such as \"aber\", \"schon\", \"halt\", \"grad\", \"eba\", or \"zuar\", which have become an integral part of everyday Romansh speech, especially in Sursilvan.\n\nNegation was originally formed by a double negative in all Romansh dialects. Today, this usage is limited to Surmiran as in \"ia na sa betg\" 'I do not know' (it has also been included in panregional Rumantsch Grischun). While the first particle was lost in Sursilvan, where negation is now formed only with \"buc\" as in \"jeu sai buc\", the Ladin varieties lost the second particle \"brich(a)\", apparently under the influence of Italian, as in Putér \"eau nu se\".\n\nThe influence of Romansh on the local vernacular German has not been studied as thoroughly as vice versa. Apart from place names throughout the former speech area of Romansh, only a handful of Romansh words have become part of wider German usage. Such words include \"Gletscher\" 'glacier' or \"Murmeltier\" 'marmot' (derived from Romansh \"murmunt\"), as well as culinary items such as Maluns or Capuns. The Romansh influence is much stronger in the German dialects of Grisons. It is sometimes controversially suspected that the pronunciation /k/ or /h/ in words such as \"Khind\" and \"bahe\", as opposed to /x/ in other Swiss German dialects (\"Chind\" and \"bache\"), is an influence of Romansh.\n\nIn morphosyntax, the use of the auxiliary verb \"kho\" 'to come' as opposed to \"wird\" 'will' in phrases such as \"leg di warm a, sunscht khunscht krank\" ('put on warm clothes, otherwise you will get sick') in Grisons-German is sometimes attributed to Romansh, as well as the lack of a distinction between the accusative and dative case in some Grisons-German dialects and the word order in phrases such as \"i tet froge jemand wu waiss\" ('I would ask someone who knows'). In addition, some words, neuter in most dialects of German, are masculine in Grisons-German. Examples include \"der Brot\" 'the bread' or \"der Gäld\" 'the money'. Common words of Romansh origin in Grisons-German include \"Schaffa\" (derived from Romansh \"scaffa\" 'cupboard'), \"Spus/Spüslig\" 'bridegroom' and \"Spus\" 'bride', \"Banitsch\" 'cart used for moving dung', and \"Pon\" 'container made of wood'. In areas where Romansh either is still spoken or has disappeared recently, Romansh words are even more common in the local dialects of German.\n\nThe influence of German has been seen in different ways by linguists and language activists. The Italian dialectologist Ascoli for instance described Romansh as \"a body that has lost its soul and taken on an entirely foreign one in its place\" in the 1880s. This opinion was shared by many, who saw the influence of German as a threat to and corruption of Romansh, often referring to it as a disease infecting Romansh. This view was prevalent until after World War II, with many contemporary linguists and activists by contrast seeing these loan elements as completely natural and as an integral part of Romansh, which should be seen as an enrichment of the language. This position is currently held among others by the language activists Bernard Cathomas, Iso Camartin, or Alexi Decurtins, who argue for a relaxed attitude towards loan elements, which they point out are often among the most down-to-earth elements of the language, and that the dual nature of Romansh can also be seen as an advantage in being open to cultural elements from both sides. This position is also shared by several contemporary authors in particular from the Surselva, such as Arno Camenisch, who makes heavy use of Germanisms in his works.\n\nRomansh had a rich oral tradition before the appearance of Romansh writing, but apart from songs such as the \"Canzun da Sontga Margriata\", virtually none of it survives. Prior to the 16th century, Romansh writings are known from only a few fragments.\n\nThe oldest known written records of Romansh dating from the period before 1500 are:\n\nThe first substantial surviving work in Romansh is the \"Chianzun dalla guerra dagl Chiaste da Müs\" written in the Putèr dialect in 1527 by Gian Travers. It is an epic poem describing the First Musso war which Travers himself had taken part in.\n\nSubsequent works usually have religious themes, including Bible translations, manuals for religious instructions, and biblical plays. In 1560, the first Romansh translation of the New Testament: \"L'g Nuof Sainc Testamaint da nos Signer Jesu Christ\" by Giachem Bifrun, was published. Two years later, in 1562, another writer from the Engadine, Durich Chiampel, published the \"Cudesch da Psalms\", a collection of Romansh church songs in the Vallader dialect. In the Sursilvan dialect, the first surviving works are also religious works such as catechism by Daniel Bonifaci, and in 1611 \"Ilg Vêr Sulaz da pievel giuvan\" (\"The true joys of young people\"), a series of religious instructions for Protestant youths was published by Steffan Gabriel. Four years later in 1615, a Catholic catechism \"Curt Mussament\" was published in response, written by Gion Antoni Calvenzano. The first translation of the New Testament into Sursilvan was published in 1648 by the son of Steffan Gabriel, Luci Gabriel. The first complete translation of the Bible, the \"Bibla da Cuera\" was published between 1717 and 1719.\n\nIn music, choirs have a long tradition in the Romansh-speaking areas. Apart from traditional music and song, Romansh is also used in contemporary pop or hip-hop music, some of which has become known outside the Romansh-speaking regions, for instance, in the Eurovision Song Contest 1989, Switzerland was represented by a Romansh song, \"Viver senza tei\". Since 2004, the hip-hop group Liricas Analas has become known even outside of Grisons through their Romansh songs. Other contemporary groups include the rock-band \"Passiunai\" with its lead singer Pascal Gamboni, or the rock/pop band The Capoonz. Composer Gion Antoni Derungs has written three operas with Romansh librettos: \"Il cerchel magic\" (1986), \"Il semiader\" (1998) and \"Tredeschin\" (2000).\nRomansh is used to varying extents in newspapers, the radio, and television. Radio and television broadcasts in Romansh are produced by the Radiotelevisiun Svizra Rumantscha, which is part of the Swiss public broadcasting company SRG SSR. The radio Radio Rumantsch broadcasts a 24-hour program including informational and music broadcasts. The broadcasters generally speak their own regional dialect on the air, which is considered a key factor in familiarizing Romansh speakers with the dialects outside their home region. News broadcasts are generally in the pan-regional variety Rumantsch Grischun. The two local radio stations Radio Grischa and Radio Engiadina occasionally broadcast in Romansh, but primarily use German. The Televisiun Rumantscha airs regular broadcasts on SF 1, which are subtitled in German. Programs include the informational broadcast \"Telesguard\", which is broadcast daily from Monday to Friday. The children's show \"Minisguard\" and the informational broadcast \"Cuntrasts\" are aired on weekends. Additionally, the shows \"Controvers\", \"Pled sin via\", and others are broadcast during irregular intervals.\n\nThe Romansh newspapers used to be heavily fragmented by regions and dialects. The more long-lived newspapers included the \"Gasetta Romontscha\" in the Surselva, the \"Fögl Ladin\" in the Engadine, \"Casa Paterna/La Punt\" in the Sutselva, and \"La Pagina da Surmeir\" in the Surmeir. Due to financial difficulties, most of these merged into a pan-regional daily newspaper called \"La Quotidiana\" in 1997. This newspaper includes articles in all five dialects and in Rumantsch Grischun. Apart from \"La Quotidiana\", \"La Pagina da Surmeir\" continues to be published to a regional audience, and the \"Engadiner Post\" includes two pages in Romansh. A Romansh news agency, the Agentura da Novitads Rumantscha, has been in existence since 1997.\n\nSeveral Romansh-language magazines are also published regularly, including the youth magazine \"Punts\" and the yearly publications \"Calender Romontsch\" and \"Chalender Ladin\".\n\nThe fable The Fox and the Crow by Aesop with a French version by Jean de La Fontaine; translated into the Dachsprache Rumantsch Grischun and all six dialects of Romansh: Sursilvan, Sutsilvan, Surmiran, Puter, and the similar-looking but noticeably different-sounding dialects Vallader and Jauer, as well as a translation into English.\n\n\n\n"}
{"id": "25530", "url": "https://en.wikipedia.org/wiki?curid=25530", "title": "Robert Rodriguez", "text": "Robert Rodriguez\n\nRobert Anthony Rodriguez (born June 20, 1968) is an American filmmaker, screenwriter, and musician. He shoots and produces many of his films in Mexico and his home state, Texas. Rodriguez directed the 1992 action film \"El Mariachi\", which was a commercial success after grossing $2 million against a budget of $7,000. The film spawned two sequels known collectively as the \"Mexico Trilogy\": \"Desperado\" and \"Once Upon a Time in Mexico\". He directed \"From Dusk till Dawn\" in 1996 and developed its (2014–present). Rodriguez co-directed the 2005 neo-noir crime thriller anthology \"Sin City\" (adapted from the graphic novel of the same name) and the 2014 sequel, \"\". Rodriguez also directed the \"Spy Kids\" films, \"The Faculty\", as well as \"The Adventures of Sharkboy and Lavagirl\", \"Planet Terror\", and \"Machete\". He is a friend and frequent collaborator of filmmaker Quentin Tarantino, who founded the production company A Band Apart, which Rodriguez was a member of. In December 2013, Rodriguez launched his own cable television channel, El Rey.\n\nRodríguez was born in San Antonio, Texas, the son of Mexican-American parents Rebecca (née Villegas), a nurse, and Cecilio G. Rodríguez, a salesman. He began his interest in film at age eleven, when his father bought one of the first VCRs, which came with a camera.\n\nWhile attending St. Anthony High School Seminary in San Antonio, Rodríguez was commissioned to videotape the school's football games. According to his sister, he was fired soon afterward as he had shot footage in a cinematic style, getting shots of parents' reactions and the ball traveling through the air instead of shooting the whole play. In high school, he met Carlos Gallardo; they both shot films on video throughout high school and college.\n\nRodriguez went to the College of Communication at the University of Texas at Austin, where he also developed a love of cartooning. Not having grades high enough to be accepted into the school's film program, he created a daily comic strip entitled \"Los Hooligans.\" Many of the characters were based on his siblings – in particular, one of his sisters, Maricarmen. The comic ran for three years in the student newspaper \"The Daily Texan\", while Rodríguez continued to make short films.\n\nRodríguez shot action and horror short films on video and edited on two VCRs. In late 1990, his entry in a local film contest earned him a spot in the university's film program. There he made the award-winning 16 mm short \"Bedhead\" (1991). The film chronicles the amusing misadventures of a young girl whose older brother sports an incredibly tangled mess of hair which she detests. Even at this early stage, Rodríguez's trademark style began to emerge: quick cuts, intense zooms, and fast camera movements deployed with a sense of humor.\n\n\"Bedhead\" (1991) was recognized for excellence in the Black Maria Film Festival. It was selected by Film/Video Curator Sally Berger, for the Black Maria 20th-anniversary retrospective at MoMA in 2006.\n\nThe short film \"Bedhead\" attracted enough attention to encourage him to seriously attempt a career as a filmmaker. He went on to shoot the action flick \"El Mariachi\" (1992) in Spanish; he shot it for around $7,000 with money raised by his friend Carlos Gallardo and from payments for his own participation in medical testing studies. Rodriquez won the Audience Award for this film at the Sundance Film Festival in 1993. Intended for the Spanish-language low-budget home-video market, the film was \"cleaned up\" by Columbia Pictures with post-production work costing several hundred thousand dollars before it was distributed in the United States. Its promotion still advertised it as \"the movie made for $7,000\". Rodríguez described his experiences making the film in his book \"Rebel Without a Crew\" (1995).\n\n\"Desperado\" was a sequel to \"El Mariachi\" that starred Antonio Banderas and introduced Salma Hayek to American audiences. Rodríguez went on to collaborate with Quentin Tarantino on the vampire thriller \"From Dusk till Dawn\" (also both co-producing its two sequels), and he is currently writing, directing, and producing the for his own cable network, El Rey. Rodriguez has also worked with Kevin Williamson, on the horror film \"The Faculty\".\n\nIn 2001, Rodríguez enjoyed his first Hollywood hit with \"Spy Kids\", which went on to become a movie franchise. A third \"mariachi\" film also appeared in late 2003, \"Once Upon a Time in Mexico\", which completed the Mexico Trilogy (also called the Mariachi Trilogy). He operates a production company called Troublemaker Studios, formerly Los Hooligans Productions.\n\nRodríguez co-directed \"Sin City\" (2005), an adaptation of the Frank Miller \"Sin City\" comic books; Quentin Tarantino guest-directed a scene. During production in 2004, Rodríguez insisted Miller to be credited as co-director, because he considered the visual style of Miller's comic art to be just as important as his own in the film. However, the Directors Guild of America would not allow it, citing that only \"legitimate teams\", \"e.g.\", the Wachowskis, could share the director's credit. Rodríguez chose to resign from the DGA, stating, \"It was easier for me to quietly resign before shooting because otherwise I'd be forced to make compromises I was unwilling to make or set a precedent that might hurt the guild later on.\" By resigning from the DGA, Rodríguez was forced to relinquish his director's seat on the film \"John Carter of Mars\" for Paramount Pictures. Rodríguez had already signed on and had been announced as director of that film, planning to begin filming soon after completing \"Sin City\".\n\n\"Sin City\" was a critical hit in 2005 as well as a box office success, particularly for a hyperviolent comic book adaptation that did not have name recognition comparable to the \"X-Men\" or \"Spider-Man\". He has stated that he is interested in eventually adapting all of Miller's \"Sin City\" comic books.\n\nRodríguez released \"The Adventures of Sharkboy and Lavagirl\" in 2005, a superhero-kid movie intended for the same younger audiences as his \"Spy Kids\" series. \"Sharkboy and Lavagirl\" was based on a story conceived by Rodríguez's 7-year-old son, Racer, who was given credit for the screenplay. The film was not a major success, grossing just $39 million at the box office.\n\nRodríguez wrote and directed the film \"Planet Terror\" as part of the double-bill release \"Grindhouse\" (2007). Quentin Tarantino directed \"Grindhouse\"'s other film.\n\nHe also has a series of \"Ten Minute Film School\" segments on several of his DVD releases, showing aspiring filmmakers how to make good, profitable movies using inexpensive tactics. Starting with the \"Once Upon a Time in Mexico\" DVD, Rodríguez began creating a series called, \"Ten Minute Cooking School\" where he revealed his recipe for \"Puerco Pibil\" (based on Cochinita pibil, an old dish from Yucatán), the same food Johnny Depp's character, \"Agent Sands\" ate in the film. The popularity of this series led to the inclusion of another \"Cooking School\" on the two-disc version of the \"Sin City\" DVD where Rodríguez teaches the viewer how to make \"Sin City Breakfast Tacos\", a dish (made for his cast and crew during late-night shoots and editing sessions) utilizing his grandmother's tortilla recipe and different egg mixes for the filling. He had initially planned to release a third \"Cooking School\" with the DVD release of \"Planet Terror\" but then announced on the \"Film School\" segment of the DVD that he would put it on the \"Grindhouse\" DVD set instead. The Cooking School, titled \"Texas Barbecue...from the GRAVE!\", is a dish based on the \"secret barbecue recipe\" of JT Hague, Jeff Fahey's character in the film.\n\nRodríguez is a strong supporter of digital filmmaking, having been introduced to the practice by director George Lucas, who personally invited Rodríguez to use the digital cameras at Lucas's headquarters. He was presented with the Extraordinary Contribution to Filmmaking Award at the 2010 Austin Film Festival.\n\nOn April 23, 2009, it was announced that Rodríguez would produce a new Predator sequel, entitled \"Predators\". This film's script was based on early drafts he had written after seeing the original. Rodriguez's ideas included a planet-sized game preserve and various creatures used by the Predators to hunt a group of abducted yet skilled humans. Opening to mostly positive reviews, the film fared reasonably well at the box office.\n\n\"Machete\" is a feature film directed by Rodríguez and released in September 2010. It is an expansion of a fake trailer Rodriguez directed for the 2007 film \"Grindhouse\". It starred Danny Trejo as the title character. Trejo, Rodriguez's 2nd cousin, has worked with him in some of his other movies such as \"Desperado\", \"From Dusk Till Dawn\", \"Once Upon a Time in Mexico\" and \"Spy Kids\", where Trejo's character was also known as Machete. Although originally announced to be released direct-to-DVD as an extra on the \"Planet Terror\" DVD, the film was produced as a theatrical release.\n\nAccording to Rodríguez, the origins of the film go back to \"Desperado\". He says, \"When I met Danny, I said, 'This guy should be like the Mexican Jean-Claude Van Damme or Charles Bronson, putting out a movie every year and his name should be Machete.' So I decided to do that way back when, never got around to it until finally now. So now, of course, I want to keep going and do a feature.\" In an interview with \"Rolling Stone\" magazine, Rodriguez said that he wrote the screenplay back in 1993 when he cast Trejo in \"Desperado\". \"So I wrote him this idea of a federale from Mexico who gets hired to do hatchet jobs in the U.S. I had heard sometimes FBI or DEA have a really tough job that they don't want to get their own agents killed on, they'll hire an agent from Mexico to come do the job for $25,000. I thought, \"That's \"Machete\". He would come and do a really dangerous job for a lot of money to him but for everyone else over here it's peanuts.\" But I never got around to making it.\"\n\nRodríguez hoped to film \"Machete\" at the same time as \"\". Additionally, during Comic-Con International 2008, he took the time to speak about Machete, including such topics as: status, possible sequels after the release of Machete, and production priorities. It was also revealed that he has regularly pulled sequences from it for his other productions including Once Upon a Time in Mexico. \"Machete\" was released in theaters September 3, 2010 in the U.S.A.\n\nOn May 5, 2010, Robert Rodríguez responded to Arizona's controversial immigration law by releasing an \"illegal\" trailer on Ain't It Cool News. The fake trailer combined elements of the \"Machete\" trailer that appeared in \"Grindhouse\" with footage from the actual film, and implied that the film would be about Machete leading a revolt against anti-immigration politicians and border vigilantes. Several movie websites, including Internet Movie Database, reported that it was the official teaser for the film. However, Rodriguez later revealed the trailer to be a joke, explaining \"it was Cinco de Mayo and I had too much tequila.\"\n\nSince 1998, he has owned the film rights to Mike Allred's off-beat comic \"Madman\". The two have hinted at the project being close to beginning on several occasions without anything coming of it. However, other projects have been completed first (Allred was instrumental in connecting Rodríguez with Frank Miller, leading to the production of \"Sin City\"). In 2004, Allred, while promoting his comic book, \"The Golden Plates\", announced that a screenplay by George Huang was near completion. In March 2006, it was announced that production on \"Sin City: A Dame to Kill For\" would be postponed. Allred announced at the 2006 WonderCon that production would likely commence on \"Madman the Movie\" in 2006. Huang is actually friends with Rodriguez, who advised him to pursue filmmaking as a career when Rodriguez landed a deal with Columbia Pictures where Huang was an employee.\n\nIn May 2007 it was announced that Rodríguez had signed on to direct a remake of \"Barbarella\" for a 2008 release. At the 2007 Comic-Con convention, actress Rosario Dawson announced that because of \"Barbarella\", production of \"Sin City: A Dame to Kill For\" would be put on hold. She also announced that she would be playing an amazon in the Barbarella film. As of June 2008, plans to remake the film Barbarella with Rose McGowan as the lead have been delayed; the actress and director are instead remaking the film \"Red Sonja\".\n\nIn May 2008 Rodríguez is said to be shopping around a prison drama television series called \"Woman in Chains!\", with Rose McGowan being a possibility for a lead role.\n\nAs of May 2009, Rodríguez plans to produce a live-action remake of \"Fire and Ice\", a 1983 film collaboration between painter Frank Frazetta and animator Ralph Bakshi. The deal was closed shortly after Frazetta's death.\n\nIn 2011, Rodríguez announced at Comic-Con that he had purchased the film rights to \"Heavy Metal\" and planned to develop a new animated film at the new Quick Draw Studios.\n\nIn October 2015, it was reported that Rodriguez will direct and produce \"\" with James Cameron and Jon Landau co-producing.\n\nIn November 2015 it was announced Rodriguez directed the film \"100 Years\", which will not be released until 2115.\n\nIn March 2017, it was announced that Rodriguez will direct \"Escape from New York\", a remake of the dystopian sci-fi action film with original director John Carpenter producing.\n\nRodríguez announced in April 2006 that he and his wife Elizabeth Avellán, with whom he had five children, had separated after 16 years of marriage. Avellán has continued to produce most of his films since the split-up, so their professional relationship has continued.\n\nHe reportedly had a \"dalliance\" with actress Rose McGowan during the shooting of \"Grindhouse\". In October 2007, \"Elle Magazine\" revealed that Rodríguez cast McGowan as the title role in his remake of \"Barbarella\". After some reports of their breaking up and being together again, they split up in October 2009.\n\nIn October 2010, he walked Alexa Vega down the aisle at her wedding to producer Sean Covel.\n\nIn March 2014, Rodriguez showed his collection of Frank Frazetta original paintings in Austin, Texas, during the SXSW festival.\n\nRodríguez not only has the credits of producing, directing and writing his films, he also frequently serves as editor, director of photography, camera operator, steadicam operator, composer, production designer, visual effects supervisor, and sound editor on his films. This has earned him the nickname of \"the one-man film crew\". He abbreviates his numerous roles in his film credits; \"Once Upon a Time in Mexico\", for instance, is \"shot, chopped, and scored by Robert Rodriguez\", and \"Sin City\" is \"shot and cut by Robert Rodriguez\".\n\nHe calls his style of making movies \"Mariachi-style\" (in reference to his first feature film \"El Mariachi\") in which (according to the back cover of his book \"Rebel Without a Crew\")\n\"Creativity, not money, is used to solve problems.\"\n\nIn his book \"The DV Rebel's Guide\", Stu Maschwitz coined the term \"Robert Rodriguez list\", i.e. the filmmaker compiling a list of things they have access to like cool cars, apartments, horses, samurai swords and so on, and then writing the screenplay based on that list.\n\nRodriguez wrote a blurb for the book that stated:\n\"I'd been wanting to write a book for the new breed of digital filmmakers, but now I don't have to. My pal and fellow movie maker Tom Moore has compressed years of experience into this thorough guide. Don't make a movie without reading this book!\" \n\n\n"}
{"id": "25531", "url": "https://en.wikipedia.org/wiki?curid=25531", "title": "Romantic comedy film", "text": "Romantic comedy film\n\nRomantic comedy films (also known as the portmanteaus romedy or romcom) are films with light-hearted, humorous plotlines, centered on romantic ideals such as that true love is able to surmount most obstacles. One dictionary definition is \"a funny movie, play, or television program about a love story that ends happily\". Another definition states that its \"primary distinguishing feature is a love plot in which two sympathetic and well-matched lovers are united or reconciled\".\n\nRomantic comedy films are a certain genre of comedy films as well as of romance films, and may also have elements of screwball comedies. However, a romantic comedy is classified as a film with two genres not a single new genre. Some television series can also be classified as romantic comedies.\n\nIn a typical romantic comedy the two lovers tend to be young, likeable, and apparently meant for each other, yet they are kept apart by some complicating circumstance (e.g., class differences, parental interference; a previous girlfriend or boyfriend) until, surmounting all obstacles, they are finally wedded. A wedding-bells, fairy-tale-style happy ending is practically mandatory.\n\nThe basic plot of a romantic comedy is that two characters meet, part ways due to an argument or other obstacle, then ultimately reunite. Sometimes the two leads meet and become involved initially, then must confront challenges to their union. Sometimes they are hesitant to become romantically involved because they believe that they do not like each other, because one of them already has a partner, or because of social pressures. However, the screenwriters leave clues that suggest that the characters are, in fact, attracted to each other and that they would be a good love match. The protagonists often separate or seek time apart to sort out their feelings or deal with the external obstacles to their being together.\n\nWhile the two protagonists are separated, one or both of them usually realizes that they are ideal for each other, or that they are in love with each other. Then, after one of the two makes some spectacular effort (sometimes called the \"grand gesture\") to find the other person and declare their love, or through an astonishing coincidental encounter, the two meet again. Then, perhaps with some comic friction or awkwardness, they declare their love for each other and the film ends happily. The couple does not, however, have to marry, or live together \"happily ever after\". The ending of a romantic comedy is meant to affirm the primary importance of the love relationship in its protagonists' lives, even if they physically separate in the end (e.g. \"Shakespeare in Love\", \"Roman Holiday\").\n\nThere are many variations on this basic plotline. Sometimes, instead of the two lead characters ending up in each other's arms, another love match will be made between one of the principal characters and a secondary character (e.g., \"My Best Friend's Wedding\" and \"My Super Ex-Girlfriend\"). Alternatively, the film may be a rumination on the impossibility of love, as in Woody Allen's film \"Annie Hall.\" The basic format of a romantic comedy film can be found in much earlier sources, such as Shakespeare plays like \"Much Ado About Nothing\" and \"A Midsummer Night's Dream\".\n\nSome comedy films, such as \"Knocked Up\", combine themes of romantic comedies and stoner comedies, creating a subgenre that appeals to both men and women. Often known as \"bromance\", such films usually use sexual elements which bring the two characters together. Films in this genre include \"American Pie 2\" and even \"Wedding Crashers\".\n\nRomantic comedies have begun to spread out of their conventional and traditional structure into other territory. This territory explores more subgenres and more complex topics. These films still follow the typical plot of \"a light and humorous movie, play, etc., whose central plot is a happy love story\" but with more complexity. These are a few ways romantic comedies are adding more subtlety and complexity into the genre.\n\nSome romantic comedies have adopted extreme or strange circumstances for the main characters, as in \"Warm Bodies\" where the protagonist is a zombie who falls in love with a human girl after eating her boyfriend. Another strange set of circumstances is in \"Zack and Miri Make a Porno\" where the two protagonists are building a relationship while trying to make a porno together. Both these films take the typical story-arch and then utilize circumstances to add originality.\n\nOther romantic comedies flip the standard conventions of the romantic comedy genre. In films like \"500 Days of Summer\", the two main interests do not end up together, leaving the protagonist somewhat distraught. Other films like \"Adam\" have the two main interests end up separated but still content and pursuing other goals and love interests.\n\nSome romantic comedies use reversal of gender roles to add comedic effect. These films contain characters who possess qualities that diverge from the gender role that society has imposed upon them, as seen in \"Forgetting Sarah Marshall\" in which the male protagonist is especially in touch with his emotions and \"Made of Honor\" in which the female bridesmaids are shown in a negative and somewhat masculine light in order to advance the likability of the male lead.\n\nOther remakes of romantic comedies involve similar elements but explore more adult themes such as marriage, responsibility or even disability. Two films by Judd Apatow such as \"This is 40\" or \"Knocked Up\" deal with these before-mentioned issues. \"This is 40\" chronicles the mid-life crisis of a couple entering their 40s, and \"Knocked Up\" addresses unintended pregnancy and the ensuing assuming of responsibility. \"Silver Linings Playbook\" deals with mental illness and the courage to start a new relationship.\n\nAll of these go against the stereotype of what romantic comedy has become as a genre. Yet the genre of romantic comedy is simply a structure and all of these elements do not negate the fact that these films are still romantic comedies.\n\nOne of the conventions of romantic comedy films is the entertainment factor in a contrived encounter of two potential romantic partners in unusual or comic circumstances, which film critics such as Roger Ebert or the Associated Press' Christy Lemire have called a \"meet-cute\" situation. During a \"meet-cute\", scriptwriters often create a humorous sense of awkwardness between the two potential partners by depicting an initial clash of personalities or beliefs, an embarrassing situation, or by introducing a comical misunderstanding or mistaken identity situation. Sometimes the term is used without a hyphen (a \"meet cute\"), or as a verb (\"to meet cute\").\n\nRoger Ebert describes the \"concept of a Meet Cute\" as \"when boy meets girl in a cute way.\" As an example, he cites \"The Meet Cute in \"Lost and Found\" [which] has Jackson and Segal running their cars into each other in Switzerland. Once recovered, they Meet Cute again when they run into each other while on skis. Eventually... they fall in love.\"\n\nIn many romantic comedies, the potential couple comprises polar opposites, two people of different temperaments, situations, social statuses, or all three (\"It Happened One Night\"), who would not meet or talk under normal circumstances, and the meet cute's contrived situation provides the opportunity for these two people to meet.\n\nCertain movies are entirely driven by the meet-cute situation, and contrived circumstances throw the couple together for much of the screenplay. However, movies in which the contrived situation is the main feature, such as \"Some Like It Hot\", rather than the romance being the main feature, are not considered \"meet-cutes\".\n\nThe use of the meet-cute is less marked in television series and novels, because these formats have more time to establish and develop romantic relationships. In situation comedies, relationships are static and meet-cute is not necessary, though flashbacks may recall one (\"The Dick Van Dyke Show\", \"Mad About You\") and lighter fare may require contrived romantic meetings.\n\nThe heyday of \"meet cute\" in films was during the Great Depression in the 1930s; screwball comedy films made a heavy use of contrived romantic \"meet cutes\", perhaps because the more rigid class consciousness and class divisions of this period made cross-social class romances into tantalizing fantasies.\n\nThe \"Oxford Dictionary of Literary Terms\" defines romantic comedy as \"a general term for comedies that deal mainly with the follies and misunderstandings of young lovers, in a light‐hearted and happily concluded manner which usually avoids serious satire\". This reference states that the \"best‐known examples are Shakespeare's comedies of the late 1590s, \"A Midsummer Night's Dream\", \"Twelfth Night\", and \"As You Like It\" being the most purely romantic, while \"Much Ado About Nothing\" approaches the comedy of manners and \"The Merchant of Venice\" is closer to tragicomedy.\"\n\nComedies since ancient Greece have often incorporated sexual or social elements.\n\nIt was not until the creation of romantic love in the western European medieval period, though, that \"romance\" came to refer to \"romantic love\" situations, rather than the heroic adventures of medieval Romance. These adventures, however, often revolved about a knight's feats on behalf of a lady, and so the modern themes of love were quickly woven into them, as in Chrétien de Troyes's \"Lancelot, the Knight of the Cart\".\n\nShakespearean comedy and Restoration comedy remain influential. The creation of huge economic social strata in the Gilded Age, combined with the heightened openness about sex after the Victorian era and the celebration of Sigmund Freud's theories, and the birth of the film industry in the early twentieth century, gave birth to the screwball comedy. As class consciousness declined and World War II unified various social orders, the savage screwball comedies of the twenties and thirties, proceeding through Rock Hudson–Doris Day-style comedies, gave way to more innocuous comedies. This style faded in the 1960s, and the genre lay mostly dormant until the more sexually charged \"When Harry Met Sally\" had a successful box office run in 1989, paving the way for a rebirth for the Hollywood romantic comedy in the mid-1990s.\n\nThe French film industry went in a completely different direction, with less inhibitions about sex. Virginia Woolf, tired of stories that ended in 'happily ever after' at the beginning of a serious relationship, called \"Middlemarch\" by George Eliot, with its portrayal of a difficult marriage, \"one of the few English novels written for grown-up people.\"\n\nWith the increase of romantic comedy movies, there has been an apparent change in the way society views romance. Researchers are asking whether the romance projected in romantic comedies are preventing true love in real life. The increase in use of technology has also led the society to spend a great amount of time engaging in mediated reality and less time with each other. Even though researchers have only started to explore the impact of romantic comedy films on human romance, the few studies conducted have already shown correlation between romantic comedies and the love delusion. Romantic comedies are very popular. They depict relationships that some scholars think affect how people view relationships outside of this virtual world. These scholars believe romantic comedies can cause their audience to be discontent in their relationships because romantic comedies cause women to place men as the center of their universe. Depictions of stalking, men fighting for women no matter what, and placing women’s happiness solely on men are depicted in romantic comedies.They can teach women and men that guys should make the first move in a relationship. They sometimes depict that the guy should be masculine and smart while the girl should be feminine and passive. They can place men as the key to women’s happiness and this causes women and men in real life to put too much pressure on relationships.\n\nIn the past, love has not always been the real reason of people coming together. In some cultures, arranged marriages were common to keep the caste systems or to join kingdoms. Today, love is the root of all romance, and it is over-emphasized through these films. It tells viewers that love conquers all and will ultimately bring a never-ending happiness that is rarely affected by any conflict. When people do not experience the romance portrayed in these movies, they often wonder what they are doing wrong. Although people should be able to tell between an overly romanticized love and realistic love, they are often caught up in constantly trying to echo the stories they see on screen. While most know that the idea of a perfect relationship is unrealistic, some perceptions of love are heavily influenced by media portrayals.\n\nA study was conducted at Heriot Watt University in Edinburgh to understand this phenomenon. They studied 40 top box office films released between 1995 and 2005 to establish common themes. Then they asked hundreds of people to complete a questionnaire to describe their beliefs and expectations in romantic relationships. Researchers found that people who enjoyed movies such as \"You’ve Got Mail, The Wedding Planner\" and \"While You Were Sleeping,\" often failed to communicate with their partners effectively. They also believe that if someone is meant to be with you, then they should know your needs without you telling them. Although this study is just one of a handful, it shows a correlation of how people's expectations are distorted through watching romantic comedies.\n\n\n"}
{"id": "25532", "url": "https://en.wikipedia.org/wiki?curid=25532", "title": "Renaissance", "text": "Renaissance\n\nThe Renaissance (, ) was a period in European history, from the 14th to the 17th century, regarded as the cultural bridge between the Middle Ages and modern history. It started as a cultural movement in Italy in the Late Medieval period and later spread to the rest of Europe, marking the beginning of the Early Modern Age.\n\nThe intellectual basis of the Renaissance was its own invented version of humanism, derived from the rediscovery of classical Greek philosophy, such as that of Protagoras, who said that \"Man is the measure of all things.\" This new thinking became manifest in art, architecture, politics, science and literature. Early examples were the development of perspective in oil painting and the recycled knowledge of how to make concrete. Although the invention of metal movable type sped the dissemination of ideas from the later 15th century, the changes of the Renaissance were not uniformly experienced across Europe.\n\nAs a cultural movement, the Renaissance encompassed innovative flowering of Latin and vernacular literatures, beginning with the 14th-century resurgence of learning based on classical sources, which contemporaries credited to Petrarch; the development of linear perspective and other techniques of rendering a more natural reality in painting; and gradual but widespread educational reform. In politics, the Renaissance contributed to the development of the customs and conventions of diplomacy, and in science to an increased reliance on observation and inductive reasoning. Although the Renaissance saw revolutions in many intellectual pursuits, as well as social and political upheaval, it is perhaps best known for its artistic developments and the contributions of such polymaths as Leonardo da Vinci and Michelangelo, who inspired the term \"Renaissance man\".\n\nThe Renaissance began in Florence, in the 14th century. Various theories have been proposed to account for its origins and characteristics, focusing on a variety of factors including the social and civic peculiarities of Florence at the time: its political structure; the patronage of its dominant family, the Medici; and the migration of Greek scholars and texts to Italy following the Fall of Constantinople to the Ottoman Turks. Other major centres were northern Italian city-states such as Venice, Genoa, Milan, Bologna, and finally Rome during the Renaissance Papacy.\n\nThe Renaissance has a long and complex historiography, and, in line with general scepticism of discrete periodizations, there has been much debate among historians reacting to the 19th-century glorification of the \"Renaissance\" and individual culture heroes as \"Renaissance men\", questioning the usefulness of \"Renaissance\" as a term and as a historical delineation. The art historian Erwin Panofsky observed of this resistance to the concept of \"Renaissance\":\n\nIt is perhaps no accident that the factuality of the Italian Renaissance has been most vigorously questioned by those who are not obliged to take a professional interest in the aesthetic aspects of civilization—historians of economic and social developments, political and religious situations, and, most particularly, natural science—but only exceptionally by students of literature and hardly ever by historians of Art.\n\nSome observers have called into question whether the Renaissance was a cultural \"advance\" from the Middle Ages, instead seeing it as a period of pessimism and nostalgia for classical antiquity, while social and economic historians, especially of the \"longue durée\", have instead focused on the continuity between the two eras, which are linked, as Panofsky observed, \"by a thousand ties\". \n\nThe word \"Renaissance\", literally meaning \"Rebirth\" in French, first appeared in English in the 1830s. The word also occurs in Jules Michelet's 1855 work, \"Histoire de France\". The word \"Renaissance\" has also been extended to other historical and cultural movements, such as the Carolingian Renaissance and the Renaissance of the 12th century.\n\nThe Renaissance was a cultural movement that profoundly affected European intellectual life in the early modern period. Beginning in Italy, and spreading to the rest of Europe by the 16th century, its influence was felt in literature, philosophy, art, music, politics, science, religion, and other aspects of intellectual inquiry. Renaissance scholars employed the humanist method in study, and searched for realism and human emotion in art.\n\nRenaissance humanists such as Poggio Bracciolini sought out in Europe's monastic libraries the Latin literary, historical, and oratorical texts of Antiquity, while the Fall of Constantinople (1453) generated a wave of émigré Greek scholars bringing precious manuscripts in ancient Greek, many of which had fallen into obscurity in the West. It is in their new focus on literary and historical texts that Renaissance scholars differed so markedly from the medieval scholars of the Renaissance of the 12th century, who had focused on studying Greek and Arabic works of natural sciences, philosophy and mathematics, rather than on such cultural texts.\n\nIn the revival of neo-Platonism Renaissance humanists did not reject Christianity; quite the contrary, many of the Renaissance's greatest works were devoted to it, and the Church patronized many works of Renaissance art. However, a subtle shift took place in the way that intellectuals approached religion that was reflected in many other areas of cultural life. In addition, many Greek Christian works, including the Greek New Testament, were brought back from Byzantium to Western Europe and engaged Western scholars for the first time since late antiquity. This new engagement with Greek Christian works, and particularly the return to the original Greek of the New Testament promoted by humanists Lorenzo Valla and Erasmus, would help pave the way for the Protestant Reformation.\n\nWell after the first artistic return to classicism had been exemplified in the sculpture of Nicola Pisano, Florentine painters led by Masaccio strove to portray the human form realistically, developing techniques to render perspective and light more naturally. Political philosophers, most famously Niccolò Machiavelli, sought to describe political life as it really was, that is to understand it rationally. A critical contribution to Italian Renaissance humanism Giovanni Pico della Mirandola wrote the famous text \"\"De hominis dignitate\"\" (Oration on the Dignity of Man, 1486), which consists of a series of theses on philosophy, natural thought, faith and magic defended against any opponent on the grounds of reason. In addition to studying classical Latin and Greek, Renaissance authors also began increasingly to use vernacular languages; combined with the introduction of printing, this would allow many more people access to books, especially the Bible.\n\nIn all, the Renaissance could be viewed as an attempt by intellectuals to study and improve the secular and worldly, both through the revival of ideas from antiquity, and through novel approaches to thought. Some scholars, such as Rodney Stark, play down the Renaissance in favor of the earlier innovations of the Italian city-states in the High Middle Ages, which married responsive government, Christianity and the birth of capitalism. This analysis argues that, whereas the great European states (France and Spain) were absolutist monarchies, and others were under direct Church control, the independent city republics of Italy took over the principles of capitalism invented on monastic estates and set off a vast unprecedented commercial revolution that preceded and financed the Renaissance.\n\nMany argue that the ideas characterizing the Renaissance had their origin in late 13th-century Florence, in particular with the writings of Dante Alighieri (1265–1321) and Petrarch (1304–1374), as well as the paintings of Giotto di Bondone (1267–1337). Some writers date the Renaissance quite precisely; one proposed starting point is 1401, when the rival geniuses Lorenzo Ghiberti and Filippo Brunelleschi competed for the contract to build the bronze doors for the Baptistery of the Florence Cathedral (Ghiberti won). Others see more general competition between artists and polymaths such as Brunelleschi, Ghiberti, Donatello, and Masaccio for artistic commissions as sparking the creativity of the Renaissance. Yet it remains much debated why the Renaissance began in Italy, and why it began when it did. Accordingly, several theories have been put forward to explain its origins.\n\nDuring the Renaissance, money and art went hand in hand. Artists depended entirely on patrons while the patrons needed money to foster artistic talent. Wealth was brought to Italy in the 14th, 15th, and 16th centuries by expanding trade into Asia and Europe. Silver mining in Tyrol increased the flow of money. Luxuries from the Eastern world, brought home during the Crusades, increased the prosperity of Genoa and Venice.\n\nJules Michelet defined the 16th-century Renaissance in France as a period in Europe's cultural history that represented a break from the Middle Ages, creating a modern understanding of humanity and its place in the world.\n\nIn stark contrast to the High Middle Ages, when Latin scholars focused almost entirely on studying Greek and Arabic works of natural science, philosophy and mathematics, Renaissance scholars were most interested in recovering and studying Latin and Greek literary, historical, and oratorical texts. Broadly speaking, this began in the 14th century with a Latin phase, when Renaissance scholars such as Petrarch, Coluccio Salutati (1331–1406), Niccolò de' Niccoli (1364–1437) and Poggio Bracciolini (1380–1459) scoured the libraries of Europe in search of works by such Latin authors as Cicero, Lucretius, Livy and Seneca. By the early 15th century, the bulk of such Latin literature had been recovered; the Greek phase of Renaissance humanism was under way, as Western European scholars turned to recovering ancient Greek literary, historical, oratorical and theological texts.\n\nUnlike with Latin texts, which had been preserved and studied in Western Europe since late antiquity, the study of ancient Greek texts was very limited in medieval Western Europe. Ancient Greek works on science, maths and philosophy had been studied since the High Middle Ages in Western Europe and in the medieval Islamic world (normally in translation), but Greek literary, oratorical and historical works (such as Homer, the Greek dramatists, Demosthenes and Thucydides) were not studied in either the Latin or medieval Islamic worlds; in the Middle Ages these sorts of texts were only studied by Byzantine scholars. One of the greatest achievements of Renaissance scholars was to bring this entire class of Greek cultural works back into Western Europe for the first time since late antiquity. Arab logicians had inherited Greek ideas after they had invaded and conquered Egypt and the Levant. Their translations and commentaries on these ideas worked their way through the Arab West into Iberia and Sicily, which became important centers for this transmission of ideas. From the 11th to the 13th century, many schools dedicated to the translation of philosophical and scientific works from Classical Arabic to Medieval Latin were established in Iberia. Most notably the Toledo School of Translators. This work of translation from Islamic culture, though largely unplanned and disorganized, constituted one of the greatest transmissions of ideas in history. This movement to reintegrate the regular study of Greek literary, historical, oratorical and theological texts back into the Western European curriculum is usually dated to the 1396 invitation from Coluccio Salutati to the Byzantine diplomat and scholar Manuel Chrysoloras (c.1355–1415) to teach Greek in Florence. This legacy was continued by a number of expatriate Greek scholars, from Basilios Bessarion to Leo Allatius.\n\nThe unique political structures of late Middle Ages Italy have led some to theorize that its unusual social climate allowed the emergence of a rare cultural efflorescence. Italy did not exist as a political entity in the early modern period. Instead, it was divided into smaller city states and territories: the Kingdom of Naples controlled the south, the Republic of Florence and the Papal States at the center, the Milanese and the Genoese to the north and west respectively, and the Venetians to the east. Fifteenth-century Italy was one of the most urbanised areas in Europe. Many of its cities stood among the ruins of ancient Roman buildings; it seems likely that the classical nature of the Renaissance was linked to its origin in the Roman Empire's heartland.\n\nHistorian and political philosopher Quentin Skinner points out that Otto of Freising (c. 1114–1158), a German bishop visiting north Italy during the 12th century, noticed a widespread new form of political and social organization, observing that Italy appeared to have exited from Feudalism so that its society was based on merchants and commerce. Linked to this was anti-monarchical thinking, represented in the famous early Renaissance fresco cycle \"Allegory of Good and Bad Government in Siena\" by Ambrogio Lorenzetti (painted 1338–1340), whose strong message is about the virtues of fairness, justice, republicanism and good administration. Holding both Church and Empire at bay, these city republics were devoted to notions of liberty. Skinner reports that there were many defences of liberty such as the Matteo Palmieri (1406–1475) celebration of Florentine genius not only in art, sculpture and architecture, but \"the remarkable efflorescence of moral, social and political philosophy that occurred in Florence at the same time\".\n\nEven cities and states beyond central Italy, such as the Republic of Florence at this time, were also notable for their merchant Republics, especially the Republic of Venice. Although in practice these were oligarchical, and bore little resemblance to a modern democracy, they did have democratic features and were responsive states, with forms of participation in governance and belief in liberty. The relative political freedom they afforded was conducive to academic and artistic advancement. Likewise, the position of Italian cities such as Venice as great trading centres made them intellectual crossroads. Merchants brought with them ideas from far corners of the globe, particularly the Levant. Venice was Europe's gateway to trade with the East, and a producer of fine glass, while Florence was a capital of textiles. The wealth such business brought to Italy meant large public and private artistic projects could be commissioned and individuals had more leisure time for study.\n\nOne theory that has been advanced is that the devastation in Florence caused by the Black Death, which hit Europe between 1348 and 1350, resulted in a shift in the world view of people in 14th-century Italy. Italy was particularly badly hit by the plague, and it has been speculated that the resulting familiarity with death caused thinkers to dwell more on their lives on Earth, rather than on spirituality and the afterlife. It has also been argued that the Black Death prompted a new wave of piety, manifested in the sponsorship of religious works of art. However, this does not fully explain why the Renaissance occurred specifically in Italy in the 14th century. The Black Death was a pandemic that affected all of Europe in the ways described, not only Italy. The Renaissance's emergence in Italy was most likely the result of the complex interaction of the above factors.\n\nThe plague was carried by fleas on sailing vessels returning from the ports of Asia, spreading quickly due to lack of proper sanitation: the population of England, then about 4.2 million, lost 1.4 million people to the bubonic plague. Florence's population was nearly halved in the year 1347. As a result of the decimation in the populace the value of the working class increased, and commoners came to enjoy more freedom. To answer the increased need for labor, workers traveled in search of the most favorable position economically.\n\nThe demographic decline due to the plague had economic consequences: the prices of food dropped and land values declined by 30 to 40% in most parts of Europe between 1350 and 1400. Landholders faced a great loss, but for ordinary men and women it was a windfall. The survivors of the plague found not only that the prices of food were cheaper but also that lands were more abundant, and many of them inherited property from their dead relatives.\n\nThe spread of disease was significantly more rampant in areas of poverty. Epidemics ravaged cities, particularly children. Plagues were easily spread by lice, unsanitary drinking water, armies, or by poor sanitation. Children were hit the hardest because many diseases, such as typhus and syphilis, target the immune system, leaving young children without a fighting chance. Children in city dwellings were more affected by the spread of disease than the children of the wealthy.\n\nThe Black Death caused greater upheaval to Florence's social and political structure than later epidemics. Despite a significant number of deaths among members of the ruling classes, the government of Florence continued to function during this period. Formal meetings of elected representatives were suspended during the height of the epidemic due to the chaotic conditions in the city, but a small group of officials was appointed to conduct the affairs of the city, which ensured continuity of government.\n\nIt has long been a matter of debate why the Renaissance began in Florence, and not elsewhere in Italy. Scholars have noted several features unique to Florentine cultural life that may have caused such a cultural movement. Many have emphasized the role played by the Medici, a banking family and later ducal ruling house, in patronizing and stimulating the arts. Lorenzo de' Medici (1449–1492) was the catalyst for an enormous amount of arts patronage, encouraging his countrymen to commission works from the leading artists of Florence, including Leonardo da Vinci, Sandro Botticelli, and Michelangelo Buonarroti. Works by Neri di Bicci, Botticelli, da Vinci and Filippino Lippi had been commissioned additionally by the convent di San Donato agli Scopeti of the Augustinians order in Florence.\n\nThe Renaissance was certainly underway before Lorenzo de' Medici came to power – indeed, before the Medici family itself achieved hegemony in Florentine society. Some historians have postulated that Florence was the birthplace of the Renaissance as a result of luck, i.e. because \"Great Men\" were born there by chance: Leonardo da Vinci, Botticelli and Michelangelo were all born in Tuscany. Arguing that such chance seems improbable, other historians have contended that these \"Great Men\" were only able to rise to prominence because of the prevailing cultural conditions at the time.\n\nIn some ways humanism was not a philosophy but a method of learning. In contrast to the medieval scholastic mode, which focused on resolving contradictions between authors, humanists would study ancient texts in the original and appraise them through a combination of reasoning and empirical evidence. Humanist education was based on the programme of 'Studia Humanitatis', the study of five humanities: poetry, grammar, history, moral philosophy and rhetoric. Although historians have sometimes struggled to define humanism precisely, most have settled on \"a middle of the road definition... the movement to recover, interpret, and assimilate the language, literature, learning and values of ancient Greece and Rome\". Above all, humanists asserted \"the genius of man ... the unique and extraordinary ability of the human mind\".\n\nHumanist scholars shaped the intellectual landscape throughout the early modern period. Political philosophers such as Niccolò Machiavelli and Thomas More revived the ideas of Greek and Roman thinkers and applied them in critiques of contemporary government. Pico della Mirandola wrote the \"manifesto\" of the Renaissance, the \"Oration on the Dignity of Man\", a vibrant defence of thinking. Matteo Palmieri (1406–1475), another humanist, is most known for his work \"Della vita civile\" (\"On Civic Life\"; printed 1528), which advocated civic humanism, and for his influence in refining the Tuscan vernacular to the same level as Latin. Palmieri drew on Roman philosophers and theorists, especially Cicero, who, like Palmieri, lived an active public life as a citizen and official, as well as a theorist and philosopher and also Quintilian. Perhaps the most succinct expression of his perspective on humanism is in a 1465 poetic work \"La città di vita\", but an earlier work, \"Della vita civile\" (On Civic Life), is more wide-ranging. Composed as a series of dialogues set in a country house in the Mugello countryside outside Florence during the plague of 1430, Palmieri expounds on the qualities of the ideal citizen. The dialogues include ideas about how children develop mentally and physically, how citizens can conduct themselves morally, how citizens and states can ensure probity in public life, and an important debate on the difference between that which is pragmatically useful and that which is honest.\n\nThe humanists believed that it is important to transcend to the afterlife with a perfect mind and body, which could be attained with education. The purpose of humanism was to create a universal man whose person combined intellectual and physical excellence and who was capable of functioning honorably in virtually any situation. This ideology was referred to as the \"uomo universale\", an ancient Greco-Roman ideal. Education during the Renaissance was mainly composed of ancient literature and history as it was thought that the classics provided moral instruction and an intensive understanding of human behavior.\n\nRenaissance art marks a cultural rebirth at the close of the Middle Ages and rise of the Modern world. One of the distinguishing features of Renaissance art was its development of highly realistic linear perspective. Giotto di Bondone (1267–1337) is credited with first treating a painting as a window into space, but it was not until the demonstrations of architect Filippo Brunelleschi (1377–1446) and the subsequent writings of Leon Battista Alberti (1404–1472) that perspective was formalized as an artistic technique.\n\nThe development of perspective was part of a wider trend towards realism in the arts. Painters developed other techniques, studying light, shadow, and, famously in the case of Leonardo da Vinci, human anatomy. Underlying these changes in artistic method was a renewed desire to depict the beauty of nature and to unravel the axioms of aesthetics, with the works of Leonardo, Michelangelo and Raphael representing artistic pinnacles that were much imitated by other artists. Other notable artists include Sandro Botticelli, working for the Medici in Florence, Donatello, another Florentine, and Titian in Venice, among others.\n\nIn the Netherlands, a particularly vibrant artistic culture developed. The work of Hugo van der Goes and Jan van Eyck was particularly influential on the development of painting in Italy, both technically with the introduction of oil paint and canvas, and stylistically in terms of naturalism in representation (see \"Renaissance in the Netherlands\"). Later, the work of Pieter Brueghel the Elder would inspire artists to depict themes of everyday life.\n\nIn architecture, Filippo Brunelleschi was foremost in studying the remains of ancient classical buildings. With rediscovered knowledge from the 1st-century writer Vitruvius and the flourishing discipline of mathematics, Brunelleschi formulated the Renaissance style that emulated and improved on classical forms. His major feat of engineering was building the dome of the Florence Cathedral. Another building demonstrating this style is the church of St. Andrew in Mantua, built by Alberti. The outstanding architectural work of the High Renaissance was the rebuilding of St. Peter's Basilica, combining the skills of Bramante, Michelangelo, Raphael, Sangallo and Maderno.\n\nDuring the Renaissance, architects aimed to use columns, pilasters, and entablatures as an integrated system. The Roman orders types of columns are used: Tuscan, Doric, Ionic, Corinthian and Composite. These can either be structural, supporting an arcade or architrave, or purely decorative, set against a wall in the form of pilasters. One of the first buildings to use pilasters as an integrated system was in the Old Sacristy (1421–1440) by Brunelleschi. Arches, semi-circular or (in the Mannerist style) segmental, are often used in arcades, supported on piers or columns with capitals. There may be a section of entablature between the capital and the springing of the arch. Alberti was one of the first to use the arch on a monumental. Renaissance vaults do not have ribs; they are semi-circular or segmental and on a square plan, unlike the Gothic vault, which is frequently rectangular.\n\nRenaissance artists were not pagans, although they admired antiquity and kept some ideas and symbols of the medieval past. Nicola Pisano (c. 1220–c. 1278) imitated classical forms by portraying scenes from the Bible. His \"Annunciation\", from the Baptistry at Pisa, demonstrates that classical models influenced Italian art before the Renaissance took root as a literary movement \n\nThe rediscovery of ancient texts and the invention of printing democratized learning and allowed a faster propagation of ideas. In the first period of the Italian Renaissance, humanists favoured the study of humanities over natural philosophy or applied mathematics, and their reverence for classical sources further enshrined the Aristotelian and Ptolemaic views of the universe. Writing around 1450, Nicholas Cusanus anticipated the heliocentric worldview of Copernicus, but in a philosophical fashion.\n\nScience and art were intermingled in the early Renaissance, with polymath artists such as Leonardo da Vinci making observational drawings of anatomy and nature. Da Vinci set up controlled experiments in water flow, medical dissection, and systematic study of movement and aerodynamics, and he devised principles of research method that led Fritjof Capra to classify him as the \"father of modern science\". Other examples of Da Vinci's contribution during this period include machines designed to saw marbles and lift monoliths and new discoveries in acoustics, botany, geology, anatomy and mechanics.\n\nA suitable environment had developed to question scientific doctrine. The discovery in 1492 of the New World by Christopher Columbus challenged the classical worldview. The works of Ptolemy (in geography) and Galen (in medicine) were found to not always match everyday observations. As the Protestant Reformation and Counter-Reformation clashed, the Northern Renaissance showed a decisive shift in focus from Aristotelean natural philosophy to chemistry and the biological sciences (botany, anatomy, and medicine). The willingness to question previously held truths and search for new answers resulted in a period of major scientific advancements.\n\nSome view this as a \"scientific revolution\", heralding the beginning of the modern age, others as an acceleration of a continuous process stretching from the ancient world to the present day. Significant scientific advances were made during this time by Galileo Galilei, Tycho Brahe and Johannes Kepler. Copernicus, in \"De Revolutionibus\", posited that the Earth moved around the Sun. \"De humani corporis fabrica\" (\"On the Workings of the Human Body\"), by Andreas Vesalius, gave a new confidence to the role of dissection, observation, and the mechanistic view of anatomy.\n\nAnother important development was in the \"process\" for discovery, the scientific method, focusing on empirical evidence and the importance of mathematics, while discarding Aristotelian science. Early and influential proponents of these ideas included Copernicus, Galileo, and Francis Bacon. The new scientific method led to great contributions in the fields of astronomy, physics, biology, and anatomy.\n\nApplied innovation extended to commerce. At the end of the 15th century Luca Pacioli published the first work on bookkeeping, making him the founder of accounting.\n\nFrom this changing society emerged a common, unifying musical language, in particular the polyphonic style of the Franco-Flemish school. The development of printing made distribution of music possible on a wide scale. Demand for music as entertainment and as an activity for educated amateurs increased with the emergence of a bourgeois class. Dissemination of chansons, motets, and masses throughout Europe coincided with the unification of polyphonic practice into the fluid style that culminated in the second half of the sixteenth century in the work of composers such as Palestrina, Lassus, Victoria and William Byrd.\n\nThe new ideals of humanism, although more secular in some aspects, developed against a Christian backdrop, especially in the Northern Renaissance. Much, if not most, of the new art was commissioned by or in dedication to the Church. However, the Renaissance had a profound effect on contemporary theology, particularly in the way people perceived the relationship between man and God. Many of the period's foremost theologians were followers of the humanist method, including Erasmus, Zwingli, Thomas More, Martin Luther, and John Calvin.\n\nThe Renaissance began in times of religious turmoil. The late Middle Ages was a period of political intrigue surrounding the Papacy, culminating in the Western Schism, in which three men simultaneously claimed to be true Bishop of Rome. While the schism was resolved by the Council of Constance (1414), a resulting reform movement known as Conciliarism sought to limit the power of the pope. Although the papacy eventually emerged supreme in ecclesiastical matters by the Fifth Council of the Lateran (1511), it was dogged by continued accusations of corruption, most famously in the person of Pope Alexander VI, who was accused variously of simony, nepotism and fathering four children (most of whom were married off, presumably for the consolidation of power) while a cardinal.\n\nChurchmen such as Erasmus and Luther proposed reform to the Church, often based on humanist textual criticism of the New Testament. In October 1517 Luther published the 95 Theses, challenging papal authority and criticizing its perceived corruption, particularly with regard to instances of sold indulgences. The 95 Theses led to the Reformation, a break with the Roman Catholic Church that previously claimed hegemony in Western Europe. Humanism and the Renaissance therefore played a direct role in sparking the Reformation, as well as in many other contemporaneous religious debates and conflicts.\n\nPope Paul III came to the papal throne (1534–1549) after the sack of Rome in 1527, with uncertainties prevalent in the Catholic Church following the Protestant Reformation. Nicolaus Copernicus dedicated \"De revolutionibus orbium coelestium\" (On the Revolutions of the Celestial Spheres) to Paul III, who became the grandfather of Alessandro Farnese (cardinal), who had paintings by Titian, Michelangelo, and Raphael, as well as an important collection of drawings, and who commissioned the masterpiece of Giulio Clovio, arguably the last major illuminated manuscript, the \"Farnese Hours\".\n\nBy the 15th century, writers, artists, and architects in Italy were well aware of the transformations that were taking place and were using phrases such as \"modi antichi\" (in the antique manner) or \"alle romana et alla antica\" (in the manner of the Romans and the ancients) to describe their work. In the 1330s Petrarch referred to pre-Christian times as \"antiqua\" (ancient) and to the Christian period as \"nova\" (new). From Petrarch's Italian perspective, this new period (which included his own time) was an age of national eclipse.\nLeonardo Bruni was the first to use tripartite periodization in his \"History of the Florentine People\" (1442). Bruni's first two periods were based on those of Petrarch, but he added a third period because he believed that Italy was no longer in a state of decline. Flavio Biondo used a similar framework in \"Decades of History from the Deterioration of the Roman Empire\" (1439–1453).\n\nHumanist historians argued that contemporary scholarship restored direct links to the classical period, thus bypassing the Medieval period, which they then named for the first time the \"Middle Ages\". The term first appears in Latin in 1469 as \"media tempestas\" (middle times). The term \"la rinascita\" (rebirth) first appeared, however, in its broad sense in Giorgio Vasari's \"Lives of the Artists\", 1550, revised 1568). Vasari divides the age into three phases: the first phase contains Cimabue, Giotto, and Arnolfo di Cambio; the second phase contains Masaccio, Brunelleschi, and Donatello; the third centers on Leonardo da Vinci and culminates with Michelangelo. It was not just the growing awareness of classical antiquity that drove this development, according to Vasari, but also the growing desire to study and imitate nature.\n\nIn the 15th century, the Renaissance spread rapidly from its birthplace in Florence to the rest of Italy and soon to the rest of Europe. The invention of the printing press by German printer Johannes Gutenberg allowed the rapid transmission of these new ideas. As it spread, its ideas diversified and changed, being adapted to local culture. In the 20th century, scholars began to break the Renaissance into regional and national movements.\n\nThe Renaissance in Northern Europe has been termed the \"Northern Renaissance\". While Renaissance ideas were moving north from Italy, there was a simultaneous southward spread of some areas of innovation, particularly in music. The music of the 15th century Burgundian School defined the beginning of the Renaissance in music, and the polyphony of the Netherlanders, as it moved with the musicians themselves into Italy, formed the core of the first true international style in music since the standardization of Gregorian Chant in the 9th century. The culmination of the Netherlandish school was in the music of the Italian composer Palestrina. At the end of the 16th century Italy again became a center of musical innovation, with the development of the polychoral style of the Venetian School, which spread northward into Germany around 1600.\n\nThe paintings of the Italian Renaissance differed from those of the Northern Renaissance. Italian Renaissance artists were among the first to paint secular scenes, breaking away from the purely religious art of medieval painters. Northern Renaissance artists initially remained focused on religious subjects, such as the contemporary religious upheaval portrayed by Albrecht Dürer. Later, the works of Pieter Bruegel influenced artists to paint scenes of daily life rather than religious or classical themes. It was also during the Northern Renaissance that Flemish brothers Hubert and Jan van Eyck perfected the oil painting technique, which enabled artists to produce strong colors on a hard surface that could survive for centuries. A feature of the Northern Renaissance was its use of the vernacular in place of Latin or Greek, which allowed greater freedom of expression. This movement had started in Italy with the decisive influence of Dante Alighieri on the development of vernacular languages; in fact the focus on writing in Italian has neglected a major source of Florentine ideas expressed in Latin. The spread of the printing press technology boosted the Renaissance in Northern Europe as elsewhere, with Venice becoming a world center of printing.\n\nIn England, the sixteenth century marked the beginning of the English Renaissance with the work of writers William Shakespeare, Christopher Marlowe, Edmund Spenser, Sir Thomas More, Francis Bacon, Sir Philip Sidney, as well as great artists, architects (such as Inigo Jones who introduced Italianate architecture to England), and composers such as Thomas Tallis, John Taverner, and William Byrd.\n\nThe word \"Renaissance\" is borrowed from the French language, where it means \"re-birth\". It was first used in the eighteenth century and was later popularized by French historian Jules Michelet (1798–1874) in his 1855 work, \"Histoire de France\" (History of France).\n\nIn 1495 the Italian Renaissance arrived in France, imported by King Charles VIII after his invasion of Italy. A factor that promoted the spread of secularism was the inability of the Church to offer assistance against the Black Death. Francis I imported Italian art and artists, including Leonardo da Vinci, and built ornate palaces at great expense. Writers such as François Rabelais, Pierre de Ronsard, Joachim du Bellay and Michel de Montaigne, painters such as Jean Clouet, and musicians such as Jean Mouton also borrowed from the spirit of the Renaissance.\n\nIn 1533, a fourteen-year-old Caterina de' Medici (1519–1589), born in Florence to Lorenzo II de' Medici and Madeleine de la Tour d'Auvergne, married Henry II of France, second son of King Francis I and Queen Claude. Though she became famous and infamous for her role in France's religious wars, she made a direct contribution in bringing arts, sciences and music (including the origins of ballet) to the French court from her native Florence.\n\nIn the second half of the 15th century, the Renaissance spirit spread to Germany and the Low Countries, where the development of the printing press (ca. 1450) and early Renaissance artists such as the painters Jan van Eyck (1395–1441) and Hieronymus Bosch (1450–1516) and the composers Johannes Ockeghem (1410–1497), Jacob Obrecht (1457–1505) and Josquin des Prez (1455–1521) predated the influence from Italy. In the early Protestant areas of the country humanism became closely linked to the turmoil of the Protestant Reformation, and the art and writing of the German Renaissance frequently reflected this dispute. However, the gothic style and medieval scholastic philosophy remained exclusively until the turn of the 16th century. Emperor Maximilian I of Habsburg (ruling 1493–1519) was the first truly Renaissance monarch of the Holy Roman Empire.\n\nCulture in the Netherlands at the end of the 15th century was influenced by the Italian Renaissance through trade via Bruges, which made Flanders wealthy. Its nobles commissioned artists who became known across Europe. In science, the anatomist Andreas Vesalius led the way; in cartography, Gerardus Mercator's map assisted explorers and navigators. In art, Dutch and Flemish Renaissance painting ranged from the strange work of Hieronymus Bosch to the everyday life depictions of Pieter Brueghel the Elder.\n\nThe Renaissance arrived in the Iberian peninsula through the Mediterranean possessions of the Aragonese Crown and the city of Valencia. Many early Spanish Renaissance writers come from the Kingdom of Aragon, including Ausiàs March and Joanot Martorell. In the Kingdom of Castile, the early Renaissance was heavily influenced by the Italian humanism, starting with writers and poets such as the Marquis of Santillana, who introduced the new Italian poetry to Spain in the early 15th century. Other writers, such as Jorge Manrique, Fernando de Rojas, Juan del Encina, Juan Boscán Almogáver and Garcilaso de la Vega, kept a close resemblance to the Italian canon. Miguel de Cervantes's masterpiece Don Quixote is credited as the first Western novel. Renaissance humanism flourished in the early 16th century, with influential writers such as philosopher Juan Luis Vives, grammarian Antonio de Nebrija and natural historian Pedro de Mexía.\n\nLater Spanish Renaissance tended towards religious themes and mysticism, with poets such as fray Luis de León, Teresa of Ávila and John of the Cross, and treated issues related to the exploration of the New World, with chroniclers and writers such as Inca Garcilaso de la Vega and Bartolomé de las Casas, giving rise to a body of work, now known as Spanish Renaissance literature. The late Renaissance in Spain produced artists such as El Greco and composers such as Tomás Luis de Victoria and Antonio de Cabezón.\n\nAlthough Italian Renaissance had a modest impact in Portuguese arts, Portugal was influential in broadening the European worldview, stimulating humanist inquiry. Renaissance arrived through the influence of wealthy Italian and Flemish merchants who invested in the profitable commerce overseas. As the pioneer headquarters of European exploration, Lisbon flourished in the late 15th century, attracting experts who made several breakthroughs in mathematics, astronomy and naval technology, including Pedro Nunes, João de Castro, Abraham Zacuto and Martin Behaim. Cartographers Pedro Reinel, Lopo Homem, Estêvão Gomes and Diogo Ribeiro made crucial advances in mapping the world. Apothecary Tomé Pires and physicians Garcia de Orta and Cristóvão da Costa collected and published works on plants and medicines, soon translated by Flemish pioneer botanist Carolus Clusius.\n\nIn architecture, the huge profits of the spice trade financed a sumptuous composite style in the first decades of the 16th century, the Manueline, incorporating maritime elements. The primary painters were Nuno Gonçalves, Gregório Lopes and Vasco Fernandes. In music, Pedro de Escobar and Duarte Lobo produced four songbooks, including the Cancioneiro de Elvas. In literature, Sá de Miranda introduced Italian forms of verse. Bernardim Ribeiro developed pastoral romance, plays by Gil Vicente fused it with popular culture, reporting the changing times, and Luís de Camões inscribed the Portuguese feats overseas in the epic poem Os Lusíadas. Travel literature especially flourished: João de Barros, Castanheda, António Galvão, Gaspar Correia, Duarte Barbosa, and Fernão Mendes Pinto, among others, described new lands and were translated and spread with the new printing press. After joining the Portuguese exploration of Brazil in 1500, Amerigo Vespucci coined the term New World, in his letters to Lorenzo di Pierfrancesco de' Medici.\n\nThe intense international exchange produced several cosmopolitan humanist scholars, including Francisco de Holanda, André de Resende and Damião de Góis, a friend of Erasmus who wrote with rare independence on the reign of King Manuel I. Diogo and André de Gouveia made relevant teaching reforms via France. Foreign news and products in the Portuguese factory in Antwerp attracted the interest of Thomas More and Dürer to the wider world. There, profits and know-how helped nurture the Dutch Renaissance and Golden Age, especially after the arrival of the wealthy cultured Jewish community expelled from Portugal.\n\nAfter Italy, Hungary was the first European country where the renaissance appeared. The Renaissance style came directly from Italy during the Quattrocento to Hungary first in the Central European region, thanks to the development of early Hungarian-Italian relationships – not only in dynastic connections, but also in cultural, humanistic and commercial relations – growing in strength from the 14th century. The relationship between Hungarian and Italian Gothic styles was a second reason – exaggerated breakthrough of walls is avoided, preferring clean and light structures. Large-scale building schemes provided ample and long term work for the artists, for example, the building of the Friss (New) Castle in Buda, the castles of Visegrád, Tata and Várpalota. In Sigismund's court there were patrons such as Pipo Spano, a descendant of the Scolari family of Florence, who invited Manetto Ammanatini and Masolino da Pannicale to Hungary.\n\nThe new Italian trend combined with existing national traditions to create a particular local Renaissance art. Acceptance of Renaissance art was furthered by the continuous arrival of humanist thought in the country. Many young Hungarians studying at Italian universities came closer to the Florentine humanist center, so a direct connection with Florence evolved. The growing number of Italian traders moving to Hungary, specially to Buda, helped this process. New thoughts were carried by the humanist prelates, among them Vitéz János, archbishop of Esztergom, one of the founders of Hungarian humanism. During the long reign of emperor Sigismund of Luxemburg the Royal Castle of Buda became probably the largest Gothic palace of the late Middle Ages. King Matthias Corvinus (r. 1458–1490) rebuilt the palace in early Renaissance style and further expanded it.\n\nAfter the marriage in 1476 of King Matthias to Beatrice of Naples, Buda became one of the most important artistic centres of the Renaissance north of the Alps. The most important humanists living in Matthias' court were Antonio Bonfini and the famous Hungarian poet Janus Pannonius. András Hess set up a printing press in Buda in 1472. Matthias Corvinus's library, the \"Bibliotheca Corviniana\", was Europe's greatest collections of secular books: historical chronicles, philosophic and scientific works in the 15th century. His library was second only in size to the Vatican Library. (However, the Vatican Library mainly contained Bibles and religious materials.)\n\nIn 1489, Bartolomeo della Fonte of Florence wrote that Lorenzo de' Medici founded his own Greek-Latin library encouraged by the example of the Hungarian king. Corvinus's library is part of UNESCO World Heritage.\nOther important figures of Hungarian Renaissance include Bálint Balassi (poet), Sebestyén Tinódi Lantos (poet), Bálint Bakfark (composer and lutenist), and Master MS (fresco painter).\n\nAn early Italian humanist who came to Poland in the mid-15th century was Filippo Buonaccorsi. Many Italian artists came to Poland with Bona Sforza of Milan, when she married King Sigismund I the Old in 1518. This was supported by temporarily strengthened monarchies in both areas, as well as by newly established universities. The Polish Renaissance lasted from the late 15th to the late 16th century and was the Golden Age of Polish culture. Ruled by the Jagiellon dynasty, the Kingdom of Poland (from 1569 known as the Polish–Lithuanian Commonwealth) actively participated in the broad European Renaissance. The multi-national Polish state experienced a substantial period of cultural growth thanks in part to a century without major wars – aside from conflicts in the sparsely populated eastern and southern borderlands. The Reformation spread peacefully throughout the country (giving rise to the Polish Brethren), while living conditions improved, cities grew, and exports of agricultural products enriched the population, especially the nobility (\"szlachta\") who gained dominance in the new political system of Golden Liberty. The Polish Renaissance architecture has three periods of development.\n\nThe greatest monument of this style in the territory of the former Duchy of Pomerania is the Ducal Castle in Szczecin.\n\nRenaissance trends from Italy and Central Europe influenced Russia in many ways. Their influence was rather limited, however, due to the large distances between Russia and the main European cultural centers and the strong adherence of Russians to their Orthodox traditions and Byzantine legacy.\n\nPrince Ivan III introduced Renaissance architecture to Russia by inviting a number of architects from Italy, who brought new construction techniques and some Renaissance style elements with them, while in general following the traditional designs of Russian architecture. In 1475 the Bolognese architect Aristotele Fioravanti came to rebuild the Cathedral of the Dormition in the Moscow Kremlin, which had been damaged in an earthquake. Fioravanti was given the 12th-century Vladimir Cathedral as a model, and he produced a design combining traditional Russian style with a Renaissance sense of spaciousness, proportion and symmetry.\n\nIn 1485 Ivan III commissioned the building of the royal residence, Terem Palace, within the Kremlin, with Aloisio da Milano as the architect of the first three floors. He and other Italian architects also contributed to the construction of the Kremlin walls and towers. The small banquet hall of the Russian Tsars, called the Palace of Facets because of its facetted upper story, is the work of two Italians, Marco Ruffo and Pietro Solario, and shows a more Italian style. In 1505, an Italian known in Russia as Aleviz Novyi or Aleviz Fryazin arrived in Moscow. He may have been the Venetian sculptor, Alevisio Lamberti da Montagne. He built 12 churches for Ivan III, including the Cathedral of the Archangel, a building remarkable for the successful blending of Russian tradition, Orthodox requirements and Renaissance style. It is believed that the Cathedral of the Metropolitan Peter in Vysokopetrovsky Monastery, another work of Aleviz Novyi, later served as an inspiration for the so-called \"octagon-on-tetragon\" architectural form in the Moscow Baroque of the late 17th century.\n\nBetween the early 16th and the late 17th centuries, an original tradition of stone tented roof architecture developed in Russia. It was quite unique and different from the contemporary Renaissance architecture elsewhere in Europe, though some research terms the style 'Russian Gothic' and compares it with the European Gothic architecture of the earlier period. The Italians, with their advanced technology, may have influenced the invention of the stone tented roof (the wooden tents were known in Russia and Europe long before). According to one hypothesis, an Italian architect called Petrok Maly may have been an author of the Ascension Church in Kolomenskoye, one of the earliest and most prominent tented roof churches.\n\nBy the 17th century the influence of Renaissance painting resulted in Russian icons becoming slightly more realistic, while still following most of the old icon painting canons, as seen in the works of Bogdan Saltanov, Simon Ushakov, Gury Nikitin, Karp Zolotaryov and other Russian artists of the era. Gradually the new type of secular portrait painting appeared, called \"parsúna\" (from \"persona\" – person), which was transitional style between abstract iconographics and real paintings.\n\nIn the mid 16th-century Russians adopted printing from Central Europe, with Ivan Fyodorov being the first known Russian printer. In the 17th century printing became widespread, and woodcuts became especially popular. That led to the development of a special form of folk art known as lubok printing, which persisted in Russia well into the 19th century.\n\nA number of technologies from the European Renaissance period were adopted by Russia rather early and subsequently perfected to become a part of a strong domestic tradition. Mostly these were military technologies, such as cannon casting adopted by at least the 15th century. The Tsar Cannon, which is the world's largest bombard by caliber, is a masterpiece of Russian cannon making. It was cast in 1586 by Andrey Chokhov and is notable for its rich, decorative relief. Another technology, that according to one hypothesis originally was brought from Europe by the Italians, resulted in the development of vodka, the national beverage of Russia. As early as 1386 Genoese ambassadors brought the first aqua vitae (\"water of life\") to Moscow and presented it to Grand Duke Dmitry Donskoy. The Genoese likely developed this beverage with the help of the alchemists of Provence, who used an Arab-invented distillation apparatus to convert grape must into alcohol. A Moscovite monk called Isidore used this technology to produce the first original Russian vodka c. 1430.\n\n\nThe Italian artist and critic Giorgio Vasari (1511–1574) first used the term \"rinascita\" retrospectively in his book \"The Lives of the Artists\" (published 1550). In the book Vasari attempted to define what he described as a break with the barbarities of gothic art: the arts (he held) had fallen into decay with the collapse of the Roman Empire and only the Tuscan artists, beginning with Cimabue (1240–1301) and Giotto (1267–1337) began to reverse this decline in the arts. Vasari saw antique art as central to the rebirth of Italian art.\n\nHowever, only in the 19th century did the French word \"Renaissance\" achieve popularity in describing the self-conscious cultural movement based on revival of Roman models that began in the late-13th century. French historian Jules Michelet (1798–1874) defined \"The Renaissance\" in his 1855 work \"Histoire de France\" as an entire historical period, whereas previously it had been used in a more limited sense. For Michelet, the Renaissance was more a development in science than in art and culture. He asserted that it spanned the period from Columbus to Copernicus to Galileo; that is, from the end of the 15th century to the middle of the 17th century. Moreover, Michelet distinguished between what he called, \"the bizarre and monstrous\" quality of the Middle Ages and the democratic values that he, as a vocal Republican, chose to see in its character. A French nationalist, Michelet also sought to claim the Renaissance as a French movement.\n\nThe Swiss historian Jacob Burckhardt (1818–1897) in his \"The Civilization of the Renaissance in Italy\" (1860), by contrast, defined the Renaissance as the period between Giotto and Michelangelo in Italy, that is, the 14th to mid-16th centuries. He saw in the Renaissance the emergence of the modern spirit of individuality, which the Middle Ages had stifled. His book was widely read and became influential in the development of the modern interpretation of the Italian Renaissance. However, Buckhardt has been accused of setting forth a linear Whiggish view of history in seeing the Renaissance as the origin of the modern world.\n\nMore recently, some historians have been much less keen to define the Renaissance as a historical age, or even as a coherent cultural movement. The historian Randolph Starn, of the University of California Berkeley, stated in 1998:\n\nThere is debate about the extent to which the Renaissance improved on the culture of the Middle Ages. Both Michelet and Burckhardt were keen to describe the progress made in the Renaissance towards the modern age. Burckhardt likened the change to a veil being removed from man's eyes, allowing him to see clearly.\n\nOn the other hand, many historians now point out that most of the negative social factors popularly associated with the medieval period – poverty, warfare, religious and political persecution, for example – seem to have worsened in this era, which saw the rise of Machiavellian politics, the Wars of Religion, the corrupt Borgia Popes, and the intensified witch-hunts of the 16th century. Many people who lived during the Renaissance did not view it as the \"golden age\" imagined by certain 19th-century authors, but were concerned by these social maladies. Significantly, though, the artists, writers, and patrons involved in the cultural movements in question believed they were living in a new era that was a clean break from the Middle Ages. Some Marxist historians prefer to describe the Renaissance in material terms, holding the view that the changes in art, literature, and philosophy were part of a general economic trend from feudalism towards capitalism, resulting in a bourgeois class with leisure time to devote to the arts.\n\nJohan Huizinga (1872–1945) acknowledged the existence of the Renaissance but questioned whether it was a positive change. In his book \"The Waning of the Middle Ages\", he argued that the Renaissance was a period of decline from the High Middle Ages, destroying much that was important. The Latin language, for instance, had evolved greatly from the classical period and was still a living language used in the church and elsewhere. The Renaissance obsession with classical purity halted its further evolution and saw Latin revert to its classical form. Robert S. Lopez has contended that it was a period of deep economic recession. Meanwhile, George Sarton and Lynn Thorndike have both argued that scientific progress was perhaps less original than has traditionally been supposed. Finally, Joan Kelly argued that the Renaissance led to greater gender dichotomy, lessening the agency women had had during the Middle Ages.\n\nSome historians have begun to consider the word \"Renaissance\" to be unnecessarily loaded, implying an unambiguously positive rebirth from the supposedly more primitive \"Dark Ages\", the Middle Ages. Most historians now prefer to use the term \"early modern\" for this period, a more neutral designation that highlights the period as a transitional one between the Middle Ages and the modern era. Others such as Roger Osborne have come to consider the Italian Renaissance as a repository of the myths and ideals of western history in general, and instead of rebirth of ancient ideas as a period of great innovation.\n\nThe term \"Renaissance\" has also been used to define periods outside of the 15th and 16th centuries. Charles H. Haskins (1870–1937), for example, made a case for a Renaissance of the 12th century. Other historians have argued for a Carolingian Renaissance in the 8th and 9th centuries, and still later for an Ottonian Renaissance in the 10th century. Other periods of cultural rebirth have also been termed \"renaissances\", such as the Bengal Renaissance, Tamil Renaissance, Nepal Bhasa renaissance, al-Nahda or the Harlem Renaissance.\n\n\n\n\n\n"}
{"id": "25533", "url": "https://en.wikipedia.org/wiki?curid=25533", "title": "Rheged", "text": "Rheged\n\nRheged () was one of the kingdoms of the \"Hen Ogledd\" (\"Old North\"), the Brittonic-speaking region of what is now Northern England and southern Scotland, during the post-Roman era and Early Middle Ages. It is recorded in several poetic and bardic sources, although its borders are not described in any of them. Some modern scholars have suggested that it included what is now Cumbria in North West England and possibly extended into Lancashire and Scotland. In some sources, Rheged is intimately associated with the king Urien Rheged and his family. Its inhabitants spoke Cumbric, a Brittonic dialect closely related to Old Welsh.\n\nThe name Rheged appears regularly as an epithet of a certain Urien in a number of early Welsh poems and royal genealogies. His victories over the Anglian chieftains of Bernicia in the second half of the 6th century are recorded by Nennius and celebrated by the bard Taliesin, who calls him \"Ruler of Rheged\". He is thus placed squarely in the North of Britain and perhaps specifically in Westmorland when referred to as \"Ruler of Llwyfenydd\" (identified with the Lyvennet Valley). Later legend associates Urien with the city of Carlisle (the Roman Luguvalium), only twenty-five miles away; Higham suggests that Rheged was \"broadly conterminous with the earlier \"Civitas Carvetiorum\", the Roman administrative unit based on Carlisle\". Although it is possible that Rheged was merely a stronghold, it was not uncommon for sub-Roman monarchs to use their kingdom's name as an epithet. It is generally accepted, therefore, that Rheged was a kingdom covering a large part of modern Cumbria.\n\nPlace-name evidence, e.g., Dunragit (possibly \"Fort of Rheged\") suggests that, at least in one period of its history, Rheged lay in Dumfries and Galloway. More to the point, recent archaeological excavations at Trusty's Hill, a vitrified fort near Gatehouse of Fleet, and the analysis of its artifacts in the context of other sites and their artifacts have led to claims that the kingdom was centred on Galloway early in the 7th century. \n\nMore problematic interpretations suggest that it could also have reached as far south as Rochdale in Greater Manchester, recorded in the Domesday Book as \"Recedham\". The River Roch on which Rochdale stands was recorded in the 13th century as \"Rached\" or \"Rachet\". These place-names may (apparently) incorporate the element 'Rheged' precisely because they lay on or near its borders. Certainly Urien's kingdom stretched eastward at one time, as he was also \"Ruler of Catraeth\" (Catterick in North Yorkshire).\n\nThe traditional royal genealogy of Urien and his successors traces their ancestry back to Coel Hen (considered by some to be the origins of the Old King Cole of folk tradition), who is considered by many to be a mythical figure; if he has some historicity, he may have ruled a considerable part of the North in the early 5th century. All of those listed below may have ruled in Rheged, but only three of their number can be verified from external sources:\n\n\nA second royal genealogy exists for a line, perhaps of kings, descended from Cynfarch Oer's brother: Elidir Lydanwyn. According to \"Bonedd Gwŷr y Gogledd\" Elidir's son, Llywarch Hen, was a ruler in North Britain in the 6th century. He was driven from his territory by princely in-fighting after Urien's death and was perhaps in old age associated with Powys. However, it is possible, because of internal inconsistencies, that the poetry connected to Powys was associated with Llywarch's name at a later, probably 9th century, date. Llywarch is referred to in some poems as king of South Rheged, and in others as king of Argoed, suggesting that the two regions were the same. Searching for Llywarch's kingdom has led some historians to propose that Rheged may have been divided between sons, resulting in northern and southern successor states. The connections of the family of Llywarch and Urien with Powys has suggested to some, on grounds of proximity, that the area of modern Lancashire may have been their original home.\n\nAfter Bernicia united with Deira to become the kingdom of Northumbria, Rheged was annexed by Northumbria, some time before AD 730. There was a royal marriage between Prince (later King) Oswiu of Northumbria and the Rhegedian princess Riemmelth, granddaughter of Rum (Rhun), probably in 638, so it is probable that it was a peaceful takeover, both kingdoms being inherited by the same man.\n\nAfter Rheged was incorporated into Northumbria, the old Cumbric language was gradually replaced by Old English, Cumbric surviving only in remote upland communities. In the 10th century, after the power of Northumbria was destroyed by Viking incursions and settlement, large areas west of the Pennines fell without warfare under the control of the British Kingdom of Strathclyde, with Leeds recorded as being on the border between the Britons and the Norse Kingdom of York. This may have represented the political assertion of lingering British culture in the region. The area of Cumbria remained under the control of Strathclyde until the early 11th century when Strathclyde itself was absorbed into the Scottish kingdom. The name of the people, whose modern Welsh form is \"Cymry\" has, however, survived in the name of Cumberland and now Cumbria; it probably derives from an old Celtic word *\"Kombroges\" meaning \"fellow countrymen\".\n\n\n"}
{"id": "25534", "url": "https://en.wikipedia.org/wiki?curid=25534", "title": "Romanian language", "text": "Romanian language\n\nRomanian (obsolete spellings Rumanian, Roumanian; autonym: \"limba română\" , \"the Romanian language\", or \"românește\", lit. \"in Romanian\") is a Romance language spoken by around 24-26 million people as a native language, primarily in Romania and Moldova, and by another 4 million people as a second language. It has official status in Romania and the Republic of Moldova. It is one of the official languages of the European Union.\n\nRomanian is a part of the Balkan-Romance group that evolved from several dialects of Vulgar Latin separated from the Western Romance during the 5th–8th centuries. To distinguish it within that group in comparative linguistics it is called \"Daco-Romanian\" as opposed to its closest relatives, Aromanian, Megleno-Romanian, and Istro-Romanian.\n\nDuring Soviet times—and to some extent even today—Romanian was called \"Moldovan\" in the Republic of Moldova, although the Constitutional Court ruled in 2013 that \"the official language of the republic is Romanian\".\n\nRomanian speakers are scattered across many other countries, notably Australia, Italy, Spain, Ukraine, Bulgaria, the United States, Canada, Brazil, Mexico, Argentina, Greece, Turkey, Russia, Portugal, the United Kingdom, Cyprus, France and Germany.\n\nEastern Romance languages, like the other branches of Romance languages, descend from Vulgar Latin, adopted in Dacia by a process of Romanization during early centuries AD.\n\nThe influence of the military in Dacia is due to the distribution of the military units in this bridgehead of the Roman Empire's defense (two legiones, 12 alae, 41 cohortes and 13 numeri), contrary, e.g., to that of the Rhenish army, which was concentrated at the Germanic limes and so left little influence on the local spoken Gallo-Latin. The identification of numerous words of military (Dacian-)Roman usage – 52 semantic specific changes and inherited military Latin words with their classical meanings – is at the heart of the hypothesis that the Romanian language is the continuation of the military Latin spoken in the north-eastern frontier region of the Roman Empire. These vestiges of military usage are unique to Romanian in its language family.\n\nThus, Romanian is scientifically very interesting from a linguistic and historical viewpoint, since Romance languages did not prevail in the other frontier regions of the Roman Empire in Europe, Asia and Africa, although Africa's falling under Arab sway surely played a role in the ultimate demise of any Romance dialect. Also, the conservation in Romanian of these numerous vestiges of Latin military slang (sermo castrensis) – such as (\"to waylay\"), (\"helmet\"), (\"emperor\"), (\"to encircle with pressure\"), (\"to venture\"), (\"to make thin a tree for its collapse on the invaders\"), (\"made thin a tree\"), \"fiancé\" (< Lat. \"soldiers\", metonymy), (\"to advance\"), (\"to kill\"), \"sense\" a.s.o. (< Lat. \"beak at prow of Roman warship\"), \"village\" (< Lat. \"trench for defence\", metonymy), \"plain\" (< Lat. \"plain place for camping\", metonymy), (\"to subject\"), \"veranda\" (< Lat. \"tent out of agglomerated fortress\", metonymy), \"homeland\" (< Lat. \"earth\" ˃ Arom. \"țară\" \"earth\"), etc. and their absence in Aromanian (Balkan Romanian dialect spoken in peaceful area) – indicates the continuity of the s in the northern Danubian region, this despite dire and constant defensive wars with Germanic, \"Turanian\" (Turkic peoples and Magyars) and Slavic populations who entered and eventually settled there.\n\nThis linguistic evidence challenges the Roeslerian theory. The vestiges from sermo castrensis particularize the Romanian language in the neolatin area, together with its isolated history. According to Cristian Mihail, the Roslerian theory is annihilated because of the fact that the Romanian words in common with the Albanian words not preserve the sound „l” between vowels – in accordance, i.e. with Rom. \"māgurā\" and Alb. \"magulë\" etc. – likewise with Romanian words from Latin linguistic stratum (Rom. \"scara\" < Lat. \"scala\" etc.) unlike the words from Slavic later stratum, which preserve the sound „l” intervowels (cf. Rom. \"mila\", no \"*mira\" < Sl. \"mila\") would prove that the Romanian words in common with the Albanian words proceed of a latter stratum in Balkan region, near the Albanians, as supporting also by linguistics the continuity of the Latinophons (Romanians) in the Nordic-Danubian region.\n\nThe Roman Empire withdrew from Dacia in 271–272 AD, leaving it to the Goths. The history of Eastern Romance between the 3rd century and the development of Proto-Romanian by the 10th century, when the area came under the influence of the Byzantine Empire, is unknown. It is a matter of debate whether Proto-Romanian developed among Romanized people who were left behind in Dacia by the Roman withdrawal or among Latin-speakers in the Balkans south of the Danube.\n\nDuring the High and Late Middle Ages, Romanian became influenced by the Slavic languages and to some degree by Greek. Romanian remains unattested throughout the Middle Ages, and only enters the historical record in the early 16th century.\n\nThe use of the denomination \"Romanian\" (\"română\") for \"our beautiful language\" (\"limba noastră cea frumoasă\") and use of the demonym \"Romanians\" (\"Români\") for speakers of this language predates the foundation of the modern Romanian state. Although the followers of the former Romanian voievodships used to designate themselves as \"Ardeleni\" (or \"Ungureni\"), \"Moldoveni\" or \"Munteni\", the name of \"rumână\" or \"rumâniască\" for the Romanian language itself is attested earlier, during the 16th century, by various foreign travellers into the Carpathian Romance-speaking space, as well as in other historical documents written in Romanian at that time such as (\"The Chronicles of the land of Moldova\") by Grigore Ureche.\n\nIn 1534, Tranquillo Andronico notes: \"\"Valachi nunc se Romanos vocant\"\" (\"The Wallachians are now calling themselves Romans\"). Francesco della Valle writes in 1532 that Romanians \"are calling themselves Romans in their own language\", and he subsequently quotes the expression: \"\"Știi Românește?\"\" (\"Do you know Romanian?\").\n\nAfter travelling through Wallachia, Moldavia and Transylvania Ferrante Capecci accounts in 1575 that the indigenous population of these regions call themselves \"românești\" (\"\"romanesci\"\").\n\nPierre Lescalopier writes in 1574 that those who live in Moldavia, Wallachia and the vast part of Transylvania, \"\"se consideră adevărați urmași ai romanilor și-și numesc limba \"românește\", adică romana\"\" (\"they consider themselves as the descendants of the Romans and they name their language Romanian\").\n\nThe Transylvanian Saxon Johann Lebel writes in 1542 that \"\"Vlachi\" se numeau între ei \"Romuini\"\" and the Polish chronicler Stanislaw Orzechowski (Orichovius) notes in 1554 that \"în limba lor \"walachii\" se numesc \"romini \"\" (\"In their language the Wallachians call themselves Romini\").\n\nThe Croatian prelate and diplomat Antun Vrančić recorded in 1570 that \"\"Vlachs in Transylvania, Moldavia and Wallachia designate themselves as \"Romans\"\" and the Transylvanian Hungarian Martin Szentiványi in 1699 quotes the following: \"«Si noi sentem Rumeni»\" (\"Și noi suntem români\" – \"We are Romans as well\") and \"«Noi sentem di sange Rumena»\" (\"Noi suntem de sânge român\" – \"We are of Roman blood\").\n\nIn (1582) stands written \"«.[...] că văzum cum toate limbile au și înfluresc întru cuvintele slăvite a lui Dumnezeu numai noi românii pre limbă nu avem. Pentru aceia cu mare muncă scoasem de limba jidovească si grecească si srâbească pre limba românească 5 cărți ale lui Moisi prorocul si patru cărți și le dăruim voo frați rumâni și le-au scris în cheltuială multă... și le-au dăruit voo fraților români... și le-au scris voo fraților români\"\" and in Letopisețul Țării Moldovei written by the Moldavian chronicler Grigore Ureche we can read: \"«În Țara Ardialului nu lăcuiesc numai unguri, ce și sași peste seamă de mulți și români peste tot locul...»\" (\"In Transylvania there live not solely Hungarians or Saxons, but overwhelmingly many Romanians everywhere around.\").\n\nNevertheless, the oldest extant document written in Romanian remains Neacșu's letter (1521) and was written using Cyrillic letters (which remained in use up until the late 19th century). There are no records of any other documents written in Romanian from before 1521.\n\nMiron Costin, in his \"De neamul moldovenilor\" (1687), while noting that Moldavians, Wallachians, and the Romanians living in the Kingdom of Hungary have the same origin, says that although people of Moldavia call themselves \"Moldavians\", they name their language \"Romanian\" (\"românește\") instead of \"Moldavian\" (\"moldovenește\").\n\nDimitrie Cantemir, in his \"\" (Berlin, 1714), points out that the inhabitants of Moldavia, Wallachia and Transylvania spoke the same language. He notes, however, some differences in accent and vocabulary.\nCantemir's work provides one of the earliest histories of the language, in which he notes, like Ureche before him, the evolution from Latin and notices the Greek and Polish borrowings. Additionally, he introduces the idea that some words must have had Dacian roots. Cantemir also notes that while the idea of a Latin origin of the language was prevalent in his time, other scholars considered it to have derived from Italian.\n\nThe slow process of Romanian establishing itself as an official language, used in the public sphere, in literature and ecclesiastically, began in the late 15th century and ended in the early decades of the 18th century, by which time Romanian had begun to be regularly used by the Church. The oldest Romanian texts of a literary nature are religious manuscripts (\"Codicele Voroneţean\", \"Psaltirea Scheiană\"), translations of essential Christian texts. These are considered either propagandistic results of confessional rivalries, for instance between Lutheranism and Calvinism, or as initiatives by Romanian monks stationed at Peri Monastery in Maramureş to distance themselves from the influence of the Mukacheve eparchy in Ukraine.\n\nThe language remains poorly attested during the Early Modern period.\n\nThe first Romanian grammar was published in Vienna in 1780.\nFollowing the annexation of Bessarabia by Russia (after 1812), Moldavian was established as an official language in the governmental institutions of Bessarabia, used along with Russian,\nThe publishing works established by Archbishop Gavril Bănulescu-Bodoni were able to produce books and liturgical works in Moldavian between 1815–1820.\n\nThe linguistic situation in Bessarabia from 1812 to 1918 was the gradual development of bilingualism. Russian continued to develop as the official language of privilege, whereas Romanian remained the principal vernacular.\n\nThe period from 1905 to 1917 was one of increasing linguistic conflict, with the re-awakening of Romanian national consciousness. In 1905 and 1906, the Bessarabian \"zemstva\" asked for the re-introduction of Romanian in schools as a \"compulsory language\", and the \"liberty to teach in the mother language (Romanian language)\". At the same time, Romanian-language newspapers and journals began to appear, such as \"Basarabia\" (1906), \"Viața Basarabiei\" (1907), \"Moldovanul\" (1907), \"Luminătorul\" (1908), \"Cuvînt moldovenesc\" (1913), \"Glasul Basarabiei\" (1913). From 1913, the synod permitted that \"the churches in Bessarabia use the Romanian language\".\nRomanian finally became the official language with the Constitution of 1923.\n\nRomanian has preserved a part of the Latin declension, but whereas Latin had six cases, from a morphological viewpoint, Romanian has only five: the nominative, accusative, genitive, dative, and marginally the vocative. Romanian nouns also preserve the neuter gender, although instead of functioning as a separate gender with its own forms in adjectives, the Romanian neuter became a mixture of masculine and feminine. The verb morphology of Romanian has shown the same move towards a compound perfect and future tense as the other Romance languages. Compared with the other Romance languages, during its evolution, Romanian simplified the original Latin tense system in extreme ways, in particular the absence of sequence of tenses.\n\nRomanian is spoken mostly in Central and the Balkan region of Southern Europe, although speakers of the language can be found all over the world, mostly due to emigration of Romanian nationals and the return of immigrants to Romania back to their original countries. Romanian speakers account for 0.5% of the world's population, and 4% of the Romance-speaking population of the world.\n\nRomanian is the single official and national language in Romania and Moldova, although it shares the official status at regional level with other languages in the Moldovan autonomies of Gagauzia and Transnistria. Romanian is also an official language of the Autonomous Province of Vojvodina in Serbia along with five other languages. Romanian minorities are encountered in Serbia (Timok Valley), Ukraine (Chernivtsi and Odessa oblasts), and Hungary (Gyula). Large immigrant communities are found in Italy, Spain, France, and Portugal.\n\nIn 1995, the largest Romanian-speaking community in the Middle East was found in Israel, where Romanian was spoken by 5% of the population. Romanian is also spoken as a second language by people from Arabic-speaking countries who have studied in Romania. It is estimated that almost half a million Middle Eastern Arabs studied in Romania during the 1980s. Small Romanian-speaking communities are to be found in Kazakhstan and Russia. Romanian is also spoken within communities of Romanian and Moldovan immigrants in the United States, Canada and Australia, although they do not make up a large homogeneous community statewide.\n\nAccording to the Constitution of Romania of 1991, as revised in 2003, Romanian is the official language of the Republic.\n\nRomania mandates the use of Romanian in official government publications, public education and legal contracts. Advertisements as well as other public messages must bear a translation of foreign words, while trade signs and logos shall be written predominantly in Romanian.\n\nThe Romanian Language Institute (\"Institutul Limbii Române\"), established by the Ministry of Education of Romania, promotes Romanian and supports people willing to study the language, working together with the Ministry of Foreign Affairs' Department for Romanians Abroad.\n\nRomanian is the official language of the Republic of Moldova. The 1991 Declaration of Independence names the official language Romanian. The Constitution of Moldova names the state language of the country Moldovan. In December 2013, a decision of the Constitutional Court of Moldova ruled that the Declaration of Independence takes precedence over the Constitution and the state language should be called Romanian.\n\nScholars agree that Moldovan and Romanian are the same language, with the glottonym \"Moldovan\" used in certain political contexts. It has been the sole official language since the adoption of the Law on State Language of the Moldavian SSR in 1989. This law mandates the use of Moldovan in all the political, economical, cultural and social spheres, as well as asserting the existence of a \"linguistic Moldo-Romanian identity\". It is also used in schools, mass media, education and in the colloquial speech and writing. Outside the political arena the language is most often called \"Romanian\". In the breakaway territory of Transnistria, it is co-official with Ukrainian and Russian.\n\nIn the 2014 census, out of the 2,804,801 people living in Moldova, 24% (652,394) stated Romanian as their most common language, whereas 56% stated Moldovan. While in the urban centers speakers are split evenly between the two names (with the capital Chișinău showing a strong preference for the name \"Romanian\", i.e. 3:2), in the countryside hardly a quarter of Romanian/Moldovan speakers indicated Romanian as their native language. It should be noted that unofficial results of this census first showed a stronger preference for the name Romanian, however the initial reports were later dismissed by the Institute for Statistics, which led to speculations in the media regarding the forgery of the census results.\n\nThe Constitution of the Republic of Serbia determines that in the regions of the Republic of Serbia inhabited by national minorities, their own languages and scripts shall be officially used as well, in the manner established by law.\n\nThe Statute of the Autonomous Province of Vojvodina determines that, together with the Serbo-Croat language and the Cyrillic script, and the Latin script as stipulated by the law, the Hungarian, Slovak, Romanian and Rusyn languages and their scripts, as well as languages and scripts of other nationalities, shall simultaneously be officially used in the work of the bodies of the Autonomous Province of Vojvodina, in the manner established by the law. The bodies of the Autonomous Province of Vojvodina are: the Assembly, the Executive Council and the Provincial administrative bodies.\nThe Romanian language and script are officially used in eight municipalities: Alibunar, Biserica Albă (), Zitiște (Žitište), Zrenianin (Zrenjanin), Kovăcița (Kovačica), Cuvin (Kovin), Plandiște (Plandište) and Sečanj. In the municipality of Vârșeț (Vršac), Romanian is official only in the villages of Voivodinț (Vojvodinci), Marcovăț (Markovac), Straja (Straža), Jamu Mic (Mali Žam), Srediștea Mică (Malo Središte), Mesici (Mesić), Jablanka, Sălcița (Salčica), Râtișor (Ritiševo), Oreșaț (Orašac) and Coștei (Kuštilj).\n\nIn the 2002 Census, the last carried out in Serbia, 1.5% of Vojvodinians stated Romanian as their native language.\n\nIn parts of Ukraine where Romanians constitute a significant share of the local population (districts in Chernivtsi, Odessa and Zakarpattia oblasts) Romanian is taught in schools as a primary language and there are Romanian-language newspapers, TV, and radio broadcasting.\nThe University of Chernivtsi in western Ukraine trains teachers for Romanian schools in the fields of Romanian philology, mathematics and physics.\n\nIn Hertsa Raion of Ukraine as well as in other villages of Chernivtsi Oblast and Zakarpattia Oblast, Romanian has been declared a \"regional language\" alongside Ukrainian as per the 2012 legislation on languages in Ukraine.\n\nRomanian is an official or administrative language in various communities and organisations, such as the Latin Union and the European Union. Romanian is also one of the five languages in which religious services are performed in the autonomous monastic state of Mount Athos, spoken in the monk communities of Prodromos and Lacu.\nRomanian is taught in some areas that have Romanian minority communities, such as Vojvodina in Serbia, Bulgaria, Ukraine and Hungary. The Romanian Cultural Institute (ICR) has since 1992 organised summer courses in Romanian for language teachers. There are also non-Romanians who study Romanian as a foreign language, for example the Nicolae Bălcescu High-school in Gyula, Hungary.\n\nRomanian is taught as a foreign language in tertiary institutions, mostly in European countries such as Germany, France and Italy, and the Netherlands, as well as in the United States. Overall, it is taught as a foreign language in 43 countries around the world.\n\nRomanian has become popular in other countries through movies and songs performed in the Romanian language. Examples of Romanian acts that had a great success in non-Romanophone countries are the bands O-Zone (with their No. 1 single \"Dragostea Din Tei/Numa Numa\" across the world in 2003–2004), Akcent (popular in the Netherlands, Poland and other European countries), Activ (successful in some Eastern European countries), DJ Project (popular as clubbing music) SunStroke Project (known by viral video \"Epic sax guy\") and Alexandra Stan (worldwide no.1 hit with \"Mr. Saxobeat)\" and Inna as well as high-rated movies like \"4 Months, 3 Weeks and 2 Days\", \"The Death of Mr. Lazarescu\", \"\" or \"California Dreamin'\" (all of them with awards at the Cannes Film Festival).\n\nAlso some artists wrote songs dedicated to the Romanian language. The multiplatinum pop trio O-Zone (originally from Moldova) released a song called \"\"Nu mă las de limba noastră\"\" (\"I won't forsake our language\"). The final verse of this song, \"Eu nu mă las de limba noastră, de limba noastră cea română\" is translated in English as \"I won't forsake our language, our Romanian language\". Also, the Moldovan musicians Doina and Ion Aldea Teodorovici performed a song called \"The Romanian language\".\n\nThe term \"Romanian\" is sometimes used also in a more general sense, encompassing four varieties: (Daco-)Romanian, Aromanian, Megleno-Romanian, and Istro-Romanian. The four languages, whose mutual intelligibility is low, are the offspring of the Romance varieties spoken both to the north and to south of the Danube, before the settlement of the Slavonian tribes south of the river: Daco-Romanian in the north, Aromanian and Megleno-Romanian in the south, whereas Istro-Romanian is thought to be the offspring of an 11th-century migration from Romania. These four are also known as the Eastern Romance languages. When the term \"Romanian\" is used in this larger sense, the term \"Daco-Romanian\" is used for Romanian proper. The origin of the term \"Daco-Romanian\" can be traced back to the first printed book of Romanian grammar in 1780, by Samuil Micu and Gheorghe Șincai. There, the Romanian dialect spoken north of the Danube is called \"lingua Daco-Romana\" to emphasize its origin and its area of use, which includes the former Roman province of Dacia, although it is spoken also south of the Danube, in Dobrudja, Central Serbia and northern Bulgaria.\n\nThis article deals with the Romanian (i.e. Daco-Romanian) language, and thus only its dialectal variations are discussed here. The differences between the regional varieties are small, limited to regular phonetic changes, few grammar aspects, and lexical particularities. There is a single written standard (literary) Romanian language used by all speakers, regardless of region. Like most natural languages, Romanian dialects are part of a dialect continuum. The dialects of Romanian are also referred to as \"subdialects\" (see reasons for this terminology) and are distinguished primarily by phonetic differences. Romanians themselves speak of the differences as \"accents\" or \"speeches\" (in Romanian: \"accent\" or \"grai\").\n\nDepending on the criteria used for classifying these dialects, fewer or more are found, ranging from 2 to 20, although the most widespread approaches give a number of five dialects. These are grouped into two main types, southern and northern, further divided as follows:\n\nOver the last century, however, regional accents have been weakened due to mass communication and greater mobility.\n\nRomanian is a Romance language, belonging to the Italic branch of the Indo-European language family, having much in common with languages such as French, Italian, Spanish and Portuguese.\n\nHowever, the languages closest to Romanian are the other Eastern Romance languages, spoken south of the Danube: Aromanian/Macedo-Romanian, Megleno-Romanian and Istro-Romanian, which are frequently classified as dialects of Romanian. An alternative name for Romanian used by linguists to disambiguate with the other Eastern Romance languages is \"Daco-Romanian\", referring to the area where it is spoken (which corresponds roughly to the onetime Roman province of Dacia).\n\nCompared with the other Romance languages, the closest relative of Romanian is Italian; the two languages show a limited degree of asymmetrical mutual intelligibility, especially in their cultivated forms: speakers of Romanian seem to understand Italian more easily than the other way around. Romanian has obvious grammatical and lexical similarities with French, Catalan, Spanish and Portuguese, with a high phonological similarity with Portuguese in particular; however, it is not mutually intelligible with them to any practical extent. Romanian speakers will usually need some formal study of basic grammar and vocabulary before being able to understand more than individual words and simple sentences. The same is true for speakers of these languages trying to understand Romanian. Because of its separation from the other Romance languages, it has diverged from them and is an outlier in various ways, somewhat like English in regards to the other Germanic languages.\n\nRomanian has had a greater share of foreign influence than some other Romance languages such as Italian in terms of vocabulary and other aspects. One such study was done by Italian-American linguist Mario Pei in 1949, which analyzed the differentiation degree of languages in comparison to their inheritance language (in the case of Romance languages to Latin comparing phonology, inflection, discourse, syntax, vocabulary, and intonation) revealed the following percentages (the higher the percentage, the greater the distance from Latin):\n\nThe lexical similarity of Romanian with Italian has been estimated at 77%, followed by French at 75%, Sardinian 74%, Catalan 73%, Portuguese and Rhaeto-Romance 72%, Spanish 71%.\n\nIn modern times Romanian vocabulary has been strongly influenced by French and, to a lesser extent, Italian and other languages.\n\nThe Dacian language was an Indo-European language spoken by the ancient Dacians, mostly north of the Danube river but also in Moesia and other regions south of the Danube. It may have been the first language to influence the Latin spoken in Dacia, but little is known about it. Dacian is usually considered to have been a northern branch of the Thracian language, and, like Thracian, Dacian was a satem language. About 300 words found only in Romanian or with a cognate in the Albanian language may be inherited from Dacian (for example: \"barză\" \"stork\", \"balaur\" \"dragon\", \"mal\" \"shore\", \"brânză\" \"cheese\"). Some of these possibly Dacian words are related to pastoral life (for example, \"brânză\" \"cheese\"). Some linguists and historians have asserted that Albanians are Dacians who were not Romanized and migrated southward.\n\nA different view is that these non-Latin words with Albanian cognates are not necessarily Dacian, but rather were brought into the territory that is modern Romania by Romance-speaking shepherds migrating north from Albania, Serbia, and northern Greece who became the Romanian people.\n\nWhile most of Romanian grammar and morphology are based on Latin, there are some features that are shared only with other languages of the Balkans and not found in other Romance languages. The shared features of Romanian and the other languages of the Balkan language area (Bulgarian, Macedonian, Albanian, Greek, and Serbian) include a suffixed definite article, the syncretism of genitive and dative case and the formation of the future and the alternation of infinitive with subjunctive constructions. According to a well-established scholarly theory, most Balkanisms could be traced back to the development of the Balkan Romance languages; these features were adopted by other languages due to language shift.\n\nThe Slavic influences on Romanian are especially noticeable and can be observed at all linguistic levels: lexis, phonetics, morphology and syntax. About 20% of modern Romanian words are of Slavic origin. This is due to the migration of Slavic tribes who traversed the territory of present-day Romania during the early evolution of the language and the continuing use of Church Slavonic as the liturgical language of the Romanian Orthodox Church. This process of the introduction of Slavic in Dacia was similar to the appearance of various Germanic dialects in the Western Roman Empire, where Gallic Latin, Iberian Latin, and Northern Italian dialects became strongly Germanized. However, due to the lower Romance-speaking populace in the East, Slavic remained spoken for much longer and did not die out immediately.\n\nEven before the 19th century, Romanian came in contact with several other languages. Some notable examples include:\n\nIn addition, many more words were borrowed from Classical Latin through the influence of written language and the liturgical language of the Roman Catholic Church, as Latin did hold an important position in Transylvania after the 11th century as it was part of Kingdom of Hungary, a Roman Catholic country, until it was occupied by Romanians after World War I. Throughout the Middle Ages and into the early modern period, most literate Romanian speakers, including Roman Catholics and Orthodox, were also literate in Latin; and thus they easily adopted Latin words, along with Hungarian, into their writing—and eventually speech—in Romanian. This caused Romanian to easily reduce some of its Slavic loanwords.\n\nSince the 19th century, many literary or learned words were borrowed from the other Romance languages, especially from French and Italian (for example: \"birou\" \"desk, office\", \"avion\" \"airplane\", \"exploata\" \"exploit\"). It was estimated that about 38% of words in Romanian are of French and/or Italian origin (in many cases both languages); and adding this to Romanian's native stock, about 75%–85% of Romanian words can be traced to Latin. The use of these Romanianized French and Italian learned loans has tended to increase at the expense of Slavic loanwords, many of which have become rare or fallen out of use. As second or third languages, French and Italian themselves are better known in Romania than in Romania's neighbors. Along with the switch to the Latin alphabet in Moldova, the re-latinization of the vocabulary has tended to reinforce the Latin character of the language.\n\nIn the process of lexical modernization, much of the native Latin stock have acquired doublets from other Romance languages, thus forming a further and more modern and literary lexical layer. Typically, the native word is a noun and the learned loan is an adjective. Some examples of doublets:\n\nIn the 20th century, an increasing number of English words have been borrowed (such as: \"gem\" < jam; \"interviu\" < interview; \"meci\" < match; \"manager\" < manager; \"fotbal\" < football; \"sandviș\" < sandwich; \"bișniță\" < business; \"chec\" < cake). These words are assigned grammatical gender in Romanian and handled according to Romanian rules; thus \"the manager\" is \"managerul\". Some borrowings, for example in the computer field, appear to have awkward (perhaps contrived and ludicrous) 'Romanisation,' such as \"cookie-uri\" which is the plural of the Internet term \"cookie.\"\n\nA statistical analysis sorting Romanian words by etymological source carried out by Macrea (1961) based on the DLRM (49,649 words) showed the following makeup:\n\n\nIf the analysis is restricted to a core vocabulary of 2,500 frequent, semantically rich and productive words, then the Latin inheritance comes first, followed by Romance and classical Latin neologisms, whereas the Slavic borrowings come third. The Romanian lexicon is similar by 77% with Italian, 75% with French, 74% with Sardinian, 73% with Catalan, 72% with Portuguese and Rheto-Romance, 71% with Spanish.\n\nOverall Romanian grammar is more conservative in its preservation of Latin grammatical constructs than other Romance languages. (Scholars disagree on the reasons for this).\n\nRomanian nouns are characterized by gender (feminine, masculine, and neuter), and declined by number (singular and plural) and case (nominative/accusative, dative/genitive and vocative). The articles, as well as most adjectives and pronouns, agree in gender, number and case with the noun they reference.\n\nRomanian is the only Romance language where definite articles are \"enclitic\": that is, attached to the end of the noun (as in Scandinavian, and Bulgarian), instead of in front (\"proclitic\"). They were formed, as in other Romance languages, from the Latin demonstrative pronouns.\n\nAs in all Romance languages, Romanian verbs are highly inflected for person, number, tense, mood, and voice. The usual word order in sentences is subject–verb–object (SVO). Romanian has four verbal conjugations which further split into ten conjugation patterns. Verbs can be put in five moods that are inflected for the person (indicative, conditional/optative, imperative, subjunctive, and presumptive) and four impersonal moods (infinitive, gerund, supine, and participle).\n\nRomanian has seven vowels: , , , , , and . Additionally, and may appear in some borrowed words. Arguably, the diphthongs and are also part of the phoneme set. There are twenty-two consonants. The two approximants and can appear before or after any vowel, creating a large number of glide-vowel sequences which are, strictly speaking, not diphthongs.\n\nIn final positions after consonants, a short can be deleted, surfacing only as the palatalization of the preceding consonant (e.g., ). Similarly, a deleted may prompt labialization of a preceding consonant, though this has ceased to carry any morphological meaning.\n\nOwing to its isolation from the other Romance languages, the phonetic evolution of Romanian was quite different, but the language does share a few changes with Italian, such as → (Lat. clarus → Rom. chiar, Ital. chiaro, Lat. clamare → Rom. \"che\"mare, Ital. \"chi\"amare) and → (Lat. *\"gl\"acia (\"gl\"acies) → Rom. \"ghe\"ață, Ital. \"ghi\"accia, \"ghi\"accio, Lat. *un\"gl\"a (ungula) → Rom. un\"ghi\"e, Ital. un\"ghi\"a), although this did not go as far as it did in Italian with other similar clusters (Rom. \"pl\"ace, Ital. \"pi\"ace); another similarity with Italian is the change from or to or (Lat. pax, pa\"ce\"m → Rom. and Ital. pa\"ce\", Lat. dul\"ce\"m → Rom. dul\"ce\", Ital. dol\"ce\", Lat. \"ci\"rcus → Rom. \"ce\"rc, Ital. \"ci\"rco) and or to or (Lat. \"ge\"lu → Rom. \"ge\"r, Ital. \"ge\"lo, Lat. mar\"gi\"nem → Rom. and Ital. mar\"gi\"ne, Lat. \"ge\"mere → Rom. \"ge\"me (\"ge\"mere), Ital. \"ge\"mere). There are also a few changes shared with Dalmatian, such as (probably phonetically ) → (Lat. cognatus → Rom. cumnat, Dalm. comnut) and → in some situations (Lat. coxa → Rom. coa\"ps\"ă, Dalm. co\"ps\"a).\n\nAmong the notable phonetic changes are:\n\nOn the other hand, it (along with French) has \"lost\" (qu) sound before from original Latin, turning it either into (Lat. quattuor → Rom.\"patru\", \"four\"; cf. It. \"quattro\") or (Lat. quando → Rom.\"când\", \"when\"; Lat. quale → Rom.\"care\", \"which\").\n\nThe first written record about a Romance language spoken in the Middle Ages in the Balkans is from 587. A Vlach muleteer accompanying the Byzantine army noticed that the load was falling from one of the animals and shouted to a companion \"Torna, torna frate\" (meaning \"Return, return brother!\"), and, \"sculca\" (out of bed) . Theophanes Confessor recorded it as part of a 6th-century military expedition by Commentiolus and Priscus against the Avars and Slovenes.\n\n\"Libri III de moribus et actis primorum Normanniae ducum\" by Dudo of Saint-Quentin states that Richard I of Normandy was sent by his father William I Longsword to learn the Dacian language with Bothon because the inhabitants of Bayeux spoke more Dacian than Roman.\n\nThe oldest surviving written text in Romanian is a letter from late June 1521, in which Neacșu of Câmpulung wrote to the mayor of Brașov about an imminent attack of the Turks. It was written using the Cyrillic alphabet, like most early Romanian writings. The earliest surviving writing in Latin script was a late 16th-century Transylvanian text which was written with the Hungarian alphabet conventions.\nIn the late 18th century, Transylvanian scholars noted the Latin origin of Romanian and adapted the Latin alphabet to the Romanian language, using some orthographic rules from Italian, recognized as Romanian's closest relative. The Cyrillic alphabet remained in (gradually decreasing) use until 1860, when Romanian writing was first officially regulated.\n\nIn the Soviet Republic of Moldova, a special version of the Cyrillic alphabet derived from the Russian version was used until 1989, when Romanian language spoken there officially returned to the Romanian Latin alphabet, although in the breakaway territory of Transnistria the Cyrillic alphabet is used to this day.\n\nThe Romanian alphabet is as follows:\nK, Q, W and Y, not part of the native alphabet, were officially introduced in the Romanian alphabet in 1982 and are mostly used to write loanwords like \"kilogram\", \"quasar\", \"watt\", and \"yoga\".\n\nThe Romanian alphabet is based on the Latin script with five additional letters , , , , . Formerly, there were as many as 12 additional letters, but some of them were abolished in subsequent reforms. Also, until the early 20th century, a short vowel marker was used.\n\nToday the Romanian alphabet is largely phonemic. However, the letters \"â\" and \"î\" both represent the same close central unrounded vowel . \"Â\" is used only inside words; \"î\" is used at the beginning or the end of single words and in the middle of compound words. Another exception from a completely phonetic writing system is the fact that vowels and their respective semivowels are not distinguished in writing. In dictionaries the distinction is marked by separating the entry word into syllables for words containing a hiatus.\n\nStressed vowels also are not marked in writing, except very rarely in cases where by misplacing the stress a word might change its meaning and if the meaning is not obvious from the context. For example, \"trei copíi\" means \"three children\" while \"trei cópii\" means \"three copies\".\n\n\nUses of punctuation peculiar to Romanian are:\n\nPrior to 2010, there existed a minor spelling difference between standard forms of Romanian language used in Romania and the variant (also called Moldovan) used in the Republic of Moldova—the Academy of Sciences of Moldova did not switch to the new spelling rules introduced by the Romanian Academy in 1993. In 2000, the Moldovan Academy recommended adopting the spelling rules used in Romania, and in 2010 the Academy launched a schedule for the transition to the new rules that was completed in 2011 (regarding publications) and is currently under implementation in the educational system (due to be completed within two school years). However, as of 2015 most Moldovan commercial websites maintain the 'old' spelling.\n\nEnglish text:\n\nRomanian – highlighted words were \"directly\" derived from Latin:\n\nContemporary Romanian – highlighted words are French or Italian loanwords:\n\nRomanian, excluding French and Italian loanwords – highlighted words are Slavic loanwords:\n\nRomanian, excluding loanwords and having almost the same meaning:\n\n\n\n"}
{"id": "25536", "url": "https://en.wikipedia.org/wiki?curid=25536", "title": "Republic", "text": "Republic\n\nA republic () is a form of government in which the country is considered a \"public matter\" – not the private concern or property of the rulers – and where offices of state are elected or appointed, rather than inherited. It is a form of government under which the head of state is not a monarch.\n\nIn American English, the definition of a republic can also refer specifically to a government in which elected individuals represent the citizen body, known elsewhere as a representative democracy (a democratic republic), and exercise power according to the rule of law (a constitutional republic).\n\n, 159 of the world's 206 sovereign states use the word \"republic\" as part of their official names; not all of these are republics in the sense of having elected governments, nor do all nations with elected governments use the word \"republic\" in their names.\n\nBoth modern and ancient republics vary widely in their ideology, composition, and practicality. In the classical and medieval period of Europe, many states were fashioned on the Roman Republic, which referred to the governance of the city of Rome, between it having kings and emperors. The Italian medieval and Renaissance political tradition, today referred to as \"civic humanism\", is sometimes considered to derive directly from Roman republicans such as Sallust and Tacitus. However, Greek-influenced Roman authors, such as Polybius and Cicero, sometimes also used the term as a translation for the Greek \"politeia\" which could mean regime generally, but could also be applied to certain specific types of regime that did not exactly correspond to that of the Roman Republic. Republics were not equated with classical democracies such as Athens, but had a democratic aspect.\n\nRepublics became more common in the Western world starting in the late 18th century, eventually displacing absolute monarchy as the most common form of government in Europe. In modern republics, the executive is legitimized both by a constitution and by popular suffrage. In his work, \"The Spirit of the Laws\", Montesquieu classified both democracies, where all the people have a share in rule, and aristocracies, where only some of the people rule, as republican forms of government.\n\nMost often a republic is a single sovereign state, but there are also sub-sovereign state entities that are referred to as republics, or that have governments that are described as 'republican' in nature. For instance, Article IV of the United States Constitution \"guarantee[s] to every State in this Union a Republican form of Government\". In contrast, the Soviet Union was constitutionally described as a \"federal multinational state\", composed of 15 republics, two of which – Ukraine and Belarus – had their own seats at the United Nations.\n\nThe term originates as the Latin translation of Greek word \"politeia\". Cicero, among other Latin writers, translated \"politeia\" as \"res publica\" and it was in turn translated by Renaissance scholars as \"republic\" (or similar terms in various western European languages).\n\nThe term \"politeia\" can be translated as \"form of government\", \"polity\", or \"regime\", and is therefore not always a word for a specific type of regime as the modern word republic is. (One of Plato's major works on political science was titled \"Politeia\" and in English it is thus known as \"The Republic\". However, apart from the title, in modern translations of \"The Republic\", alternative translations of \"politeia\" are also used.) However, in Book III of his \"Politics\" (1279a), Aristotle was apparently the first classical writer to state that the term \"politeia\" can be used to refer more specifically to one type of \"politeia\": \"When the citizens at large govern for the public good, it is called by the name common to all governments (\"to koinon onoma pasōn tōn politeiōn\"), government (\"politeia\")\". And also amongst classical Latin, the term \"republic\" can be used in a general way to refer to any regime, or in a specific way to refer to governments which work for the public good.\n\nIn medieval Northern Italy, a number of city states had commune or signoria based governments. In the late Middle Ages, writers, such as Giovanni Villani, began writing about the nature of these states and the differences from other types of regime. They used terms such as \"libertas populi\", a free people, to describe the states. The terminology changed in the 15th century as the renewed interest in the writings of Ancient Rome caused writers to prefer using classical terminology. To describe non-monarchical states writers, most importantly Leonardo Bruni, adopted the Latin phrase \"res publica\".\n\nWhile Bruni and Machiavelli used the term to describe the states of Northern Italy, which were not monarchies, the term \"res publica\" has a set of interrelated meanings in the original Latin. The term can quite literally be translated as \"public matter\". It was most often used by Roman writers to refer to the state and government, even during the period of the Roman Empire.\n\nIn subsequent centuries, the English word \"commonwealth\" came to be used as a translation of \"res publica\", and its use in English was comparable to how the Romans used the term \"res publica\". Notably, during The Protectorate of Oliver Cromwell the word \"commonwealth\" was the most common term to call the new monarchless state, but the word \"republic\" was also in common use. Likewise, in Polish, the term was translated as \"rzeczpospolita\", although the translation is now only used with respect to Poland.\n\nPresently, the term \"republic\" commonly means a system of government which derives its power from the people rather than from another basis, such as heredity or divine right.\n\nWhile the philosophical terminology developed in classical Greece and Rome, as already noted by Aristotle there was already a long history of city states with a wide variety of constitutions, not only in Greece but also in the Middle East. After the classical period, during the Middle Ages, many free cities developed again, such as Venice.\n\nThe modern type of \"republic\" itself is different from any type of state found in the classical world. Nevertheless, there are a number of states of the classical era that are today still called republics. This includes ancient Athens, Sparta and the Roman Republic. While the structure and governance of these states was very different from that of any modern republic, there is debate about the extent to which classical, medieval, and modern republics form a historical continuum. J. G. A. Pocock has argued that a distinct republican tradition stretches from the classical world to the present. Other scholars disagree. Paul Rahe, for instance, argues that the classical republics had a form of government with few links to those in any modern country.\n\nThe political philosophy of the classical republics have in any case had an influence on republican thought throughout the subsequent centuries. Philosophers and politicians advocating for republics, such as Machiavelli, Montesquieu, Adams, and Madison, relied heavily on classical Greek and Roman sources which described various types of regimes.\n\nAristotle's \"Politics\" discusses various forms of government. One form Aristotle named \"politeia\", which consisted of a mixture of the other forms. He argued that this was one of the ideal forms of government. Polybius expanded on many of these ideas, again focusing on the idea of mixed government. The most important Roman work in this tradition is Cicero's \"De re publica\".\n\nOver time, the classical republics were either conquered by empires or became ones themselves. Most of the Greek republics were annexed to the Macedonian Empire of Alexander. The Roman Republic expanded dramatically conquering the other states of the Mediterranean that could be considered republics, such as Carthage. The Roman Republic itself then became the Roman Empire.\n\nThe term \"republic\" is not commonly used to refer to pre-classical city states, especially if outside Europe and the area which was under Graeco-Roman influence. However some early states outside Europe had governments that are sometimes today considered similar to republics.\n\nIn the ancient Near East, a number of cities of the Eastern Mediterranean achieved collective rule. Arwad has been cited as one of the earliest known examples of a republic, in which the people, rather than a monarch, are described as sovereign. The Israelite confederation of the era before the United Monarchy has also been considered a type of republic. In Africa the Axum Empire was organized as a confederation ruled similarly to a royal republic. Similarly the Igbo nation of what is now Nigeria.\n\nThe ancient Indian subcontinent had a number of early republics known as Mahajanapadas. Mahajanapadas consisted of sixteen oligarchic republics that existed during the sixth centuries BCE to fourth centuries BCE. Some Indian scholars, such as K.P. Jayaswal, have argued that a number of states in ancient India had republican forms of government. While there are no surviving constitutions or works of political philosophy from this period in Indian history, but surviving religious texts do refer to a number of states having sabhās or gaṇa sangha, a type of republic or council-based, as opposed to monarchical, government. Ancient Greek writers mention Alexander the Great encountering city states and regions where a council of elders ruled with paramount authority.\nThe Icelandic Commonwealth was established in 930 AD by refugees from Norway who had fled the unification of that country under King Harald Fairhair. The Commonwealth consisted of a number of clans run by chieftains, and the Althing was a combination of parliament and supreme court where disputes appealed from lower courts were settled, laws were decided, and decisions of national importance were taken. One such example was the Christianisation of Iceland in 1000, where the Althing decreed, in order to prevent an invasion, that all Icelanders must be baptized, and forbade celebration of pagan rituals. Contrary to most states, the Icelandic Commonwealth had no official leader.\n\nIn the early 13th century, the Age of the Sturlungs, the Commonwealth began to suffer from long conflicts between warring clans. This, combined with pressure from the Norwegian king Haakon IV for the Icelanders to re-join the Norwegian \"family\", led the Icelandic chieftains to accept Haakon IV as king by the signing of the \"Gamli sáttmáli\" (\"Old Covenant\") in 1262. This effectively brought the Commonwealth to an end. The Althing, however, is still Iceland's parliament, almost 800 years later.\n\nIn Europe new republics appeared in the late Middle Ages when a number of small states embraced republican systems of government. These were generally small, but wealthy, trading states, like the Italian city-states and the Hanseatic League, in which the merchant class had risen to prominence. Knud Haakonssen has noted that, by the Renaissance, Europe was divided with those states controlled by a landed elite being monarchies and those controlled by a commercial elite being republics.\n\nAcross Europe a wealthy merchant class developed in the important trading cities. Despite their wealth they had little power in the feudal system dominated by the rural land owners, and across Europe began to advocate for their own privileges and powers. The more centralized states, such as France and England, granted limited city charters.\n\nIn the more loosely governed Holy Roman Empire, 51 of the largest towns became free imperial cities. While still under the dominion of the Holy Roman Emperor most power was held locally and many adopted republican forms of government. The same rights to imperial immediacy were secured by the major trading cities of Switzerland. The towns and villages of alpine Switzerland had, courtesy of geography, also been largely excluded from central control. Unlike Italy and Germany, much of the rural area was thus not controlled by feudal barons, but by independent farmers who also used communal forms of government. When the Habsburgs tried to reassert control over the region both rural farmers and town merchants joined the rebellion. The Swiss were victorious, and the Swiss Confederacy was proclaimed, and Switzerland has retained a republican form of government to the present.\n\nItaly was the most densely populated area of Europe, and also one with the weakest central government. Many of the towns thus gained considerable independence and adopted commune forms of government. Completely free of feudal control, the Italian city-states expanded, gaining control of the rural hinterland. The two most powerful were the Republic of Venice and its rival the Republic of Genoa. Each were large trading ports, and further expanded by using naval power to control large parts of the Mediterranean. It was in Italy that an ideology advocating for republics first developed. Writers such as Bartholomew of Lucca, Brunetto Latini, Marsilius of Padua, and Leonardo Bruni saw the medieval city-states as heirs to the legacy of Greece and Rome.\n\nTwo Russian cities with powerful merchant class—Novgorod and Pskov—also adopted republican forms of government in 12th and 13th centuries, respectively, which ended when the republics were conquered by Muscovy/Russia at the end 15th – beginning of 16th century.\n\nThe dominant form of government for these early republics was control by a limited council of elite patricians. In those areas that held elections, property qualifications or guild membership limited both who could vote and who could run. In many states no direct elections were held and council members were hereditary or appointed by the existing council. This left the great majority of the population without political power, and riots and revolts by the lower classes were common. The late Middle Ages saw more than 200 such risings in the towns of the Holy Roman Empire. Similar revolts occurred in Italy, notably the Ciompi Revolt in Florence.\n\nFollowing the collapse of the Seljuk Sultanate of Rum and establishment of the Turkish Anatolian Beyliks, the Ahiler merchant fraternities established a state centered on Ankara that is sometimes compared to the Italian mercantile republics.\n\nWhile the classical writers had been the primary ideological source for the republics of Italy, in Northern Europe, the Protestant Reformation would be used as justification for establishing new republics. Most important was Calvinist theology, which developed in the Swiss Confederacy, one of the largest and most powerful of the medieval republics. John Calvin did not call for the abolition of monarchy, but he advanced the doctrine that the faithful had the duty to overthrow irreligious monarchs. Advocacy for republics appeared in the writings of the Huguenots during the French Wars of Religion.\n\nCalvinism played an important role in the republican revolts in England and the Netherlands. Like the city-states of Italy and the Hanseatic League, both were important trading centres, with a large merchant class prospering from the trade with the New World. Large parts of the population of both areas also embraced Calvinism. During the Dutch Revolt (beginning in 1566), the Dutch Republic emerged from rejection of Spanish Habsburg rule. However, the country did not adopt the republican form of government immediately: in the formal declaration of independence (Act of Abjuration, 1581), the throne of king Philip was only declared vacant, and the Dutch magistrates asked the Duke of Anjou, queen Elizabeth of England and prince William of Orange, one after another, to replace Philip. It took until 1588 before the Estates (the \"Staten\", the representative assembly at the time) decided to vest the sovereignty of the country in themselves.\n\nIn 1641 the English Civil War began. Spearheaded by the Puritans and funded by the merchants of London, the revolt was a success, and King Charles I was executed. In England James Harrington, Algernon Sidney, and John Milton became some of the first writers to argue for rejecting monarchy and embracing a republican form of government. The English Commonwealth was short lived, and the monarchy soon restored. The Dutch Republic continued in name until 1795, but by the mid-18th century the stadtholder had become a \"de facto\" monarch. Calvinists were also some of the earliest settlers of the British and Dutch colonies of North America.\n\nAlong with these initial republican revolts, early modern Europe also saw a great increase in monarchial power. The era of absolute monarchy replaced the limited and decentralized monarchies that had existed in most of the Middle Ages. It also saw a reaction against the total control of the monarch as a series of writers created the ideology known as liberalism.\n\nMost of these Enlightenment thinkers were far more interested in ideas of constitutional monarchy than in republics. The Cromwell regime had discredited republicanism, and most thinkers felt that republics ended in either anarchy or tyranny. Thus philosophers like Voltaire opposed absolutism while at the same time being strongly pro-monarchy.\n\nJean-Jacques Rousseau and Montesquieu praised republics, and looked on the city-states of Greece as a model. However, both also felt that a nation-state like France, with 20 million people, would be impossible to govern as a republic. Rousseau admired the republican experiment in Corsica (1755–1769) and described his ideal political structure of small self-governing communes. Montesquieu felt that a city-state should ideally be a republic, but maintained that a limited monarchy was better suited to a large nation.\n\nThe American Revolution began as a rejection only of the authority of the British Parliament over the colonies, not of the monarchy. The failure of the British monarch to protect the colonies from what they considered the infringement of their rights to representative government, the monarch's branding of those requesting redress as traitors, and his support for sending combat troops to demonstrate authority resulted in widespread perception of the British monarchy as tyrannical. With the United States Declaration of Independence the leaders of the revolt firmly rejected the monarchy and embraced republicanism. The leaders of the revolution were well versed in the writings of the French liberal thinkers, and also in history of the classical republics. John Adams had notably written a book on republics throughout history. In addition, the widely distributed and popularly read-aloud tract \"Common Sense\", by Thomas Paine, succinctly and eloquently laid out the case for republican ideals and independence to the larger public. The Constitution of the United States, ratified in 1789, created a relatively strong federal republic to replace the relatively weak confederation under the first attempt at a national government with the Articles of Confederation and Perpetual Union ratified in 1783. The first ten amendments to the Constitution, called the United States Bill of Rights, guaranteed certain natural rights fundamental to republican ideals that justified the Revolution.\n\nThe French Revolution was also not republican at its outset. Only after the Flight to Varennes removed most of the remaining sympathy for the king was a republic declared and Louis XVI sent to the guillotine. The stunning success of France in the French Revolutionary Wars saw republics spread by force of arms across much of Europe as a series of client republics were set up across the continent. The rise of Napoleon saw the end of the French First Republic and her Sister Republics, each replaced by 'popular monarchies'. Throughout the Napoleonic period, the victors extinguished many of the oldest republics on the continent, including the Republic of Venice, the Republic of Genoa, and the Dutch Republic. They were eventually transformed into monarchies or absorbed into neighbouring monarchies.\n\nOutside Europe another group of republics was created as the Napoleonic Wars allowed the states of Latin America to gain their independence. Liberal ideology had only a limited impact on these new republics. The main impetus was the local European descended Creole population in conflict with the Peninsulares—governors sent from overseas. The majority of the population in most of Latin America was of either African or Amerindian descent, and the Creole elite had little interest in giving these groups power and broad-based popular sovereignty. Simón Bolívar, both the main instigator of the revolts and one of its most important theorists, was sympathetic to liberal ideals but felt that Latin America lacked the social cohesion for such a system to function and advocated autocracy as necessary.\n\nIn Mexico this autocracy briefly took the form of a monarchy in the First Mexican Empire. Due to the Peninsular War, the Portuguese court was relocated to Brazil in 1808. Brazil gained independence as a monarchy on September 7, 1822, and the Empire of Brazil lasted until 1889. In the other states various forms of autocratic republic existed until most were liberalized at the end of the 20th century.\nThe French Second Republic was created in 1848, but abolished by Napoleon III who proclaimed himself Emperor in 1852. The French Third Republic was established in 1870, when a civil revolutionary committee refused to accept Napoleon III's surrender during the Franco-Prussian War. Spain briefly became the First Spanish Republic in 1873–74, but the monarchy was soon restored. By the start of the 20th century France, Switzerland and San Marino remained the only republics in Europe. This changed when, after the 1908 Lisbon Regicide, the 5 October 1910 revolution established the Portuguese Republic.\nIn East Asia, China had seen considerable anti-Qing sentiment during the 19th century, and a number of protest movements developed calling for constitutional monarchy. The most important leader of these efforts was Sun Yat-sen, whose Three Principles of the People combined American, European, and Chinese ideas. Under his leadership the Republic of China was proclaimed on January 1, 1912.\n\nRepublicanism expanded significantly in the aftermath of World War I, when several of the largest European empires collapsed: the Russian Empire (1917), German Empire (1918), Austro-Hungarian Empire (1918), and Ottoman Empire (1922) were all replaced by republics. New states gained independence during this turmoil, and many of these, such as Ireland, Poland, Finland and Czechoslovakia, chose republican forms of government. Following Greece's defeat in the Greco-Turkish War (1919–22), the monarchy was briefly replaced by the Second Hellenic Republic (1924–35). In 1931, the proclamation of the Second Spanish Republic (1931–39) resulted in the Spanish Civil War that would be the prelude of World War II.\n\nRepublican ideas were spreading, especially in Asia. The United States began to have considerable influence in East Asia in the later part of the 19th century, with Protestant missionaries playing a central role. The liberal and republican writers of the west also exerted influence. These combined with native Confucian inspired political philosophy that had long argued that the populace had the right to reject unjust government that had lost the Mandate of Heaven.\n\nTwo short-lived republics were proclaimed in East Asia, the Republic of Formosa and the First Philippine Republic.\n\nIn the years following World War II, most of the remaining European colonies gained their independence, and most became republics. The two largest colonial powers were France and the United Kingdom. Republican France encouraged the establishment of republics in its former colonies. The United Kingdom attempted to follow the model it had for its earlier settler colonies of creating independent Commonwealth realms still linked under the same monarchy. While most of the settler colonies and the smaller states of the Caribbean retained this system, it was rejected by the newly independent countries in Africa and Asia, which revised their constitutions and became republics.\n\nBritain followed a different model in the Middle East; it installed local monarchies in several colonies and mandates including Iraq, Jordan, Kuwait, Bahrain, Oman, Yemen and Libya. In subsequent decades revolutions and coups overthrew a number of monarchs and installed republics. Several monarchies remain, and the Middle East is the only part of the world where several large states are ruled by monarchs with almost complete political control.\n\nIn the wake of the First World War, the Russian monarchy fell during the Russian Revolution. The Russian Provisional Government was established in its place on the lines of a liberal republic, but this was overthrown by the Bolsheviks who went on to establish the Union of Soviet Socialist Republics. This was the first republic established under Marxist-Leninist ideology. Communism was wholly opposed to monarchy, and became an important element of many republican movements during the 20th century. The Russian Revolution spread into Mongolia, and overthrew its theocratic monarchy in 1924. In the aftermath of the Second World War the communists gradually gained control of Romania, Bulgaria, Yugoslavia, Hungary and Albania, ensuring that the states were reestablished as socialist republics rather than monarchies.\n\nCommunism also intermingled with other ideologies. It was embraced by many national liberation movements during decolonization. In Vietnam, communist republicans pushed aside the Nguyễn Dynasty, and monarchies in neighbouring Laos and Cambodia were overthrown by communist movements in the 1970s. Arab socialism contributed to a series of revolts and coups that saw the monarchies of Egypt, Iraq, Libya, and Yemen ousted. In Africa Marxist-Leninism and African socialism led to the end of monarchy and the proclamation of republics in states such as Burundi and Ethiopia.\n\nIslamic political philosophy has a long history of opposition to absolute monarchy, notably in the work of Al-Farabi. Sharia law took precedence over the will of the ruler, and electing rulers by means of the Shura was an important doctrine. While the early caliphate maintained the principles of an elected ruler, later states became hereditary or military dictatorships though many maintained some pretense of a consultative shura.\n\nNone of these states are typically referred to as republics. The current usage of republic in Muslim countries is borrowed from the western meaning, adopted into the language in the late 19th century. The 20th century saw republicanism become an important idea in much of the Middle East, as monarchies were removed in many states of the region. Iraq became a secular state. Some nations, such as Indonesia and Azerbaijan, began as secular. In Iran, the 1979 revolution overthrew the monarchy and created an Islamic republic based on the ideas of Islamic democracy.\n\nWith no monarch, most modern republics use the title president for the head of state. Originally used to refer to the presiding officer of a committee or governing body in Great Britain the usage was also applied to political leaders, including the leaders of some of the Thirteen Colonies (originally Virginia in 1608); in full, the \"President of the Council.\" The first republic to adopt the title was the United States of America. Keeping its usage as the head of a committee the President of the Continental Congress was the leader of the original congress. When the new constitution was written the title of President of the United States was conferred on the head of the new executive branch.\n\nIf the head of state of a republic is also the head of government, this is called a presidential system. There are a number of forms of presidential government. A full-presidential system has a president with substantial authority and a central political role.\n\nIn other states the legislature is dominant and the presidential role is almost purely ceremonial and apolitical, such as in Germany and India. These states are parliamentary republics and operate similarly to constitutional monarchies with parliamentary systems where the power of the monarch is also greatly circumscribed. In parliamentary systems the head of government, most often titled prime minister, exercises the most real political power. Semi-presidential systems have a president as an active head of state, but also have a head of government with important powers.\n\nThe rules for appointing the president and the leader of the government, in some republics permit the appointment of a president and a prime minister who have opposing political convictions: in France, when the members of the ruling cabinet and the president come from opposing political factions, this situation is called cohabitation.\n\nIn some countries, like Switzerland, Bosnia and Herzegovina and San Marino, the head of state is not a single person but a committee (council) of several persons holding that office. The Roman Republic had two consuls, elected for a one year-term by the \"comitia centuriata\", consisting of all adult, freeborn males who could prove citizenship.\n\nIn liberal democracies presidents are elected, either directly by the people or indirectly by a parliament or council. Typically in presidential and semi-presidential systems the president is directly elected by the people, or is indirectly elected as done in the United States. In that country the president is officially elected by an electoral college, chosen by the States, all of which do so by direct election of the electors. The indirect election of the president through the electoral college conforms to the concept of republic as one with a system of indirect election. In the opinion of some, direct election confers legitimacy upon the president and gives the office much of its political power. However, this concept of legitimacy differs from that expressed in the United States Constitution which established the legitimacy of the United States president as resulting from the signing of the Constitution by nine states. The idea that direct election is required for legitimacy also contradicts the spirit of the Great Compromise, whose actual result was manifest in the clause that provides voters in smaller states with slightly more representation in presidential selection than those in large states.\n\nIn states with a parliamentary system the president is usually elected by the parliament. This indirect election subordinates the president to the parliament, and also gives the president limited legitimacy and turns most presidential powers into reserve powers that can only be exercised under rare circumstance. There are exceptions where elected presidents have only ceremonial powers, such as in Ireland.\n\nThe distinction between a republic and a monarchy is not always clear. The constitutional monarchies of the former British Empire and Western Europe today have almost all real political power vested in the elected representatives, with the monarchs only holding either theoretical powers, no powers or rarely used reserve powers. Real legitimacy for political decisions comes from the elected representatives and is derived from the will of the people. While hereditary monarchies remain in place, political power is derived from the people as in a republic. These states are thus sometimes referred to as crowned republics.\n\nTerms such as \"liberal republic\" are also used to describe all of the modern liberal democracies.\n\nThere are also self-proclaimed republics that act similarly to monarchies with absolute power vested in the leader and passed down from father to son. North Korea and Syria are two notable examples where a son has inherited political control. Neither of these states are officially monarchies. There is no constitutional requirement that power be passed down within one family, but it has occurred in practice.\n\nThere are also elective monarchies where ultimate power is vested in a monarch, but the monarch is chosen by some manner of election. A current example of such a state is Malaysia where the Yang di-Pertuan Agong is elected every five years by the Conference of Rulers composed of the nine hereditary rulers of the Malay states, and the Vatican City-State, where the pope is selected by cardinal-electors, currently all cardinals under a specific age. While rare today, elective monarchs were common in the past. The Holy Roman Empire is an important example, where each new emperor was chosen by a group of electors. Islamic states also rarely employed primogeniture, instead relying on various forms of election to choose a monarch's successor.\n\nThe Polish–Lithuanian Commonwealth had an elective monarchy, with a wide suffrage of some 500,000 nobles. The system, known as the Golden Liberty, had developed as a method for powerful landowners to control the crown. The proponents of this system looked to classical examples, and the writings of the Italian Renaissance, and called their elective monarchy a \"rzeczpospolita\", based on \"res publica.\"\n\nIn general being a republic also implies sovereignty as for the state to be ruled by the people it cannot be controlled by a foreign power. There are important exceptions to this, for example, republics in the Soviet Union were member states which had to meet three criteria to be named republics:\n\n\nIt is sometimes argued that the former Soviet Union was also a supra-national republic, based on the claim that the member states were different nations.\n\nSocialist Federative Republic of Yugoslavia (and earlier names) was a federal entity composed of six republics (Socialist Republic of Bosnia and Herzegovina, Croatia, Macedonia, Montenegro, Serbia, and Slovenia). Each republic had its parliament, government, institute of citizenship, constitution, etc... but certain functions were delegated to the federation (army, monetary matters). Each republic also had a right of self-determination according to the conclusions of the second session of the AVNOJ and according to the federal constitution.\n\nStates of the United States are required, like the federal government, to be republican in form, with final authority resting with the people. This was required because the states were intended to create and enforce most domestic laws, with the exception of areas delegated to the federal government and prohibited to the states. The founding fathers of the country intended most domestic laws to be handled by the states. Requiring the states to be a republic in form was seen as protecting the citizens' rights and preventing a state from becoming a dictatorship or monarchy, and reflected unwillingness on the part of the original 13 states (all independent republics) to unite with other states that were not republics. Additionally, this requirement ensured that only other republics could join the union.\n\nIn the example of the United States, the original 13 British colonies became independent states after the American Revolution, each having a republican form of government. These independent states initially formed a loose confederation called the United States and then later formed the current United States by ratifying the current U.S. Constitution, creating a union of sovereign states with the union or federal government also being a republic. Any state joining the union later was also required to be a republic.\n\nThe term \"republic\" originated from the writers of the Renaissance as a descriptive term for states that were not monarchies. These writers, such as Machiavelli, also wrote important prescriptive works describing how such governments should function. These ideas of how a government and society should be structured is the basis for an ideology known as classical republicanism or civic humanism. This ideology is based on the Roman Republic and the city states of Ancient Greece and focuses on ideals such as civic virtue, rule of law, and mixed government.\n\nThis understanding of a republic as a distinct form of government from a liberal democracy is one of the main theses of the Cambridge School of historical analysis. This grew out of the work of J. G. A. Pocock who in 1975 argued that a series of scholars had expressed a consistent set of republican ideals. These writers included Machiavelli, Milton, Montesquieu, and the founders of the United States of America.\n\nPocock argued that this was an ideology with a history and principles distinct from liberalism. These ideas were embraced by a number of different writers, including Quentin Skinner, Philip Pettit and Cass Sunstein. These subsequent writers have further explored the history of the idea, and also outlined how a modern republic should function.\n\nA distinct set of definitions for the word \"republic\" evolved in the United States. In common parlance, a republic is a state that does not practice direct democracy but rather has a government indirectly controlled by the people. This understanding of the term was originally developed by James Madison, and notably employed in Federalist Paper No. 10. This meaning was widely adopted early in the history of the United States, including in Noah Webster's dictionary of 1828. It was a novel meaning to the term; representative democracy was not an idea mentioned by Machiavelli and did not exist in the classical republics. Also, there is evidence that contemporaries of Madison considered the meaning of the word to reflect the definition found elsewhere, as is the case with a quotation of Benjamin Franklin taken from the notes of James McHenry where the question is put forth, \"a Republic or a Monarchy?\"\n\nThe term \"republic\" does not appear in the Declaration of Independence, but does appear in Article IV of the Constitution which \"guarantee[s] to every State in this Union a Republican form of Government.\" What exactly the writers of the constitution felt this should mean is uncertain. The Supreme Court, in \"Luther v. Borden\" (1849), declared that the definition of \"republic\" was a \"political question\" in which it would not intervene. In two later cases, it did establish a basic definition. In \"United States v. Cruikshank\" (1875), the court ruled that the \"equal rights of citizens\" were inherent to the idea of a republic.\n\nHowever, the term \"republic\" is not synonymous with the republican form. The republican form is defined as one in which the powers of sovereignty are vested in the people and are exercised by the people, either directly, or through representatives chosen by the people, to whom those powers are specially delegated. \"In re Duncan\", 139 U.S. 449, 11 S.Ct. 573, 35 L.Ed. 219; \"Minor v. Happersett\", 88 U.S. (21 Wall.) 162, 22 L.Ed. 627.\nBeyond these basic definitions the word \"republic\" has a number of other connotations. W. Paul Adams observes that \"republic\" is most often used in the United States as a synonym for state or government, but with more positive connotations than either of those terms. Republicanism is often referred to as the founding ideology of the United States. Traditionally scholars believed this American republicanism was a derivation of the classical liberal ideologies of John Locke and others developed in Europe.\n\nA political philosophy of republicanism that formed during the Renaissance period, and initiated by Machiavelli, was thought to have had little impact on the founders of the United States. In the 1960s and 1970s a revisionist school led by the likes of Bernard Bailyn began to argue that republicanism was just as or even more important than liberalism in the creation of the United States. This issue is still much disputed and scholars like Isaac Kramnick completely reject this view.\n\n\n• Thomas Corwin, Senate Speech Against the Mexican War-Congressional Globe 1847 \n\n"}
{"id": "25538", "url": "https://en.wikipedia.org/wiki?curid=25538", "title": "Robyn", "text": "Robyn\n\nRobin Miriam Carlsson (born 12 June 1979), known as Robyn, is a Swedish singer, songwriter and record producer. Robyn first came to the music scene with her 1995 debut album \"Robyn Is Here\" which spawned two \"Billboard\" Hot 100 top 10 hit singles; \"Do You Know (What It Takes)\" and \"Show Me Love\". Her second and third studio albums \"My Truth\" (1999) and \"Don't Stop the Music\" (2002) were only released in her native country. Robyn returned to international success with her fourth album \"Robyn\" (2005) which earned her critical acclaim and a Grammy Award nomination. The album spawned the hit singles; \"Be Mine!\" and the UK number one \"With Every Heartbeat\". In 2010 she released a trilogy consisting of three mini albums of the \"Body Talk\" series. The albums received widespread critical acclaim, three Grammy Award nominations and produced three top 10 hits; \"Dancing On My Own\", \"Hang with Me\" and \"Indestructible\". Robyn followed up with the release of two collab EPs; \"Do It Again\" (2014) and \"Love Is Free\" (2015).\n\nRobyn voiced the character of Miranda in the 1989 Swedish–Norwegian animated film \"The Journey to Melonia\". The film, directed by Per Åhlin, is very loosely based on William Shakespeare's \"The Tempest\". She also did the Swedish voice of Anne-Marie in All Dogs Go to Heaven . In 1991, at the age of 12, Robyn recorded the theme song for the Swedish television show \"Lilla Sportspegeln\", named \"\"Du kan alltid bli nummer ett\"\" (\"You Can Always be Number One\"). She performed her first self-written song at this age on another television show, \"Söndagsöppet\" (\"Sundays\"). Robyn was rediscovered by Swedish pop singer Meja in the early 1990s. Meja and her band Legacy of Sound visited Robyn's school and were involved with a musical workshop. Robyn's performances impressed Meja so much so that she contacted her management and a meeting was arranged with Robyn and her parents. At age 14, following the completion of her middle school education in 1993, Robyn signed with Ricochet Records Sweden (which was acquired by BMG in 1994). She collaborated with producers Max Martin and Denniz Pop, who provided the singer with a gritty yet popular sound. Ulf Lindstrom and Johan Ekhé assisted with writing duties, helped to produce the album, and stayed on board with Robyn until the completion of her album \"Don't Stop the Music\" in 2003.\n\nRobyn started her career in the pop music industry at the age of 16. She signed a record deal with RCA Records in 1994 to release her debut single, \"You've Got That Somethin'\", in Sweden. Later that same year, her Swedish breakthrough came with the single \"Do You Really Want Me (Show Respect)\". These singles became part of the album \"Robyn Is Here\", released in October 1995. Robyn contributed vocals to Blacknuss' 1996 single \"Roll with Me.\" She entered Sweden's pre-selection for the Eurovision Song Contest 1997, as co-writer and producer of the song \"Du gör mig hel igen\" (\"You Make Me Whole Again\"), which was performed by Cajsalisa Ejemyr. In Melodifestivalen 1997 the song ended up in fourth place.\n\nRobyn's US breakthrough came in late 1997, when the dance-pop singles \"Show Me Love\" and \"Do You Know (What It Takes)\" reached the top 10 on the \"Billboard\" Hot 100. She performed on the children's show \"All That\" in 1997, singing \"Show Me Love,\" proving her growing popularity in the US. The songs also performed well in the UK. Robyn re-released \"Do You Really Want Me (Show Respect)\" internationally but it did not fare as well as the other releases. In the US, it was ineligible to chart because there was no retail single available, but it reached number 32 on the Hot 100 Airplay chart. The song \"Show Me Love\" was used prominently in the 1998 Lukas Moodysson film \"Fucking Åmål\", and the song's title was used as the film's title in English-speaking countries. As Robyn's popularity grew across the globe, and especially in the US, she was diagnosed with exhaustion and returned to Sweden to recover.\n\nRobyn's second album, \"My Truth\", was released in Sweden in May 1999 with subsequent releases elsewhere in Europe. The single \"Electric\" was a hit and propelled \"My Truth\" to the number two position in Sweden. \"My Truth\"'s theme was autobiographical and included the tracks \"Universal Woman\" and \"Giving You Back\". Despite her success in the US market with \"Robyn Is Here\", \"My Truth\" was not released there. In 1999, Robyn contributed to Christian Falk's debut solo album \"Quel Bordel\" (\"What a Mess\"), appearing on the tracks \"Remember\" and \"Celebration\". In 2000, she appeared on the track \"Intro/Fristil\" on Petter's self-titled album. In 2001, Robyn performed the song \"Say You'll Walk the Distance\" for the soundtrack of the film \"On the Line\".\n\nIn July 2001, Robyn signed a worldwide deal with Jive Records moving from BMG after being \"disillusioned with the lack of artistic control\" she had there; a year later Jive was acquired by BMG when it bought Zomba Records. She later said \"I was back where I started!\" In November 2002, Robyn released the album \"Don't Stop the Music\" in Sweden. Singles \"Keep This Fire Burning\" and \"Don't Stop the Music\" graced playlists in Scandinavia and mainland Europe. The title track (a subsequent single) was later covered by Swedish girl group Play, and the lead single, \"Keep This Fire Burning,\" was covered by British soul singer Beverley Knight. In May 2004, the album \"Robyn's Best\" was released in the US. It was essentially a condensed version of her debut album containing no material from her later releases. In 2006, following her departure from BMG, \"Det Bästa Med Robyn\" (\"The Best of Robyn\") was released in Sweden. It included material from her first three albums. Notable omissions from this release were the singles \"Don't Stop the Music\" and \"Keep This Fire Burning\".\n\nThe decade-long relationship between Robyn and her label ceased in 2004. When they reacted negatively to \"Who's That Girl?\", which showcased a new electro-pop sound, Robyn decided to release music on her own. In early 2005, she announced she would be leaving Jive Records to start her own record label. Konichiwa Records was created, with its aim firmly set on liberating Robyn artistically. Robyn revealed on her website that her new album would be released earlier than anticipated, and noted several fabled collaborators on the album, including Klas Åhlund from Teddybears STHLM, Swedish duo The Knife and former Cheiron Studios producer Alexander Kronlund.\nRobyn released the single \"Be Mine!\" in March 2005. A month later, her fourth studio album, \"Robyn\", became her first number-one album upon its release in Sweden. Sampling influences from electronica, rap, R&B and new age, \"Robyn\" received rave reviews, and gained the singer three Swedish Grammy Awards in 2006 for \"Årets Album\" (Best Album), \"Årets Kompositör\" (Best Writer, alongside Klas Åhlund) and \"Årets Pop Kvinnlig\" (Best Pop Female). It also garnered Robyn interest on a global level. She gained recognition for co-writing the song \"Money for Nothing\" for Darin Zanyar, his debut single. Robyn released three more singles—\"Who's That Girl?\", \"Handle Me\" and \"Crash and Burn Girl\"—from the eponymous LP, which proved immensely popular in Sweden. Robyn featured on the Basement Jaxx track \"Hey U\", taken from their album \"Crazy Itch Radio\", released in 2006. The year also marked the release of Christian Falk's second album, \"People Say\", on which Robyn contributed the tracks \"Dream On\" and \"C.C.C\". In December 2006, Robyn released \"The Rakamonie EP\" in the UK as a preview to her more recent material. This was followed by the release of \"Konichiwa Bitches\" in March 2007. The revised edition of \"Robyn\" was released in the UK in April 2007, and contains two new tracks—\"With Every Heartbeat\" (a collaboration with Kleerup) and \"Cobrastyle\" (a cover of a 2006 single by Swedish rockers Teddybears)—alongside slightly altered versions of two of the original music. It was removed from British stores to make way for an August re-release.\n\nThe second single from the UK release was \"With Every Heartbeat\", released in late July and reached number one on the UK singles chart. Robyn was featured on Jo Whiley's BBC Radio 1 showcase show, \"Live Lounge\", a reflection of her growing popularity in Britain. Follow-up singles \"Handle Me\", \"Be Mine!\", \"Who's That Girl?\" and \"Dream On\" were top thirty hits. In Australia, where \"Robyn\" reached the top ten of the iTunes Store's album chart, \"With Every Heartbeat\" receiving substantial attention on radio and video networks in Australia. Also in 2007, Robyn contributed vocals to Fleshquartet's single \"This One's for You\", from their album \"Voices of Eden\". Konichiwa Records signed an international licensing deal with Universal Music Group to launch and distribute Robyn's music globally. Releases in the UK are issued under the Island Records label. \"The Rakamonie EP\" was released in January 2008 under Cherrytree Records, a subsidiary of Interscope, and the US edition of \"Robyn\" was released in April 2008. \"With Every Heartbeat\", \"Handle Me\" and \"Cobrastyle\" were top ten club hits, and the former received airplay at US pop and dance radio stations. Robyn was visible in the US market in 2007 when Britney Spears released the single \"Piece of Me\", which contains Robyn's backing vocals. She was also featured on the Fyre Department remix of \"Sexual Eruption\" by rapper Snoop Dogg. Robyn completed a short US tour to promote \"Robyn\", and was the supporting act for Madonna's Sticky & Sweet Tour at select European dates in 2008. In January 2009, Robyn won a Swedish Grammis Award for Best Live Act 2008.\n\nShe released the first album of the \"Body Talk\" trilogy, \"Body Talk Pt. 1\", on 14 June 2010 in the Nordic countries on EMI and on 15 June in the US on Interscope Records. The album was preceded by the single \"Dancing on My Own\" on 1 June 2010. It was Robyn's first number-one hit in Sweden and her fourth top-ten hit in the UK and the US, peaking at number eight on the UK Singles Chart and number three on \"Billboard\"'s Hot Dance Club Songs chart. In July 2010 she sang a minimalist, electro cover version of Alicia Keys' \"Try Sleeping with a Broken Heart\" in a live performance on iheartradio. Robyn made the All Hearts Tour in July–August 2010 with American singer Kelis to promote the \"Body Talk\" albums, and a four-date UK tour at the end of October.\nOn 6 September 2010, \"Body Talk Pt. 2\" was released in the UK. It was preceded by the lead single, a dance version of \"Hang with Me\" from \"Body Talk Pt. 1\", on 5 September. The album includes a duet with American rapper Snoop Dogg, \"U Should Know Better\". Robyn performed \"Dancing on My Own\" with deadmau5 at the 2010 MTV Video Music Awards on 12 September. In a BBC \"Newsbeat\" interview, Robyn explained her decision to release three albums in one year: \"It was just something I felt like I needed to do. I just never thought about selling records or not, making this decision. I just did it for myself. It's a way of, for me, to stay inspired and to be able to do the things I like to do\". She said that she would not do it again: \"When you do 16 or 13 songs in one go, you kind of empty yourself, and it takes a while to fill back up and have new things to talk about, so I think it's good for everyone\". Robyn announced the release of the single, \"Indestructible\", on 13 October 2010; an acoustic version appeared on \"Body Talk Pt. 2\". The song was released on 17 November in Scandinavia and 22 November in the UK. Co-written by Klas Åhlund, it was described as a \"pulsating full power version [that] takes every ounce of that emotion and wraps it up in another exceptional disco-pop record worthy of any dance-floor or passion-laden sing-a-long.\" Robyn planned to collaborate with Swedish producer Max Martin on the song, \"Time Machine\"; Martin produced Robyn's US hits \"Do You Know (What It Takes)\" and \"Show Me Love\", both of which peaked in the top 10 on the \"Billboard\" 100 in 1997. Combined, the \"Body Talk\" albums have sold 91,000 copies in the US\n\nIn 2010 Robyn guest-starred on \"War at the Roses\", an episode of \"Gossip Girl\", in which she performed the acoustic version of \"Hang With Me\". \"Dancing on My Own\" was also featured at the end of the episode. In November, she said she would return to the studio in January 2011 with enough material to release a new album later that year. Robyn supported Coldplay on their 2012 tour as the opening act in Dallas, Houston, Tampa, Miami, Atlanta, Charlotte, Philadelphia and Washington, D.C. In mid-2013, Robyn appeared with Paul Rudd and Sean Combs in \"Go Kindergarten\" on the Lonely Island's \"The Wack Album\". On 21 and 22 June 2013, Robyn posted two videos of the Snoop Dogg collaboration: \"U Should Know Better\" and \"Behind The Scenes\", and a game, Mixory. That year she received the Stockholm KTH Royal Institute of Technology Great Prize for \"artistic contributions and embrace of technology\", a prize of 1.2 million Swedish kronor (£117,197), which she planned to donate to a cause of her choice.\n\nIn 2014 Robyn sang on Neneh Cherry's \"Out of the Black\" from her album, \"Blank Project\". In 2014 Robyn announced the Do It Again Tour with Röyksopp and a collaborative mini-album, \"Do It Again\". The tour ended prematurely upon the death of Robyn's longtime friend and collaborator, Christian Falk. An EP of their final collaboration, \"Love Is Free\", was released soon after. In 2015 Robyn appeared at the Popaganda Festival in Sweden performing songs written with Falk, but announced that subsequent performances would have to wait because she was still grieving.\n\nIn May 2016 Robyn debuted a continuous dance set of remixed versions of her songs at the Boston Calling Music Festival, with plans for more dates throughout the year.\nIn November 2016, she released another collaboration EP, this time with Mr. Tophat called \"Trust Me\".\n\nIn 2017 she worked on a track from Todd Rundgren's new album \"White Knight\".\n\nRobyn's parents helmed an independent theatre group; growing up in that environment had a strong influence on her sense of style. \"I was around people who dressed up for work every day, and so the concept of how you can use clothes to change your personality or communicate who you are is very interesting to me.\" \n\nRobyn started dating Olof Inger in 2003, and they were engaged until 2011.\nShe has since become engaged to videographer Max Vitali, referring to him in a 2013 interview with \"Collection of Style\" magazine as her fiancé: \"We became friends when we made the video for 'Be Mine', and now we work together a lot. He made all the videos for the last album [\"Body Talk\"].\" Robyn has two younger siblings, Jac and Effie.\n\n\n\n"}
{"id": "25540", "url": "https://en.wikipedia.org/wiki?curid=25540", "title": "Request for Comments", "text": "Request for Comments\n\nA Request for Comments (RFC) is a type of publication from the Internet Engineering Task Force (IETF) and the Internet Society (ISOC), the principal technical development and standards-setting bodies for the Internet.\n\nAn RFC is authored by engineers and computer scientists in the form of a memorandum describing methods, behaviors, research, or innovations applicable to the working of the Internet and Internet-connected systems. It is submitted either for peer review or simply to convey new concepts, information, or (occasionally) engineering humor. The IETF adopts some of the proposals published as RFCs as Internet Standards.\n\nRequest for Comments documents were invented by Steve Crocker in 1969 to help record unofficial notes on the development of ARPANET. RFCs have since become official documents of Internet specifications, communications protocols, procedures, and events.\n\nThe inception of the RFC format occurred in 1969 as part of the seminal ARPANET project. Today, it is the official publication channel for the Internet Engineering Task Force (IETF), the Internet Architecture Board (IAB), and to some extent the global community of computer network researchers in general.\n\nThe authors of the first RFCs typewrote their work and circulated hard copies among the ARPA researchers. Unlike the modern RFCs, many of the early RFCs were actual requests for comments and were titled as such to avoid sounding too declarative and to encourage discussion. The RFC leaves questions open and is written in a less formal style. This less formal style is now typical of Internet Draft documents, the precursor step before being approved as an RFC.\n\nIn December 1969, researchers began distributing new RFCs via the newly operational ARPANET. RFC 1, entitled \"Host Software\", was written by Steve Crocker of the University of California, Los Angeles (UCLA), and published on April 7, 1969. Although written by Steve Crocker, the RFC emerged from an early working group discussion between Steve Crocker, Steve Carr and Jeff Rulifson.\n\nIn RFC 3, which first defined the RFC series, Crocker started attributing the RFC series to the Network Working Group. Rather than being a formal committee, it was a loose association of researchers interested in the ARPANET project. In effect, it included anyone who wanted to join the meetings and discussions about the project.\n\nMany of the subsequent RFCs of the 1970s also came from UCLA, because UCLA was one of the first Interface Message Processors (IMPs) on ARPANET.\nThe Augmentation Research Center (ARC) at Stanford Research Institute, directed by Douglas Engelbart, was another of the four first ARPANET nodes and the source of early RFCs.\nThe ARC became the first network information center (InterNIC), which was managed by Elizabeth J. Feinler to distribute the RFCs along with other network information. From 1969 until 1998, Jon Postel served as the RFC editor. On his death in 1998, his obituary was published as RFC 2468.\n\nFollowing the expiration of the original ARPANET contract with the U.S. federal government, the Internet Society, acting on behalf of the IETF, contracted with the Networking Division of the University of Southern California (USC) Information Sciences Institute (ISI) to assume the editorship and publishing responsibilities under the direction of the IAB. \nSandy Ginoza joined USC/ISI in 1999 to work on RFC editing, and Alice Hagens in 2005.\nBob Braden took over the role of RFC project lead, while Joyce K. Reynolds continued to be part of the team until October 13, 2006.\n\nIn July 2007, \"streams\" of RFCs were defined, so that the editing duties could be divided. IETF documents came from IETF working groups or submissions sponsored by an IETF area director from the Internet Engineering Steering Group. The IAB can publish its own documents. A research stream of documents comes from the Internet Research Task Force (IRTF), and an independent stream from other outside sources.\nA new model was proposed in 2008, refined, and published in August 2009, splitting the task into several roles,\nincluding the RFC Series Advisory Group (RSAG). The model was updated in 2012.\nThe streams were also refined in December 2009, with standards defined for their style.\nIn January 2010 the RFC editor function was moved to a contractor, Association Management Solutions, with Glenn Kowack serving as interim series editor.\nIn late 2011, Heather Flanagan was hired as the permanent RFC Series Editor.\nAlso at that time, an RFC Series Oversight Committee (RSOC) was created.\n\nThe RFC Editor assigns each RFC a serial number. Once assigned a number and published, an RFC is never rescinded or modified; if the document requires amendments, the authors publish a revised document. Therefore, some RFCs supersede others; the superseded RFCs are said to be \"deprecated\", \"obsolete\", or \"obsoleted by\" the superseding RFC. Together, the serialized RFCs compose a continuous historical record of the evolution of Internet standards and practices. The RFC process is documented in RFC 2026 (\"The Internet Standards Process, Revision 3\")\n\nThe RFC production process differs from the standardization process of formal standards organizations such as ISO. Internet technology experts may submit an Internet Draft without support from an external institution. Standards-track RFCs are published with approval from the IETF, and are usually produced by experts participating in working groups, which first publish an Internet Draft. This approach facilitates initial rounds of peer review before documents mature into RFCs.\n\nThe RFC tradition of pragmatic, experience-driven, after-the-fact standards authorship accomplished by individuals or small working groups can have important advantages over the more formal, committee-driven process typical of ISO and national standards bodies.\n\nMost RFCs use a common set of terms such as \"MUST\" and \"NOT RECOMMENDED\" (as defined by RFC 2119), augmented Backus–Naur form (ABNF) (RFC 5234) as a meta-language, and simple text-based formatting, in order to keep the RFCs consistent and easy to understand.\n\nThe RFC series contains three sub-series for IETF RFCs:\n\nThere are four streams of RFCs: (1) IETF, (2) IRTF, (3) IAB, and (4) \"independent submission\". Only the IETF creates BCPs and RFCs on standards track. An \"independent submission\" is checked by the IESG for conflicts with IETF work; the quality is assessed by an \"independent submission editorial board\". In other words, IRTF and \"independent \" RFCs are supposed to contain relevant info or experiments for the Internet at large not in conflict with IETF work; compare RFC 4846, RFC 5742, and RFC 5744.\n\nThe official source for RFCs on the World Wide Web is the RFC Editor. Almost any published RFC can be retrieved via a URL of the form <nowiki>http://www.rfc-editor.org/rfc/rfc5000.txt</nowiki>, shown for RFC 5000.\n\nEvery RFC is submitted as plain ASCII text and is published in that form, but may also be available in other formats.\n\nFor easy access to the metadata of an RFC, including abstract, keywords, author(s), publication date, errata, status, and especially later updates, the RFC Editor site offers a search form with many features. A redirection sets some efficient parameters, example: .\n\nThe official International Standard Serial Number (ISSN) of the RFC series is 2070-1721.\n\nNot all RFCs are standards. Each RFC is assigned a designation with regard to status within the Internet standardization process. This status is one of the following: \"Informational\", \"Experimental\", \"Best Current Practice\", \"Standards Track\", or \"Historic\".\n\nEach RFC is static; if the document is changed, it is submitted again and assigned a new RFC number.\n\nStandards-track documents are further divided into \"Proposed Standard\", \"Draft Standard\", and \"Internet Standard\" documents.\n\nOnly the IETF, represented by the Internet Engineering Steering Group (IESG), can approve standards-track RFCs.\n\nIf an RFC becomes an Internet Standard (STD), it is assigned an STD number but retains its RFC number. The definitive list of Internet Standards is the Official Internet Protocol Standards. Previously STD 1 used to maintain a snapshot of the list.\n\nWhen an Internet Standard is updated, its STD number stays the same, now referring to a new RFC or set of RFCs. A given Internet Standard, STD \"n\", may be RFCs \"x\" and \"y\" at a given time, but later the same standard may be updated to be RFC \"z\" instead. For example, in 2007 RFC 3700 was an Internet Standard—STD 1—and in May 2008 it was replaced with RFC 5000, so RFC 3700 changed to \"Historic\", RFC 5000 became an Internet Standard, and STD 1 is RFC 5000.\n\n(Best Current Practices work in a similar fashion; BCP \"n\" refers to a certain RFC or set of RFCs, but which RFC or RFCs may change over time).\n\nAn \"informational\" RFC can be nearly anything from April 1 jokes to widely recognized essential RFCs like Domain Name System Structure and Delegation (RFC 1591). Some informational RFCs formed the FYI sub-series.\n\nAn \"experimental\" RFC can be an IETF document or an individual submission to the 'RFC Editor'. A draft is designated experimental if it is unclear the proposal will work as intended or unclear if the proposal will be widely adopted. An experimental RFC may be promoted to standards track if it becomes popular and works well.\n\nThe Best Current Practice subseries collects administrative documents and other texts which are considered as official rules and not only \"informational\", but which do not affect \"over the wire data\". The border between standards track and BCP is often unclear. If a document only affects the Internet Standards Process, like BCP 9, or IETF administration, it is clearly a BCP. If it only defines rules and regulations for Internet Assigned Numbers Authority (IANA) registries it is less clear; most of these documents are BCPs, but some are on the standards track.\n\nThe BCP series also covers technical recommendations for how to practice Internet standards; for instance the recommendation to use source filtering to make DoS attacks more difficult (RFC 2827: \"\"Network Ingress Filtering: Defeating Denial of Service Attacks which employ IP Source Address Spoofing\"\") is BCP 38.\n\nA \"historic\" RFC is one that the technology defined by the RFC is no longer recommended for use, which differs from \"Obsoletes\" header in a replacement RFC. For example, RFC 821 (SMTP) itself is obsoleted by various newer RFCs, but SMTP itself is still \"current technology\", so it is not in \"Historic\" status. On the other hand, since BGP version 4 has entirely superseded earlier BGP versions, the RFCs describing those earlier versions (e.g. RFC 1267) have been designated historic.\n\nStatus \"unknown\" is used for some very old RFCs, where it is unclear which status the document would get if it were published today. Some of these RFCs would not be published at all today; an early RFC was often just that: a simple request for comments, not intended to specify a protocol, administrative procedure, or anything else for which the RFC series is used today.\n\n\n"}
{"id": "25596", "url": "https://en.wikipedia.org/wiki?curid=25596", "title": "Ragga", "text": "Ragga\n\nRaggamuffin music, usually abbreviated as ragga, is a subgenre of dancehall and reggae music, in which the instrumentation primarily consists of electronic music. Similar to hip hop, sampling often serves a prominent role in raggamuffin music.\n\nIn the mid-1980s, French Antilles Kassav, the first in the Caribbean to use MIDI technology, took Caribbean music to another level by recording in a digital format. Wayne Smith's \"Under Mi Sleng Teng\" was produced by King Jammy in 1985 on a Casio MT-40 synthesizer and is generally recognized as the seminal ragga song. \"Sleng Teng\" boosted Jammy's popularity immensely, and other producers quickly released their own versions of the riddim, accompanied by dozens of different vocalists.\n\nRagga is now mainly used as a synonym for dancehall reggae or for describing dancehall with a deejay chatting rather than singjaying or singing on top of the riddim.\n\nRagga originated in Jamaica during the 1980s, at the same time that electronic dance music's popularity was increasing globally. One of the reasons for ragga's swift propagation is that it is generally easier and less expensive to produce than reggae performed on traditional musical instruments. Ragga evolved first in Jamaica, and later in Europe, North America, and Africa, eventually spreading to Japan, India, and the rest of the world. Ragga heavily influenced early jungle music, and also spawned the syncretistic bhangragga style when fused with bhangra. In the 1990s, ragga and breakcore music fused, creating a style known as raggacore.\n\nThe term \"raggamuffin\" is an intentional misspelling of \"ragamuffin\", a word that entered the Jamaican Patois lexicon after the British Empire colonized Jamaica in the 17th century. Despite the British colonialists' pejorative application of the term, Jamaican youth appropriated it as an ingroup designation. The term \"raggamuffin music\" describes the music of Jamaica's \"ghetto dwellers\".\n\nIn the late 1980s, influential Jamaican rapper Daddy Freddy's pioneering efforts in fusing ragga with hip hop music earned him international acclaim while helping to publicize and popularize ragga. In 1987, Daddy Freddy and Asher D's \"Ragamuffin Hip-Hop\" became the first multinational single to feature the word \"ragga\" in its title. In 1992, Canadian hip hop group Rascalz released their debut album under the name Ragga Muffin Rascals. As ragga matured, an increasing number of dancehall artists began to appropriate stylistic elements of hip hop music, while ragga music, in turn, influenced more and more hip hop artists, most notably KRS-One, the Boot Camp Clik, Das EFX, Busta Rhymes, as well as some artists with ragga-influenced styles, like early Common, Main Source, Ill Al Scratch, Fu-Schnickens, and Redman. Artists like Mad Lion grew in popularity during this early 90's trend, exemplified by his crossing from reggae to hip-hop culture.\n\nSome ragga artists believe that the assimilation of hip hop sensibilities is crucial to the international marketability of dancehall music. Indeed, the appeal to the contemporary rhythm and blues and hip hop music audiences in the English-speaking world contributed substantially to the multinational commercial success of such dancehall artists as:\n\n\n"}
{"id": "25597", "url": "https://en.wikipedia.org/wiki?curid=25597", "title": "Religious conversion", "text": "Religious conversion\n\nReligious conversion is the adoption of a set of beliefs identified with one particular religious denomination to the exclusion of others. Thus \"religious conversion\" would describe the abandoning of adherence to one denomination and affiliating with another. This might be from one to another denomination within the same religion, for example, from Baptist to Catholic Christianity or from Sunni to Shi'a Islam. In some cases, religious conversion \"marks a transformation of religious identity and is symbolized by special rituals\".\n\nPeople convert to a different religion for various reasons, including: active conversion by free choice due to a change in beliefs, secondary conversion, deathbed conversion, conversion for convenience, marital conversion, and forced conversion.\n\nConversion or reaffiliation for convenience is an insincere act, sometimes for relatively trivial reasons such as a parent converting to enable a child to be admitted to a good school associated with a religion, or a person adopting a religion more in keeping with the social class they aspire to. When people marry one spouse may convert to the religion of the other.\n\nForced conversion is adoption of a different religion under duress. The convert may secretly retain the previous beliefs and continue, covertly, with the practices of the original religion, while outwardly maintaining the forms of the new religion. Over generations a family forced against their will to convert may wholeheartedly adopt the new religion.\n\n\"Proselytism\" is the act of attempting to convert by persuasion another individual from a different religion or belief system. (See proselyte).\n\nApostate is a term used by members of a religion or denomination to refer to someone who has left that religion or denomination.\n\nJewish law has a number of requirements of potential converts. They should desire conversion to Judaism for its own sake, and for no other motives. A male convert needs to undergo a ritual circumcision conducted according to Jewish law (if already circumcised, a needle is used to draw a symbolic drop of blood while the appropriate blessings are said), and the convert must commit to observe Jewish law. A convert must join the Jewish community and reject any previous religious affiliation. Ritual immersion in a small pool of water known as a \"mikvah\" is required.\n\nThe Greek word \"proselyte\" means a convert to Judaism. It is known that some Chinese, Khazars, Edomites, and Ethiopians, as well as many Arabs, particularly in Yemen, were converts. As late as the 6th century the Eastern Roman empire and Caliph Umar ibn Khattab were issuing decrees against conversion to Judaism, implying that this was still occurring.\n\nWithin Christianity 'conversion' refers variously to three different phenomena: a person becoming Christian who was previously not Christian; a Christian moving from one Christian denomination to another; a particular spiritual development, sometimes called the second conversion, or the conversion of the baptised.\n\nConversion to Christianity is the religious conversion of a previously non-Christian person to some form of Christianity. Some Christian sects require full conversion for new members regardless of any history in other Christian sects, or from certain other sects. The exact requirements vary between different churches and denominations. All Christian sects hold that baptism is a necessary ritual, but the practice differs. Jesus Christ was baptized at the beginning of his ministry, and prior to that event, John the Baptist had been baptizing Jewish believers as a sign of repentance, though not of conversion per se. Baptism is usually understood as an outward symbol of an inward change. Prior to that Awakening at Antioch (Acts ch.8 ff; see also Acts 2:38), all converts to Christianity were ethnic and religious Jews. Following the Awakening, Pagans and infidels were required to undergo Christian baptism to be ultimately accepted in the Kingdom of God. Christian Baptism has some parallels with Jewish Immersion by Mikvah.\n\nConverting to Catholicism involves religious education followed by initial participation in the sacraments, which are baptism, confession, penance, and communion. In general, conversion to Christian Faith primarily involves repentance for sin and a decision to live a life that is holy and acceptable to God through faith in the atoning death and resurrection of Jesus Christ. Most other sects require a period of indoctrination prior to acceptance. All of this is essentially done through a voluntary exercise of the will of the individual concerned. True conversion to Christianity is thus a personal, internal matter and cannot be forced.\n\nChristians consider that conversion requires internalization of the new belief system. It implies a new reference point for the convert's self-identity, and is a matter of belief and social structure—of both faith and affiliation. This typically entails the sincere avowal of a new belief system, but may also present itself in other ways, such as adoption into an identity group or spiritual lineage.\n\nCatholics, and Orthodox denominations encourage infant baptism before children are aware of their status. In Roman Catholicism and certain high church forms of Protestantism, baptized children are expected to participate in confirmation classes as pre-teens. In Eastern Orthodoxy, the equivalent of confirmation, chrismation, is administered to all converts, adult and infant alike, immediately after baptism.\n\nMethods of baptism include immersion, sprinkling (aspersion) and pouring (affusion). Baptism received by adults or younger people who have reached the age of accountability where they can make a personal religious decision is referred to as believer's baptism among conservative or evangelical Protestant groups.\nIt is intended as a public statement of a person's prior decision to become a Christian. Some Christian groups such as Catholics, Churches of Christ, and Christadelphians believe baptism is essential to salvation.\n\n \"Conversion\" derives from the Latin \"conversiōn-em\", literally meaning \"turning round\" and figuratively meaning a \"change in character\". \"Change of heart\", \"metanoia\", and \"regeneration\" are among the synonyms for conversion. Conversion is, therefore, more than a mere change in religious identity, but a change in nature (regeneration), evidenced by a change in values. Jesus demands \"\"metánoia\" (conversion)\" to become a good tree that bears good fruit (, ).\n\nAccording to Christianity, a convert renounces sin as worthless and treasures instead the supreme worth of Christ in Jesus' sacrificial death and resurrection.\nChristian conversion is a \"deeply personal\" matter. It entails changes in thinking, priorities and commitments: \"a whole new direction in one's life\".\n\nBecause conversion is a change in values that embraces God and rejects sin, it includes a personal commitment to a life of holiness as described by Paul of Tarsus and exemplified by Jesus. In some Protestant traditions, this is called \"accepting Christ as one's Savior and following him as Lord.\" In another variation, the 1910 Catholic Dictionary defines \"conversion\" as \"Any turning or changing from a state of sin to repentance, from a lax to a fervent way of life, from unbelief to faith, and from a non-Christian religion to Christianity.\" The Eastern Orthodox understanding of conversion is illustrated in the rite of baptism, in which the convert faces west while publicly renouncing and symbolically spitting upon Satan, and then turns to the east to worship Christ \"as king and God\".\n\nTransferring from one Christian denomination to another may consist of a relatively simple transfer of membership, especially if moving from one Trinitarian denomination to another, and if the person has received water baptism in the name of the Trinity. If not, then the person may be required to be baptized or rebaptized before acceptance by the new church. Some denominations, such as those in the Anabaptist tradition, require previously baptized Christians to be re-baptized. The Eastern Orthodox Church treats a transfer from another denomination of Christianity to Orthodoxy (conceived of as the one true Church) as a category of conversion and repentance, though re-baptism is not always required.\n\nThe process of conversion to Christianity varies somewhat among Christian denominations. Most Protestants believe in conversion by \"faith\" to attain salvation. According to this understanding, a person professes faith in Jesus Christ as God, their Lord and savior. Repentance for sin and a holy living are expected of those professing faith in Jesus Christ. While an individual may make such a decision privately, usually it entails being baptized and becoming a member of a denomination or church. In these traditions, a person is considered to become a Christian by publicly acknowledging the foundational Christian doctrines that Jesus Christ died, was buried, and was resurrected for the remission of sins.\n\nThis table summarizes three Protestant beliefs.\nMuch of the theology of Latter Day Saint baptism was established during the early Latter Day Saint movement founded by Joseph Smith. According to this theology, baptism must be by immersion, for the remission of sins (meaning that through baptism, past sins are forgiven), and occurs after one has shown faith and repentance. Mormon baptism does not purport to remit any sins other than personal ones, as adherents do not believe in original sin. Latter Day Saints baptisms also occur only after an \"age of accountability\" which is defined as the age of eight years. The theology thus rejects infant baptism.\n\nIn addition, Latter Day Saint theology requires that baptism may only be performed with one who has been called and ordained by God with priesthood authority. Because the churches of the Latter Day Saint movement operate under a lay priesthood, children raised in a Mormon family are usually baptized by a father or close male friend or family member who has achieved the office of priest, which is conferred upon worthy male members at least 16 years old in the LDS Church.\n\nBaptism is seen as symbolic both of Jesus' death, burial and resurrection and is also symbolic of the baptized individual putting off of the natural or sinful man and becoming spiritually reborn as a disciple of Jesus.\n\nMembership into a Latter Day Saint church is granted only by baptism whether or not a person has been raised in the church. Latter Day Saint churches do not recognize baptisms of other faiths as valid because they believe baptisms must be performed under the church's unique authority. Thus, all who come into one of the Latter Day Saint faiths as converts are baptized, even if they have previously received baptism in another faith.\n\nWhen performing a Baptism, Latter Day Saints say the following prayer before performing the ordinance:\n\nBaptisms inside and outside the temples are usually done in a baptistry, although they can be performed in any body of water in which the person may be completely immersed. The person administering the baptism must recite the prayer exactly, and immerse every part, limb, hair and clothing of the person being baptized. If there are any mistakes, or if any part of the person being baptized is not fully immersed, the baptism must be redone. In addition to the baptizer, two priesthood holders witness the baptism to ensure that it is performed properly.\n\nFollowing baptism, Latter Day Saints receive the Gift of the Holy Ghost by the laying on of hands of a Melchizedek Priesthood holder.\n\nLatter Day Saints hold that one may be baptized after death through the vicarious act of a living individual, and holders of the Melchezidek Priesthood practice baptism for the dead as a missionary ritual. This doctrine answers the question of the righteous non-believer and the unevangelized by providing a post-mortem means of repentance and salvation.\n\nThere are five pillars, or foundations, of Islam but the primary, and most important is to believe that there is only one God and creator, referred to as Allah (the word for God in Arabic) and that the Islamic prophet, Muhammad, is God's final messenger. The time of a person's conversion is counted from the moment they sincerely make this \"declaration of faith\", called the shahadah in front of witnesses.\n\nIslam teaches that everyone is Muslim at birth because every child that is born has a natural inclination to goodness and to worship the one true God alone, but the parents or society can cause them to deviate from the straight path. When someone accepts Islam, they are considered to revert to the original condition. In Islam, circumcision is a \"Sunnah\" custom not mentioned in the Qur'an. The majority clerical opinion holds that circumcision is not a condition for entering Islam. The Shafi`i and Hanbali schools regard it as obligatory, while the Maliki and Hanafi schools regard it as only recommended. However, it is not a precondition for the acceptance of a person's Islamic practices, nor is choosing to forgo circumcision considered a sin. It is not one of the Five Pillars of Islam.\n\nIn sharing their faith with others, Bahá'ís are cautioned to \"obtain a hearing\" – meaning to make sure the person they are proposing to teach is open to hearing what they have to say. \"Bahá'í pioneers\", rather than attempting to supplant the cultural underpinnings of the people in their adopted communities, are encouraged to integrate into the society and apply Bahá'í principles in living and working with their neighbors.\n\nBahá'ís recognize the divine origins of all revealed religion, and believe that these religions occurred sequentially as part of a Divine plan (see Progressive revelation), with each new revelation superseding and fulfilling that of its predecessors. Bahá'ís regard their own faith as the most recent (but not the last), and believe its teachings – which are centered around the principle of the oneness of humanity – are most suited to meeting the needs of a global community.\n\nIn most countries conversion is a simple matter of filling out a card stating a declaration of belief. This includes acknowledgement of Bahá'u'llah – the Founder of the Faith – as the Messenger of God for this age, awareness and acceptance of His teachings, and intention to be obedient to the institutions and laws He established.\n\nConversion to the Bahá'í Faith carries with it an explicit belief in the common foundation of all revealed religion, a commitment to the unity of mankind, and active service to the community at large, especially in areas that will foster unity and concord. Since the Bahá'í Faith has no clergy, converts to this Faith are encouraged to be active in all aspects of community life. Even a recent convert may be elected to serve on a Local Spiritual Assembly – the guiding Bahá'í institution at the community level.\n\nSince 1800 CE, religious conversion from and to Hinduism has been a controversial subject within Hinduism. Some have suggested that the concept of missionary conversion, either way, is contrary to the precepts of Hinduism. Religious leaders of some of Hinduism sects such as Brahmo Samaj have seen Hinduism as a non-missionary religion yet welcomed new members, while other leaders of Hinduism's diverse schools have stated that with the arrival of missionary Islam and Christianity in India, this \"there is no such thing as proselytism in Hinduism\" view must be re-examined.\n\nHinduism is a diverse system of thought with beliefs spanning monotheism, polytheism, panentheism, pantheism, pandeism, monism, and atheism among others. Hinduism has no traditional ecclesiastical order, no centralized religious authorities, no universally accepted governing body, no prophet(s), no binding holy book nor any mandatory prayer attendance requirements. Hinduism has been described as a way of life. In its diffuse and open structure, numerous schools and sects of Hinduism have developed and spun off in India with help from its ascetic scholars, since the Vedic age. The six Astika and two Nastika schools of Hindu philosophy, in its history, did not develop a missionary or proselytization methodology, and they co-existed with each other. Most Hindu sub-schools and sects do not actively seek converts. Individuals have had a choice to enter, leave or change their god(s), spiritual convictions, accept or discard any rituals and practices, and pursue spiritual knowledge and liberation (moksha) in different ways. However, various schools of Hinduism do have some core common beliefs, such as the belief that all living beings have Atman (soul), a belief in karma theory, spirituality, ahimsa (non-violence) as the greatest dharma or virtue, and others.\n\nReligious conversion to Hinduism has a long history outside India. Merchants and traders of India, particularly from Indian peninsula, carried their religious ideas, which led to religious conversions to Hinduism in Indonesia, Vietnam, Cambodia and Burma. Some sects of Hindus, particularly of the Bhakti schools began seeking or accepting converts in early to mid 20th century. For example, Arya Samaj, Saiva Siddhanta Church, BAPS, and the International Society for Krishna Consciousness accept those who have a desire to follow their sects of Hinduism, and each has their own religious conversion procedure.\n\nIn recent decades, mainstream Hinduism schools have attempted to systematize ways to accept religious converts, with an increase in inter-religious mixed marriages. The steps involved in becoming a Hindu have variously included a period where the interested person gets an informal \"ardha-Hindu\" name and studies ancient literature on spiritual path and practices (English translations of Upanishads, Agamas, Epics, ethics in Sutras, festivals, yoga). If after a period of study, the individual still wants to convert, a \"Namakarana Samskaras\" ceremony is held, where the individual adopts a traditional Hindu name. The initiation ceremony may also include \"Yajna\" (i.e., fire ritual with Sanskrit hymns) under guidance of a local Hindu priest. Some of these places are \"mathas\" and \"asramas\" (hermitage, monastery), where one or more \"gurus\" (spiritual guide) conduct the conversion and offer spiritual discussions. Some schools encourage the new convert to learn and participate in community activities such as festivals (Diwali etc.), read and discuss ancient literature, learn and engage in rites of passages (ceremonies of birth, first feeding, first learning day, age of majority, wedding, cremation and others).\n\nSikhism is not known to openly proselytize, but accepts converts.\n\nJainism accepts anyone who wants to embrace the religion. There is no specific ritual for becoming a Jain. One does not need to ask any authorities for admission. One becomes a Jain on one's own by observing the five vows (\"vratas\") The five main vows as mentioned in the ancient Jain texts like Tattvarthasutra are:\n\nFollowing the five vows is the main requirement in Jainism. All other aspects such as visiting temples are secondary. Jain monks and nuns are required to observe these five vows strictly.\nPersons newly adhering to Buddhism traditionally \"take Refuge\" (express faith in the Three Jewels—Buddha, Dharma, and Sangha) before a monk, nun, or similar representative. But cultural or secular Buddhists often hold multiple religious identities, combining the religion with some East Asian religions in different countries and ethnics, such as:\n\nThroughout the timeline of Buddhism, conversions of entire countries and regions to Buddhism were frequent, as Buddhism spread throughout Asia. For example, in the 11th century in Burma, king Anoratha converted his entire country to Theravada Buddhism. At the end of the 12th century, Jayavarman VII set the stage for conversion of the Khmer people to Theravada Buddhism. Mass conversions of areas and communities to Buddhism occur up to the present day, for example, in the Dalit Buddhist movement in India there have been organized mass conversions.\n\nExceptions to encouraging conversion may occur in some Buddhist movements. In Tibetan Buddhism, for example, the current Dalai Lama discourages active attempts to win converts.\n\nIn the second half of the 20th century, the rapid growth of new religious movements (NRMs) led some psychologists and other scholars to propose that these groups were using \"brainwashing\" or \"mind control\" techniques to gain converts. This theory was publicized by the popular news media but disputed by other scholars, including some sociologists of religion.\n\nIn the 1960s sociologist John Lofland lived with Unification Church missionary Young Oon Kim and a small group of American church members in California and studied their activities in trying to promote their beliefs and win converts to their church. Lofland noted that most of their efforts were ineffective and that most of the people who joined did so because of personal relationships with other members, often family relationships. Lofland published his findings in 1964 as a doctoral thesis entitled \"The World Savers: A Field Study of Cult Processes\", and in 1966 in book form by Prentice-Hall as \"\". It is considered to be one of the most important and widely cited studies of the process of religious conversion, and one of the first modern sociological studies of a new religious movement.\n\nThe Church of Scientology attempts to gain converts by offering \"free stress tests\". It has also used the celebrity status of some of its members (most famously the American actor Tom Cruise) to attract converts. The Church of Scientology requires that all converts sign a legal waiver which covers their relationship with the Church of Scientology before engaging in Scientology services.\n\nResearch in the United States and the Netherlands has shown a positive correlation between areas lacking mainstream churches and the percentage of people who are a member of a new religious movement. This applies also for the presence of New Age centres.\n\nOn the other end of the scale are religions that do not accept any converts, or do so very rarely. Often these are relatively small, close-knit minority religions that are ethnically based such as the Yazidis, Druze, and Mandaeans. Zoroastrianism classically does not accept converts, but this issue has become controversial in the 20th century due to the rapid decline in membership. Chinese traditional religion lacks clear criteria for membership, and hence for conversion. The Shakers and some Indian eunuch brotherhoods do not allow procreation, so that every member is a convert.\n\nThe United Nations Universal Declaration of Human Rights defines religious conversion as a human right: \"Everyone has the right to freedom of thought, conscience and religion; this right includes freedom to change his religion or belief\" (Article 18). Despite this UN-declared human right, some groups forbid or restrict religious conversion (see below).\n\nBased on the declaration the United Nations Commission on Human Rights (UNCHR) drafted the International Covenant on Civil and Political Rights, a legally binding treaty. It states that \"Everyone shall have the right to freedom of thought, conscience and religion. This right shall include freedom to have or to adopt a religion or belief of his choice\" (Article 18.1). \"No one shall be subject to coercion which would impair his freedom to have or to adopt a religion or belief of his choice\" (Article 18.2).\n\nThe UNCHR issued a General Comment on this Article in 1993: \"The Committee observes that the freedom to 'have or to adopt' a religion or belief necessarily entails the freedom to choose a religion or belief, \"including the right to replace one's current religion or belief with another\" or to adopt atheistic views [...] Article 18.2 bars coercion that would impair the right to have or adopt a religion or belief, including the use of threat of physical force or penal sanctions to compel believers or non-believers to adhere to their religious beliefs and congregations, to recant their religion or belief \"or to convert\".\" (CCPR/C/21/Rev.1/Add.4, General Comment No. 22.; emphasis added)\n\nSome countries distinguish voluntary, motivated conversion from organized proselytism, attempting to restrict the latter. The boundary between them is not easily defined: what one person considers legitimate evangelizing, or witness-bearing, another may consider intrusive and improper. Illustrating the problems that can arise from such subjective viewpoints is this extract from an article by Dr. C. Davis, published in Cleveland State University's \"Journal of Law and Health\": \"According to the Union of American Hebrew Congregations, Jews for Jesus and Hebrew Christians constitute two of the most dangerous cults, and its members are appropriate candidates for deprogramming. Anti-cult evangelicals ... protest that 'aggressiveness and proselytizing ... are basic to authentic Christianity,' and that Jews for Jesus and Campus Crusade for Christ are not to be labeled as cults. Furthermore, certain Hassidic groups who physically attacked a meeting of the Hebrew Christian 'cult' have themselves been labeled a 'cult' and equated with the followers of Reverend Moon, by none other than the President of the Central Conference of American Rabbis.\"\n\nSince the collapse of the former Soviet Union the Russian Orthodox Church has enjoyed a revival. However, it takes exception to what it considers illegitimate proselytizing by the Roman Catholic Church, the Salvation Army, Jehovah's Witnesses, and other religious movements in what it refers to as its \"canonical territory\".\n\nGreece has a long history of conflict, mostly with Jehovah's Witnesses, but also with some Pentecostals, over its laws on proselytism. This situation stems from a law passed in the 1930s by the dictator Ioannis Metaxas. A Jehovah's Witness, Minos Kokkinakis, won the equivalent of $14,400 in damages from the Greek state after being arrested for trying to preach his faith from door to door. In another case, \"Larissis v. Greece\", a member of the Pentecostal church also won a case in the European Court of Human Rights.\n\nSome Islamic countries with Islamic law outlaw and carry strict sentences for proselytizing. Several Islamic countries under Islamic law—Saudi Arabia, Yemen, Afghanistan, Pakistan, Egypt, Iran, and the Maldives—outlaw apostasy and carry imprisonment or the death penalty for those leaving Islam and those enticing Muslims to leave Islam. Also, induced religious conversions in the Indian states Orissa has resulted in communal riots.\n\n\n"}
{"id": "25599", "url": "https://en.wikipedia.org/wiki?curid=25599", "title": "Rubidium", "text": "Rubidium\n\nRubidium is a chemical element with symbol Rb and atomic number 37. Rubidium is a soft, silvery-white metallic element of the alkali metal group, with an atomic mass of 85.4678. Elemental rubidium is highly reactive, with properties similar to those of other alkali metals, including rapid oxidation in air. On Earth, natural rubidium comprises two isotopes: 72% is the stable isotope, Rb; 28% is the slightly radioactive Rb, with a half-life of 49 billion years—more than three times longer than the estimated age of the universe.\n\nGerman chemists Robert Bunsen and Gustav Kirchhoff discovered rubidium in 1861 by the newly developed technique, flame spectroscopy.\n\nRubidium's compounds have various chemical and electronic applications. Rubidium metal is easily vaporized and has a convenient spectral absorption range, making it a frequent target for laser manipulation of atoms.\n\nRubidium is not a known nutrient for any living organisms. However, rubidium ions have the same charge as potassium ions, and are actively taken up and treated by animal cells in similar ways.\n\nRubidium is a very soft, ductile, silvery-white metal. It is the second most electropositive of the non-radioactive alkali metals and melts at a temperature of . Similar to other alkali metals, rubidium metal reacts violently with water. As with potassium (which is slightly less reactive) and caesium (which is slightly more reactive), this reaction is usually vigorous enough to ignite the hydrogen gas it produces. Rubidium has also been reported to ignite spontaneously in air. It forms amalgams with mercury and alloys with gold, iron, caesium, sodium, and potassium, but not lithium (even though rubidium and lithium are in the same group).\n\nRubidium has a very low ionization energy of only 406 kJ/mol. Rubidium and potassium show a very similar purple color in the flame test, and distinguishing the two elements requires something more sophisticated, such as spectroscopy.\n\nRubidium chloride (RbCl) is probably the most used rubidium compound: among several other chlorides, it is used to induce living cells to take up DNA; it is also used as a biomarker, because in nature, it is found only in small quantities in living organisms and when present, replaces potassium. Other common rubidium compounds are the corrosive rubidium hydroxide (RbOH), the starting material for most rubidium-based chemical processes; rubidium carbonate (RbCO), used in some optical glasses, and rubidium copper sulfate, RbSO·CuSO·6HO. Rubidium silver iodide (RbAgI) has the highest room temperature conductivity of any known ionic crystal, a property exploited in thin film batteries and other applications.\n\nRubidium forms a number of oxides when exposed to air, including rubidium monoxide (RbO), RbO, and RbO; rubidium in excess oxygen gives the superoxide RbO. Rubidium forms salts with halides, producing rubidium fluoride, rubidium chloride, rubidium bromide, and rubidium iodide.\n\nAlthough rubidium is monoisotopic, rubidium in the Earth's crust is composed of two isotopes: the stable Rb (72.2%) and the radioactive Rb (27.8%). Natural rubidium is radioactive, with specific activity of about 670 Bq/g, enough to significantly expose a photographic film in 110 days. \n\nTwenty four additional rubidium isotopes have been synthesized with half-lives of less than 3 months; most are highly radioactive and have few uses.\n\nRubidium-87 has a half-life of  years, which is more than three times the age of the universe of  years, making it a primordial nuclide. It readily substitutes for potassium in minerals, and is therefore fairly widespread. Rb has been used extensively in dating rocks; Rb beta decays to stable Sr. During fractional crystallization, Sr tends to concentrate in plagioclase, leaving Rb in the liquid phase. Hence, the Rb/Sr ratio in residual magma may increase over time, and the progressing differentiation results in rocks with elevated Rb/Sr ratios. The highest ratios (10 or more) occur in pegmatites. If the initial amount of Sr is known or can be extrapolated, then the age can be determined by measurement of the Rb and Sr concentrations and of the Sr/Sr ratio. The dates indicate the true age of the minerals only if the rocks have not been subsequently altered (see rubidium-strontium dating).\n\nRubidium-82, one of the element's non-natural isotopes, is produced by electron-capture decay of strontium-82 with a half-life of 25.36 days. With a half-life of 76 seconds, rubidium-82 decays by positron emission to stable krypton-82.\n\nRubidium is the twenty-third most abundant element in the Earth's crust, roughly as abundant as zinc and rather more common than copper. It occurs naturally in the minerals leucite, pollucite, carnallite, and zinnwaldite, which contain as much as 1% rubidium oxide. Lepidolite contains between 0.3% and 3.5% rubidium, and is the commercial source of the element. Some potassium minerals and potassium chlorides also contain the element in commercially significant quantities.\n\nSeawater contains an average of 125 µg/L of rubidium compared to the much higher value for potassium of 408 mg/L and the much lower value of 0.3 µg/L for caesium.\n\nBecause of its large ionic radius, rubidium is one of the \"incompatible elements.\" During magma crystallization, rubidium is concentrated together with its heavier analogue caesium in the liquid phase and crystallizes last. Therefore, the largest deposits of rubidium and caesium are zone pegmatite ore bodies formed by this enrichment process. Because rubidium substitutes for potassium in the crystallization of magma, the enrichment is far less effective than that of caesium. Zone pegmatite ore bodies containing mineable quantities of caesium as pollucite or the lithium minerals lepidolite are also a source for rubidium as a by-product.\n\nTwo notable sources of rubidium are the rich deposits of pollucite at Bernic Lake, Manitoba, Canada, and the rubicline ((Rb,K)AlSiO) found as impurities in pollucite on the Italian island of Elba, with a rubidium content of 17.5%. Both of those deposits are also sources of caesium.\n\nAlthough rubidium is more abundant in Earth's crust than caesium, the limited applications and the lack of a mineral rich in rubidium limits the production of rubidium compounds to 2 to 4 tonnes per year. Several methods are available for separating potassium, rubidium, and caesium. The fractional crystallization of a rubidium and caesium alum (Cs,Rb)Al(SO)·12HO yields after 30 subsequent steps pure rubidium alum. Two other methods are reported, the chlorostannate process and the ferrocyanide process.\n\nFor several years in the 1950s and 1960s, a by-product of potassium production called Alkarb was a main source for rubidium. Alkarb contained 21% rubidium, with the rest being potassium and a small amount of caesium. Today the largest producers of caesium, such as the Tanco Mine, Manitoba, Canada, produce rubidium as a by-product from pollucite.\n\nRubidium was discovered in 1861 by Robert Bunsen and Gustav Kirchhoff, in Heidelberg, Germany, in the mineral lepidolite through spectroscopy. Because of the bright red lines in its emission spectrum, they chose a name derived from the Latin word \"rubidus\", meaning \"deep red\".\n\nRubidium is a minor component in lepidolite. Kirchhoff and Bunsen processed 150 kg of a lepidolite containing only 0.24% rubidium oxide (RbO). Both potassium and rubidium form insoluble salts with chloroplatinic acid, but those salts show a slight difference in solubility in hot water. Therefore, the less-soluble rubidium hexachloroplatinate (RbPtCl) could be obtained by fractional crystallization. After reduction of the hexachloroplatinate with hydrogen, the process yielded 0.51 grams of rubidium chloride for further studies. Bunsen and Kirchhoff began their first large-scale isolation of caesium and rubidium compounds with of mineral water, which yielded 7.3 grams of caesium chloride and 9.2 grams of rubidium chloride. Rubidium was the second element, shortly after caesium, to be discovered by spectroscopy, just one year after the invention of the spectroscope by Bunsen and Kirchhoff.\n\nThe two scientists used the rubidium chloride to estimate that the atomic weight of the new element was 85.36 (the currently accepted value is 85.47). They tried to generate elemental rubidium by electrolysis of molten rubidium chloride, but instead of a metal, they obtained a blue homogeneous substance which \"neither under the naked eye nor under the microscope showed the slightest trace of metallic substance.\" They presumed it was a subchloride (); however, the product was probably a colloidal mixture of the metal and rubidium chloride. In a second attempt to produce metallic rubidium, Bunsen was able to reduce rubidium by heating charred rubidium tartrate. Although the distilled rubidium was pyrophoric, they were able to determine the density and the melting point. The quality of this research in the 1860s can be appraised by the fact that their determined density differs less than 0.1 g/cm and the melting point by less than 1 °C from the presently accepted values.\n\nThe slight radioactivity of rubidium was discovered in 1908, but that was before the theory of isotopes was established in 1910, and the low level of activity (half-life greater than 10 years) made interpretation complicated. The now proven decay of Rb to stable Sr through beta decay was still under discussion in the late 1940s.\n\nRubidium had minimal industrial value before the 1920s. Since then, the most important use of rubidium is research and development, primarily in chemical and electronic applications. In 1995, rubidium-87 was used to produce a Bose–Einstein condensate, for which the discoverers, Eric Allin Cornell, Carl Edwin Wieman and Wolfgang Ketterle, won the 2001 Nobel Prize in Physics.\n\nRubidium compounds are sometimes used in fireworks to give them a purple color. Rubidium has also been considered for use in a thermoelectric generator using the magnetohydrodynamic principle, where rubidium ions are formed by heat at high temperature and passed through a magnetic field. These conduct electricity and act like an armature of a generator thereby generating an electric current. Rubidium, particularly vaporized Rb, is one of the most commonly used atomic species employed for laser cooling and Bose–Einstein condensation. Its desirable features for this application include the ready availability of inexpensive diode laser light at the relevant wavelength, and the moderate temperatures required to obtain substantial vapor pressures. For cold atom applications requiring tunable interactions, Rb is preferable due to its rich Feshbach spectrum.\n\nRubidium has been used for polarizing He, producing volumes of magnetized He gas, with the nuclear spins aligned rather than random. Rubidium vapor is optically pumped by a laser and the polarized Rb polarizes He through the hyperfine interaction. Such spin-polarized He cells are useful for neutron polarization measurements and for producing polarized neutron beams for other purposes.\n\nThe resonant element in atomic clocks utilizes the hyperfine structure of rubidium's energy levels, and rubidium is useful for high-precision timing. It is used as the main component of secondary frequency references (rubidium oscillators) in cell site transmitters and other electronic transmitting, networking, and test equipment. These rubidium standards are often used with GPS to produce a \"primary frequency standard\" that has greater accuracy and is less expensive than caesium standards. Such rubidium standards are often mass-produced for the telecommunication industry.\n\nOther potential or current uses of rubidium include a working fluid in vapor turbines, as a getter in vacuum tubes, and as a photocell component. Rubidium is also used as an ingredient in special types of glass, in the production of superoxide by burning in oxygen, in the study of potassium ion channels in biology, and as the vapor in atomic magnetometers. In particular, Rb is used with other alkali metals in the development of spin-exchange relaxation-free (SERF) magnetometers.\n\nRubidium-82 is used for positron emission tomography. Rubidium is very similar to potassium and tissue with high potassium content will also accumulate the radioactive rubidium. One of the main uses is myocardial perfusion imaging. As a result of changes in the blood brain barrier in brain tumors, rubidium collects more in brain tumors than normal brain tissue, allowing the use of radioisotope rubidium-82 in nuclear medicine to locate and image brain tumors. Rubidium-82 has a very short half-life of 76 seconds, and the production from decay of strontium-82 must be done close to the patient.\n\nRubidium was tested for the influence on manic depression and depression. Dialysis patients suffering from depression show a depletion in rubidium and therefore a supplementation may help during depression. In some tests the rubidium was administered as rubidium chloride with up to 720 mg per day for 60 days.\n\nRubidium reacts violently with water and can cause fires. To ensure safety and purity, this metal is usually kept under a dry mineral oil or sealed in glass ampoules in an inert atmosphere. Rubidium forms peroxides on exposure even to small amount of air diffused into the oil, and storage is subject to similar precautions as the storage of metallic potassium.\n\nRubidium, like sodium and potassium, almost always has +1 oxidation state when dissolved in water, even in biological contexts. The human body tends to treat Rb ions as if they were potassium ions, and therefore concentrates rubidium in the body's intracellular fluid (i.e., inside cells). The ions are not particularly toxic; a 70 kg person contains on average 0.36 g of rubidium, and an increase in this value by 50 to 100 times did not show negative effects in test persons. The biological half-life of rubidium in humans measures 31–46 days. Although a partial substitution of potassium by rubidium is possible, when more than 50% of the potassium in the muscle tissue of rats was replaced with rubidium, the rats died.\n\n\n\n"}
{"id": "25600", "url": "https://en.wikipedia.org/wiki?curid=25600", "title": "Ruthenium", "text": "Ruthenium\n\nRuthenium is a chemical element with symbol Ru and atomic number 44. It is a rare transition metal belonging to the platinum group of the periodic table. Like the other metals of the platinum group, ruthenium is inert to most other chemicals. The Baltic German scientist Karl Ernst Claus discovered the element in 1844 and named it after his homeland, the Russian Empire. Ruthenium is usually found as a minor component of platinum ores; the annual production is about 20 tonnes. Most ruthenium produced is used in wear-resistant electrical contacts and thick-film resistors. A minor application for ruthenium is in platinum alloys and as a chemistry catalyst.\n\nA polyvalent hard white metal, ruthenium is a member of the platinum group and is in group 8 of the periodic table:\n\nWhereas all other group 8 elements have 2 electrons in the outermost shell, in ruthenium, the outermost shell has only one electron (the final electron is in a lower shell). This anomaly is observed in the neighboring metals niobium (41), molybdenum (42), and rhodium (45).\n\nRuthenium has four crystal modifications and does not tarnish unless subject to high temperatures. Ruthenium dissolves in fused alkalis to give ruthenates (), is not attacked by acids (even aqua regia) but is attacked by halogens at high temperatures. Indeed, ruthenium is most readily attacked by oxidizing agents. Small amounts of ruthenium can increase the hardness of platinum and palladium. The corrosion resistance of titanium is increased markedly by the addition of a small amount of ruthenium. The metal can be plated by electroplating and by thermal decomposition. A ruthenium-molybdenum alloy is known to be superconductive at temperatures below 10.6 K. Ruthenium is the last of the 4d transition metals that can assume the group oxidation state +8, and even then it is less stable there than the heavier congener osmium: this is the first group from the left of the table where the second and third-row transition metals display notable differences in chemical behavior. Like iron but unlike osmium, ruthenium can form aqueous cations in its lower oxidation states of +2 and +3.\n\nRuthenium is the first in a downward trend in the melting and boiling points and atomization enthalpy in the 4d transition metals after the maximum seen at molybdenum, because the 4d subshell is more than half full and the electrons are contributing less to metallic bonding. (Technetium, the previous element, has an exceptionally low value that is off the trend due to its half-filled [Kr]4d5s configuration, though the small amount of energy needed to excite it to a [Kr]4d5s configuration indicates that it is not as far off the trend in the 4d series as manganese in the 3d transition series.) Unlike the lighter congener iron, ruthenium is paramagnetic at room temperature, as iron also is above its Curie point.\n\nThe reduction potentials in acidic aqueous solution for some common ruthenium ions are shown below:\n\nNaturally occurring ruthenium is composed of seven stable isotopes. Additionally, 34 radioactive isotopes have been discovered. Of these radioisotopes, the most stable are Ru with a half-life of 373.59 days, Ru with a half-life of 39.26 days and Ru with a half-life of 2.9 days.\n\nFifteen other radioisotopes have been characterized with atomic weights ranging from 89.93 u (Ru) to 114.928 u (Ru). Most of these have half-lives that are less than five minutes except Ru (half-life: 1.643 hours) and Ru (half-life: 4.44 hours).\n\nThe primary decay mode before the most abundant isotope, Ru, is electron capture and the primary mode after is beta emission. The primary decay product before Ru is technetium and the primary decay product after is rhodium.\n\nAs the 74th most abundant element in Earth's crust, ruthenium is relatively rare, found in about 100 parts per trillion. This element is generally found in ores with the other platinum group metals in the Ural Mountains and in North and South America. Small but commercially important quantities are also found in pentlandite extracted from Sudbury, Ontario, Canada, and in pyroxenite deposits in South Africa. The native form of ruthenium is a very rare mineral (Ir replaces part of Ru in its structure).\n\nRoughly 12 tonnes of ruthenium are mined each year with world reserves estimated as 5,000 tonnes. The composition of the mined platinum group metal (PGM) mixtures varies widely, depending on the geochemical formation. For example, the PGMs mined in South Africa contain on average 11% ruthenium while the PGMs mined in the former USSR contain only 2% (1992). Ruthenium, osmium, and iridium are considered the minor platinum group metals.\n\nRuthenium, like the other platinum group metals, is obtained commercially as a by-product from nickel, and copper, and platinum metals ore processing. During electrorefining of copper and nickel, noble metals such as silver, gold, and the platinum group metals precipitate as \"anode mud\", the feedstock for the extraction. The metals are converted to ionized solutes by any of several methods, depending on the composition of the feedstock. One representative method is fusion with sodium peroxide followed by dissolution in aqua regia, and solution in a mixture of chlorine with hydrochloric acid. Osmium, ruthenium, rhodium, and iridium are insoluble in aqua regia and readily precipitate, leaving the other metals in solution. Rhodium is separated from the residue by treatment with molten sodium bisulfate. The insoluble residue, containing Ru, Os, and Ir is treated with sodium oxide, in which Ir is insoluble, producing dissolved Ru and Os salts. After oxidation to the volatile oxides, is separated from by precipitation of (NH)RuCl with ammonium chloride or by distillation or extraction with organic solvents of the volatile osmium tetroxide. Hydrogen is used to reduce ammonium ruthenium chloride yielding a powder. The product is reduced using hydrogen, yielding the metal as a powder or sponge metal that can be treated with powder metallurgy techniques or argon-arc welding.\n\nThe oxidation states of ruthenium range from 0 to +8, and −2. The properties of ruthenium and osmium compounds are often similar. The +2, +3, and +4 states are the most common. The most prevalent precursor is ruthenium trichloride, a red solid that is poorly defined chemically but versatile synthetically.\n\nRuthenium can be oxidized to ruthenium(IV) oxide (RuO, oxidation state +4) which can in turn be oxidized by sodium metaperiodate to the volatile yellow tetrahedral ruthenium tetroxide, RuO, an aggressive, strong oxidizing agent with structure and properties analogous to osmium tetroxide. Like osmium tetroxide, ruthenium tetroxide is a potent fixative and stain for electron microscopy of organic materials, and is mostly used to reveal the structure of polymer samples. Dipotassium ruthenate (KRuO, +6), and potassium perruthenate (KRuO, +7) are also known. Unlike osmium tetroxide, ruthenium tetroxide is less stable and is strong enough as an oxidising agent to oxidise dilute hydrochloric acid and organic solvents like ethanol at room temperature, and is easily reduced to ruthenate () in aqueous alkaline solutions; it decomposes to form the dioxide above 100 °C. Unlike iron but like osmium, ruthenium does not form oxides in its lower +2 and +3 oxidation states. Ruthenium forms dichalcogenides only when reacted directly with the chalcogens, which are diamagnetic semiconductors crystallizing in the pyrite structure and thus must contain ruthenium(II).\n\nLike iron, ruthenium does not readily form oxoanions, and prefers to achieve high coordination numbers with hydroxide ions instead. Ruthenium tetroxide is reduced by cold dilute potassium hydroxide to form black potassium perruthenate, KRuO, with ruthenium in the +7 oxidation state. Potassium perruthenate can also be produced by oxidising potassium ruthenate, KRuO, with chlorine gas. The perruthenate ion is unstable and is reduced by water to form the orange ruthenate. Potassium ruthenate may be synthesized by reacting ruthenium metal with potassium hydroxide and potassium nitrate.\n\nSome mixed oxides are also known, such as MRuO, NaRuO, NaRuO, and MLnRuO.\n\nThe highest known ruthenium halide is the hexafluoride, a dark brown solid that melts at 54 °C. It hydrolyzes violently upon contact with water and easily disproportionates to form a mixture of lower ruthenium fluorides, releasing fluorine gas. Ruthenium pentafluoride is a tetrameric dark green solid that is also readily hydrolyzed, melting at 86.5 °C. The yellow ruthenium tetrafluoride is probably also polymeric and can be formed by reducing the pentafluoride with iodine. Among the binary compounds of ruthenium, these high oxidation states are known only in the oxides and fluorides.\n\nRuthenium trichloride is a well-known compound, existing in a black α-form and a dark brown β-form: the trihydrate is red. Of the known trihalides, trifluoride is dark brown and decomposes above 650 °C, tetrabromide is dark-brown and decomposes above 400 °C, and triiodide is black. Of the dihalides, difluoride is not known, dichloride is brown, dibromide is black, and diiodide is blue. The only known oxyhalide is the pale green ruthenium(VI) oxyfluoride, RuOF.\n\nRuthenium forms a variety of coordination complexes. Examples are the many pentammine derivatives [Ru(NH)L] that often exist for both Ru(II) and Ru(III). Derivatives of bipyridine and terpyridine are numerous, best known being the luminescent tris(bipyridine)ruthenium(II) chloride.\n\nRuthenium forms a wide range compounds with carbon-ruthenium bonds. Grubbs' catalyst is used for alkene metathesis. Ruthenocene is analogous to ferrocene structurally, but exhibits distinctive redox properties. The colorless liquid ruthenium pentacarbonyl converts in the absence of CO pressure to the dark red solid triruthenium dodecacarbonyl. Ruthenium trichloride reacts with carbon monoxide to give many derivatives including RuHCl(CO)(PPh) and Ru(CO)(PPh) (Roper's complex). Heating solutions of ruthenium trichloride in alcohols with triphenylphosphine gives tris(triphenylphosphine)ruthenium dichloride (RuCl(PPh)), which converts to the hydride complex chlorohydridotris(triphenylphosphine)ruthenium(II) (RuHCl(PPh)).\n\nThough naturally occurring platinum alloys containing all six platinum-group metals were used for a long time by pre-Columbian Americans and known as a material to European chemists from the mid-16th century, not until the mid-18th century was platinum identified as a pure element. That natural platinum contained palladium, rhodium, osmium and iridium was discovered in the first decade of the 19th century. Platinum in alluvial sands of Russian rivers gave access to raw material for use in plates and medals and for the minting of ruble coins, starting in 1828. Residues from platinum production for coinage were available in the Russian Empire, and therefore most of the research on them was done in Eastern Europe.\n\nIt is possible that the Polish chemist Jędrzej Śniadecki isolated element 44 (which he called \"vestium\" after the asteroid Vesta discovered shortly before) from South American platinum ores in 1807. He published an announcement of his discovery in 1808. His work was never confirmed, however, and he later withdrew his claim of discovery.\n\nJöns Berzelius and Gottfried Osann nearly discovered ruthenium in 1827. They examined residues that were left after dissolving crude platinum from the Ural Mountains in aqua regia. Berzelius did not find any unusual metals, but Osann thought he found three new metals, which he called pluranium, ruthenium, and polinium. This discrepancy led to a long-standing controversy between Berzelius and Osann about the composition of the residues. As Osann was not able to repeat his isolation of ruthenium, he eventually relinquished his claims. The name \"ruthenium\" was chosen by Osann because the analysed samples stemmed from the Ural Mountains in Russia. The name itself derives from Ruthenia, the Latin word for Rus', a historical area that included present-day western Russia, Ukraine, Belarus, and parts of Slovakia and Poland.\n\nIn 1844, Karl Ernst Claus, a Russian scientist of Baltic German descent, showed that the compounds prepared by Gottfried Osann contained small amounts of ruthenium, which Claus had discovered the same year. Claus isolated ruthenium from the platinum residues of rouble production while he was working in Kazan University, Kazan, the same way its heavier congener osmium had been discovered four decades earlier. Claus showed that ruthenium oxide contained a new metal and obtained 6 grams of ruthenium from the part of crude platinum that is insoluble in aqua regia. Choosing the name for the new element, Claus stated: \"I named the new body, in honour of my Motherland, ruthenium. I had every right to call it by this name because Mr. Osann relinquished his ruthenium and the word does not yet exist in chemistry.\"\n\nBecause it hardens platinum and palladium alloys, ruthenium is used in electrical contacts, where a thin film is sufficient to achieve the desired durability. With similar properties and lower cost than rhodium, electric contacts are a major use of ruthenium. The plate is applied to the base by electroplating or sputtering.\n\nRuthenium dioxide with lead and bismuth ruthenates are used in thick-film chip resistors. These two electronic applications account for 50% of the ruthenium consumption.\n\nRuthenium is seldom alloyed with metals outside the platinum group, where small quantities improve some properties. The added corrosion resistance in titanium alloys led to the development of a special alloy with 0.1% ruthenium. Ruthenium is also used in some advanced high-temperature single-crystal superalloys, with applications that include the turbines in jet engines. Several nickel based superalloy compositions are described, such as EPM-102 (with 3% Ru), TMS-162 (with 6% Ru), TMS-138, and TMS-174, the latter two containing 6% rhenium. Fountain pen nibs are frequently tipped with ruthenium alloy. From 1944 onward, the famous Parker 51 fountain pen was fitted with the \"RU\" nib, a 14K gold nib tipped with 96.2% ruthenium and 3.8% iridium.\n\nRuthenium is a component of mixed-metal oxide (MMO) anodes used for cathodic protection of underground and submerged structures, and for electrolytic cells for such processes as generating chlorine from salt water. The fluorescence of some ruthenium complexes is quenched by oxygen, finding use in optode sensors for oxygen. Ruthenium red, [(NH)Ru-O-Ru(NH)-O-Ru(NH)], is a biological stain used to stain polyanionic molecules such as pectin and nucleic acids for light microscopy and electron microscopy. The beta-decaying isotope 106 of ruthenium is used in radiotherapy of eye tumors, mainly malignant melanomas of the uvea. Ruthenium-centered complexes are being researched for possible anticancer properties. Compared with platinum complexes, those of ruthenium show greater resistance to hydrolysis and more selective action on tumors.\n\nRuthenium tetroxide exposes latent fingerprints by reacting on contact with fatty oils or fats with sebaceous contaminants and producing brown/black ruthenium dioxide pigment.\n\nRuthenium is a versatile catalyst. With an aqueous suspension of CdS particles loaded with ruthenium dioxide, the energy of visible light can split Hydrogen sulfide. This process may one day be used to remove HS in oil refineries and other industrial processing facilities. Organometallic ruthenium carbene and alkylidene complexes have been found to be highly efficient catalysts for olefin metathesis, a process with important applications in organic and pharmaceutical chemistry. Ruthenium-promoted cobalt catalysts are used in Fischer-Tropsch synthesis. Supported ruthenium can also be used as a catalyst in ammonia decomposition.\n\nRuthenium is one of several metals used extensively as a catalyst for hydrogen transfer reactions (sometimes referred to as \"borrowing hydrogen\" reactions). In these reactions an alcohol is converted to a carbonyl compound through transfer of two hydrogen atoms to the catalyst. A reaction is then performed on the newly-formed carbonyl group, followed by return of the two hydrogen atoms from the catalyst to the product of the reaction. An example of an application is the conversion of alcohols to amines. Alternatively, an electron-deficient alkene such as crotononitrile may used to absorb the hydrogen removed from the alcohol by the ruthenium catalyst. Applications of this technique include the oxidation of alcohols to esters and formation of alkenes from alcohols.\n\nSome ruthenium complexes absorb light throughout the visible spectrum and are being actively researched for solar energy technologies. For example, Ruthenium-based compounds have been used for light absorption in dye-sensitized solar cells, a promising new low-cost solar cell system.\n\nChemical vapor deposition of ruthenium is used to produce thin films of pure ruthenium on substrates. These films show promise for use in microchips and for the giant magnetoresistive read element for hard disk drives. Ruthenium is also suggested for microelectronics because it is compatible with semiconductor processing techniques.\n\nMany ruthenium-based oxides show very unusual properties, such as a quantum critical point behavior, exotic superconductivity, and high-temperature ferromagnetism.\n\n"}
{"id": "25601", "url": "https://en.wikipedia.org/wiki?curid=25601", "title": "Rhodium", "text": "Rhodium\n\nRhodium is a chemical element with symbol Rh and atomic number 45. It is a rare, silvery-white, hard, and chemically inert transition metal. It is a member of the platinum group. It has only one naturally occurring isotope, Rh. Naturally occurring rhodium is usually found as the free metal, alloyed with similar metals, and rarely as a chemical compound in minerals such as bowieite and rhodplumsite. It is one of the rarest and most valuable precious metals.\n\nRhodium is a noble metal, resistant to corrosion, found in platinum or nickel ores together with the other members of the platinum group metals. It was discovered in 1803 by William Hyde Wollaston in one such ore, and named for the rose color of one of its chlorine compounds, produced after it reacted with the powerful acid mixture aqua regia.\n\nThe element's major use (approximately 80% of world rhodium production) is as one of the catalysts in the three-way catalytic converters in automobiles. Because rhodium metal is inert against corrosion and most aggressive chemicals, and because of its rarity, rhodium is usually alloyed with platinum or palladium and applied in high-temperature and corrosion-resistive coatings. White gold is often plated with a thin rhodium layer to improve its appearance while sterling silver is often rhodium-plated for tarnish resistance.\n\nRhodium detectors are used in nuclear reactors to measure the neutron flux level.\n\nRhodium (Greek \"rhodon\" (ῥόδον) meaning \"rose\") was discovered in 1803 by William Hyde Wollaston, soon after his discovery of palladium. He used crude platinum ore presumably obtained from South America. His procedure involved dissolving the ore in aqua regia and neutralizing the acid with sodium hydroxide (NaOH). He then precipitated the platinum as ammonium chloroplatinate by adding ammonium chloride (). Most other metals like copper, lead, palladium and rhodium were precipitated with zinc. Diluted nitric acid dissolved all but palladium and rhodium. Of these, palladium dissolved in aqua regia but rhodium did not, and the rhodium was precipitated by the addition of sodium chloride as . After being washed with ethanol, the rose-red precipitate was reacted with zinc, which displaced the rhodium in the ionic compound and thereby released the rhodium as free metal.\n\nAfter the discovery, the rare element had only minor applications; for example, by the turn of the century, rhodium-containing thermocouples were used to measure temperatures up to 1800 °C. The first major application was electroplating for decorative uses and as corrosion-resistant coating. The introduction of the three-way catalytic converter by Volvo in 1976 increased the demand for rhodium. The previous catalytic converters used platinum or palladium, while the three-way catalytic converter used rhodium to reduce the amount of NO in the exhaust.\n\nRhodium is a hard, silvery, durable metal that has a high reflectance. Rhodium metal does not normally form an oxide, even when heated. Oxygen is absorbed from the atmosphere only at the melting point of rhodium, but is released on solidification. Rhodium has both a higher melting point and lower density than platinum. It is not attacked by most acids: it is completely insoluble in nitric acid and dissolves slightly in aqua regia.\n\nRhodium belongs to group 9 of the periodic table, but the configuration of electrons in the outermost shells is atypical for the group. This anomaly is also observed in the neighboring elements, niobium (41), ruthenium (44), and palladium (46).\n\nThe common oxidation state of rhodium is +3, but oxidation states from +0 to +6 are also observed.\n\nUnlike ruthenium and osmium, rhodium forms no volatile oxygen compounds. The known stable oxides include , , , , and . Halogen compounds are known in nearly the full range of possible oxidation states. Rhodium(III) chloride, rhodium(IV) fluoride, rhodium(V) fluoride and rhodium(VI) fluoride are examples. The lower oxidation states are stable only in the presence of ligands.\n\nThe best-known rhodium-halogen compound is the Wilkinson's catalyst chlorotris(triphenylphosphine)rhodium(I). This catalyst is used in the hydroformylation or hydrogenation of alkenes.\n\nNaturally occurring rhodium is composed of only one isotope, Rh. The most stable radioisotopes are Rh with a half-life of 3.3 years, Rh with a half-life of 207 days, Rh with a half-life of 2.9 years, and Rh with a half-life of 16.1 days. Twenty other radioisotopes have been characterized with atomic weights ranging from 92.926 u (Rh) to 116.925 u (Rh). Most of these have half-lives shorter than an hour, except Rh (20.8 hours) and Rh (35.36 hours). It has numerous meta states, the most stable being Rh (0.141 MeV) with a half-life of about 2.9 years and Rh (0.157 MeV) with a half-life of 4.34 days (see isotopes of rhodium).\n\nIn isotopes weighing less than 103 (the stable isotope), the primary decay mode is electron capture and the primary decay product is ruthenium In isotopes greater than 103, the primary decay mode is beta emission and the primary product is palladium.\n\nRhodium is one of the rarest elements in the Earth's crust, comprising an estimated 0.0002 parts per million (2 × 10). Its rarity affects its price and its use in commercial applications.\n\nThe industrial extraction of rhodium is complex because the ores are mixed with other metals such as palladium, silver, platinum, and gold and there are very few rhodium-bearing minerals. It is found in platinum ores and extracted as a white inert metal that is difficult to fuse. Principal sources are located in South Africa; in river sands of the Ural Mountains; and in North America, including the copper-nickel sulfide mining area of the Sudbury, Ontario, region. Although the quantity at Sudbury is very small, the large amount of processed nickel ore makes rhodium recovery cost-effective.\n\nThe main exporter of rhodium is South Africa (approximately 80% in 2010) followed by Russia. The annual world production is 30 tonnes. The price of rhodium is highly variable. In 2007, rhodium cost approximately eight times more than gold, 450 times more than silver, and 27,250 times more than copper by weight. In 2008, the price briefly rose above $10,000 per ounce ($350,000 per kilogram). The economic slowdown of the 3rd quarter of 2008 pushed rhodium prices sharply back below $1,000 per ounce ($35,000 per kilogram); the price rebounded to $2,750 by early 2010 ($97,000 per kilogram) (more than twice the gold price), but in late 2013, the prices were less than $1000.\n\nPolitical and financial problems led to very low oil prices and oversupply, causing most metals to drop in price. The economies of China, India and other emerging countries slowed in 2014 and 2015. In 2014 alone, 23,722,890 motor vehicles were produced in China, excluding motorbikes. This resulted in a rhodium price of 740.00 US-$ per Troy ounce (31.1 grams) in late November 2015.\n\nRhodium is a fission product of uranium-235; therefore, each kilogram of fission product contains a significant amount of the lighter platinum group metals including rhodium. Used nuclear fuel is a potential source of rhodium. However, the extraction is complex and expensive, and the presence of rhodium radioisotopes requires a period of cooling storage for multiple half-lives of the longest-lived isotope (about 10 years). These factors make the source unattractive and no large-scale extraction has been attempted.\n\nThe primary use of this element is in automobiles as a catalytic converter, changing harmful unburned hydrocarbons, carbon monoxide, and nitrogen oxide exhaust emissions into less noxious gases. Of 30,000 kg of rhodium consumed worldwide in 2012, 81% (24,300 kg) went into and 8,060 kg was recovered from this application. About 964 kg of rhodium was used in the glass industry, mostly for production of fiberglass and flat-panel glass, and 2,520 kg was used in the chemical industry.\n\nIn 2012, 81% of the world production of rhodium was consumed in automobile catalytic converters. Rhodium is preferable to the other platinum metals in the reduction of nitrogen oxides to nitrogen and oxygen:\n\nRhodium catalysts are used in a number of industrial processes, notably in catalytic carbonylation of methanol to produce acetic acid by the Monsanto process. It is also used to catalyze addition of hydrosilanes to molecular double bonds, a process important in manufacture of certain silicone rubbers. Rhodium catalysts are also used to reduce benzene to cyclohexane.\n\nThe complex of a rhodium ion with BINAP is a widely used chiral catalyst for chiral synthesis, as in the synthesis of menthol.\n\nRhodium finds use in jewelry and for decorations. It is electroplated on white gold and platinum to give it a reflective white surface at time of sale, after which the thin layer wears away with use. This is known as rhodium flashing in the jewelry business. It may also be used in coating sterling silver to protect against tarnish (silver sulfide, AgS, produced from atmospheric hydrogen sulfide, HS). Solid (pure) rhodium jewelry is very rare, more because of the difficulty of fabrication (high melting point and poor malleability) than because of the high price. The high cost ensures that rhodium is applied only as an electroplate.\n\nRhodium has also been used for honors or to signify elite status, when more commonly used metals such as silver, gold or platinum were deemed insufficient. In 1979 the \"Guinness Book of World Records\" gave Paul McCartney a rhodium-plated disc for being history's all-time best-selling songwriter and recording artist.\n\nRhodium is used as an alloying agent for hardening and improving the corrosion resistance of platinum and palladium. These alloys are used in furnace windings, bushings for glass fiber production, thermocouple elements, electrodes for aircraft spark plugs, and laboratory crucibles. Other uses include:\n\nBeing a noble metal, pure rhodium is inert. However, chemical complexes of rhodium can be reactive. Median lethal dose (LD) for rats is 198 mg of rhodium chloride () per kilogram of body weight. Like the other noble metals, all of which are too inert to occur as chemical compounds in nature, rhodium has not been found to serve any biological function. In elemental form, the metal is harmless.\n\nPeople can be exposed to rhodium in the workplace by inhalation. The Occupational Safety and Health Administration (OSHA) has specified the legal limit (Permissible exposure limit) for rhodium exposure in the workplace at 0.1 mg/m over an 8-hour workday, and the National Institute for Occupational Safety and Health (NIOSH) has set the recommended exposure limit (REL), at the same level. At levels of 100 mg/m, rhodium is immediately dangerous to life or health. For soluble compounds, the PEL and REL are both 0.001 mg/m.\n\n\n"}
{"id": "25602", "url": "https://en.wikipedia.org/wiki?curid=25602", "title": "Radium", "text": "Radium\n\nRadium is a chemical element with symbol Ra and atomic number 88. It is the sixth element in group 2 of the periodic table, also known as the alkaline earth metals. Pure radium is silvery-white, but it readily reacts with nitrogen (rather than oxygen) on exposure to air, forming a black surface layer of radium nitride (RaN). All isotopes of radium are highly radioactive, with the most stable isotope being radium-226, which has a half-life of 1600 years and decays into radon gas (specifically the isotope radon-222). When radium decays, ionizing radiation is a product, which can excite fluorescent chemicals and cause radioluminescence.\n\nRadium, in the form of radium chloride, was discovered by Marie and Pierre Curie in 1898. They extracted the radium compound from uraninite and published the discovery at the French Academy of Sciences five days later. Radium was isolated in its metallic state by Marie Curie and André-Louis Debierne through the electrolysis of radium chloride in 1911.\n\nIn nature, radium is found in uranium and (to a lesser extent) thorium ores in trace amounts as small as a seventh of a gram per ton of uraninite. Radium is not necessary for living organisms, and adverse health effects are likely when it is incorporated into biochemical processes because of its radioactivity and chemical reactivity. Currently, other than its use in nuclear medicine, radium has no commercial applications; formerly, it was used as a radioactive source for radioluminescent devices and also in radioactive quackery for its supposed curative powers. Today, these former applications are no longer in vogue because radium's toxicity has since become known, and less dangerous isotopes are used instead in radioluminescent devices.\n\nRadium is the heaviest known alkaline earth metal and is the only radioactive member of its group. Its physical and chemical properties most closely resemble its lighter congener barium.\n\nPure radium is a volatile silvery-white metal, although its lighter congeners calcium, strontium, and barium have a slight yellow tint. Its color rapidly vanishes in air, yielding a black layer of radium nitride (RaN). Its melting point is either or and its boiling point is . Both of these values are slightly lower than those of barium, confirming periodic trends down the group 2 elements. Like barium and the alkali metals, radium crystallizes in the body-centered cubic structure at standard temperature and pressure: the radium–radium bond distance is 514.8 picometers. Radium has a density of 5.5 g/cm, higher than that of barium, again confirming periodic trends; the radium-barium density ratio is comparable to the radium-barium atomic mass ratio, due to the two elements' similar crystal structures.\n\nRadium, like barium, is a highly reactive metal and always exhibits its group oxidation state of +2. It forms the colorless Ra cation in aqueous solution, which is highly basic and does not form complexes readily. Most radium compounds are therefore simple ionic compounds, though participation from the 6s and 6p electrons (in addition to the valence 7s electrons) is expected due to relativistic effects and would enhance the covalent character of radium compounds such as RaF and RaAt. For this reason, the standard electrode potential for the half-reaction Ra (aq) + 2e → Ra (s) is −2.916 V, even slightly lower than the value −2.92 V for barium, whereas the values had previously smoothly increased down the group (Ca: −2.84 V; Sr: −2.89 V; Ba: −2.92 V). The values for barium and radium are almost exactly the same as those of the heavier alkali metals potassium, rubidium, and caesium.\n\nSolid radium compounds are white as radium ions provide no specific coloring, but they gradually turn yellow and then dark over time due to self-radiolysis from radium's alpha decay. Insoluble radium compounds coprecipitate with all barium, most strontium, and most lead compounds.\n\nRadium oxide (RaO) has not been characterized well past its existence, despite oxides being common compounds for the other alkaline earth metals. Radium hydroxide (Ra(OH)) is the most readily soluble among the alkaline earth hydroxides and is a stronger base than its barium congener, barium hydroxide. It is also more soluble than actinium hydroxide and thorium hydroxide: these three adjacent hydroxides may be separated by precipitating them with ammonia.\n\nRadium chloride (RaCl) is a colorless, luminous compound. It becomes yellow after some time due to self-damage by the alpha radiation given off by radium when it decays. Small amounts of barium impurities give the compound a rose color. It is soluble in water, though less so than barium chloride, and its solubility decreases with increasing concentration of hydrochloric acid. Crystallization from aqueous solution gives the dihydrate RaCl·2HO, isomorphous with its barium analog.\n\nRadium bromide (RaBr) is also a colorless, luminous compound. In water, it is more soluble than radium chloride. Like radium chloride, crystallization from aqueous solution gives the dihydrate RaBr·2HO, isomorphous with its barium analog. The ionizing radiation emitted by radium bromide excites nitrogen molecules in the air, making it glow. The alpha particles emitted by radium quickly gain two electrons to become neutral helium, with builds up inside and weakens radium bromide crystals. This effect sometimes causes the crystals to break or even explode.\n\nRadium nitrate (Ra(NO)) is a white compound that can be made by dissolving radium carbonate in nitric acid. As the concentration of nitric acid increases, the solubility of radium nitrate decreases, an important property for the chemical purification of radium.\n\nRadium forms much the same insoluble salts as its lighter congener barium: it forms the insoluble sulfate (RaSO, the most insoluble known sulfate), chromate (RaCrO), carbonate (RaCO), iodate (Ra(IO)), tetrafluoroberyllate (RaBeF), and nitrate (Ra(NO)). With the exception of the carbonate, all of these are less soluble in water than the corresponding barium salts, but they are all isostructural to their barium counterparts. Additionally, radium phosphate, oxalate, and sulfite are probably also insoluble, as they coprecipitate with the corresponding insoluble barium salts. The great insolubility of radium sulfate (at 20 °C, only 2.1 mg will dissolve in 1 kg of water) means that it is one of the less biologically dangerous radium compounds. The large ionic radius of Ra (148 pm) results in weak complexation and poor extraction of radium from aqueous solutions when not at high pH.\n\nRadium has 33 known isotopes, with mass numbers from 202 to 234: all of them are radioactive. Four of these – Ra (half-life 11.4 days), Ra (3.64 days), Ra (1600 years), and Ra (5.75 years) – occur naturally in the decay chains of primordial thorium-232, uranium-235, and uranium-238 (Ra from uranium-235, Ra from uranium-238, and the other two from thorium-232). These isotopes nevertheless still have half-lives too short to be primordial radionuclides and only exist in nature from these decay chains. Together with the artificial Ra (15 d), these are the five most stable isotopes of radium. All other known radium isotopes have half-lives under two hours, and the majority have half-lives under a minute. At least 12 nuclear isomers have been reported; the most stable of them is radium-205m, with a half-life of between 130 and 230 milliseconds, which is still shorter than twenty-four ground-state radium isotopes.\n\nIn the early history of the study of radioactivity, the different natural isotopes of radium were given different names. In this scheme, Ra was named actinium X (AcX), Ra thorium X (ThX), Ra radium (Ra), and Ra mesothorium 1 (MsTh). When it was realized that all of these are isotopes of radium, many of these names fell out of use, and \"radium\" came to refer to all isotopes, not just Ra. Some of radium-226's decay products received historical names including \"radium\", ranging from radium A to radium G, with the letter indicating approximately how far they were down the chain from their parent Ra.\n\nRa is the most stable isotope of radium and is the last isotope in the (4\"n\" + 2) decay chain of uranium-238 with a half-life of over a millennium: it makes up almost all of natural radium. Its immediate decay product is the dense radioactive noble gas radon, which is responsible for much of the danger of environmental radium. It is 2.7 million times more radioactive than the same molar amount of natural uranium (mostly uranium-238), due to its proportionally shorter half-life.\n\nA sample of radium metal maintains itself at a higher temperature than its surroundings because of the radiation it emits – alpha particles, beta particles, and gamma rays. More specifically, natural radium (which is mostly Ra) emits mostly alpha particles, but other steps in its decay chain (the uranium or radium series) emit alpha or beta particles, and almost all particle emissions are accompanied by gamma rays.\n\nAll isotopes of radium have half-lives much shorter than the age of the Earth, so that any primordial radium would have decayed long ago. Radium nevertheless still occurs in the environment, as the isotopes Ra, Ra, Ra, and Ra are part of the decay chains of natural thorium and uranium isotopes; since thorium and uranium have very long half-lives, these daughters are continually being regenerated by their decay. Of these four isotopes, the longest-lived is Ra (half-life 1600 years), a decay product of natural uranium. Because of its relative longevity, Ra is the most common isotope of the element, making up about one part per trillion of the Earth's crust; essentially all natural radium is Ra. Thus, radium is found in tiny quantities in the uranium ore uraninite and various other uranium minerals, and in even tinier quantities in thorium minerals. One ton of pitchblende typically yields about one seventh of a gram of radium. One kilogram of the Earth's crust contains about 900 picograms of radium, and one liter of sea water contains about 89 femtograms of radium.\n\nUranium had no large scale application in the late 19th century and therefore no large uranium mines existed. In the beginning the only large source for uranium ore was the silver mines in Joachimsthal, Austria-Hungary (now Jáchymov, Czech Republic). The uranium ore was only a by-product of the mining activities.\n\nIn the first extraction of radium Curie used the residues after extraction of uranium from pitchblende. The uranium had been extracted by dissolution in sulfuric acid leaving radium sulfate, which is similar to barium sulfate but even less soluble in the residues. The residues also contained rather substantial amounts of barium sulfate which thus acted as a carrier for the radium sulfate. The first steps of the radium extraction process involved boiling with sodium hydroxide followed by hydrochloric acid treatment to remove as much as possible of other compounds. The remaining residue was then treated with sodium carbonate to convert the barium sulfate into barium carbonate carrying the radium, thus making it soluble in hydrochloric acid. After dissolution the barium and radium are reprecipitated as sulfates and this was repeated one or few times, for further purification of the mixed sulfate. Some impurities, that form insoluble sulfides, were removed by treating the chloride solution with hydrogen sulfide followed by filtering. When the mixed sulfate were pure enough they were once more converted to mixed chloride and barium and radium were separated by fractional crystallisation while monitoring the progress using a spectroscope (radium gives characteristic red lines in contrast to the green barium lines), and the electroscope.\n\nAfter the isolation of radium by Marie and Pierre Curie from uranium ore from Joachimsthal several scientists started to isolate radium in small quantities. Later small companies purchased mine tailings from Joachimsthal mines and started isolating radium. In 1904 the Austrian government nationalised the mines and stopped exporting raw ore. For some time the radium availability was low.\n\nThe formation of an Austrian monopoly and the strong urge of other countries to have access to radium led to a worldwide search for uranium ores. The United States took over as leading producer in the early 1910s. The Carnotite sands in Colorado provide some of the element, but richer ores are found in the Congo and the area of the Great Bear Lake and the Great Slave Lake of northwestern Canada. Neither of the deposits is mined for radium but the uranium content makes mining profitable.\n\nThe Curies' process was still used for industrial radium extraction in 1940, but mixed bromides were then used for the fractionation. If the barium content of the uranium ore is not high enough it is easy to add some to carry the radium. These processes were applied to high grade uranium ores but may not work well with low grade ores.\n\nSmall amounts of radium were still extracted from uranium ore by this method of mixed precipitation and ion exchange as late as the 1990s, but today they are extracted only from spent nuclear fuel. and it is still in this range today, while the annual production of pure radium compounds is only about 100 g in total today. The chief radium-producing countries are Belgium, Canada, the Czech Republic, Slovakia, the United Kingdom, and Russia. The amounts of radium produced were and are always relatively small; for example, in 1918, 13.6 g of radium were produced in the United States. In 1954, the total worldwide supply of purified radium amounted to about 5 pounds (2.3 kg). The metal is isolated by reducing radium oxide with aluminium metal in a vacuum at 1200 °C.\n\nRadium was discovered by Marie Sklodowska-Curie and her husband Pierre Curie on 21 December 1898, in a uraninite sample. While studying the mineral earlier, the Curies removed uranium from it and found that the remaining material was still radioactive. They separated out an element similar to bismuth from pitchblende in July 1898, that turned out to be polonium. They then separated out a radioactive mixture consisting mostly of two components: compounds of barium, which gave a brilliant green flame color, and unknown radioactive compounds which gave carmine spectral lines that had never been documented before. The Curies found the radioactive compounds to be very similar to the barium compounds, except that they were more insoluble. This made it possible for the Curies to separate out the radioactive compounds and discover a new element in them. The Curies announced their discovery to the French Academy of Sciences on 26 December 1898. The naming of radium dates to about 1899, from the French word \"radium\", formed in Modern Latin from \"radius\" (\"ray\"): this was in recognition of radium's power of emitting energy in the form of rays.\n\nIn 1910, radium was isolated as a pure metal by Marie Curie and André-Louis Debierne through the electrolysis of a pure radium chloride (RaCl) solution using a mercury cathode, producing a radium–mercury amalgam. This amalgam was then heated in an atmosphere of hydrogen gas to remove the mercury, leaving pure radium metal. The same year, E. Eoler isolated radium by thermal decomposition of its azide, Ra(N). Radium metal was first industrially produced in the beginning of the 20th century by Biraco, a subsidiary company of Union Minière du Haut Katanga (UMHK) in its Olen plant in Belgium.\n\nThe common historical unit for radioactivity, the curie, is based on the radioactivity of Ra.\n\nSome of the few practical uses of radium are derived from its radioactive properties. More recently discovered radioisotopes, such as cobalt-60 and caesium-137, are replacing radium in even these limited uses because several of these isotopes are more powerful emitters, safer to handle, and available in more concentrated form.\n\nRadium was formerly used in self-luminous paints for watches, nuclear panels, aircraft switches, clocks, and instrument dials. A typical self-luminous watch that uses radium paint contains around 1 microgram of radium. In the mid-1920s, a lawsuit was filed against the United States Radium Corporation by five dying \"Radium Girl\" dial painters who had painted radium-based luminous paint on the dials of watches and clocks. The dial painters routinely licked their brushes to give them a fine point, thereby ingesting radium. Their exposure to radium caused serious health effects which included sores, anemia, and bone cancer. This is because radium is treated as calcium by the body, and deposited in the bones, where radioactivity degrades marrow and can mutate bone cells.\n\nDuring the litigation, it was determined that the company's scientists and management had taken considerable precautions to protect themselves from the effects of radiation, yet had not seen fit to protect their employees. Additionally, for several years the companies had attempted to cover up the effects and avoid liability by insisting that the Radium Girls were instead suffering from syphilis. This complete disregard for employee welfare had a significant impact on the formulation of occupational disease labor law.\n\nAs a result of the lawsuit, the adverse effects of radioactivity became widely known, and radium-dial painters were instructed in proper safety precautions and provided with protective gear. In particular, dial painters no longer licked paint brushes to shape them (which caused some ingestion of radium salts). Radium was still used in dials as late as the 1960s, but there were no further injuries to dial painters. This highlighted that the harm to the Radium Girls could easily have been avoided.\n\nFrom the 1960s the use of radium paint was discontinued. In many cases luminous dials were implemented with non-radioactive fluorescent materials excited by light; such devices glow in the dark after exposure to light, but the glow fades. Where long-lasting self-luminosity in darkness was required, safer radioactive promethium-147 (half-life 2.6 years) or tritium (half-life 12 years) paint was used; both continue to be used today. These had the added advantage of not degrading the phosphor over time, unlike radium. Tritium emits very low-energy beta radiation (even lower-energy than the beta radiation emitted by promethium) which cannot penetrate the skin, rather than the penetrating gamma radiation of radium and is regarded as safer.\n\nClocks, watches, and instruments dating from the first half of the 20th century, often in military applications, may have been painted with radioactive luminous paint. They are usually no longer luminous; however, this is not due to radioactive decay of the radium (which has a half-life of 1600 years) but to the fluorescence of the zinc sulfide fluorescent medium being worn out by the radiation from the radium. The appearance of an often thick layer of green or yellowish brown paint in devices from this period suggests a radioactive hazard. The radiation dose from an intact device is relatively low and usually not an acute risk; but the paint is dangerous if released and inhaled or ingested.\n\nRadium was once an additive in products such as toothpaste, hair creams, and even food items due to its supposed curative powers. Such products soon fell out of vogue and were prohibited by authorities in many countries after it was discovered they could have serious adverse health effects. (See, for instance, \"Radithor\" or \"Revigator\" types of \"Radium water\" or \"Standard Radium Solution for Drinking\".) Spas featuring radium-rich water are still occasionally touted as beneficial, such as those in Misasa, Tottori, Japan. In the U.S., nasal radium irradiation was also administered to children to prevent middle-ear problems or enlarged tonsils from the late 1940s through the early 1970s.\n\nRadium (usually in the form of radium chloride or radium bromide) was used in medicine to produce radon gas which in turn was used as a cancer treatment; for example, several of these radon sources were used in Canada in the 1920s and 1930s. However, many treatments that were used in the early 1900s are not used anymore because of the harmful effects radium bromide exposure caused. Some examples of these effects are anaemia, cancer, and genetic mutations. Safer gamma emitters such as Co, which is less costly and available in larger quantities, are usually used today to replace the historical use of radium in this application.\n\nEarly in the 1900s, biologists used radium to induce mutations and study genetics. As early as 1904, Daniel MacDougal used radium in an attempt to determine whether it could provoke sudden large mutations and cause major evolutionary shifts. Thomas Hunt Morgan used radium to induce changes resulting in white-eyed fruit flies.\nNobel-winning biologist Hermann Muller briefly studied the effects of radium on fruit fly mutations before turning to more affordable x-ray experiments.\n\nHoward Atwood Kelly, one of the founding physicians of Johns Hopkins Hospital, was a major pioneer in the medical use of radium to treat cancer. His first patient was his own aunt in 1904, who died shortly after surgery. Kelly was known to use excessive amounts of radium to treat various cancers and tumors. As a result, some of his patients died from radium exposure. His method of radium application was inserting a radium capsule near the affected area then sewing the radium \"points\" directly to the tumor. This was the same method used to treat Henrietta Lacks, the host of the original HeLa cells, for cervical cancer. Currently, safer and more available radioisotopes are used instead.\n\nThe isotope Ra (under the trade name Xofigo) was approved by the United States Food and Drug Administration in 2013 for use in medicine as a cancer treatment of bone metastasis. The main indication of treatment with Xofigo is the therapy of bony metastases from castration-resistant prostate cancer due to the favourable characteristics of this alpha-emitter radiopharmaceutical. Ra has also been used in experiments concerning therapeutic irradiation, as it is the only reasonably long-lived radium isotope which does not have radon as one of its daughters.\n\nRadium is still used today as a radiation source in some industrial radiography devices to check for flawed metallic parts, similarly to X-ray imaging. When mixed with beryllium, radium acts as a neutron source. Radium-beryllium neutron sources are still sometimes used even today, but other materials such as polonium are now more common: about 1500 polonium-beryllium neutron sources, with an individual activity of , have been used annually in Russia. These RaBeF-based (α, n) neutron sources have been deprecated despite the high number of neutrons they emit (1.84×10 neutrons per second) in favour of Am–Be sources. The main disposal of Ra is via irradiation in a nuclear reactor to form Ac.\n\nRadium is highly radioactive and its immediate daughter, radon gas, is also radioactive. When ingested, 80% of the ingested radium leaves the body through the feces, while the other 20% goes into the bloodstream, mostly accumulating in the bones. Exposure to radium, internal or external, can cause cancer and other disorders, because radium and radon emit alpha and gamma rays upon their decay, which kill and mutate cells. At the time of the Manhattan Project in 1944, the \"tolerance dose\" for workers was set at 0.1 micrograms of ingested radium.\n\nSome of the biological effects of radium were apparent from the start. The first case of so-called \"radium-dermatitis\" was reported in 1900, only 2 years after the element's discovery. The French physicist Antoine Becquerel carried a small ampoule of radium in his waistcoat pocket for 6 hours and reported that his skin became ulcerated. Pierre and Marie Curie were so intrigued by radiation that they sacrificed their own health to learn more about it. Pierre Curie attached a tube filled with radium to his arm for ten hours, which resulted in the appearance of a skin lesion, suggesting the use of radium to attack cancerous tissue as it had attacked healthy tissue. Handling of radium has been blamed for Marie Curie's death due to aplastic anemia. A significant amount of radium's danger comes from its daughter radon: being a gas, it can enter the body far more readily than can its parent radium.\n\nToday, Ra is considered to be the most toxic of the quantity radioelements, and it must be handled in tight glove boxes with significant airstream circulation that is then treated to avoid escape of its daughter Rn to the environment. Old ampoules containing radium solutions must be opened with care because radiolytic decomposition of water can produce an overpressure of hydrogen and oxygen gas.\n\n\n\n"}
{"id": "25603", "url": "https://en.wikipedia.org/wiki?curid=25603", "title": "Rhenium", "text": "Rhenium\n\nRhenium is a chemical element with symbol Re and atomic number 75. It is a silvery-white, heavy, third-row transition metal in group 7 of the periodic table. With an estimated average concentration of 1 part per billion (ppb), rhenium is one of the rarest elements in the Earth's crust. Rhenium has the third-highest melting point and second-highest boiling point of any element at 5903 K. Rhenium resembles manganese and technetium chemically and is mainly obtained as a by-product of the extraction and refinement of molybdenum and copper ores. Rhenium shows in its compounds a wide variety of oxidation states ranging from −1 to +7.\n\nDiscovered in 1925, rhenium was the last stable element to be discovered. It was named after the river Rhine in Europe.\n\nNickel-based superalloys of rhenium are used in the combustion chambers, turbine blades, and exhaust nozzles of jet engines. These alloys contain up to 6% rhenium, making jet engine construction the largest single use for the element, with the chemical industry's catalytic uses being next-most important. Because of the low availability relative to demand, rhenium is expensive, with an average price of approximately US$2,750 per kilogram (US$85.53 per troy ounce) ; it is also of critical strategic military importance, for its use in high performance military jet and rocket engines.\n\nRhenium ( meaning: \"Rhine\") was the last-discovered of the elements that have a stable isotope (other new elements discovered in nature since then, such as francium, are radioactive). The existence of a yet-undiscovered element at this position in the periodic table had been first predicted by Dmitri Mendeleev. Other calculated information was obtained by Henry Moseley in 1914. It is generally considered to have been discovered by Walter Noddack, Ida Tacke, and Otto Berg in Germany. In 1925 they reported that they had detected the element in platinum ore and in the mineral columbite. They also found rhenium in gadolinite and molybdenite. In 1928 they were able to extract 1 g of the element by processing 660 kg of molybdenite. It was estimated in 1968 that 75% of the rhenium metal in the United States was used for research and the development of refractory metal alloys. It took several years from that point before the superalloys became widely used.\n\nIn 1908, Japanese chemist Masataka Ogawa announced that he had discovered the 43rd element and named it \"nipponium\" (Np) after Japan (\"Nippon\" in Japanese). However, recent analysis indicated the presence of rhenium (element 75), not element 43, although this reinterpretation is controversial. The symbol Np was later used for the element neptunium, and the name \"nihonium\", also named after Japan, along with symbol Nh, was later used for element 113. Element 113 was also discovered by a team of Japanese scientists and was named in respectful homage to Ogawa's work.\n\nRhenium is a silvery-white metal with one of the highest melting points of all elements, exceeded by only tungsten and carbon. It also has one of the highest boiling points of all elements. It is also one of the densest, exceeded only by platinum, iridium and osmium. Rhenium has a hexagonal close-packed crystal structure, with lattice parameters \"a\" = 276.1 pm and \"c\" = 445.6 pm.\n\nIts usual commercial form is a powder, but this element can be consolidated by pressing and sintering in a vacuum or hydrogen atmosphere. This procedure yields a compact solid having a density above 90% of the density of the metal. When annealed this metal is very ductile and can be bent, coiled, or rolled. Rhenium-molybdenum alloys are superconductive at 10 K; tungsten-rhenium alloys are also superconductive around 4–8 K, depending on the alloy. Rhenium metal superconducts at 1.697 ± 0.006 K.\nIn bulk form and at room temperature and atmospheric pressure, the element resists alkalis, sulfuric acid, hydrochloric acid, dilute (but not concentrated) nitric acid, and aqua regia.\n\nRhenium has one stable isotope, rhenium-185, which nevertheless occurs in minority abundance, a situation found only in two other elements (indium and tellurium). Naturally occurring rhenium is only 37.4% Re, and 62.6% Re, which is unstable but has a very long half-life (≈10 years). This lifetime can be greatly affected by the charge state of rhenium atom. The beta decay of Re is used for rhenium-osmium dating of ores. The available energy for this beta decay (2.6 keV) is one of the lowest known among all radionuclides. The isotope rhenium-186m is notable as being one of the longest lived metastable isotopes with a half-life of around 200,000 years. There are twenty-five other recognized radioactive isotopes of rhenium.\n\nRhenium compounds are known for all the oxidation states between −3 and +7 except −2. The oxidation states +7, +6, +4, and +2 are the most common. Rhenium is most available commercially as salts of perrhenate, including sodium and ammonium perrhenates. These are white, water-soluble compounds.\n\nThe most common rhenium chlorides are ReCl, ReCl, ReCl, and ReCl. The structures of these compounds often feature extensive Re-Re bonding, which is characteristic of this metal in oxidation states lower than VII. Salts of [ReCl] feature a quadruple metal-metal bond. Although the highest rhenium chloride features Re(VI), fluorine gives the d Re(VII) derivative rhenium heptafluoride. Bromides and iodides of rhenium are also well known.\n\nLike tungsten and molybdenum, with which it shares chemical similarities, rhenium forms a variety of oxyhalides. The oxychlorides are most common, and include ReOCl, ReOCl.\n\nThe most common oxide is the volatile colourless ReO. Rhenium trioxide ReO adopts a perovskite-like structure. Other oxides include ReO, ReO, and ReO. The sulfides are ReS and ReS. Perrhenate salts can be converted to tetrathioperrhenate by the action of ammonium hydrosulfide.\n\nRhenium diboride (ReB) is a hard compound having the hardness similar to that of tungsten carbide, silicon carbide, titanium diboride or zirconium diboride.\n\nDirhenium decacarbonyl is the most common entry to organorhenium chemistry. Its reduction with sodium amalgam gives Na[Re(CO)] with rhenium in the formal oxidation state −1. Dirhenium decacarbonyl can be oxidised with bromine to bromopentacarbonylrhenium(I):\n\nReduction of this pentacarbonyl with zinc and acetic acid gives pentacarbonylhydridorhenium:\n\nMethylrhenium trioxide (\"MTO\"), CHReO is a volatile, colourless solid has been used as a catalyst in some laboratory experiments. It can be prepared by many routes, a typical method is the reaction of ReO and tetramethyltin:\nAnalogous alkyl and aryl derivatives are known. MTO catalyses for the oxidations with hydrogen peroxide. Terminal alkynes yield the corresponding acid or ester, internal alkynes yield diketones, and alkenes give epoxides. MTO also catalyses the conversion of aldehydes and diazoalkanes into an alkene.\n\nA distinctive derivative of rhenium is nonahydridorhenate, originally thought to be the \"rhenide\" anion, Re, but actually containing the anion in which the oxidation state of rhenium is +7.\n\nRhenium is one of the rarest elements in Earth's crust with an average concentration of 1 ppb; other sources quote the number of 0.5 ppb making it the 77th most abundant element in Earth's crust. Rhenium is probably not found free in nature (its possible natural occurrence is uncertain), but occurs in amounts up to 0.2% in the mineral molybdenite (which is primarily molybdenum disulfide), the major commercial source, although single molybdenite samples with up to 1.88% have been found. Chile has the world's largest rhenium reserves, part of the copper ore deposits, and was the leading producer as of 2005. It was only recently that the first rhenium mineral was found and described (in 1994), a rhenium sulfide mineral (ReS) condensing from a fumarole on Russia's Kudriavy volcano, Iturup island, in the Kuril Islands. Kudryavy discharges up to 20–60 kg rhenium per year mostly in the form of rhenium disulfide. Named rheniite, this rare mineral commands high prices among collectors. \n\nCommercial rhenium is extracted from molybdenum roaster-flue gas obtained from copper-sulfide ores. Some molybdenum ores contain 0.001% to 0.2% rhenium. Rhenium(VII) oxide and perrhenic acid readily dissolve in water; they are leached from flue dusts and gasses and extracted by precipitating with potassium or ammonium chloride as the perrhenate salts, and purified by recrystallization. Total world production is between 40 and 50 tons/year; the main producers are in Chile, the United States, Peru, and Poland. Recycling of used Pt-Re catalyst and special alloys allow the recovery of another 10 tons per year. Prices for the metal rose rapidly in early 2008, from $1000–$2000 per kg in 2003–2006 to over $10,000 in February 2008. The metal form is prepared by reducing ammonium perrhenate with hydrogen at high temperatures:\n\nRhenium is added to high-temperature superalloys that are used to make jet engine parts, using 70% of the worldwide rhenium production. Another major application is in platinum–rhenium catalysts, which are primarily used in making lead-free, high-octane gasoline.\n\nThe nickel-based superalloys have improved creep strength with the addition of rhenium. The alloys normally contain 3% or 6% of rhenium. Second-generation alloys contain 3%; these alloys were used in the engines for the F-15 and F-16, whereas the newer single-crystal third-generation alloys contain 6% of rhenium; they are used in the F-22 and F-35 engines. Rhenium is also used in the superalloys, such as CMSX-4 (2nd gen) and CMSX-10 (3rd gen) that are used in industrial gas turbine engines like the GE 7FA. Rhenium can cause superalloys to become microstructurally unstable, forming undesirable TCP (topologically close packed) phases. In 4th- and 5th-generation superalloys, ruthenium is used to avoid this effect. Among others the new superalloys are EPM-102 (with 3% Ru) and TMS-162 (with 6% Ru), as well as TMS-138 and TMS-174.\n\nFor 2006, the consumption is given as 28% for General Electric, 28% Rolls-Royce plc and 12% Pratt & Whitney, all for superalloys, whereas the use for catalysts only accounts for 14% and the remaining applications use 18%. In 2006, 77% of the rhenium consumption in the United States was in alloys. The rising demand for military jet engines and the constant supply made it necessary to develop superalloys with a lower rhenium content. For example, the newer CFM International CFM56 high-pressure turbine (HPT) blades will use Rene N515 with a rhenium content of 1.5% instead of Rene N5 with 3%.\n\nRhenium improves the properties of tungsten. Tungsten-rhenium alloys are more ductile at low temperature, allowing them to be more easily machined. The high-temperature stability is also improved. The effect increases with the rhenium concentration, and therefore tungsten alloys are produced with up to 27% of Re, which is the solubility limit. Tungsten-rhenium wire was originally created in efforts to develop a wire that was more ductile after recrystallization. This allows the wire to meet specific performance objectives, including superior vibration resistance, improved ductility, and higher resistivity. One application for the tungsten-rhenium alloys is X-ray sources. The high melting point of both compounds, together with the high atomic mass, makes them stable against the prolonged electron impact. Rhenium tungsten alloys are also applied as thermocouples to measure temperatures up to 2200 °C.\n\nThe high temperature stability, low vapor pressure, good wear resistance and ability to withstand arc corrosion of rhenium are useful in self-cleaning electrical contacts. In particular, the discharge occurring during the switching oxidizes the contacts. However, rhenium oxide ReO has poor stability (sublimes at ~360 °C) and therefore is removed during the discharge.\n\nRhenium has a high melting point and a low vapor pressure similar to tantalum and tungsten. Therefore, rhenium filaments exhibit a higher stability if the filament is operated not in vacuum, but in oxygen-containing atmosphere. Those filaments are widely used in mass spectrometers, in ion gauges and in photoflash lamps in photography.\n\nRhenium in the form of rhenium-platinum alloy is used as catalyst for catalytic reforming, which is a chemical process to convert petroleum refinery naphthas with low octane ratings into high-octane liquid products. Worldwide, 30% of catalysts used for this process contain rhenium. The olefin metathesis is the other reaction for which rhenium is used as catalyst. Normally ReO on alumina is used for this process. Rhenium catalysts are very resistant to chemical poisoning from nitrogen, sulfur and phosphorus, and so are used in certain kinds of hydrogenation reactions.\n\nThe isotopes Re and Re are radioactive and are used for treatment of liver cancer. They both have similar penetration depth in tissue (5 mm for Re and 11 mm for Re), but Re has advantage of longer lifetime (90 hours vs. 17 hours).\n\nRe is also being used experimentally in a novel treatment of pancreatic cancer where it is delivered by means of the bacterium \"Listeria monocytogenes\".\n\nRelated by periodic trends, rhenium has a similar chemistry to that of technetium; work done to label rhenium onto target compounds can often be translated to technetium. This is useful for radiopharmacy, where it is difficult to work with technetium – especially the 99m isotope used in medicine – due to its expense and short half-life.\n\nVery little is known about the toxicity of rhenium and its compounds because they are used in very small amounts. Soluble salts, such as the rhenium halides or perrhenates, could be hazardous due to elements other than rhenium or due to rhenium itself. Only a few compounds of rhenium have been tested for their acute toxicity; two examples are potassium perrhenate and rhenium trichloride, which were injected as a solution into rats. The perrhenate had an LD value of 2800 mg/kg after seven days (this is very low toxicity, similar to that of table salt) and the rhenium trichloride showed LD of 280 mg/kg.\n\n"}
{"id": "25604", "url": "https://en.wikipedia.org/wiki?curid=25604", "title": "Radon", "text": "Radon\n\nRadon is a chemical element with symbol Rn and atomic number 86. It is a radioactive, colorless, odorless, tasteless noble gas. It occurs naturally as an intermediate step in the normal radioactive decay chains through which thorium and uranium slowly decay into lead; radon, itself, is a decay product of radium. Its most stable isotope, Rn, has a half-life of 3.8 days. Since thorium and uranium are two of the most common radioactive elements on Earth, and since their isotopes have very long half-lives, on the order of billions of years, radon will be present in nature long into the future in spite of its short half-life as it is continually being regenerated.\n\nUnlike all the other intermediate elements in the aforementioned decay chains, radon is, under normal conditions, gaseous and easily inhaled. Radon gas is a health hazard. It is often the single largest contributor to an individual's background radiation dose, but due to local differences in geology, the level of the radon-gas hazard differs from location to location. Despite its short lifetime, radon gas from natural sources can accumulate in buildings, especially, due to its high density, in low areas such as basements and crawl spaces. Radon can also occur in ground water – for example, in some spring waters and hot springs.\n\nEpidemiological studies have shown a clear link between breathing high concentrations of radon and incidence of lung cancer. Radon is a contaminant that affects indoor air quality worldwide. According to the United States Environmental Protection Agency, radon is the second most frequent cause of lung cancer, after cigarette smoking, causing 21,000 lung cancer deaths per year in the United States. About 2,900 of these deaths occur among people who have never smoked. While radon is the second most frequent cause of lung cancer, it is the number one cause among non-smokers, according to EPA estimates. As radon itself decays, it produces other radioactive elements called radon daughters (also known as radon progeny) or decay products. Unlike the gaseous radon itself, radon daughters are solids and stick to surfaces, such as dust particles in the air. If such contaminated dust is inhaled, these particles can also cause lung cancer.\n\nRadon is a colorless, odorless, and tasteless gas and therefore not detectable by human senses alone. At standard temperature and pressure, radon forms a monatomic gas with a density of 9.73 kg/m, about 8 times the density of the Earth's atmosphere at sea level, 1.217 kg/m. Radon is one of the densest gases at room temperature and is the densest of the noble gases. Although colorless at standard temperature and pressure, when cooled below its freezing point of , radon emits a brilliant radioluminescence that turns from yellow to orange-red as the temperature lowers. Upon condensation, radon glows because of the intense radiation it produces. Radon is sparingly soluble in water, but more soluble than lighter noble gases. Radon is appreciably more soluble in organic liquids than in water.\n\nBeing a noble gas, radon is chemically not very reactive. However, the 3.8-day half-life of radon-222 makes it useful in physical sciences as a natural tracer. Because radon is a gas at standard conditions, unlike its parents, it can readily be extracted from them for research.\n\nRadon is a member of the zero-valence elements that are called noble gases. It is inert to most common chemical reactions, such as combustion, because the outer valence shell contains eight electrons. This produces a stable, minimum energy configuration in which the outer electrons are tightly bound. 1037 kJ/mol is required to extract one electron from its shells (also known as the first ionization energy). In accordance with periodic trends, radon has a lower electronegativity than the element one period before it, xenon, and is therefore more reactive. Early studies concluded that the stability of radon hydrate should be of the same order as that of the hydrates of chlorine () or sulfur dioxide (), and significantly higher than the stability of the hydrate of hydrogen sulfide ().\n\nBecause of its cost and radioactivity, experimental chemical research is seldom performed with radon, and as a result there are very few reported compounds of radon, all either fluorides or oxides. Radon can be oxidized by powerful oxidizing agents such as fluorine, thus forming radon difluoride. It decomposes back to its elements at a temperature of above 250 °C, and is reduced by water to radon gas and hydrogen fluoride: it may also be reduced back to its elements by hydrogen gas. It has a low volatility and was thought to be . Because of the short half-life of radon and the radioactivity of its compounds, it has not been possible to study the compound in any detail. Theoretical studies on this molecule predict that it should have a Rn–F bond distance of 2.08 Å, and that the compound is thermodynamically more stable and less volatile than its lighter counterpart . The octahedral molecule was predicted to have an even lower enthalpy of formation than the difluoride. The higher fluorides RnF and RnF have been claimed, and are calculated to be stable, but it is doubtful whether they have yet been synthesized. The [RnF] ion is believed to form by the following reaction:\n\nFor this reason, antimony pentafluoride together with chlorine trifluoride and NFSbF have been considered for radon gas removal in uranium mines due to the formation of radon–fluorine compounds; furthermore, the existence of RnF allows for safer handling of its parent radium as the fluoride, as the alpha radiation from Ra is not strong enough to cause radiolysis of the strong Ra–F bond and thus RaF decays to form involatile RnF. Additionally, salts of the [RnF] cation with the anions , , and are known. Radon is also oxidised by dioxygen difluoride at −100 °C.\n\nRadon oxides are among the few other reported ; only the trioxide has been confirmed. Higher fluorides may have been observed in experiments where unknown radon-containing products distilled together with xenon hexafluoride, and perhaps in the production of radon trioxide: these may have been RnF, RnF, or both. Extrapolation down the noble gas group would suggest also the possible existence of RnO, RnO, and RnOF, as well as the first chemically stable noble gas chlorides RnCl and RnCl, but none of these have yet been found. Radon carbonyl RnCO has been predicted to be stable and to have a linear molecular geometry. The molecules and RnXe were found to be significantly stabilized by spin-orbit coupling. Radon caged inside a fullerene has been proposed as a drug for tumors. Despite the existence of Xe(VIII), no Rn(VIII) compounds have been claimed to exist; RnF should be highly unstable chemically (XeF is thermodynamically unstable). It is predicted that the most stable Rn(VIII) compound would be barium perradate (BaRnO), analogous to barium perxenate. The instability of Rn(VIII) is due to the relativistic stabilization of the 6s shell, also known as the inert pair effect.\n\nRadon reacts with the liquid halogen fluorides ClF, ClF, ClF, BrF, BrF, and IF to form RnF. In halogen fluoride solution, radon is involatile and exists as the RnF and Rn cations; addition of fluoride anions results in the formation of the complexes and , paralleling the chemistry of beryllium(II) and aluminium(III). The standard electrode potential of the Rn/Rn couple has been estimated as +2.0 V.\n\nRadon has no stable isotopes. Thirty-seven radioactive isotopes have been characterized, with atomic masses ranging from 193 to 229. The most stable isotope is Rn, which is a decay product of Ra, a decay product of U. A trace amount of the (highly unstable) isotope Rn is also among the daughters of Rn.\n\nThree other radon isotopes have a half-life of over an hour: Rn, Rn and Rn. The Rn isotope is a natural decay product of the most stable thorium isotope (Th), and is commonly referred to as thoron. It has a half-life of 55.6 seconds and also emits alpha radiation. Similarly, Rn is derived from the most stable isotope of actinium (Ac)—named \"actinon\"—and is an alpha emitter with a half-life of 3.96 seconds. No radon isotopes occur significantly in the neptunium (Np) decay series, though a trace amount of the (extremely unstable) isotope Rn is produced.\n\nRn belongs to the radium and uranium-238 decay chain, and has a half-life of 3.8235 days. Its four first products (excluding marginal decay schemes) are very short-lived, meaning that the corresponding disintegrations are indicative of the initial radon distribution. Its decay goes through the following sequence:\n\nThe radon equilibrium factor is the ratio between the activity of all short-period radon progenies (which are responsible for most of radon's biological effects), and the activity that would be at equilibrium with the radon parent.\n\nIf a closed volume is constantly supplied with radon, the concentration of short-lived isotopes will increase until an equilibrium is reached where the rate of decay of each decay product will equal that of the radon itself. The equilibrium factor is 1 when both activities are equal, meaning that the decay products have stayed close to the radon parent long enough for the equilibrium to be reached, within a couple of hours. Under these conditions each additional pCi/L of radon will increase exposure, by 0.01 WL (Working Level -a measure of radioactivity commonly used in mining. A detailed explanation of WL is given in Concentration Units). These conditions are not always met; in many homes, the equilibrium fraction is typically 40%; that is, there will be 0.004 WL of daughters for each pCi/L of radon in air. Pb takes much longer (decades) to come in equilibrium with radon, but, if the environment permits accumulation of dust over extended periods of time, Pb and its decay products may contribute to overall radiation levels as well.\n\nBecause of their electrostatic charge, radon progenies adhere to surfaces or dust particles, whereas gaseous radon does not. Attachment removes them from the air, usually causing the equilibrium factor in the atmosphere to be less than one. The equilibrium factor is also lowered by air circulation or air filtration devices, and is increased by airborne dust particles, including cigarette smoke. In high concentrations, airborne radon isotopes contribute significantly to human health risk. The equilibrium factor found in epidemiological studies is 0.4.\n\nRadon was the fifth radioactive element to be discovered, in 1899 by Ernest Rutherford and Robert B. Owens, after uranium, thorium, radium and polonium. In 1900 Friedrich Ernst Dorn reported some experiments in which he noticed that radium compounds emanate a radioactive gas he named \"Radium Emanation\" (\"Ra Em\"). Before that, in 1899, Pierre and Marie Curie observed that the gas emitted by radium remained radioactive for a month. Later that year, Robert B. Owens and Ernest Rutherford, at McGill University in Montreal, noticed variations when trying to measure radiation from thorium oxide. Rutherford noticed that the compounds of thorium continuously emit a radioactive gas that retains the radioactive powers for several minutes, and called this gas \"emanation\" (from Latin \"emanare\"—to elapse and \"emanatio\"—expiration), and later \"Thorium Emanation\" (\"Th Em\"). In 1901, he demonstrated that the emanations are radioactive, but credited the Curies for the discovery of the element. In 1903, similar emanations were observed from actinium by André-Louis Debierne and were called \"Actinium Emanation\" (\"Ac Em\").\n\nSeveral names were suggested for these three gases: \"exradio\", \"exthorio\", and \"exactinio\" in 1904; \"radon\", \"thoron\", and \"akton\" in 1918; \"radeon\", \"thoreon\", and \"actineon\" in 1919, and eventually \"radon\", \"thoron\", and \"actinon\" in 1920. The likeness of the spectra of these three gases with those of argon, krypton, and xenon, and their observed chemical inertia led Sir William Ramsay to suggest in 1904 that the \"emanations\" might contain a new element of the noble gas family.\n\nIn 1910, Ramsay and Robert Whytlaw-Gray isolated radon, determined its density, and determined that it was the heaviest known gas. They wrote that \"L'expression de l'émanation du radium est fort incommode\", (the expression 'radium emanation' is very awkward) and suggested the new name niton (Nt) (from the Latin \"nitens\" meaning \"shining\") to emphasize the radioluminescence property, and in 1912 it was accepted by the International Commission for Atomic Weights. In 1923, the International Committee for Chemical Elements and International Union of Pure and Applied Chemistry (IUPAC) chose among the names radon (Rn), thoron (Tn), and actinon (An). Later, when isotopes were numbered instead of named, the element took the name of the most stable isotope, \"radon\", while Tn was renamed Rn and An was renamed Rn, which caused some confusion in the literature regarding the element's discovery as while Dorn had discovered radon the isotope, he had not been the first to discover radon the element. As late as the 1960s, the element was also referred to simply as \"emanation\". The first synthesized compound of radon, radon fluoride, was obtained in 1962. Even today, the word \"radon\" may refer to either the element or its isotope Rn, with \"thoron\" remaining in use as a short name for Rn to stem this ambiguity.\n\nThe danger of high exposure to radon in mines, where exposures can reach 1,000,000 Bq/m, has long been known. In 1530, Paracelsus described a wasting disease of miners, the \"mala metallorum\", and Georg Agricola recommended ventilation in mines to avoid this mountain sickness (\"Bergsucht\"). In 1879, this condition was identified as lung cancer by Herting and Hesse in their investigation of miners from Schneeberg, Germany. The first major studies with radon and health occurred in the context of uranium mining in the Joachimsthal region of Bohemia. In the US, studies and mitigation only followed decades of health effects on uranium miners of the Southwestern United States employed during the early Cold War; standards were not implemented until 1971.\n\nThe presence of radon in indoor air was documented as early as 1950. Beginning in the 1970s research was initiated to address sources of indoor radon, determinants of concentration, health effects, and mitigation approaches. In the United States, the problem of indoor radon received widespread publicity and intensified investigation after a widely publicized incident in 1984. During routine monitoring at a Pennsylvania nuclear power plant, a worker was found to be contaminated with radioactivity. A high concentration of radon in his home was subsequently identified as responsible.\n\nAll discussions of radon concentrations in the environment refer to Rn. While the average rate of production of Rn (from the thorium decay series) is about the same as that of Rn, the amount of Rn in the environment is much less than that of Rn because of the short half-life of Rn (55 seconds, versus 3.8 days respectively).\n\nRadon concentration in the atmosphere is usually measured in becquerel per cubic meter (Bq/m), the SI derived unit. Another unit of measurement common in the US is picocuries per liter (pCi/L); 1 pCi/L=37 Bq/m. Typical domestic exposures average about 48 Bq/m indoors, though this varies widely, and 15 Bq/m outdoors.\n\nIn the mining industry, the exposure is traditionally measured in \"working level\" (WL), and the cumulative exposure in \"working level month\" (WLM); 1 WL equals any combination of short-lived Rn daughters (Po, Pb, Bi, and Po) in 1 liter of air that releases 1.3 × 10 MeV of potential alpha energy; one WL is equivalent to 2.08 × 10 joules per cubic meter of air (J/m). The SI unit of cumulative exposure is expressed in joule-hours per cubic meter (J·h/m). One WLM is equivalent to 3.6 × 10 J·h/m. An exposure to 1 WL for 1 working month (170 hours) equals 1 WLM cumulative exposure. A cumulative exposure of 1 WLM is roughly equivalent to living one year in an atmosphere with a radon concentration of 230 Bq/m.\n\nRn decays to Pb and other radioisotopes. The levels of Pb can be measured. The rate of deposition of this radioisotope is weather-dependent.\n\nRadon concentrations found in natural environments are much too low to be detected by chemical means. A 1000 Bq/m (relatively high) concentration corresponds to 0.17 picogram per cubic meter. The average concentration of radon in the atmosphere is about 6 molar percent, or about 150 atoms in each ml of air. The radon activity of the entire Earth's atmosphere originates from only a few tens of grams of radon, consistently replaced by decay of larger amounts of radium and uranium.\n\nRadon is produced by the radioactive decay of radium-226, which is found in uranium ores, phosphate rock, shales, igneous and metamorphic rocks such as granite, gneiss, and schist, and to a lesser degree, in common rocks such as limestone. Every square mile of surface soil, to a depth of 6 inches (2.6 km to a depth of 15 cm), contains approximately 1 gram of radium, which releases radon in small amounts to the atmosphere. On a global scale, it is estimated that 2,400 million curies (90 EBq) of radon are released from soil annually.\n\nRadon concentration can differ widely from place to place. In the open air, it ranges from 1 to 100 Bq/m, even less (0.1 Bq/m) above the ocean. In caves or aerated mines, or ill-aerated houses, its concentration climbs to 20–2,000 Bq/m.\n\nRadon concentration can be much higher in mining contexts. Ventilation regulations instruct to maintain radon concentration in uranium mines under the \"working level\", with 95th percentile levels ranging up to nearly 3 WL (546 pCi Rn per liter of air; 20.2 kBq/m, measured from 1976 to 1985).\nThe concentration in the air at the (unventilated) Gastein Healing Gallery averages 43 kBq/m (1.2 nCi/L) with maximal value of 160 kBq/m (4.3 nCi/L).\n\nRadon mostly appears with the decay chain of the radium and uranium series (Rn), and marginally with the thorium series (Rn). The element emanates naturally from the ground, and some building materials, all over the world, wherever traces of uranium or thorium can be found, and particularly in regions with soils containing granite or shale, which have a higher concentration of uranium. Not all granitic regions are prone to high emissions of radon. Being a rare gas, it usually migrates freely through faults and fragmented soils, and may accumulate in caves or water. Owing to its very short half-life (four days for Rn), radon concentration decreases very quickly when the distance from the production area increases. Radon concentration varies greatly with season and atmospheric conditions. For instance, it has been shown to accumulate in the air if there is a meteorological inversion and little wind.\n\nHigh concentrations of radon can be found in some spring waters and hot springs. The towns of Boulder, Montana; Misasa; Bad Kreuznach, Germany; and the country of Japan have radium-rich springs that emit radon. To be classified as a radon mineral water, radon concentration must be above 2 nCi/L (74 kBq/m). The activity of radon mineral water reaches 2,000 kBq/m in Merano and 4,000 kBq/m in Lurisia (Italy).\n\nNatural radon concentrations in the Earth's atmosphere are so low that radon-rich water in contact with the atmosphere will continually lose radon by volatilization. Hence, ground water has a higher concentration of Rn than surface water, because radon is continuously produced by radioactive decay of Ra present in rocks. Likewise, the saturated zone of a soil frequently has a higher radon content than the unsaturated zone because of diffusional losses to the atmosphere.\n\nIn 1971, Apollo 15 passed 110 km (68 mi) above the Aristarchus plateau on the Moon, and detected a significant rise in alpha particles thought to be caused by the decay of Rn. The presence of Rn has been inferred later from data obtained from the Lunar Prospector alpha particle spectrometer.\n\nRadon is found in some petroleum. Because radon has a similar pressure and temperature curve to propane, and oil refineries separate petrochemicals based on their boiling points, the piping carrying freshly separated propane in oil refineries can become radioactive because of decaying radon and its products.\n\nResidues from the petroleum and natural gas industry often contain radium and its daughters. The sulfate scale from an oil well can be radium rich, while the water, oil, and gas from a well often contains radon. Radon decays to form solid radioisotopes that form coatings on the inside of pipework.\n\nHigh concentrations of radon in homes were discovered by chance in 1985 after the stringent radiation testing conducted at a nuclear power plant entrance revealed that Stanley Watras, an engineer at the plant, was contaminated by radioactive substances. Typical domestic exposures are of approximately 100 Bq/m (2.7 pCi/L) indoors. Some level of radon will be found in all buildings. Radon mostly enters a building directly from the soil through the lowest level in the building that is in contact with the ground. High levels of radon in the water supply can also increase indoor radon air levels. Typical entry points of radon into buildings are cracks in solid foundations, construction joints, cracks in walls, gaps in suspended floors, gaps around service pipes, cavities inside walls, and the water supply. Radon concentrations in the same location may differ by a factor of two over a period of 1 hour. Also, the concentration in one room of a building may be significantly different from the concentration in an adjoining room.\n\nThe distribution of radon concentrations will generally differ from room to room, and the readings are averaged according to regulatory protocols. Indoor radon concentration is usually assumed to follow a lognormal distribution on a given territory. Thus, the geometric mean is generally used for estimating the \"average\" radon concentration in an area.\n\nThe mean concentration ranges from less than 10 Bq/m to over 100 Bq/m in some European countries. Typical geometric standard deviations found in studies range between 2 and 3, meaning (given the 68–95–99.7 rule) that the radon concentration is expected to be more than a hundred times the mean concentration for 2 to 3% of the cases.\n\nSome of the highest radon hazard in the United States is found in Iowa and in the Appalachian Mountain areas in southeastern Pennsylvania. Some of the highest readings ever have been recorded in the Irish town of Mallow, County Cork, prompting local fears regarding lung cancer. Iowa has the highest average radon concentrations in the United States due to significant glaciation that ground the granitic rocks from the Canadian Shield and deposited it as soils making up the rich Iowa farmland. Many cities within the state, such as Iowa City, have passed requirements for radon-resistant construction in new homes.\n\nIn a few locations, uranium tailings have been used for landfills and were subsequently built on, resulting in possible increased exposure to radon.\n\nSince radon is a colorless, odorless gas the only way to know how much is present in the air or water is to perform tests. In the United States radon test kits are available to the public at retail stores, such as hardware stores, for home use and testing is available through licensed professionals, who are often home inspectors. Efforts to reduce indoor radon levels are called radon mitigation. In the U.S. the Environmental Protection Agency recommends all houses be tested for radon.\n\nRadon is obtained as a by-product of uraniferous ores processing after transferring into 1% solutions of hydrochloric or hydrobromic acids. The gas mixture extracted from the solutions contains , , He, Rn, , and hydrocarbons. The mixture is purified by passing it over copper at 720 °C to remove the and the , and then KOH and are used to remove the acids and moisture by sorption. Radon is condensed by liquid nitrogen and purified from residue gases by sublimation.\n\nRadon commercialization is regulated, but it is available in small quantities for the calibration of Rn measurement systems, at a price of almost $6,000 per milliliter of radium solution (which only contains about 15 picograms of actual radon at a given moment).\nRadon is produced by a solution of radium-226 (half-life of 1600 years). Radium-226 decays by alpha-particle emission, producing radon that collects over samples of radium-226 at a rate of about 1 mm/day per gram of radium; equilibrium is quickly achieved and radon is produced in a steady flow, with an activity equal to that of the radium (50 Bq). Gaseous Rn (half-life of about four days) escapes from the capsule through diffusion.\n\nAn early-20th-century form of quackery was the treatment of maladies in a radiotorium. It was a small, sealed room for patients to be exposed to radon for its \"medicinal effects\". The carcinogenic nature of radon due to its ionizing radiation became apparent later on. Radon's molecule-damaging radioactivity has been used to kill cancerous cells, but it does not increase the health of healthy cells. The ionizing radiation causes the formation of free radicals, which results in genetic and other cell damage, resulting in increased rates of illness, including cancer.\n\nExposure to radon, a process known as radiation hormesis, has been suggested to mitigate autoimmune diseases such as arthritis. As a result, in the late 20th century and early 21st century, \"health mines\" established in Basin, Montana attracted people seeking relief from health problems such as arthritis through limited exposure to radioactive mine water and radon. The practice is discouraged because of the well-documented ill effects of high-doses of radiation on the body.\n\nRadioactive water baths have been applied since 1906 in Jáchymov, Czech Republic, but even before radon discovery they were used in Bad Gastein, Austria. Radium-rich springs are also used in traditional Japanese onsen in Misasa, Tottori Prefecture. Drinking therapy is applied in Bad Brambach, Germany. Inhalation therapy is carried out in Gasteiner-Heilstollen, Austria, in Świeradów-Zdrój, Czerniawa-Zdrój, Kowary, Lądek Zdrój, Poland, in Harghita Băi, Romania, and in Boulder, United States. In the US and Europe there are several \"radon spas\", where people sit for minutes or hours in a high-radon atmosphere in the belief that low doses of radiation will invigorate or energize them.\n\nRadon has been produced commercially for use in radiation therapy, but for the most part has been replaced by radionuclides made in accelerators and nuclear reactors. Radon has been used in implantable seeds, made of gold or glass, primarily used to treat cancers.\nThe gold seeds were produced by filling a long tube with radon pumped from a radium source, the tube being then divided into short sections by crimping and cutting. The gold layer keeps the radon within, and filters out the alpha and beta radiations, while allowing the gamma rays to escape (which kill the diseased tissue). The activities might range from 0.05 to 5 millicuries per seed (2 to 200 MBq). The gamma rays are produced by radon and the first short-lived elements of its decay chain (Po, Pb, Bi, Po).\n\nRadon and its first decay products being very short-lived, the seed is left in place. After 12 half-lives (43 days), radon radioactivity is at 1/2000 of its original level. At this stage, the predominant residual activity originates from the radon decay product Pb, whose half-life (22.3 years) is 2000 times that of radon (and whose activity is thus 1/2000 of radon's), and its descendants Bi and Po.\n\nIn the early part of the 20th century in the US, gold contaminated with Pb entered the jewelry industry. This was from gold seeds that had held Rn that had been melted down after the radon had decayed.\n\nRadon emanation from the soil varies with soil type and with surface uranium content, so outdoor radon concentrations can be used to track air masses to a limited degree. This fact has been put to use by some atmospheric scientists. Because of radon's rapid loss to air and comparatively rapid decay, radon is used in hydrologic research that studies the interaction between ground water and streams. Any significant concentration of radon in a stream is a good indicator that there are local inputs of ground water.\n\nRadon soil-concentration has been used in an experimental way to map buried close-subsurface geological faults because concentrations are generally higher over the faults. Similarly, it has found some limited use in prospecting for geothermal gradients.\n\nSome researchers have investigated changes in groundwater radon concentrations for earthquake prediction. Radon has a half-life of approximately 3.8 days, which means that it can be found only shortly after it has been produced in the radioactive decay chain. For this reason, it has been hypothesized that increases in radon concentration is due to the generation of new cracks underground, which would allow increased ground water circulation, flushing out radon. The generation of new cracks might not unreasonably be assumed to precede major earthquakes. In the 1970s and 1980s, scientific measurements of radon emissions near faults found that earthquakes often occurred with no radon signal, and radon was often detected with no earthquake to follow. It was then dismissed by many as an unreliable indicator. As of 2009, it was under investigation as a possible precursor by NASA.\n\nRadon is a known pollutant emitted from geothermal power stations because it is present in the material pumped from deep underground. It disperses rapidly, and no radiological hazard has been demonstrated in various investigations. In addition, typical systems re-inject the material deep underground rather that releasing it at the surface, so its environmental impact is minimal.\n\nIn the 1940s and '50s, radon was used for industrial radiography, Other X-ray sources, which became available after World War II, quickly replaced radon for this application, as they were lower in cost and had less hazard of alpha radiation.\n\nRadon-222 decay products have been classified by the International Agency for Research on Cancer as being carcinogenic to humans, and as a gas that can be inhaled, lung cancer is a particular concern for people exposed to elevated levels of radon for sustained periods. During the 1940s and '50s, when safety standards requiring expensive ventilation in mines were not widely implemented, radon exposure was linked to lung cancer among non-smoking miners of uranium and other hard rock materials in what is now the Czech Republic, and later among miners from the Southwestern United States and South Australia. Despite these hazards being known in the early 1950s, this occupational hazard remained poorly managed in many mines until the 1970s. During this period, several entrepreneurs opened former uranium mines in the USA to the general public and advertised alleged health benefits from breathing radon gas underground. Health benefits claimed included pain, sinus, asthma and arthritis relief but these were proven to be false and the government banned such ads in 1975.\n\nSince that time, ventilation and other measures have been used to reduce radon levels in most affected mines that continue to operate. In recent years, the average annual exposure of uranium miners has fallen to levels similar to the concentrations inhaled in some homes. This has reduced the risk of occupationally induced cancer from radon, although health issues may persist for those who are currently employed in affected mines and for those who have been employed in them in the past. As the relative risk for miners has decreased, so has the ability to detect excess risks among that population.\n\nResidues from processing of uranium ore can also be a source of radon. Radon resulting from the high radium content in uncovered dumps and tailing ponds can be easily released into the atmosphere and affect people living in the vicinity.\n\nIn addition to lung cancer, researchers have theorized a possible increased risk of leukemia due to radon exposure. Empirical support from studies of the general population is inconsistent, and a study of uranium miners found a correlation between radon exposure and chronic lymphocytic leukemia.\n\nMiners (as well as milling and ore transportation workers) who worked in the uranium industry in the United States between the 1940s and 1971 may be eligible for compensation under the Radiation Exposure Compensation Act (RECA). Surviving relatives may also apply in cases where the formerly employed person is deceased.\n\nRadon exposure (mostly radon daughters) has been linked to lung cancer in numerous case-control studies performed in the United States, Europe and China. There are approximately 21,000 deaths per year in the US due to radon-induced lung cancers. One of the most comprehensive radon studies performed in the United States by Dr. R. William Field and colleagues found a 50% increased lung cancer risk even at the protracted exposures at the EPA's action level of 4 pCi/L. North American and European Pooled analyses further support these findings. However, the discussion about the opposite results is still going on, especially a recent retrospective case-control study of lung cancer risk showed substantial cancer rate reduction for radon concentrations between 50 and 123 Bq per cubic meter.\n\nMost models of residential radon exposure are based on studies of miners, and direct estimates of the risks posed to homeowners would be more desirable. Because of the difficulties of measuring the risk of radon relative to smoking, models of their effect have often made use of them.\n\nRadon has been considered the second leading cause of lung cancer and leading environmental cause of cancer mortality by the United States Environmental Protection Agency. Others have reached similar conclusions for the United Kingdom and France. Radon exposure in homes and offices may arise from certain subsurface rock formations, and also from certain building materials (e.g., some granites). The greatest risk of radon exposure arises in buildings that are airtight, insufficiently ventilated, and have foundation leaks that allow air from the soil into basements and dwelling rooms.\n\nWHO presented in 2009 a recommended reference level (the national reference level), 100 Bq/m, for radon in dwellings. The recommendation also says that where this is not possible, 300 Bq/m should be selected as the highest level. A national reference level should not be a limit, but should represent the maximum acceptable annual average radon concentration in a dwelling.\n\nThe actionable concentration of radon in a home varies depending on the organization doing the recommendation, for example, the United States Environmental Protection Agency encourages that action be taken at concentrations as low as 74 Bq/m (2 pCi/L), and the European Union recommends action be taken when concentrations reach 400 Bq/m (11 pCi/L) for old houses and 200 Bq/m (5 pCi/L) for new ones. On 8 July 2010 the UK's Health Protection Agency issued new advice setting a \"Target Level\" of 100 Bq/m whilst retaining an \"Action Level\" of 200 Bq/m. The same levels (as UK) apply to Norway from 2010; in all new housings preventative measures should be taken against radon accumulation.\n\nResults from epidemiological studies indicate that the risk of lung cancer increases with exposure to residential radon. A well-known example of source of error is smoking. In addition, smoking is the most important risk factor for lung cancer. In the West, tobacco smoke is estimated to cause about 90% of all lung cancers.\n\nAccording to the EPA, the risk of lung cancer for smokers is significant due to synergistic effects of radon and smoking. For this population about 62 people in a total of 1,000 will die of lung cancer compared to 7 people in a total of 1,000 for people who have never smoked. It cannot be excluded that the risk of non-smokers should be primarily explained by a combination effect of radon and passive smoking (see below).\n\nRadon, like other known or suspected external risk factors for lung cancer, is a threat for smokers and former smokers. This was demonstrated by the European pooling study. A commentary to the pooling study stated: \"it is not appropriate to talk simply of a risk from radon in homes. The risk is from smoking, compounded by a synergistic effect of radon for smokers. Without smoking, the effect seems to be so small as to be insignificant.\"\n\nAccording to the European pooling study, there is a difference in risk from radon between histological types. Small cell lung carcinoma, which practically only affects smokers have high risk from radon. For other histological types such as adenocarcinoma, the type that primarily affects never smokers, the risk from radon appears to be lower.\n\nA study of radiation from post mastectomy radiotherapy shows that the simple models previously used to assess the combined and separate risks from radiation and smoking need to be developed. This is also supported by new discussion about the calculation method, LNT, which routinely has been used.\n\nAn important, but unanswered question concerns the possibility that the cancer risk from passive smoking can increase with exposure to residential radon. The basic data for the European pooling study makes it impossible to exclude that such synergy effect is an explanation for the (very limited) increase in the risk from radon that was stated for non-smokers.\n\nA study from 2001, which included 436 cases (never smokers who had lung cancer), and a control group (1649 never smokers) showed that exposure to radon increased the risk of lung cancer in never smokers. But the group that had been exposed to passive smoking at home appeared to bear the entire risk increase, while those who were not exposed to passive smoking did not show any increased risk with increasing radon level.\n\nThe effects of radon if ingested are similarly unknown, although studies have found that its biological half-life ranges from 30–70 minutes, with 90 percent removal at 100 minutes. In 1999 National Research Council investigated the issue of radon in drinking water. The risks associated with ingestion was considered almost negligible. Water from underground sources may contain significant amounts of radon depending on the surrounding rock and soil conditions, whereas surface sources generally do not.\n\nAs well as being ingested through drinking water, radon is also released from water when temperature is increased, pressure is decreased and when water is aerated. Optimum conditions for radon release and exposure occur during showering. Water with a radon concentration of 10 pCi/L can increase the indoor airborne radon concentration by 1 pCi/L under normal conditions.\n\nThere are relatively simple tests for radon gas. In some countries these tests are methodically done in areas of known systematic hazards. Radon detection devices are commercially available. Digital radon detectors provide ongoing measurements giving both daily, weekly, short-term and long-term average readouts via a digital display. Short-term radon test devices used for initial screening purposes are inexpensive, in some cases free. There are important protocols for taking short-term radon tests and it is imperative that they be strictly followed. The kit includes a collector that the user hangs in the lowest habitable floor of the house for 2 to 7 days. The user then sends the collector to a laboratory for analysis. Long term kits, taking collections for up to one year or more, are also available. An open-land test kit can test radon emissions from the land before construction begins. Radon concentrations can vary daily, and accurate radon exposure estimates require long-term average radon measurements in the spaces where an individual spends a significant amount of time.\n\nRadon levels fluctuate naturally, due to factors like transient weather conditions, so an initial test might not be an accurate assessment of a home's average radon level. Radon levels are at a maximum during the coolest part of the day when pressure differentials are greatest. Therefore, a high result (over 4 pCi/L) justifies repeating the test before undertaking more expensive abatement projects. Measurements between 4 and 10 pCi/L warrant a long term radon test. Measurements over 10 pCi/L warrant only another short term test so that abatement measures are not unduly delayed. Purchasers of real estate are advised to delay or decline a purchase if the seller has not successfully abated radon to 4 pCi/L or less.\n\nBecause the half-life of radon is only 3.8 days, removing or isolating the source will greatly reduce the hazard within a few weeks. Another method of reducing radon levels is to modify the building's ventilation. Generally, the indoor radon concentrations increase as ventilation rates decrease. In a well ventilated place, the radon concentration tends to align with outdoor values (typically 10 Bq/m, ranging from 1 to 100 Bq/m).\n\nThe four principal ways of reducing the amount of radon accumulating in a house are:\n\nAccording to the EPA the method to reduce radon \"...primarily used is a vent pipe system and fan, which pulls radon from beneath the house and vents it to the outside\", which is also called sub-slab depressurization, active soil depressurization, or soil suction. Generally indoor radon can be mitigated by sub-slab depressurization and exhausting such radon-laden air to the outdoors, away from windows and other building openings. \"EPA generally recommends methods which prevent the entry of radon. Soil suction, for example, prevents radon from entering your home by drawing the radon from below the home and venting it through a pipe, or pipes, to the air above the home where it is quickly diluted\" and \"EPA does not recommend the use of sealing alone to reduce radon because, by itself, sealing has not been shown to lower radon levels significantly or consistently\".\n\nPositive-pressure ventilation systems can be combined with a heat exchanger to recover energy in the process of exchanging air with the outside, and simply exhausting basement air to the outside is not necessarily a viable solution as this can actually draw radon gas \"into\" a dwelling. Homes built on a crawl space may benefit from a radon collector installed under a \"radon barrier\" (a sheet of plastic that covers the crawl space).\nFor crawlspaces, the EPA states \"An effective method to reduce radon levels in crawlspace homes involves covering the earth floor with a high-density plastic sheet. A vent pipe and fan are used to draw the radon from under the sheet and vent it to the outdoors. This form of soil suction is called submembrane suction, and when properly applied is the most effective way to reduce radon levels in crawlspace homes.\"\n\n"}
{"id": "25606", "url": "https://en.wikipedia.org/wiki?curid=25606", "title": "Rocca (Italian-American rapper)", "text": "Rocca (Italian-American rapper)\n\nRocca is an American rapper. He was born in California. His first official album entitled \"Sexy Smooth\" was released in January 1993 and sold many copies in the United States as well as many other countries. Rocca has 3 music videos to his credentials and wrote/rapped/starred in the \"James Bond Spoof - Secret Agent OO Soul - with Billy Dee Williams\". Rocca feels that there was an obligation to the youth of the world to try to promote positivity.\n\n\n\n"}
{"id": "25607", "url": "https://en.wikipedia.org/wiki?curid=25607", "title": "Ruby (disambiguation)", "text": "Ruby (disambiguation)\n\nA ruby is a red gemstone.\n\nRuby may also refer to:\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "25609", "url": "https://en.wikipedia.org/wiki?curid=25609", "title": "Royal Institute of Technology", "text": "Royal Institute of Technology\n\nKTH Royal Institute of Technology (KTH, ) is a university in Stockholm, Sweden, specialized in Engineering and Technology, that ranks highest in northern mainland Europe in its academic fields. The current King of Sweden Carl XVI Gustaf is its High Protector.\n\nThe core of the KTH Royal Institute of Technology was the Laboratorium Mechanicum for research and teaching in mechanics, founded in Stockholm in 1697 by Christopher Polhem after his extensive trips, studies and research abroad. This core was later called the Mechanical School prior to its 1827 transformation into The Technological Institute, Sweden's first institute of technology (polytechnic) by decision of the King Charles XIV John of Sweden, also Marshal of France, modeled after École Polytechnique which was founded by Napoleon Bonaparte in Paris, France in 1794. The Technological Institute changed its name to the present Kungliga Tekniska Högskolan (KTH Royal Institute of Technology) in 1877 by decree of King Oscar II. The Laboratorium Mechanicum was itself in 1925 handed over from the KTH Royal Institute of Technology to the Swedish Museum of Technology in Stockholm, Sweden.\n\nKTH Royal Institute of Technology is the highest ranked university of technology in northern mainland Europe, with the only exceptions being the best technical universities of Germany and the Netherlands.\n\nThe main campus buildings at Valhallavägen in Östermalm, by architect Erik Lallerstedt, were completed in 1917. The bells of the clock-tower was completed at the 100 year anniversary of the transformation of the Mechanical School to The Technological Institute in 1927. The buildings and surroundings were decorated by prominent early 20th-century Swedish artists such as Carl Milles, Axel Törneman, Georg Pauli, Tore Strindberg and Ivar Johnsson. The older buildings on the campus were renovated heavily in 1994. While the original campus was large for its time, KTH very soon outgrew it, and the campus was expanded with new buildings. Today, KTH institutions and faculties are distributed across several campuses in Stockholm County, located in Flemingsberg, Haninge, Kista and Södertälje, beyond the ones in Östermalm.\n\nKTH, School of ICT, Kista offers education and research in all the areas which today's information society is based upon - from nano scale physics and corn to the benefit of the end user. Kista is an educational environment with modern facilities, which are always open to the students. All courses are within ICT, creating a strong cohesion and an exchange over the educational programmes. Stockholm University’s computer science programmes are also located in Kista. Together, over 3000 students create a living educational environment and a vibrant student life. KTH Kista is an exciting international environment with teachers and students from all around the world. The Master's and postgraduate programmes offered by the school attracts students from the world's top universities. With companies such as Ericsson, Volvo, IBM, Tele2, TietoEnator, Microsoft, Intel and Oracle as neighbors, the cooperation between industry and KTH is widely known.\n\nSchool of Technology and Health has a part of its activities in Flemingsberg. At KTH Flemingsberg the school offers courses in Medical Engineering and conducts research within the subject.\n\nKTH's activities in Flemingsberg started in 2002. Since 2003, the school offers a Bachelor of Education in Medical Engineering, in collaboration with the Karolinska Institutet. In autumn 2008, a master of science in Medical Engineering started. located here are undergraduate studies, most research departments, and the research center: Center for Technology in Medicine and Health (CTMH), which collaborates with Karolinska Institutet and Stockholm County Council (SLL) to contribute to the development and growth of research in engineering, medicine and health.\n\nFlemingsberg is an area of high academic \"density\" and one of northern Europe's most important areas within biotechnology – both terms of research and industrial activities. Here are also Södertörn University and the Karolinska Institutet with over 10 000 students and Novum Research Center, where 1000 people are involved in research.\n\nFlemingsberg is an area of strong growth. To meet the need for student housing more apartments are planned.\n\nIn Haninge, students from two schools at KTH receive education – the School of Architecture and the Built Environment, ABE, and the School of Technology and Health, STH. Here, students study at undergraduate and master level in fields such as building engineering (ABE), computer engineering, electrical engineering and foundation training. The School of Technology and Health also has a research centre i Haninge – Centre for Health and Building.\n\nJust south of metropolitan Stockholm you will discover a modern campus with reputation for its nice campus area, safe atmosphere and the feeling of togetherness among staff and students.\n\nKTH Haninge holds a large number of courses. For example, the international master programme Architectural Lighting Design is located here, with students from over 20 different countries.\n\nKTH Haninge has a meeting point where the diverse worlds of culture, scientific research and business come together to experience and examine the significance of light and lighting in our daily lives. This is called the Lighting Laboratory.\n\nThe campus itself is located near the commuter train, which takes you to Stockholm in just 20 minutes. It is also close to a beautiful archipelago and enjoy the great outdoors in Tyresta National Park.\n\nKTH Södertälje is Södertälje’s university college campus. KTH Södertälje is a moderately large area with close and natural contacts between teachers and students.\n\nKTH Södertälje’s education is being constantly developed via a close co-operation with the town’s business community and in particular major Södertälje companies such as Scania and AstraZeneca. Among other topics, university engineers in electronics and mechanical engineering are educated here. Also, KTH offer various Master's programmes in logistics, project management, and product development.\n\nSince autumn 2007, the design studio Go Deep KTH at KTH Södertälje has been able to offer product development work via surveys, concept, visualisation and development through design. The idea with Go Deep KTH is to create realistic cooperation projects with companies, public administrations and institutions together with researchers in technology, medicine and health.\n\nAt KTH Södertälje, each year Tegelnatten is arranged, a competition where students in teams solve a 24-hour project assignment. The project assignment for design night 2008 was to provide proposals and ideas as to how future games and competitions will be designed to attract and entice the future generations.\n\nSödertälje offers KTH's students who will be studying at KTH Södertälje a guaranteed apartment in Södertälje. Students who live and study in Södertälje also receive a computer via cooperation with the municipality which they are able to use during the time they spend as a student.\n\nKTH was 1827 transformed from the Mechanical School to the Technological Institute (\"Teknologiska institutet\"), following the establishment of polytechnical schools in many European countries the early years of the 19th century, often based on the model of École Polytechnique in Paris in 1794.\n\nKTH's earliest Swedish predecessor was the \"Laboratorium mechanicum\", a collection of mechanical models for teaching created in 1697 by Christopher Polhem, who is considered to be the father of mechanics in Sweden. The models were used intermittently for teaching practical mechanics by different masters until the School of Mechanics (\"Mekaniska skolan\") was founded in 1798. This is the year from which there has been continuous teaching of technology in Sweden. The activities of the School of Mechanics was taken over by KTH when it was founded.\n\nThe institute had one professor of chemistry and one of physics, and one class in mechanical engineering and one in chemical engineering. During the first years, however, teaching was at a very elementary level, and more aimed at craftsmanship rather than engineering as such. The institute was also plagued by conflicts between the faculty and the founder and head of the institute, Gustaf Magnus Schwartz, who was responsible for the artisanal focus of the institute. A government committee was appointed in 1844 to solve the issues, which led to removing Schwartz in 1845. Instead, Joachim Åkerman, the head of the School of Mining in Falun and a former professor of chemistry at KTH, took over. He led a full reorganisation of the institute in 1846–1848, after which he returned to his post in Falun. An entrance test and a minimum age of 16 for students was introduced, which led to creating proper engineering training at the institute. In 1851, the course was extended from two years to three.\n\nIn the late 1850s, the institute entered a time of expansion. In 1863, it received its own purpose-built buildings on Drottninggatan. In 1867, its regulations were again overhauled, to state explicitly that the institute should provide scientific training to its students. In 1869, the School of Mining in Falun was moved to Stockholm and merged with the institute. In 1871, the institute took over the civil engineering course formerly arranged by the Higher Artillery College in Marieberg.\n\nIn 1877, the name was changed into the current one, which changed KTH's status from Institute (\"institut\") to College (\"högskola\"), and some courses were extended from three years to four. Architecture was also added to the curriculum.\n\nIn 1915, the degree titles conferred by KTH received legal protection. In the late 19th century, it had become common to use the title \"civilingenjör\" (literally \"civil engineer\") for most KTH-trained engineers, and not just those who studied building and construction-related subjects. The only exception was the mining engineers, which called themselves \"bergsingenjör\" (\"mountain engineer\"). For a while, the title \"civilingenjör\" was equal to \"KTH graduate\" but in 1937, Chalmers in Gothenburg became the second Swedish engineering college which were allowed to confirm these titles.\n\nIn 1917, the first buildings of KTH's new campus on Valhallavägen were completed, and still constitute its main campus.\n\nAlthough the engineering education of the late 19th and early 20th century were scientifically founded, up until the early 20th century, research as such was not seen as a central activity of an Institute of Technology. Those engineering graduates which went on to academic research had to earn their doctorates, typically in physics or chemistry, at a regular university. In 1927, KTH was finally granted the right to confer its own doctorates, under the designation \"Teknologie doktor\" (Doctor of Technology), and the first five doctors were created in 1929.\n\nIn 1984 the \"civilingenjör\" course at all Swedish universities was extended from four years to 4.5. From 1989, the shorter training in technology arranged by the municipal polytechnical schools in Sweden was gradually extended and moved into the university system, from 1989 as two-year courses and from 1995 alternatively as three-year courses. For KTH, this meant that additional campuses around the Stockholm area were added.\n\nIn present-day KTH continue to be Sweden's largest, oldest, highest ranked and most international technical university. The university provides one-third of Sweden's research and engineering education. In 2012, there were a total of 14,000 undergraduate students, 1,700 postgraduate students, and 4,600 members of staff at the university.\n\nAfter the American deployment of nuclear weapons at the end of World War II, the Swedish military leadership recognized the need for nuclear weapons to be thoroughly investigated and researched to provide Sweden with the knowledge to defend itself from a nuclear attack. With the mission to \"make something with neutrons\", the Swedish team, with scientists like Rolf Maximilian Sievert, set out to research the subject and eventually build a nuclear reactor for testing.\n\nAfter a few years of basic research, they started building a 300 kW (later expanded to 1 MW) reactor, named \"Reaktor 1\" (\"R1\"), in a reactor hall 25 meters under the surface right underneath KTH. Today this might seem ill-considered, since approximately 40,000 people lived within a 1 km radius. It was risky, but was deemed tolerable since the reactor was an important research tool for scientists at the Royal Swedish Academy of Engineering Sciences (\"Ingenjörsvetenskapsakademien\").\n\nAt 18:59 on 13 July 1954, the reactor reached critical mass and sustained Sweden's first nuclear reaction. R1 was to be the main site for almost all Swedish nuclear research until 1970 when the reactor was finally decommissioned, mostly due to the increased awareness of the risks associated with operating a reactor in a densely populated area of Stockholm. The reactor hall remains an amusement to many as once it was next door to what used to be Sweden's first nuclear reactor. Close to the reactor hall is the restaurant \"Q\".\n\nFrom 2005 KTH is organized into nine schools each consisting of a number of departments:\n\nIn February 2017, the new president announced a new plan to review the schools organization. The reorganization will aim at reducing the number of schools by integrating them.\n\nIn 2007, by government initiative, the Swedish National Agency for Higher Education employed an international expert committee to find and award the top five highest quality education areas among all universities and colleges in Sweden. The Royal Institute of Technology received one such \"Centre of Excellent Quality in Higher Education\" (in Vehicle Engineering). It is the only higher education institution in the Stockholm/Uppsala region to receive an award. In 2009, KTH was the only institute among all Sweden's universities to be awarded as a Centre of Excellent Quality in Higher Education (in computer science).\n\nIn 2016 the university was ranked 97th in the world as a general university (not only technical) beaten in Sweden only by Lund University in its capacity as a general university by QS World University Rankings. KTH Royal Institute of Technology is 2016 in the world ranked 33rd in engineering and technology and 74th in the natural sciences. The Electrical Engineering subject was ranked as number 26 worldwide in terms of highest quality in the world. KTH Royal Institute of Technology is the highest ranked institute of technology in northern mainland Europe, only rivaled by Germany's and Netherland's highest ranking institutes of technology . As a comparison, Chalmers University of Technology in Gothenburg ranks at 133 by QS World University Rankings. The other global ranking, Times Higher Education World University Rankings ranks KTH 159th in the world for 2016-17As a comparison, Times for instance ranks the Chalmers University of Technology in Gothenburg at 251—300 .\n\nMany prominent former students have attended KTH, including;\n\n\n\n\n"}
{"id": "25610", "url": "https://en.wikipedia.org/wiki?curid=25610", "title": "Rescuing Prometheus", "text": "Rescuing Prometheus\n\nRescuing Prometheus: Four Monumental Projects That Changed the Modern World is a book by Thomas P. Hughes. The book uses four extremely large engineering projects of the late 20th century as examples to explore how the limits of modern system engineering are stressed by real life projects. It also traces the development of the management of large technical system development.\n\nThe book documents four massively-cooperative projects:\n\n\n\n"}
{"id": "25611", "url": "https://en.wikipedia.org/wiki?curid=25611", "title": "Riddarfjärden", "text": "Riddarfjärden\n\nRiddarfjärden (, \"The Knight Firth\") is the easternmost bay of Lake Mälaren in central Stockholm. Stockholm was founded in 1252 on an island in the stream where Lake Mälaren (from the west) drains into the Baltic Sea (to the east); today the island is called Stadsholmen and constitutes Stockholm's Old Town.\n\nThe panorama picture featured in this article was taken from the heights of Södermalm, west of Stadsholmen, looking down on Riddarfjärden. Left to right are viewable:\n\nRiddarfjärden throughout the year\n"}
{"id": "25612", "url": "https://en.wikipedia.org/wiki?curid=25612", "title": "Random access", "text": "Random access\n\nIn computer science, random access (more precisely and more generally called direct access) is the ability to access any item of data from a population of addressable elements roughly as easily and efficiently as any other, no matter how many elements may be in the set. It is typically contrasted to sequential access. \n\nFor example, data might be stored notionally in a single sequence like a row, in two dimensions like rows and columns on a surface, or in multiple dimensions. However, given all the coordinates, a program can access each record about as quickly and easily as any other. In this sense the choice of data item is arbitrary in the sense that no matter which item is sought, all that is needed to find it, is its address, that is to say, the coordinates at which it is located, such as its row and column (or its track and record number on a magnetic drum). At first the term \"random access\" was used because the process had to be capable of finding records no matter in which sequence they were required. However, soon the term \"direct access\" gained favour because one could directly retrieve a record, no matter what its position might be. The operative attribute however is that the device can access any required record immediately on demand. The opposite is sequential access, where a remote element takes longer time to access.\n\nA typical illustration of this distinction is to compare an ancient scroll (sequential; all material prior to the data needed must be unrolled) and the book (direct: can be immediately flipped open to any arbitrary page). A more modern example is a cassette tape (sequential — one must fast forward through earlier songs to get to later ones) and a CD (direct access — one can skip to the track wanted, knowing that it would be the one retrieved).\n\nIn data structures, direct access implies the ability to access any entry in a list in constant time (independent of its position in the list and of list's size). Very few data structures can guarantee this, other than arrays (and related structures like dynamic arrays). Direct access is required, or at least valuable, in many algorithms such as binary search, integer sorting or certain versions of sieve of Eratosthenes.\n\nOther data structures, such as linked lists, sacrifice direct access to permit efficient inserts, deletes, or reordering of data. Self-balancing binary search trees may provide an acceptable compromise, where access time is not equal for all members of a collection, but the maximum time to retrieve a given member grows only logarithmically with its size.\n\n"}
{"id": "25613", "url": "https://en.wikipedia.org/wiki?curid=25613", "title": "Racism", "text": "Racism\n\nRacism is discrimination and prejudice towards people based on their race or ethnicity. Today, the use of the term \"racism\" does not easily fall under a single definition.\n\nThe ideology underlying racist practices often includes the idea that humans can be subdivided into distinct groups that are different due to their social behavior and their innate capacities as well as the idea that they can be ranked as inferior or superior. The Holocaust is a classic example of institutionalized racism which led to the death of millions of people based on race.\nWhile the concepts of race and ethnicity are considered to be separate in contemporary social science, the two terms have a long history of equivalence in both popular usage and older social science literature. \"Ethnicity\" is often used in a sense close to one traditionally attributed to \"race\": the division of human groups based on qualities assumed to be essential or innate to the group (e.g. shared ancestry or shared behavior). Therefore, \"racism\" and \"racial discrimination\" are often used to describe discrimination on an ethnic or cultural basis, independent of whether these differences are described as racial. According to a United Nations convention on racial discrimination, there is no distinction between the terms \"racial\" and \"ethnic\" discrimination. The UN convention further concludes that superiority based on racial differentiation is scientifically false, morally condemnable, socially unjust and dangerous, and there is no justification for racial discrimination, anywhere, in theory or in practice.\n\nRacist ideology can become manifest in many aspects of social life. Racism can be present in social actions, practices, or political systems (e.g., apartheid) that support the expression of prejudice or aversion in discriminatory practices. Associated social actions may include nativism, xenophobia, otherness, segregation, hierarchical ranking, supremacism, and related social phenomena.\n\nIn the 19th century, many scientists subscribed to the belief that the human population can be divided into races. The term \"racism\" is a noun describing the state of being racist, i.e., subscribing to the belief that the human population can be classified according to race. The origin of the root word \"race\" is not clear. Linguists generally agree that it came to the English language from Middle French, but there is no such agreement on how it came into Latin-based languages, generally. A recent proposal is that it derives from the Arabic \"ra's\", which means \"head, beginning, origin\" or the Hebrew \"rosh\", which has a similar meaning. Early race theorists generally held the view that some races were inferior to others and they consequently believed that the differential treatment of races was fully justified. These early theories guided pseudo-scientific research assumptions; the collective endeavors to adequately define and form hypotheses about racial differences are generally termed scientific racism.\n\nToday, most biologists, anthropologists, and sociologists reject a taxonomy of races in favor of more specific and/or empirically verifiable criteria, such as geography, ethnicity or a history of endogamy. To date, there is little evidence in human genome research which indicates that race can be defined in such a way as to be useful in determining a genetic classification of humans.\n\nAn entry in the \"Oxford English Dictionary\" (2008) simply defines racialism as \"An earlier term than racism, but now largely superseded by it,\" and cites it in a 1902 quote. The revised Oxford English Dictionary cites the shortened term \"racism\" in a quote from the following year, 1903. It was first defined by the Oxford English Dictionary as \"[t]he theory that distinctive human characteristics and abilities are determined by race\", which gives 1936 as the first recorded use. Additionally, the Oxford English Dictionary records \"racism\" as a synonym of \"racialism\": \"belief in the superiority of a particular race\". By the end of World War II, \"racism\" had acquired the same supremacist connotations formerly associated with \"racialism\": \"racism\" now implied racial discrimination, racial supremacism and a harmful intent. (The term \"race hatred\" had also been used by sociologist Frederick Hertz in the late 1920s.)\n\nAs its history indicates, the popular use of the word \"racism\" is relatively recent. The word came into widespread usage in the Western world in the 1930s, when it was used to describe the social and political ideology of Nazism, which saw \"race\" as a naturally given political unit. It is commonly agreed that racism existed before the coinage of the word, but there is not a wide agreement on a single definition of what racism is and what it is not. Today, some scholars of racism prefer to use the concept in the plural \"racisms\" in order to emphasize its many different forms that do not easily fall under a single definition and they also argue that different forms of racism have characterized different historical periods and geographical areas. Garner (2009: p. 11) summarizes different existing definitions of racism and identifies three common elements contained in those definitions of racism. First, a historical, hierarchical power relationship between groups; second, a set of ideas (an ideology) about racial differences; and, third, discriminatory actions (practices).\n\nThough many countries around the globe have passed laws related to race and discrimination, the first significant international human rights instrument developed by the United Nations (UN) was the Universal Declaration of Human Rights (UDHR). The UDHR was adopted by the United Nations General Assembly in 1948. The UDHR recognizes that if people are to be treated with dignity, they require economic rights, social rights including education, and the rights to cultural and political participation and civil liberty. It further states that everyone is entitled to these rights \"without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status.\"\n\nThe UN does not define \"racism\"; however, it does define \"racial discrimination\": According to the 1965 UN International Convention on the Elimination of All Forms of Racial Discrimination,\nthe term \"racial discrimination\" shall mean any distinction, exclusion, restriction, or preference based on race, colour, descent, or national or ethnic origin that has the purpose or effect of nullifying or impairing the recognition, enjoyment or exercise, on an equal footing, of human rights and fundamental freedoms in the political, economic, social, cultural or any other field of public life.\nIn their 1978 United Nations Educational, Scientific, and Cultural Organization (UNESCO) Declaration on Race and Racial Prejudice (Article 1), the UN states, \"All human beings belong to a single species and are descended from a common stock. They are born equal in dignity and rights and all form an integral part of humanity.\"\n\nThe UN definition of racial discrimination does not make any distinction between discrimination based on ethnicity and race, in part because the distinction between the two has been a matter of debate among academics, including anthropologists. Similarly, in British law the phrase \"racial group\" means \"any group of people who are defined by reference to their race, colour, nationality (including citizenship) or ethnic or national origin\".\n\nIn Norway, the word \"race\" has been removed from national laws concerning discrimination because the use of the phrase is considered problematic and unethical. The Norwegian Anti-Discrimination Act bans discrimination based on ethnicity, national origin, descent and skin color.\n\nSociologists, in general, recognize \"race\" as a social construct. This means that, although the concepts of race and racism are based on observable biological characteristics, any conclusions drawn about race on the basis of those observations are heavily influenced by cultural ideologies. Racism, as an ideology, exists in a society at both the individual and institutional level.\n\nWhile much of the research and work on racism during the last half-century or so has concentrated on \"white racism\" in the Western world, historical accounts of race-based social practices can be found across the globe. Thus, racism can be broadly defined to encompass individual and group prejudices and acts of discrimination that result in material and cultural advantages conferred on a majority or a dominant social group. So-called \"white racism\" focuses on societies in which white populations are the majority or the dominant social group. In studies of these majority white societies, the aggregate of material and cultural advantages is usually termed \"white privilege\".\n\nRace and race relations are prominent areas of study in sociology and economics. Much of the sociological literature focuses on white racism. Some of the earliest sociological works on racism were penned by sociologist W. E. B. Du Bois, the first African American to earn a doctoral degree from Harvard University. Du Bois wrote, \"The problem of the twentieth century is the problem of the color line.\" Wellman (1993) defines racism as \"culturally sanctioned beliefs, which, regardless of intentions involved, defend the advantages whites have because of the subordinated position of racial minorities\". In both sociology and economics, the outcomes of racist actions are often measured by the inequality in income, wealth, net worth, and access to other cultural resources, such as education, between racial groups.\n\nIn sociology and social psychology, racial identity and the acquisition of that identity, is often used as a variable in racism studies. Racial ideologies and racial identity affect individuals' perception of race and discrimination. Cazenave and Maddern (1999) define racism as \"a highly organized system of 'race'-based group privilege that operates at every level of society and is held together by a sophisticated ideology of color/'race' supremacy. Racial centrality (the extent to which a culture recognizes individuals' racial identity) appears to affect the degree of discrimination African American young adults perceive whereas racial ideology may buffer the detrimental emotional effects of that discrimination. Sellers and Shelton (2003) found that a relationship between racial discrimination and emotional distress was moderated by racial ideology and social beliefs.\n\nSome sociologists also argue that, particularly in the West where racism is often negatively sanctioned in society, racism has changed from being a blatant to a more covert expression of racial prejudice. The \"newer\" (more hidden and less easily detectable) forms of racism—which can be considered embedded in social processes and structures—are more difficult to explore as well as challenge. It has been suggested that, while in many countries overt or explicit racism has become increasingly taboo, even among those who display egalitarian explicit attitudes, an implicit or aversive racism is still maintained subconsciously.\n\nThis process has been studied extensively in social psychology as implicit associations and implicit attitudes, a component of implicit cognition. Implicit attitudes are evaluations that occur without conscious awareness towards an attitude object or the self. These evaluations are generally either favorable or unfavorable. They come about from various influences in the individual experience. Implicit attitudes are not consciously identified (or they are inaccurately identified) traces of past experience that mediate favorable or unfavorable feeling, thought, or action towards social objects. These thoughts, feelings or actions have an influence on behavior of which the individual may not be aware.\n\nTherefore, subconscious racism can influence our visual processing and how our minds work when we are subliminally exposed to faces of different colors. In thinking about crime, for example, social psychologist Jennifer L. Eberhardt (2004) of Stanford University holds that, \"blackness is so associated with crime you're ready to pick out these crime objects.\" Such exposures influence our minds and they can cause subconscious racism in our behavior towards other people or even towards objects. Thus, racist thoughts and actions can arise from stereotypes and fears of which we are not aware.\n\nLanguage, linguistics and discourse are active areas of study in the humanities, along with literature and the arts. Discourse analysis seeks to reveal the meaning of race and the actions of racists through careful study of the ways in which these factors of human society are described and discussed in various written and oral works. Van Dijk (1992), for example, examines the different ways in which descriptions of racism and racist actions are depicted by the perpetrators of such actions as well as by their victims. He notes that when descriptions of actions have negative implications for the majority, and especially for white elites, they are often seen as controversial and such controversial interpretations are typically marked with quotation marks or they are greeted with expressions of distance or doubt. The previously cited book, \"The Souls of Black Folk\" by W.E.B. Du Bois, represents early African-American literature that describes the author's experiences with racism when he was traveling in the South as an African American.\n\nMuch American fictional literature has focused on issues of racism and the black \"racial experience\" in the US, including works written by whites such as \"Uncle Tom's Cabin\", \"To Kill a Mockingbird\", and \"Imitation of Life\", or even the non-fiction work \"Black Like Me\". These books, and others like them, feed into what has been called the \"white savior narrative in film\", in which the heroes and heroines are white even though the story is about things that happen to black characters. Textual analysis of such writings can contrast sharply with black authors' descriptions of African Americans and their experiences in US society. African American writers have sometimes been portrayed in African-American studies as retreating from racial issues when they write about \"whiteness\", while others identify this as an African American literary tradition called \"the literature of white estrangement\", part of a multipronged effort to challenge and dismantle white supremacy in the US.\n\nRacism can be said to describe a condition in society in which a dominant racial group benefits from the oppression of others, whether that group wants such benefits or not.\n\nIn popular usage, as in some academic usage, little distinction is made between \"racism\" and \"ethnocentrism\". Often, the two are listed together as \"racial and ethnic\" in describing some action or outcome that is associated with prejudice within a majority or dominant group in society. Furthermore, the meaning of the term racism is often conflated with the terms prejudice, bigotry, and discrimination. Racism is a complex concept that can involve each of those, but it cannot be equated with nor is it synonymous with these other terms.\n\nAlso, the term is often used in relation to what is seen as prejudice within a minority or subjugated group, as in the concept of \"reverse racism\". Reverse racism describes discriminatory actions by members of a minority group against a dominant or formerly dominant racial or other group representative of the majority in a particular society. Those who campaign for the interests of ethnic minorities commonly reject the term \"reverse racism\". From their perspective, \"racism\" is defined not only in terms of individual prejudice, but also in terms of a power structure which protects the interests of the dominant culture and actively discriminates against ethnic minorities. From this perspective, they claim that while members of ethnic minorities may be prejudiced against members of the dominant culture, they lack the political and economic power to actively oppress them, and they are therefore incapable of \"racism\".\n\nSpecifically, the word \"racism\" appears to have been coined by Magnus Hirschfeld, a German-Jewish medical researcher who specialized in the field of sexology, or the scientific study of sex. The second edition of the Oxford English Dictionary (1989) lists the first known use of the word in English as appearing in the 1936 book \"The Coming American Fascism\" by Lawrence Dennis, a self-described fascist and advocate of fascism in America. However, Hirschfeld, who died in 1935, used the word in the title of his book \"Racism\", written in German a year before the first known use of the word by Dennis, and the word \"racism\" is used throughout the text. The word is a pejorative and was always intended as such; Hirschfeld himself denounced those he viewed as racist, and very few if any people use the word to describe themselves or their ideas, only those ideas they disagree with or find reprehensible.\n\nThe ideology underlying racism can become manifest in many aspects of social life. Such aspects are described in this section, although the list is not exhaustive.\n\nAversive racism is a form of implicit racism in which a person's unconscious negative evaluations of racial or ethnic minorities are realized by a persistent avoidance of interaction with other racial and ethnic groups. As opposed to traditional, overt racism, which is characterized by overt hatred for and explicit discrimination against racial/ethnic minorities, aversive racism is characterized by more complex, ambivalent expressions and attitudes. Aversive racism is similar in implications to the concept of symbolic or modern racism (described below), which is also a form of implicit, unconscious, or covert attitude which results in unconscious forms of discrimination.\n\nThe term was coined by Joel Kovel to describe the subtle racial behaviors of any ethnic or racial group who rationalize their aversion to a particular group by appeal to rules or stereotypes. People who behave in an aversively racial way may profess egalitarian beliefs, and will often deny their racially motivated behavior; nevertheless they change their behavior when dealing with a member of another race or ethnic group than the one they belong to. The motivation for the change is thought to be implicit or subconscious. Experiments have provided empirical support for the existence of aversive racism. Aversive racism has been shown to have potentially serious implications for decision making in employment, in legal decisions and in helping behavior.\n\nIn relation to racism, Color blindness is the disregard of racial characteristics in social interaction, for example in the rejection of affirmative action, as way to address the results of past patterns of discrimination. Critics of this attitude argue that by refusing to attend to racial disparities, racial color blindness in fact unconsciously perpetuates the patterns that produce racial inequality.\n\nEduardo Bonilla-Silva argues that color blind racism arises from an \"abstract liberalism, biologization of culture, naturalization of racial matters, and minimization of racism\". Color blind practices are \"subtle, institutional, and apparently nonracial\" because race is explicitly ignored in decision making. If race is disregarded in predominately white populations, for example, whiteness becomes the normative standard, whereas people of color are othered, and the racism these individuals experience may be minimized or erased. At an individual level, people with \"color blind prejudice\" reject racist ideology, but also reject systemic policies intended to fix institutional racism.\n\nCultural racism is a term used to describe and explain new racial ideologies and practices that have emerged since World War II. It can be defined as societal beliefs and customs that promote the assumption that the products of a given culture, including the language and traditions of that culture are superior to those of other cultures. It shares a great deal with xenophobia, which is often characterised by fear of, or aggression toward, members of an outgroup by members of an ingroup.\n\nCultural racism exists when there is a widespread acceptance of stereotypes concerning different ethnic or population groups. Where racism can be characterised by the belief that one race is inherently superior to another, cultural racism can be characterised by the belief that one culture is inherently superior to another.\n\nHistorical economic or social disparity is alleged to be a form of discrimination caused by past racism and historical reasons, affecting the present generation through deficits in the formal education and kinds of preparation in previous generations, and through primarily unconscious racist attitudes and actions on members of the general population.\n\nIn 2011, Bank of America agreed to pay $335 million to settle a federal government claim that its mortgage division, Countrywide Financial, discriminated against black and Hispanic homebuyers.\n\nDuring the Spanish colonial period, Spaniards developed a complex caste system based on race, which was used for social control and which also determined a person's importance in society. While many Latin American countries have long since rendered the system officially illegal through legislation, usually at the time of their independence, prejudice based on degrees of perceived racial distance from European ancestry combined with one's socioeconomic status remain, an echo of the colonial caste system.\n\nInstitutional racism (also known as structural racism, state racism or systemic racism) is racial discrimination by governments, corporations, religions, or educational institutions or other large organizations with the power to influence the lives of many individuals. Stokely Carmichael is credited for coining the phrase \"institutional racism\" in the late 1960s. He defined the term as \"the collective failure of an organization to provide an appropriate and professional service to people because of their colour, culture or ethnic origin\".\n\nMaulana Karenga argued that racism constituted the destruction of culture, language, religion, and human possibility and that the effects of racism were \"the morally monstrous destruction of human possibility involved redefining African humanity to the world, poisoning past, present and future relations with others who only know us through this stereotyping and thus damaging the truly human relations among peoples\".\n\nOthering is the term used by some to describe a system of discrimination whereby the characteristics of a group are used to distinguish them as separate from the norm.\n\nOthering plays a fundamental role in the history and continuation of racism. To objectify a culture as something different, exotic or underdeveloped is to generalize that it is not like 'normal' society. Europe's colonial attitude towards the Orient exemplifies this as it was thought that the East was the opposite of the West; feminine where the West was masculine, weak where the West was strong and traditional where the West was progressive. By making these generalizations and othering the East, Europe was simultaneously defining herself as the norm, further entrenching the gap.\n\nMuch of the process of othering relies on imagined difference, or the expectation of difference. Spatial difference can be enough to conclude that \"we\" are \"here\" and the \"others\" are over \"there\". Imagined differences serve to categorize people into groups and assign them characteristics that suit the imaginer's expectations.\n\nRacial discrimination refers to discrimination against someone on the basis of their race.\n\nRacial segregation is the separation of humans into socially-constructed racial groups in daily life. It may apply to activities such as eating in a restaurant, drinking from a water fountain, using a bath room, attending school, going to the movies, or in the rental or purchase of a home. Segregation is generally outlawed, but may exist through social norms, even when there is no strong individual preference for it, as suggested by Thomas Schelling's models of segregation and subsequent work.\n\nCenturies of European colonialism in the Americas, Africa and Asia were often justified by white supremacist attitudes. During the early 20th century, the phrase \"The White Man's Burden\" was widely used to justify an imperialist policy as a noble enterprise. A justification for the policy of conquest and subjugation of Native Americans emanated from the stereotyped perceptions of the indigenous people as \"merciless Indian savages\" (as described in the United States Declaration of Independence). In a 1890 article about colonial expansion onto Native American land, author L. Frank Baum wrote: \"The Whites, by law of conquest, by justice of civilization, are masters of the American continent, and the best safety of the frontier settlements will be secured by the total annihilation of the few remaining Indians.\" Attitudes of black supremacy, Arab supremacy, and East Asian supremacy also exist.\n\nSome scholars argue that in the US earlier violent and aggressive forms of racism have evolved into a more subtle form of prejudice in the late 20th century. This new form of racism is sometimes referred to as \"modern racism\" and it is characterized by outwardly acting unprejudiced while inwardly maintaining prejudiced attitudes, displaying subtle prejudiced behaviors such as actions informed by attributing qualities to others based on racial stereotypes, and evaluating the same behavior differently based on the race of the person being evaluated. This view is based on studies of prejudice and discriminatory behavior, where some people will act ambivalently towards black people, with positive reactions in certain, more public contexts, but more negative views and expressions in more private contexts. This ambivalence may also be visible for example in hiring decisions where job candidates that are otherwise positively evaluated may be unconsciously disfavored by employers in the final decision because of their race. Some scholars consider modern racism to be characterized by an explicit rejection of stereotypes, combined with resistance to changing structures of discrimination for reasons that are ostensibly non-racial, an ideology that considers opportunity at a purely individual basis denying the relevance of race in determining individual opportunities and the exhibition of indirect forms of micro-aggression toward and/or avoidance of people of other races.\n\nIn 1919, a proposal to include a racial equality provision in the Covenant of the League of Nations was supported by a majority, but not adopted in the Paris Peace Conference, 1919. In 1943, Japan and its allies declared work for the abolition of racial discrimination to be their aim at the Greater East Asia Conference. Article 1 of the 1945 UN Charter includes \"promoting and encouraging respect for human rights and for fundamental freedoms for all without distinction as to race\" as UN purpose.\n\nIn 1950, UNESCO suggested in \"The Race Question\"—a statement signed by 21 scholars such as Ashley Montagu, Claude Lévi-Strauss, Gunnar Myrdal, Julian Huxley, etc.—to \"drop the term \"race\" altogether and instead speak of ethnic groups\". The statement condemned scientific racism theories that had played a role in the Holocaust. It aimed both at debunking scientific racist theories, by popularizing modern knowledge concerning \"the race question,\" and morally condemned racism as contrary to the philosophy of the Enlightenment and its assumption of equal rights for all. Along with Myrdal's \"\" (1944), \"The Race Question\" influenced the 1954 U.S. Supreme Court desegregation decision in \"Brown v. Board of Education of Topeka\". Also in 1950, the European Convention on Human Rights was adopted, widely used on racial discrimination issues.\n\nThe United Nations use the definition of racial discrimination laid out in the \"International Convention on the Elimination of All Forms of Racial Discrimination\", adopted in 1966:\n\n... any distinction, exclusion, restriction or preference based on race, color, descent, or national or ethnic origin that has the purpose or effect of nullifying or impairing the recognition, enjoyment or exercise, on an equal footing, of human rights and fundamental freedoms in the political, economic, social, cultural or any other field of public life. (Part 1 of Article 1 of the U.N. International Convention on the Elimination of All Forms of Racial Discrimination)\nIn 2001, the European Union explicitly banned racism, along with many other forms of social discrimination, in the Charter of Fundamental Rights of the European Union, the legal effect of which, if any, would necessarily be limited to Institutions of the European Union: \"Article 21 of the charter prohibits discrimination on any ground such as race, color, ethnic or social origin, genetic features, language, religion or belief, political or any other opinion, membership of a national minority, property, disability, age or sexual orientation and also discrimination on the grounds of nationality.\"\n\nRacism existed during the 19th century as \"scientific racism\", which attempted to provide a racial classification of humanity. In 1775 Johann Blumenbach divided the world's population into five groups according to skin color (Caucasians, Mongols, etc.), positing the view that the non-caucasians had arisen through a process of degeneration. Another early view in scientific racism was the polygenist view, which held that the different races had been separately created. Polygenist Christoph Meiners for example, split mankind into two divisions which he labeled the \"beautiful White race\" and the \"ugly Black race\". In Meiners' book, \"The Outline of History of Mankind\", he claimed that a main characteristic of race is either beauty or ugliness. He viewed only the white race as beautiful. He considered ugly races to be inferior, immoral and animal-like.\n\nAnders Retzius demonstrated that neither Europeans nor others are one \"pure race\", but of mixed origins. While discredited, derivations of Blumenbach's taxonomy are still widely used for the classification of the population in the United States. , while strongly emphasizing that all humans today are of mixed origins, in 1907 claimed that the origins of human differences must be traced extraordinarily far back in time, and conjectured that the \"purest race\" today would be the Australian Aboriginals.\n\nScientific racism fell strongly out of favor in the early 20th Century, but the origins of fundamental human and societal differences are still researched within academia, in fields such as human genetics including paleogenetics, social anthropology, comparative politics, history of religions, history of ideas, prehistory, history, ethics, and psychiatry. There is widespread rejection of any methodology based on anything similar to Blumenbach's races. It is more unclear to which extent and when ethnic and national stereotypes are accepted.\n\nAlthough after World War II and the Holocaust, racist ideologies were discredited on ethical, political and scientific grounds, racism and racial discrimination have remained widespread around the world. From time to time when there is a revival of social and political tensions, new works are published which repeat past and discredited racial views such as J R Baker's 'Race'. Because of the social disapproval of explicit expressions of racism, contemporary authors may achieve a similar effect by insinuating subtle unstated stereotypes in their work as in Gladwell's 'The Tipping Point', a tactic President Obama called 'dog whistle racism'.\n\nDu Bois observed that it is not so much \"race\" that we think about, but culture: \"... a common history, common laws and religion, similar habits of thought and a conscious striving together for certain ideals of life\". Late 19th century nationalists were the first to embrace contemporary discourses on \"race\", ethnicity, and \"survival of the fittest\" to shape new nationalist doctrines. Ultimately, race came to represent not only the most important traits of the human body, but was also regarded as decisively shaping the character and personality of the nation. According to this view, culture is the physical manifestation created by ethnic groupings, as such fully determined by racial characteristics. Culture and race became considered intertwined and dependent upon each other, sometimes even to the extent of including nationality or language to the set of definition. Pureness of race tended to be related to rather superficial characteristics that were easily addressed and advertised, such as blondness. Racial qualities tended to be related to nationality and language rather than the actual geographic distribution of racial characteristics. In the case of Nordicism, the denomination \"Germanic\" was equivalent to superiority of race.\n\nBolstered by some nationalist and ethnocentric values and achievements of choice, this concept of racial superiority evolved to distinguish from other cultures that were considered inferior or impure. This emphasis on culture corresponds to the modern mainstream definition of racism: \"Racism does not originate from the existence of 'races'. It \"creates\" them through a process of social division into categories: anybody can be racialised, independently of their somatic, cultural, religious differences.\"\n\nThis definition explicitly ignores the biological concept of race, still subject to scientific debate. In the words of David C. Rowe \"A racial concept, although sometimes in the guise of another name, will remain in use in biology and in other fields because scientists, as well as lay persons, are fascinated by human diversity, some of which is captured by race.\"\n\nRacial prejudice became subject to international legislation. For instance, the Declaration on the Elimination of All Forms of Racial Discrimination, adopted by the United Nations General Assembly on November 20, 1963, address racial prejudice explicitly next to discrimination for reasons of race, colour or ethnic origin (Article I).\n\nDebates over the origins of racism often suffer from a lack of clarity over the term. Many use the term \"racism\" to refer to more general phenomena, such as xenophobia and ethnocentrism, although scholars attempt to clearly distinguish those phenomena from racism as an ideology or from scientific racism, which has little to do with ordinary xenophobia. Others conflate recent forms of racism with earlier forms of ethnic and national conflict. In most cases, ethno-national conflict seems to owe itself to conflict over land and strategic resources. In some cases, ethnicity and nationalism were harnessed in order to rally combatants in wars between great religious empires (for example, the Muslim Turks and the Catholic Austro-Hungarians).\n\nNotions of race and racism have often played central roles in ethnic conflicts. Throughout history, when an adversary is identified as \"other\" based on notions of race or ethnicity (in particular when \"other\" is construed to mean \"inferior\"), the means employed by the self-presumed \"superior\" party to appropriate territory, human chattel, or material wealth often have been more ruthless, more brutal, and less constrained by moral or ethical considerations. According to historian Daniel Richter, Pontiac's Rebellion saw the emergence on both sides of the conflict of \"the novel idea that all Native people were 'Indians,' that all Euro-Americans were 'Whites,' and that all on one side must unite to destroy the other.\" Basil Davidson states in his documentary, \"Africa: Different but Equal\", that racism, in fact, only just recently surfaced—as late as the 19th century, due to the need for a justification for slavery in the Americas.\n\nHistorically, racism was a major driving force behind the Transatlantic slave trade. It was also a major force behind racial segregation, especially in the United States in the nineteenth and early twentieth centuries and South Africa under apartheid; 19th and 20th century racism in Western world is particularly well documented and constitutes a reference point in studies and discourses about racism. Racism has played a role in genocides such as the Armenian genocide, and The Holocaust, and colonial projects like the European colonization of the Americas, Africa, and Asia. Indigenous peoples have been –and are– often subject to racist attitudes. Practices and ideologies of racism are condemned by the United Nations in the Declaration of Human Rights.\n\nAfter the Napoleonic Wars, Europe was confronted with the new \"nationalities question,\" leading to reconfigurations of the European map, on which the frontiers between the states had been delineated during the 1648 Peace of Westphalia. Nationalism had made its first appearance with the invention of the \"levée en masse\" by the French revolutionaries, thus inventing mass conscription in order to be able to defend the newly founded Republic against the \"Ancien Régime\" order represented by the European monarchies. This led to the French Revolutionary Wars (1792–1802) and then to the Napoleonic conquests, and to the subsequent European-wide debates on the concepts and realities of nations, and in particular of nation-states. The Westphalia Treaty had divided Europe into various empires and kingdoms (Ottoman Empire, Holy Roman Empire, Swedish Empire, Kingdom of France, etc.), and for centuries wars were waged between princes (\"Kabinettskriege\" in German).\n\nModern nation-states appeared in the wake of the French Revolution, with the formation of patriotic sentiments for the first time in Spain during the Peninsula War (1808–1813, known in Spain as the Independence War). Despite the restoration of the previous order with the 1815 Congress of Vienna, the \"nationalities question\" became the main problem of Europe during the Industrial Era, leading in particular to the 1848 Revolutions, the Italian unification completed during the 1871 Franco-Prussian War, which itself culminated in the proclamation of the German Empire in the Hall of Mirrors in the Palace of Versailles, thus achieving the German unification.\n\nMeanwhile, the Ottoman Empire, the \"sick man of Europe\", was confronted with endless nationalist movements, which, along with the dissolving of the Austrian-Hungarian Empire, would lead to the creation after World War I of the various nation-states of the Balkans, with \"national minorities\" in their borders.\nEthnic nationalism, which advocated the belief in a hereditary membership of the nation, made its appearance in the historical context surrounding the creation of the modern nation-states.\n\nOne of its main influences was the Romantic nationalist movement at the turn of the 19th century, represented by figures such as Johann Herder (1744–1803), Johan Fichte (1762–1814) in the \"Addresses to the German Nation\" (1808), Friedrich Hegel (1770–1831), or also, in France, Jules Michelet (1798–1874). It was opposed to liberal nationalism, represented by authors such as Ernest Renan (1823–1892), who conceived of the nation as a community, which, instead of being based on the \"Volk\" ethnic group and on a specific, common language, was founded on the subjective will to live together (\"the nation is a daily plebiscite\", 1882) or also John Stuart Mill (1806–1873).\nEthnic nationalism blended with scientific racist discourses, as well as with \"continental imperialist\" (Hannah Arendt, 1951) discourses, for example in the pan-Germanism discourses, which postulated the racial superiority of the German \"Volk\" (people/folk). The Pan-German League (\"Alldeutscher Verband\"), created in 1891, promoted German imperialism, \"racial hygiene\" and was opposed to intermarriage with Jews. Another popular current, the \"Völkisch movement\", was also an important proponent of the German ethnic nationalist discourse, and it combined Pan-Germanism with modern racial antisemitism. Members of the Völkisch movement, in particular the Thule Society, would participate in the founding of the German Workers' Party (DAP) in Munich in 1918, the predecessor of the National Socialist German Workers' Party (NSDAP; commonly known in English as the Nazi party). Pan-Germanism played a decisive role in the interwar period of the 1920s–1930s.\n\nThese currents began to associate the idea of the nation with the biological concept of a \"master race\" (often the \"Aryan race\" or the \"Nordic race\") issued from the scientific racist discourse. They conflated nationalities with ethnic groups, called \"races\", in a radical distinction from previous racial discourses that posited the existence of a \"race struggle\" inside the nation and the state itself. Furthermore, they believed that political boundaries should mirror these alleged racial and ethnic groups, thus justifying ethnic cleansing in order to achieve \"racial purity\" and also to achieve ethnic homogeneity in the nation-state.\n\nSuch racist discourses, combined with nationalism, were not, however, limited to pan-Germanism. In France, the transition from Republican, liberal nationalism, to ethnic nationalism, which made nationalism a characteristic of far-right movements in France, took place during the Dreyfus Affair at the end of the 19th century. During several years, a nationwide crisis affected French society, concerning the alleged treason of Alfred Dreyfus, a French Jewish military officer. The country polarized itself into two opposite camps, one represented by Émile Zola, who wrote \"J'accuse\" in defense of Alfred Dreyfus, and the other represented by the nationalist poet, Maurice Barrès (1862–1923), one of the founders of the ethnic nationalist discourse in France. At the same time, Charles Maurras (1868–1952), founder of the monarchist \"Action française\" movement, theorized the \"anti-France,\" composed of the \"four confederate states of Protestants, Jews, Freemasons and foreigners\" (his actual word for the latter being the pejorative \"métèques\"). Indeed, to him the first three were all \"internal foreigners\", who threatened the ethnic unity of the French people.\n\nBernard Lewis has cited the Greek philosopher Aristotle who, in his discussion of slavery, stated that while Greeks are free by nature, 'barbarians' (non-Greeks) are slaves by nature, in that it is in their nature to be more willing to submit to despotic government. Though Aristotle does not specify any particular races, he argues that people from outside Greece are more prone to the burden of slavery than those from Greece. Such proto-racism and ethnocentrism must be looked at within context, because a modern understanding of racism based on hereditary inferiority (modern racism based on: eugenics and scientific racism) was not yet developed and it is unclear whether Aristotle believed the natural inferiority of Barbarians was caused by environment and climate (like many of his contemporaries) or by birth. While Aristotle makes remarks about the most natural slaves being those with strong bodies and slave souls (unfit for rule, unintelligent) which would seem to imply a physical basis for discrimination, he also explicitly states that the right kind of souls and bodies don't always go together, implying that the greatest determinate for inferiority and natural slaves versus natural masters is the soul, not the body. This proto-racism is seen as an important precursor to modern racism by classicist Benjamin Isaac.\n\nHistorian Dante A. Puzzo, in his discussion of Aristotle, racism, and the ancient world writes that: Racism rests on two basic assumptions: that a correlation exists between physical characteristics and moral qualities; that mankind is divisible into superior and inferior stocks. Racism, thus defined, is a modern conception, for prior to the XVIth century there was virtually nothing in the life and thought of the West that can be described as racist. To prevent misunderstanding a clear distinction must be made between racism and ethnocentrism ... The Ancient Hebrews, in referring to all who were not Hebrews as Gentiles, were indulging in ethnocentrism, not in racism. ... So it was with the Hellenes who denominated all non-Hellenes—whether the wild Scythians or the Egyptians whom they acknowledged as their mentors in the arts of civilization—Barbarians, the term denoting that which was strange or foreign.\n\nIn the Middle East and North Africa region, racist opinions were expressed within the works of some of its historians and geographers including Al-Muqaddasi, Al-Jahiz, Al-Masudi, Abu Rayhan Biruni, Nasir al-Din al-Tusi, and Ibn Qutaybah. In the 14th century CE, the Tunisian scholar Ibn Khaldun wrote:\n\n...beyond [known peoples of black West Africa] to the south there is no civilization in the proper sense. There are only humans who are closer to dumb animals than to rational beings. They live in thickets and caves, and eat herbs and unprepared grain. They frequently eat each other. They cannot be considered human beings. Therefore, the Negro nations are, as a rule, submissive to slavery, because (Negroes) have little that is (essentially) human and possess attributes that are quite similar to those of dumb animals, as we have stated.\n\nThough the Qur'an expresses no racial prejudice, such prejudices later developed among Arabs for a variety of reasons: their extensive conquests and slave trade; the influence of Aristotelian ideas regarding slavery, which some Muslim philosophers directed towards Zanj (Bantu) and Turkic peoples; and the influence of Judeo-Christian ideas regarding divisions among humankind. In response to such views, the Afro-Arab author Al-Jahiz, himself having a Zanj grandfather, wrote a book entitled \"Superiority Of The Blacks To The Whites\", and explained why the Zanj were black in terms of environmental determinism in the \"On the Zanj\" chapter of \"The Essays\". By the 14th century, a significant number of slaves came from sub-Saharan Africa, leading to the likes of Egyptian historian Al-Abshibi (1388–1446) writing: \"It is said that when the [black] slave is sated, he fornicates, when he is hungry, he steals.\"\n\nHowever, the Umayyad Caliphate invaded Hispania thus creating Al-Andalus, whereby Muslim Berber invaders annihilated the Visigothic rulers, while contributing to the Golden age of Jewish culture which lasted for six centuries. It was followed by the centuries-long \"Reconquista\" terminated under the Catholic monarchs Ferdinand V and Isabella I. The legacy Catholic Spaniards then formulated the \"Cleanliness of blood\" doctrine. It was during this time in history that the Western concept of aristocratic \"blue blood\" emerged in a racialized, religious and feudal context, so as to stem the upward social mobility of the converted New Christians. Robert Lacey explains:\n\nIt was the Spaniards who gave the world the notion that an aristocrat's blood is not red but blue. The Spanish nobility started taking shape around the ninth century in classic military fashion, occupying land as warriors on horseback. They were to continue the process for more than five hundred years, clawing back sections of the peninsula from its Moorish occupiers, and a nobleman demonstrated his pedigree by holding up his sword arm to display the filigree of blue-blooded veins beneath his pale skin—proof that his birth had not been contaminated by the dark-skinned enemy. Sangre azul, blue blood, was thus a euphemism for being a white man—Spain's own particular reminder that the refined footsteps of the aristocracy through history carry the rather less refined spoor of racism.\nFollowing the expulsion of the Arabic Moors and most of the Sephardic Jews from the Iberian peninsula, the remaining Jews and Muslims were forced to convert to Roman Catholicism, becoming \"New Christians\", who were sometimes discriminated by the \"Old Christians\" in some cities (e.g. Toledo), despite condemnations by the Church and the State, who were welcoming the new flock. Inquisition was carried out by members of the Dominican Order in order to weed out the converts that still practiced Judaism and Islam in secret. The system and ideology of the \"limpieza de sangre\" ostracized false Christian converts from society to protect it against treason. The remnants of such legislation persevered into the 19th century in military contexts.\n\nIn Portugal, the legal distinction between New and Old Christian was only ended through a legal decree issued by the Marquis of Pombal in 1772, almost three centuries after the implementation of the racist discrimination. The \"limpieza de sangre\" legislation was common also during the colonization of the Americas, where it led to the racial and feudal separation of peoples and social strata in the colonies. It was however often ignored in practice, as the new colonies needed skilled people.\n\nAt the end of the Renaissance, the Valladolid debate (1550–1551) concerning the treatment of natives of the \"New World\" opposed the Dominican friar and Bishop of Chiapas Bartolomé de Las Casas to another Dominican and Humanist philosopher Juan Ginés de Sepúlveda. The latter argued that the Indians practiced human sacrifice of innocents, cannibalism, and other such \"crimes against nature\" were unacceptable and should be suppressed by any means possible including war, thus reducing them to slavery or serfdom was in accordance with Catholic theology and natural law. To the contrary, Bartolomé de Las Casas argued that the Amerindians were free men in the natural order and deserved the same treatment as others, according to Catholic theology. It was one of the many controversies concerning racism, slavery, religion, and European morality that would arise in the following centuries and which resulted in the legislation protecting the natives.\n\nAlthough antisemitism has a long history, related to Christianity and e.g. native Egyptian or Greek religions (anti-Judaism), racism itself is sometimes described as a \"modern\" phenomenon. In the view of the French philosopher and historian Michel Foucault, the first formulation of racism emerged in the Early Modern period as the \"discourse of race struggle\", a historical and political discourse, which Foucault opposed to the philosophical and juridical discourse of sovereignty. On the other hand, e.g. Chinese self-identification as a \"yellow race\" predated such European racial concepts.\n\nThis European analysis, which first appeared in Great Britain, was then carried on in France by people such as Boulainvilliers, Nicolas Fréret, and then, during the 1789 French Revolution, Sieyès, and afterward Augustin Thierry and Cournot. Boulainvilliers, who created the matrix of such racist discourse in medieval France, conceived of the \"race\" as being something closer to the sense of a \"nation\", that is, in his time, the \"race\" meant the \"people\".\n\nHe conceived of France as being divided between various nations—the unified nation-state is, of course, here an anachronism—which themselves formed different \"races\". Boulainvilliers opposed the absolute monarchy, which tried to bypass the aristocracy by establishing a direct relationship to the Third Estate. Thus, he developed the theory that the French aristocrats were the descendants of foreign invaders, whom he called the \"Franks\", while according to him, the Third Estate constituted the autochthonous, vanquished Gallo-Romans, who were dominated by the Frankish aristocracy as a consequence of the right of conquest. Early modern racism was opposed to nationalism and the nation-state: the Comte de Montlosier, in exile during the French Revolution, who borrowed Boulainvilliers' discourse on the \"Nordic race\" as being the French aristocracy that invaded the plebeian \"Gauls\", thus showed his contempt for the Third Estate, calling it \"this new people born of slaves ... mixture of all races and of all times\".\n\nWhile 19th century racism became closely intertwined with nationalism, leading to the ethnic nationalist discourse that identified the \"race\" with the \"folk\", leading to such movements as pan-Germanism, pan-Turkism, pan-Arabism, and pan-Slavism, medieval racism precisely divided the nation into various non-biological \"races\", which were thought to be the consequence of historical conquests and social conflicts. Michel Foucault traced the genealogy of modern racism to this medieval \"historical and political discourse of race struggle\". According to him, it divided itself in the 19th century according to two rival lines: on one hand, it was incorporated by racists, biologists and eugenicists, who gave it the modern sense of \"race\" and, even more, transformed this popular discourse into a \"state racism\" (e.g., Nazism). On the other hand, Marxism also seized this discourse founded on the assumption of a political struggle that provided the real engine of history and continued to act underneath the apparent peace. Thus, Marxists transformed the essentialist notion of \"race\" into the historical notion of \"class struggle\", defined by socially structured positions: capitalist or proletarian. In \"The Will to Knowledge\" (1976), Foucault analyzed another opponent of the \"race struggle\" discourse: Sigmund Freud's psychoanalysis, which opposed the concept of \"blood heredity\", prevalent in the 19th century racist discourse.\n\nAuthors such as Hannah Arendt, in her 1951 book \"The Origins of Totalitarianism\", have said that the racist ideology (\"popular racism\") which developed at the end of the 19th century helped legitimize the imperialist conquests of foreign territories and the atrocities that sometimes accompanied them (such as the Herero and Namaqua Genocide of 1904–1907 or the Armenian Genocide of 1915–1917). Rudyard Kipling's poem \"The White Man's Burden\" (1899) is one of the more famous illustrations of the belief in the inherent superiority of the European culture over the rest of the world, though it is also thought to be a satirical appraisal of such imperialism. Racist ideology thus helped legitimize the conquest and incorporation of foreign territories into an empire, which were regarded as a humanitarian obligation partially as a result of these racist beliefs.\n\nHowever, during the 19th century, Western European colonial powers were involved in the suppression of the Arab slave trade in Africa, as well as in the suppression of the slave trade in West Africa. Some Europeans during the time period objected to injustices that occurred in some colonies and lobbied on behalf of aboriginal peoples. Thus, when the Hottentot Venus was displayed in England in the beginning of the 19th century, the African Association publicly opposed itself to the exhibition. The same year that Kipling published his poem, Joseph Conrad published \"Heart of Darkness\" (1899), a clear criticism of the Congo Free State owned by Leopold II of Belgium.\n\nExamples of racial theories used include the creation of the Hamitic ethno-linguistic group during the European exploration of Africa. It was then restricted by Karl Friedrich Lepsius (1810–1877) to non-Semitic Afro-Asiatic languages.\n\nThe term \"Hamite\" was applied to different populations within North Africa, mainly comprising Ethiopians, Eritreans, Somalis, Berbers, and the ancient Egyptians. Hamites were regarded as Caucasoid peoples who probably originated in either Arabia or Asia on the basis of their cultural, physical and linguistic similarities with the peoples of those areas. Europeans considered Hamites to be more civilized than Sub-Saharan Africans, and more akin to themselves and Semitic peoples. In the first two-thirds of the 20th century, the Hamitic race was, in fact, considered one of the branches of the Caucasian race, along with the Indo-Europeans, Semites, and the Mediterranean race.\n\nHowever, the Hamitic peoples themselves were often deemed to have failed as rulers, which was usually ascribed to interbreeding with Negroes. In the mid-20th century, the German scholar Carl Meinhof (1857–1944) claimed that the Bantu race was formed by a merger of Hamitic and Negro races. The Hottentots (Nama or Khoi) were formed by the merger of Hamitic and Bushmen (San) races—both being termed nowadays as Khoisan peoples.\nIn the United States in the early 19th century, the American Colonization Society was established as the primary vehicle for proposals to return black Americans to greater freedom and equality in Africa. The colonization effort resulted from a mixture of motives with its founder Henry Clay stating; \"unconquerable prejudice resulting from their color, they never could amalgamate with the free whites of this country. It was desirable, therefore, as it respected them, and the residue of the population of the country, to drain them off\". Racism spread throughout the New World in the late 19th century and early 20th century. Whitecapping, which started in Indiana in the late 19th century, soon spread throughout all of North America, causing many African laborers to flee from the land they worked on. In the US during the 1860s, racist posters were used during election campaigns. In one of these racist posters (see above), a black man is depicted lounging idly in the foreground as one white man ploughs his field and another chops wood. Accompanying labels are: \"In the sweat of thy face shalt thou eat thy bread,\" and \"The white man must work to keep his children and pay his taxes.\" The black man wonders, \"Whar is de use for me to work as long as dey make dese appropriations.\" Above in a cloud is an image of the \"Freedman's Bureau! Negro Estimate of Freedom!\" The bureau is pictured as a large domed building resembling the U.S. Capitol and is inscribed \"Freedom and No Work.\" Its columns and walls are labeled, \"Candy,\" \"Rum, Gin, Whiskey,\" \"Sugar Plums,\" \"Indolence,\" \"White Women,\" \"Apathy,\" \"White Sugar,\" \"Idleness,\" and so on.\n\nOn June 5, 1873, Sir Francis Galton, distinguished English explorer and cousin of Charles Darwin, wrote in a letter to \"The Times\":\n\nThe Nazi party, which seized power in the 1933 German elections and maintained a dictatorship over much of Europe until the End of World War II on the European continent, deemed the Germans to be part of an Aryan \"master race\" (\"Herrenvolk\"), who therefore had the right to expand their territory and enslave or kill members of other races deemed inferior.\n\nThe racial ideology conceived by the Nazis graded humans on a scale of pure Aryan to non-Aryan, with the latter viewed as subhuman. At the top of the scale of pure Aryans were Germans and other Germanic peoples including the Dutch, Scandinavians, and the English as well as other peoples such as some northern Italians and the French who were said to have a suitable admixture of Germanic blood. Nazi policies labeled Romani people, people of color and Slavs (mainly Poles, Serbs and Russians) as inferior non-Aryan subhumans. Jews were at the bottom of the hierarchy, considered inhuman and thus unworthy of life. In accordance with Nazi racial ideology, approximately six million Jews were killed in the Holocaust. 2.5 million ethnic Poles, 0.5 million ethnic Serbs and 0.22–0.5 million Romani were killed by the regime and its collaborators.\n\nThe Nazis considered most Slavs to be Non-Aryan \"Untermenschen\". Slavic nations such as the Ukrainians, Czechs, Slovaks, Bulgarians and Croats who collaborated with Nazi Germany were perceived as ethnically superior to other Slavs, mostly due to pseudoscientific theories about these nations having a considerable admixture of Germanic blood. In the secret plan Generalplan Ost (\"Master Plan East\") the Nazis resolved to expel, enslave, or exterminate most Slavic people to provide \"living space\" for Germans, however Nazi policy towards Slavs changed during World War II due to manpower shortages which necessitated limited Slavic participation in the Waffen-SS. Significant war crimes were committed against Slavs, particularly Poles, and Soviet POWs had a far higher mortality rate than their American and British counterparts due to deliberate neglect and mistreatment.\n\nWhite supremacy was dominant in the U.S. up to the civil rights movement. On the U.S. immigration laws prior to 1965, sociologist Stephen Klineberg cited the law as clearly declaring \"that Northern Europeans are a superior subspecies of the white race.\" While anti-Asian racism was embedded in U.S. politics and culture in the early 20th century, Indians were also racialized for their anticolonialism, with U.S. officials, casting them as a \"Hindu\" menace, pushing for Western imperial expansion abroad. The Naturalization Act of 1790 limited U.S. citizenship to whites only, and in the 1923 case, \"United States v. Bhagat Singh Thind\", the Supreme Court ruled that high caste Hindus were not \"white persons\" and were therefore racially ineligible for naturalized citizenship. It was after the Luce–Celler Act of 1946 that a quota of 100 Indians per year could immigrate to the U.S. and become citizens. The Immigration and Nationality Act of 1965 dramatically opened entry to the U.S. to immigrants other than traditional Northern European and Germanic groups, and as a result would significantly alter the demographic mix in the U.S.\n\nSerious race riots in Durban between Indians and Zulus erupted in 1949. Ne Win's rise to power in Burma in 1962 and his relentless persecution of \"resident aliens\" led to an exodus of some 300,000 Burmese Indians. They migrated to escape racial discrimination and wholesale nationalisation of private enterprise a few years later in 1964. The Zanzibar Revolution of January 12, 1964 put an end to the local Arab dynasty. Thousands of Arabs and Indians in Zanzibar were massacred in riots, and thousands more were detained or fled the island. On 4 August 1972, Idi Amin, President of Uganda, ethnically cleansed Uganda's Asians giving them 90 days to leave the country.\n\nShortly after World War II the South African National Party took control of the government in South Africa. Between 1948 and 1994, the Apartheid regime took place. This regime based its ideology on the racial separation of whites and non-whites including the unequal rights of non-whites. Several protests and violence occurred during the struggle against Apartheid, the most famous of these include the Sharpeville Massacre in 1960, the Soweto uprising in 1976, the Church Street bombing of 1983 and the Cape Town peace march of 1989.\n\nDuring the Congo Civil War (1998–2003), Pygmies were hunted down like game animals and eaten. Both sides in the war regarded them as \"subhuman\" and some say their flesh can confer magical powers. UN human rights activists reported in 2003 that rebels had carried out acts of cannibalism. Sinafasi Makelo, a representative of the Mbuti pygmies, has asked the UN Security Council to recognise cannibalism as both a crime against humanity and an act of genocide. A report released by the United Nations Committee on the Elimination of Racial Discrimination condemns Botswana's treatment of the 'Bushmen' as racist. In 2008, the tribunal of the 15-nation Southern African Development Community (SADC) accused Zimbabwean President Robert Mugabe of having a racist attitude towards white people.\n\nThe mass demonstrations and riots against African students in Nanjing, China, lasted from December 1988 to January 1989. Bar owners in central Beijing had been forced by the police \"not to serve black people or Mongolians\" during the 2008 Summer Olympics, as the police associates these ethnic groups with illegal prostitution and drug trafficking. In November 2009, British newspaper \"The Guardian\" reported that Lou Jing, of mixed Chinese and African parentage, had emerged as the most famous talent show contestant in China and has become the subject of intense debate because of her skin color. Her attention in the media opened serious debates about racism in China and racial prejudice.\n\nIn Asia and Latin America, light skin is seen as more attractive. Thus, skin whitening cosmetic products are popular in East Asia and India. Some activists, most prominently at the UN conference at Durban, have asserted that the caste system in India is a form of racial discrimination, although many prominent scholars debunk this viewpoint as \"scientifically nonsense\", since there are no consistent racial differences between the different castes in India. These activists utilize genetic studies that claim to corroborate their view, although other more detailed studies have challenged these assertions as overtly simplistic Currently, there are approximately 165 million Dalits (formerly known as \"untouchables\") in India.\n\nSome 70,000 black African Mauritanians were expelled from Mauritania in the late 1980s. In the Sudan, black African captives in the civil war were often enslaved, and female prisoners were often sexually abused. The Darfur conflict has been described by some as a racial matter. In October 2006, Niger announced that it would deport the Arabs living in the Diffa region of eastern Niger to Chad. This population numbered about 150,000. While the Government collected Arabs in preparation for the deportation, two girls died, reportedly after fleeing Government forces, and three women suffered miscarriages.\nThe Jakarta riots of May 1998 targeted many Chinese Indonesians. The anti-Chinese legislation was in the Indonesian constitution until 1998. Resentment against Chinese workers has led to violent confrontations in Africa and Oceania. Anti-Chinese rioting, involving tens of thousands of people, broke out in Papua New Guinea in May 2009. Indo-Fijians suffered violent attacks after the Fiji coup of 2000. Non-indigenous citizens of Fiji are subject to discrimination. Racial divisions also exist in Guyana, Malaysia, Trinidad and Tobago, Madagascar, or South Africa.\n\nElements within Israeli society have been accused of . Accusations of racism range from birth control policies, education, and housing discrimination.\n\nOne form of racism in the United States was enforced racial segregation which existed until the 1960s when it was outlawed in the Civil Rights Act of 1964. It has been argued that this separation of races continues to exist \"de facto\" today . The causes of segregation vary from lack of access to loans and resources to discrimination in realty.\n\nScottish philosopher and economist David Hume said, \"I am apt to suspect the Negroes to be naturally inferior to the Whites. There scarcely ever was a civilised nation of that complexion, nor even any individual, eminent either in action or in speculation. No ingenious manufacture among them, no arts, no sciences.\" German philosopher Immanuel Kant stated: \"The yellow Indians do have a meagre talent. The Negroes are far below them, and at the lowest point are a part of the American people.\"\n\nIn the 19th century, the German philosopher, Georg Wilhelm Friedrich Hegel, declared that \"Africa is no historical part of the world.\" Hegel further claimed that blacks had no \"sense of personality; their spirit sleeps, remains sunk in itself, makes no advance, and thus parallels the compact, undifferentiated mass of the African continent.\"\n\nWhile opposed to slavery in the U.S, in 1858 President Abraham Lincoln stated, \"I am not, nor ever have been in favor of bringing about in any way the social and political equality of the white and black races, that I am not, nor ever have been in favor of making voters or jurors of negroes, nor of qualifying them to hold office, nor to intermarry with white people. I as much as any man am in favor of the superior position assigned to the white race\".\n\nAustrian philosopher Otto Weininger, claimed: \"A genius has perhaps scarcely ever appeared amongst the negroes, and the standard of their morality is almost universally so low that it is beginning to be acknowledged in America that their emancipation was an act of imprudence.\"\n\nThe German conservative, Oswald Spengler, remarked on what he perceived as the culturally degrading influence of Africans in modern Western culture: in \"The Hour of Decision\" Spengler denounced \"the 'happy ending' of an empty existence, the boredom of which has brought to jazz music and Negro dancing to perform the Death March for a great Culture.\" During the Nazi era, German scientists rearranged academia to support claims of a grand \"Aryan\" agent behind the splendors of all human civilizations, including India and Ancient Egypt.\n\nThe modern biological definition of race developed in the 19th century with scientific racist theories. The term \"scientific racism\" refers to the use of science to justify and support racist beliefs, which goes back to the early 18th century, though it gained most of its influence in the mid-19th century, during the New Imperialism period. Also known as academic racism, such theories first needed to overcome the Church's resistance to positivist accounts of history and its support of monogenism, the concept that all human beings were originated from the same ancestors, in accordance with creationist accounts of history.\n\nThese racist theories put forth on scientific hypothesis were combined with unilineal theories of social progress, which postulated the superiority of the European civilization over the rest of the world. Furthermore, they frequently made use of the idea of \"survival of the fittest\", a term coined by Herbert Spencer in 1864, associated with ideas of competition, which were named social Darwinism in the 1940s. Charles Darwin himself opposed the idea of rigid racial differences in \"The Descent of Man\" (1871) in which he argued that humans were all of one species, sharing common descent. He recognised racial differences as varieties of humanity, and emphasised the close similarities between people of all races in mental faculties, tastes, dispositions and habits, while still contrasting the culture of the \"lowest savages\" with European civilization.\n\nAt the end of the 19th century, proponents of scientific racism intertwined themselves with eugenics discourses of \"degeneration of the race\" and \"blood heredity.\" Henceforth, scientific racist discourses could be defined as the combination of polygenism, unilinealism, social Darwinism and eugenism. They found their scientific legitimacy on physical anthropology, anthropometry, craniometry, phrenology, physiognomy, and others now discredited disciplines in order to formulate racist prejudices.\n\nBefore being disqualified in the 20th century by the American school of cultural anthropology (Franz Boas, etc.), the British school of social anthropology (Bronisław Malinowski, Alfred Radcliffe-Brown, etc.), the French school of ethnology (Claude Lévi-Strauss, etc.), as well as the discovery of the neo-Darwinian synthesis, such sciences, in particular anthropometry, were used to deduce behaviours and psychological characteristics from outward, physical appearances.\n\nThe neo-Darwinian synthesis, first developed in the 1930s, eventually led to a gene-centered view of evolution in the 1960s. According to the Human Genome Project, the most complete mapping of human DNA to date indicates that there is no clear genetic basis to racial groups. While some genes are more common in certain populations, there are no genes that exist in all members of one population and no members of any other.\n\nThe first theory of eugenics was developed in 1869 by Francis Galton (1822–1911), who used the then popular concept of \"degeneration\". He applied statistics to study human differences and the alleged \"inheritance of intelligence\", foreshadowing future uses of \"intelligence testing\" by the anthropometry school. Such theories were vividly described by the writer Émile Zola (1840–1902), who started publishing in 1871 a twenty-novel cycle, \"Les Rougon-Macquart\", where he linked heredity to behavior. Thus, Zola described the high-born Rougons as those involved in politics (\"Son Excellence Eugène Rougon\") and medicine (\"Le Docteur Pascal\") and the low-born Macquarts as those fatally falling into alcoholism (\"L'Assommoir\"), prostitution (\"Nana\"), and homicide (\"La Bête humaine\").\n\nDuring the rise of Nazism in Germany, some scientists in Western nations worked to debunk the regime's racial theories. A few argued against racist ideologies and discrimination, even if they believed in the alleged existence of biological races. However, in the fields of anthropology and biology, these were minority positions until the mid-20th century. According to the 1950 UNESCO statement, \"The Race Question\", an international project to debunk racist theories had been attempted in the mid-1930s. However, this project had been abandoned. Thus, in 1950, UNESCO declared that it had resumed:\n\n...up again, after a lapse of fifteen years, a project that the International Committee on Intellectual Cooperation has wished to carry through but that it had to abandon in deference to the appeasement policy of the pre-war period. The race question had become one of the pivots of Nazi ideology and policy. Masaryk and Beneš took the initiative of calling for a conference to re-establish in the minds and consciences of men everywhere the truth about race ... Nazi propaganda was able to continue its baleful work unopposed by the authority of an international organisation.\nThe Third Reich's racial policies, its eugenics programs and the extermination of Jews in the Holocaust, as well as Romani people in the Porrajmos (the Romani Holocaust) and others minorities led to a change in opinions about scientific research into race after the war. Changes within scientific disciplines, such as the rise of the Boasian school of anthropology in the United States contributed to this shift. These theories were strongly denounced in the 1950 UNESCO statement, signed by internationally renowned scholars, and titled \"The Race Question\".\n\nWorks such as Arthur de Gobineau's \"An Essay on the Inequality of the Human Races\" (1853–1855) may be considered as one of the first theorizations of this new racism, founded on an essentialist notion of race, which opposed the former racial discourse, of Boulainvilliers for example, which saw in races a fundamentally historical reality, which changed over time. Gobineau, thus, attempted to frame racism within the terms of biological differences among humans, giving it the legitimacy of biology.\n\nGobineau's theories would be expanded, in France, by Georges Vacher de Lapouge (1854–1936)'s typology of races, who published in 1899 \"The Aryan and his Social Role\", in which he claimed that the white, \"Aryan race\", \"dolichocephalic\", was opposed to the \"brachycephalic\" race, of whom the \"Jew\" was the archetype. Vacher de Lapouge thus created a hierarchical classification of races, in which he identified the \"\"Homo europaeus\" (Teutonic, Protestant, etc.), the \"\"Homo alpinus\"\" (Auvergnat, Turkish, etc.), and finally the \"\"Homo mediterraneus\"\" (Neapolitan, Andalus, etc.) He assimilated races and social classes, considering that the French upper class was a representation of the \"Homo europaeus\", while the lower class represented the \"Homo alpinus\". Applying Galton's eugenics to his theory of races, Vacher de Lapouge's \"selectionism\" aimed first at achieving the annihilation of trade unionists, considered to be a \"degenerate\"; second, creating types of man each destined to one end, in order to prevent any contestation of labour conditions. His \"anthroposociology\" thus aimed at blocking social conflict by establishing a fixed, hierarchical social order.\n\nThe same year, William Z. Ripley used identical racial classification in \"The Races of Europe\" (1899), which would have a great influence in the United States. Other scientific authors include H.S. Chamberlain at the end of the 19th century (a British citizen who naturalized himself as German because of his admiration for the \"Aryan race\") and Madison Grant, a eugenicist and author of \"The Passing of the Great Race\" (1916). Madison Grant provided statistics for the Immigration Act of 1924, which severely restricted immigration of Jews, Slavs, and southern Europeans, who were subsequently hindered in seeking to escape Nazi Germany.\n\nHuman zoos (called \"People Shows\"), were an important means of bolstering \"popular racism\" by connecting it to scientific racism: they were both objects of public curiosity and of anthropology and anthropometry. Joice Heth, an African American slave, was displayed by P.T. Barnum in 1836, a few years after the exhibition of Saartjie Baartman, the \"Hottentot Venus\", in England. Such exhibitions became common in the New Imperialism period, and remained so until World War II. Carl Hagenbeck, inventor of the modern zoos, exhibited animals beside humans who were considered \"savages\".\n\nCongolese pygmy Ota Benga was displayed in 1906 by eugenicist Madison Grant, head of the Bronx Zoo, as an attempt to illustrate the \"missing link\" between humans and orangutans: thus, racism was tied to Darwinism, creating a social Darwinist ideology that tried to ground itself in Darwin's scientific discoveries. The 1931 Paris Colonial Exhibition displayed Kanaks from New Caledonia. A \"Congolese village\" was on display as late as 1958 at the Brussels' World Fair.\n\nEvolutionary psychologists John Tooby and Leda Cosmides were puzzled by the fact that in the US race is one of the three characteristics most often used in brief descriptions of individuals (the others are age and sex). They reasoned that natural selection would not have favoured the evolution of an instinct for using race as a classification, because for most of human history, humans almost never encountered members of other races. Tooby and Cosmides hypothesized that modern people use race as a proxy (rough-and-ready indicator) for coalition membership, since a better-than-random guess about \"which side\" another person is on will be helpful if one does not actually know in advance.\n\nTheir colleague Robert Kurzban designed an experiment whose results appeared to support this hypothesis. Using the Memory confusion protocol, they presented subjects with pictures of individuals and sentences, allegedly spoken by these individuals, which presented two sides of a debate. The errors that the subjects made in recalling who said what indicated that they sometimes misattributed a statement to a speaker of the same race as the \"correct\" speaker, although they also sometimes misattributed a statement to a speaker \"on the same side\" as the \"correct\" speaker. In a second run of the experiment, the team also distinguished the \"sides\" in the debate by clothing of similar colors; and in this case the effect of racial similarity in causing mistakes almost vanished, being replaced by the color of their clothing. In other words, the first group of subjects, with no clues from clothing, used race as a visual guide to guessing who was on which side of the debate; the second group of subjects used the clothing color as their main visual clue, and the effect of race became very small.\n\nSome research suggests that ethnocentric thinking may have actually contributed to the development of cooperation. Political scientists Ross Hammond and Robert Axelrod created a computer simulation wherein virtual individuals were randomly assigned one of a variety of skin colors, and then one of a variety of trading strategies: be color-blind, favor those of your own color, or favor those of other colors. They found that the ethnocentric individuals clustered together, then grew until all the non-ethnocentric individuals were wiped out.\n\nIn \"The Selfish Gene\", evolutionary biologist Richard Dawkins writes that \"Blood-feuds and inter-clan warfare are easily interpretable in terms of Hamilton's genetic theory.\" Dawkins writes that racial prejudice, while not evolutionarily adaptive, \"could be interpreted as an irrational generalization of a kin-selected tendency to identify with individuals physically resembling oneself, and to be nasty to individuals different in appearance\". Simulation-based experiments in evolutionary game theory have attempted to provide an explanation for the selection of ethnocentric-strategy phenotypes.\n\nDespite support for evolutionary theories relating to an innate origin of racism, various studies have suggested racism is associated with lower intelligence and less diverse peer groups during childhood. A neuroimaging study on amygdala activity during racial matching activities found increased activity to be associated with adolescent age as well as less racially diverse peer groups which the author conclude suggest an learned aspect of racism. A meta analysis of neuroimaging studies found amygdala activity correlated to increased scores on implicit measures of racial bias. It was also argued amygdala activity in response to racial stimuli represents increased threat perception rather than the traditional theory of the amygdala activity represented ingroup-outgroup processing. Racism has also been associated with lower childhood IQ in an analysis of 15,000 people in the UK.\n\nState racism—that is, the institutions and practices of a nation-state that are grounded in racist ideology—has played a major role in all instances of settler colonialism, from the United States to Australia. It also played a prominent role in the Nazi German regime, in fascist regimes throughout Europe, and during the early years of Japan's Shōwa period. These governments advocated and implemented ideologies and policies that were racist, xenophobic and, in the case of Nazism, genocidal. The politics of Zimbabwe promote discrimination against whites, in an effort to ethnically cleanse the country.\n\nThe Nuremberg Race Laws of 1935 prohibited sexual relations between any Aryan and Jew, considering it \"Rassenschande\", \"racial pollution\". The Nuremberg Laws stripped all Jews, even quarter- and half-Jews (second and first degree \"Mischlings\"), of their German citizenship. This meant that they had no basic citizens' rights, e.g., the right to vote. In 1936, Jews were banned from all professional jobs, effectively preventing them from having any influence in education, politics, higher education and industry. On 15 November 1938, Jewish children were banned from going to normal schools. By April 1939, nearly all Jewish companies had either collapsed under financial pressure and declining profits, or had been persuaded to sell out to the Nazi government. This further reduced their rights as human beings; they were in many ways officially separated from the German populace. Similar laws existed in Bulgaria – The Law for protection of the nation, Hungary, Romania, and Austria.\n\nLegislative state racism is known to have been enforced by the National Party of South Africa during its Apartheid regime between 1948 and 1994. Here a series of Apartheid legislation was passed through the legal systems to make it legal for white South Africans to have rights which were superior to those of non-white South Africans. Non-white South Africans were not allowed involvement in any governing matters, including voting; access to quality healthcare; the provision of basic services, including clean water; electricity; as well as access to adequate schooling. Non-white South Africans were also prevented from accessing certain public areas, from using certain public transportation and were required to live only in certain designated areas. Non-white South Africans were taxed differently than white South Africans and they were also required to carry on them at all times additional documentation, which later became known as \"dom passes\", to certify their non-white South African citizenship. All of these legislative racial laws were abolished through a series of equal human rights laws which were passed at the end of the Apartheid era in the early 1990s.\n\nThe current constitution of Liberia, as enacted in 1984, is racist in its Article 27, because it does not allow non-blacks to become Liberian citizens: \"only persons who are Negroes or of Negro descent shall qualify by birth or by naturalization to be citizens of Liberia\".\n\nAnti-racism includes beliefs, actions, movements, and policies which are adopted or developed in order to oppose racism. In general, it promotes an egalitarian society in which people are not discriminated against on the basis of race. Movements such as the Civil Rights Movement and the Anti-Apartheid Movement were examples of anti-racist movements. Nonviolent resistance is sometimes embraced as an element of anti-racist movements, although this was not always the case. Hate crime laws, affirmative action, and bans on racist speech are also examples of government policy which is intended to suppress racism.\n\nUNESCO marks March 21 as the yearly International Day for the Elimination of Racial Discrimination, in memory of the events that occurred on March 21, 1960 in Sharpeville, South Africa, where police killed demonstrators protesting against the apartheid regime.\n\nThe Museum of Tolerance offers children and adults an opportunity to interact with authentic artifacts from the Holocaust.\nThe Southern Poverty Law Center disseminates materials to teachers to help them educate their students about the causes and effects of racism.\n\n"}
{"id": "25614", "url": "https://en.wikipedia.org/wiki?curid=25614", "title": "Race (human categorization)", "text": "Race (human categorization)\n\nRace, as a social construct, is the classification of humans into groups based on physical traits, ancestry, genetics, or social relations, or the relations between those groups. First used to refer to speakers of a common language and then to denote national affiliations, by the 17th century race began to refer to physical (i.e. phenotypical) traits. The term was often used in a general biological taxonomic sense, starting from the 19th century, to denote genetically differentiated human populations defined by phenotype.\n\nSocial conceptions and groupings of races vary over time, involving folk taxonomies that define of individuals based on perceived traits. Scientists consider biological essentialism obsolete, and generally discourage racial explanations for collective differentiation in both physical and behavioral traits.\n\nEven though there is a broad scientific agreement that essentialist and typological conceptualizations of race are untenable, scientists around the world continue to conceptualize race in widely differing ways, some of which have essentialist implications. While some researchers use the concept of race to make distinctions among fuzzy sets of traits or observable differences in behaviour, others in the scientific community suggest that the idea of race often is used in a naive or simplistic way, and argue that, among humans, race has no taxonomic significance by pointing out that all living humans belong to the same species, \"Homo sapiens\", and subspecies, \"Homo sapiens sapiens\".\n\nSince the second half of the 20th century, the association of race with the ideologies and theories that grew out of the work of 19th-century anthropologists and physiologists has led to the use of the word \"race\" itself becoming problematic. Although still used in general contexts, \"race\" has often been replaced by less ambiguous and loaded terms: \"populations\", \"people(s)\", \"ethnic groups\", or \"communities\", depending on context.\n\nA popular view in American sociology is that the racial categories that are common in everyday usage are socially constructed, and that racial groups cannot be biologically defined. Nonetheless, some biologists argue that racial categories correlate with biological traits (e.g. phenotype), and that certain genetic markers have varying frequencies among human populations, some of which correspond more or less to traditional racial groupings. For this reason, there is no current consensus about whether racial categories can be considered to have significance for understanding human genetic variation.\n\nWhen people define and talk about a particular conception of race, they create a social reality through which social categorization is achieved. In this sense, races are said to be social constructs. These constructs develop within various legal, economic, and sociopolitical contexts, and may be the effect, rather than the cause, of major social situations. While race is understood to be a social construct by many, most scholars agree that race has real material effects in the lives of people through institutionalized practices of preference and discrimination.\n\nSocioeconomic factors, in combination with early but enduring views of race, have led to considerable suffering within disadvantaged racial groups. Racial discrimination often coincides with racist mindsets, whereby the individuals and ideologies of one group come to perceive the members of an outgroup as both racially defined and morally inferior. As a result, racial groups possessing relatively little power often find themselves excluded or oppressed, while hegemonic individuals and institutions are charged with holding racist attitudes. Racism has led to many instances of tragedy, including slavery and genocide.\n\nIn some countries, law enforcement uses race to profile suspects. This use of racial categories is frequently criticized for perpetuating an outmoded understanding of human biological variation, and promoting stereotypes. Because in some societies racial groupings correspond closely with patterns of social stratification, for social scientists studying social inequality, race can be a significant variable. As sociological factors, racial categories may in part reflect subjective attributions, self-identities, and social institutions.\n\nScholars continue to debate the degrees to which racial categories are biologically warranted and socially constructed, as well as the extent to which the realities of race must be acknowledged in order for society to comprehend and address racism adequately. For example, John Hartigan, Jr. argued in 2008 that race as a biological concept is becoming more tenable in a way \"that renders claims about its social construction tenuous and uncertain.\" Accordingly, the racial paradigms employed in different disciplines vary in their emphasis on biological reduction as contrasted with societal construction.\n\nIn the social sciences, theoretical frameworks such as racial formation theory and critical race theory investigate implications of race as social construction by exploring how the images, ideas and assumptions of race are expressed in everyday life. A large body of scholarship has traced the relationships between the historical, social production of race in legal and criminal language, and their effects on the policing and disproportionate incarceration of certain groups.\n\nGroups of humans have always identified themselves as distinct from neighboring groups, but such differences have not always been understood to be natural, immutable and global. These features are the distinguishing features of how the concept of race is used today. In this way the idea of race as we understand it today came about during the historical process of exploration and conquest which brought Europeans into contact with groups from different continents, and of the ideology of classification and typology found in the natural sciences.\n\nAccording to Smedley and Marks the European concept of \"race\", along with many of the ideas now associated with the term, arose at the time of the scientific revolution, which introduced and privileged the study of natural kinds, and the age of European imperialism and colonization which established political relations between Europeans and peoples with distinct cultural and political traditions. As Europeans encountered people from different parts of the world, they speculated about the physical, social, and cultural differences among various human groups. The rise of the Atlantic slave trade, which gradually displaced an earlier trade in slaves from throughout the world, created a further incentive to categorize human groups in order to justify the subordination of African slaves. Drawing on Classical sources and upon their own internal interactions—for example, the hostility between the English and Irish powerfully influenced early European thinking about the differences between people—Europeans began to sort themselves and others into groups based on physical appearance, and to attribute to individuals belonging to these groups behaviors and capacities which were claimed to be deeply ingrained. A set of folk beliefs took hold that linked inherited physical differences between groups to inherited intellectual, behavioral, and moral qualities. Similar ideas can be found in other cultures, for example in China, where a concept often translated as \"race\" was associated with supposed common descent from the Yellow Emperor, and used to stress the unity of ethnic groups in China. Brutal conflicts between ethnic groups have existed throughout history and across the world.\n\nThe first post-Classical published classification of humans into distinct races seems to be François Bernier's \"Nouvelle division de la terre par les différents espèces ou races qui l'habitent\" (\"New division of Earth by the different species or races which inhabit it\"), published in 1684. In the 18th century the differences among human groups became a focus of scientific investigation. But the scientific classification of phenotypic variation was frequently coupled with racist ideas about innate predispositions of different groups, always attributing the most desirable features to the White, European race and arranging the other races along a continuum of progressively undesirable attributes. The 1735 classification of Carl Linnaeus, inventor of zoological taxonomy, divided the human species \"Homo sapiens\" into continental varieties of \"europaeus\", \"asiaticus\", \"americanus\", and \"afer\", each associated with a different humour: sanguine, melancholic, choleric, and phlegmatic, respectively. \"Homo sapiens europaeus\" was described as active, acute, and adventurous, whereas \"Homo sapiens afer\" was said to be crafty, lazy, and careless.\n\nThe 1775 treatise \"The Natural Varieties of Mankind\", by Johann Friedrich Blumenbach proposed five major divisions: the Caucasoid race, the Mongoloid race, the Ethiopian race (later termed Negroid), the American Indian race, and the Malayan race, but he did not propose any hierarchy among the races. Blumenbach also noted the graded transition in appearances from one group to adjacent groups and suggested that \"one variety of mankind does so sensibly pass into the other, that you cannot mark out the limits between them\".\n\nFrom the 17th through 19th centuries, the merging of folk beliefs about group differences with scientific explanations of those differences produced what Smedley has called an \"ideology of race\". According to this ideology, races are primordial, natural, enduring and distinct. It was further argued that some groups may be the result of mixture between formerly distinct populations, but that careful study could distinguish the ancestral races that had combined to produce admixed groups. Subsequent influential classifications by Georges Buffon, Petrus Camper and Christoph Meiners all classified \"Negros\" as inferior to Europeans. In the United States the racial theories of Thomas Jefferson were influential. He saw Africans as inferior to Whites especially in regards to their intellect, and imbued with unnatural sexual appetites, but described Native Americans as equals to whites.\n\nIn the last two decades of the 18th century, the theory of polygenism, the belief that different races had evolved separately in each continent and shared no common ancestor, was advocated in England by historian Edward Long and anatomist Charles White, in Germany by ethnographers Christoph Meiners and Georg Forster, and in France by Julien-Joseph Virey. In the US, Samuel George Morton, Josiah Nott and Louis Agassiz promoted this theory in the mid-nineteenth century. Polygenism was popular and most widespread in the 19th century, culminating in the founding of the Anthropological Society of London (1863) during the period of the American Civil War, in opposition to the Ethnological Society, which had abolitionist sympathies.\n\nToday, all humans are classified as belonging to the species \"Homo sapiens\" and sub-species \"Homo sapiens sapiens\". However, this is not the first species of homininae: the first species of genus \"Homo\", \"Homo habilis\", evolved in East Africa at least 2 million years ago, and members of this species populated different parts of Africa in a relatively short time. \"Homo erectus\" evolved more than 1.8 million years ago, and by 1.5 million years ago had spread throughout Europe and Asia. Virtually all physical anthropologists agree that \"Archaic Homo sapiens\" (A group including the possible species H. heidelbergensis, H. rhodesiensis and H. neanderthalensis) evolved out of African \"Homo erectus\" (\"sensu lato\") or \"Homo ergaster.\" Anthropologists increasingly support the idea that anatomically modern humans (\"Homo sapiens sapiens\") evolved in North or East Africa from \"H. heidelbergensis\" and then migrated out of Africa, mixing with and replacing \"H. heidelbergensis\" and \"H. neanderthalensis\" populations throughout Europe and Asia, and \"H. rhodesiensis\" populations in Sub-Saharan Africa (a combination of the Out of Africa and Multiregional models).\n\nIn the early 20th century, many anthropologists accepted and taught the belief that biologically distinct races were isomorphic with distinct linguistic, cultural, and social groups, while popularly applying that belief to the field of eugenics, in conjunction with a practice that is now called scientific racism. After the Nazi eugenics program, along with the rise of anti-colonial movements, racial essentialism lost widespread popularity. Race anthropologists were pressured to acknowledge findings coming from studies of culture and population genetics, and to revise their conclusions about the sources of phenotypic variation. A significant number of modern anthropologists and biologists in the West came to view race as an invalid genetic or biological designation.\n\nThe first to challenge the concept of race on empirical grounds were the anthropologists Franz Boas, who provided evidence of phenotypic plasticity due to environmental factors, and Ashley Montagu, who relied on evidence from genetics. E. O. Wilson then challenged the concept from the perspective of general animal systematics, and further rejected the claim that \"races\" were equivalent to \"subspecies\".\n\nAccording to Jonathan Marks,\n\nThe term \"race\" in biology is used with caution because it can be ambiguous. Generally, when it is used it is effectively a synonym of \"subspecies\". (For animals, the only taxonomic unit below the species level is usually the subspecies; there are narrower infraspecific ranks in botany, and \"race\" does not correspond directly with any of them.)\n\nPopulation geneticists have debated whether the concept of \"population\" can provide a basis for a new conception of race. To do this, a working definition of population must be found. Surprisingly, there is no generally accepted concept of population that biologists use. Although the concept of population is central to ecology, evolutionary biology and conservation biology, most definitions of population rely on qualitative descriptions such as \"a group of organisms of the same species occupying a particular space at a particular time\". Waples and Gaggiotti identify two broad types of definitions for populations; those that fall into an \"ecological paradigm\", and those that fall into an \"evolutionary paradigm\". Examples of such definitions are:\n\nTraditionally, subspecies are seen as geographically isolated and genetically differentiated populations. That is, \"the designation 'subspecies' is used to indicate an objective degree of microevolutionary divergence\". One objection to this idea is that it does not specify what degree of differentiation is required. Therefore, any population that is somewhat biologically different could be considered a subspecies, even to the level of a local population. As a result, Templeton has argued that it is necessary to impose a threshold on the level of difference that is required for a population to be designated a subspecies.\n\nThis effectively means that populations of organisms must have reached a certain measurable level of difference to be recognised as subspecies.\nDean Amadon proposed in 1949 that subspecies would be defined according to the seventy-five percent rule which means that 75% of a population must lie outside 99% of the range of other populations for a given defining morphological character or a set of characters. The seventy-five percent rule still has defenders but other scholars argue that it should be replaced with ninety or ninety-five percent rule.\n\nIn 1978, Sewall Wright suggested that human populations that have long inhabited separated parts of the world should, in general, be considered different subspecies by the usual criterion that most individuals of such populations can be allocated correctly by inspection. Wright argued that it does not require a trained anthropologist to classify an array of Englishmen, West Africans, and Chinese with 100% accuracy by features, skin color, and type of hair despite so much variability within each of these groups that every individual can easily be distinguished from every other. However, it is customary to use the term race rather than subspecies for the major subdivisions of the human species as well as for minor ones.\n\nOn the other hand, in practice subspecies are often defined by easily observable physical appearance, but there is not necessarily any evolutionary significance to these observed differences, so this form of classification has become less acceptable to evolutionary biologists. Likewise this typological approach to race is generally regarded as discredited by biologists and anthropologists.\n\nBecause of the difficulty in classifying subspecies morphologically, many biologists have found the concept problematic, citing issues such as:\n\nSesardic argues that when several traits are analyzed at the same time, forensic anthropologists can classify a person's race with an accuracy of close to 100% based on only skeletal remains. Sesardic's claim has been disputed by Massimo Pigliucci, who accused Sesardic of \"cherry pick[ing] the scientific evidence and reach[ing] conclusions that are contradicted by it.\" Specifically, Pigliucci argues that Sesardic misrepresented a paper by Ousley et al. (2009), and neglected to mention that they identified differentiation not just between individuals from different races, but also between individuals from different tribes, local environments, and time periods. This is discussed in a later section.\n\nCladistics is another method of classification. A clade is a taxonomic group of organisms consisting of a single common ancestor and all the descendants of that ancestor. Every creature produced by sexual reproduction has two immediate lineages, one maternal and one paternal. Whereas Carl Linnaeus established a taxonomy of living organisms based on anatomical similarities and differences, cladistics seeks to establish a taxonomy—the phylogenetic tree—based on genetic similarities and differences and tracing the process of acquisition of multiple characteristics by single organisms. Some researchers have tried to clarify the idea of race by equating it to the biological idea of the clade. Often mitochondrial DNA or Y chromosome sequences are used to study ancient human migration paths. These single-locus sources of DNA do not recombine and are inherited from a single parent. Individuals from the various continental groups tend to be more similar to one another than to people from other continents, and tracing either mitochondrial DNA or non-recombinant Y-chromosome DNA explains how people in one place may be largely derived from people in some remote location. Human genetic variation is predominantly within races, continuous, and complex in structure, which is inconsistent with the concept of genetic human races.\n\nOften taxonomists prefer to use phylogenetic analysis to determine whether a population can be considered a subspecies. Phylogenetic analysis relies on the concept of derived characteristics that are not shared between groups, usually applying to populations that are allopatric (geographically separated) and therefore discretely bounded. This would make a subspecies, evolutionarily speaking, a clade – a group with a common evolutionary ancestor population. The smooth gradation of human genetic variation in general tends to rule out any idea that human population groups can be considered monophyletic (cleanly divided), as there appears to always have been considerable gene flow between human populations. Rachel Caspari (2003) have argued that clades are by definition monophyletic groups (a taxon that includes \"all\" descendants of a given ancestor) and since no groups currently regarded as races are monophyletic, none of those groups can be clades. Robin Andreasen (2000) proposes that cladistics can be used to categorize human races biologically, and that races can be both biologically real and socially constructed.\n\nFor the anthropologists Lieberman and Jackson (1995), however, there are more profound methodological and conceptual problems with using cladistics to support concepts of race. They claim that \"the molecular and biochemical proponents of this model explicitly use racial categories \"in their initial grouping of samples\"\". For example, the large and highly diverse macroethnic groups of East Indians, North Africans, and Europeans are presumptively grouped as Caucasians prior to the analysis of their DNA variation. This is claimed to limit and skew interpretations, obscure other lineage relationships, deemphasize the impact of more immediate clinal environmental factors on genomic diversity, and can cloud our understanding of the true patterns of affinity. They argue that however significant the empirical research, these studies use the term race in conceptually imprecise and careless ways. They suggest that the authors of these studies find support for racial distinctions only because they began by assuming the validity of race. \"For empirical reasons we prefer to place emphasis on clinal variation, which recognizes the existence of adaptive human hereditary variation and simultaneously stresses that such variation is not found in packages that can be labeled \"races\".\"\n\nThese scientists do not dispute the importance of cladistic research, only its retention of the word race, when reference to populations and clinal gradations are more than adequate to describe the results.\n\nOne crucial innovation in reconceptualizing genotypic and phenotypic variation was the anthropologist C. Loring Brace's observation that such variations, insofar as it is affected by natural selection, slow migration, or genetic drift, are distributed along geographic gradations or clines. In part this is due to isolation by distance. This point called attention to a problem common to phenotype-based descriptions of races (for example, those based on hair texture and skin color): they ignore a host of other similarities and differences (for example, blood type) that do not correlate highly with the markers for race. Thus, anthropologist Frank Livingstone's conclusion, that since clines cross racial boundaries, \"there are no races, only clines\".\n\nIn a response to Livingstone, Theodore Dobzhansky argued that when talking about race one must be attentive to how the term is being used: \"I agree with Dr. Livingstone that if races have to be 'discrete units', then there are no races, and if 'race' is used as an 'explanation' of the human variability, rather than vice versa, then the explanation is invalid.\" He further argued that one could use the term race if one distinguished between \"race differences\" and \"the race concept\". The former refers to any distinction in gene frequencies between populations; the latter is \"a matter of judgment\". He further observed that even when there is clinal variation, \"Race differences are objectively ascertainable biological phenomena ... but it does not follow that racially distinct populations must be given racial (or subspecific) labels.\" In short, Livingstone and Dobzhansky agree that there are genetic differences among human beings; they also agree that the use of the race concept to classify people, and how the race concept is used, is a matter of social convention. They differ on whether the race concept remains a meaningful and useful social convention.\n\nIn 1964, the biologists Paul Ehrlich and Holm pointed out cases where two or more clines are distributed discordantly—for example, melanin is distributed in a decreasing pattern from the equator north and south; frequencies for the haplotype for beta-S hemoglobin, on the other hand, radiate out of specific geographical points in Africa. As the anthropologists Leonard Lieberman and Fatimah Linda Jackson observed, \"Discordant patterns of heterogeneity falsify any description of a population as if it were genotypically or even phenotypically homogeneous\".\n\nPatterns such as those seen in human physical and genetic variation as described above, have led to the consequence that the number and geographic location of any described races is highly dependent on the importance attributed to, and quantity of, the traits considered. Scientists discovered a skin-lighting mutation that partially accounts for the appearance of Light skin in humans (people who migrated out of Africa northward into what is now Europe) which they estimate occurred 20,000 to 50,000 years ago. The East Asians owe their relatively light skin to different mutations. On the other hand, the greater the number of traits (or alleles) considered, the more subdivisions of humanity are detected, since traits and gene frequencies do not always correspond to the same geographical location. Or as put it:\n\nRecent studies of human genetic clustering have included a debate over how genetic variation is organized, with clusters and clines as the main possible orderings. argued for smooth, clinal genetic variation in ancestral populations even in regions previously considered racially homogeneous, with the apparent gaps turning out to be artifacts of sampling techniques. disputed this and offered an analysis of the Human Genetic Diversity Panel showing that there were small discontinuities in the smooth genetic variation for ancestral populations at the location of geographic barriers such as the Sahara, the Oceans, and the Himalayas. Nonetheless, stated that their findings “should not be taken as evidence of our support of any particular concept of biological race... Genetic differences among human populations derive mainly from gradations in allele frequencies rather than from distinctive 'diagnostic' genotypes.\" Using a sample of 40 populations distributed roughly evenly across the Earth's land surface, found that \"genetic diversity is distributed in a more clinal pattern when more geographically intermediate populations are sampled.\"\n\nAnother way to look at differences between populations is to measure genetic differences rather than physical differences between groups. The mid-20th-century anthropologist William C. Boyd defined race as: \"A population which differs significantly from other populations in regard to the frequency of one or more of the genes it possesses. It is an arbitrary matter which, and how many, gene loci we choose to consider as a significant 'constellation'\". Leonard Lieberman and Rodney Kirk have pointed out that \"the paramount weakness of this statement is that if one gene can distinguish races then the number of races is as numerous as the number of human couples reproducing.\" Moreover, the anthropologist Stephen Molnar has suggested that the discordance of clines inevitably results in a multiplication of races that renders the concept itself useless. The Human Genome Project states \"People who have lived in the same geographic region for many generations may have some alleles in common, but no allele will be found in all members of one population and in no members of any other.\" Massimo Pigliucci and Jonathan Kaplan argue that human races do exist, and that they correspond to the genetic classification of ecotypes, but that real human races do not correspond very much, if at all, to folk racial categories. In contrast, Walsh & Yun reviewed the literature in 2011 and reported that \"Genetic studies using very few chromosomal loci find that genetic polymorphisms divide human populations into clusters with almost 100 percent accuracy and that they correspond to the traditional anthropological categories.\"\n\nThe population geneticist Sewall Wright developed one way of measuring genetic differences between populations known as the Fixation index, which is often abbreviated to \"F\". This statistic is often used in taxonomy to compare differences between any two given populations by measuring the genetic differences among and between populations for individual genes, or for many genes simultaneously. It is often stated that the fixation index for humans is about 0.15. This translates to an estimated 85% of the variation measured in the overall human population is found within individuals of the same population, and about 15% of the variation occurs between populations. These estimates imply that any two individuals from different populations are almost as likely to be more similar to each other than either is to a member of their own group. Richard Lewontin, who affirmed these ratios, thus concluded neither \"race\" nor \"subspecies\" were appropriate or useful ways to describe human populations. However, others have noticed that group variation was relatively similar to the variation observed in other mammalian species.\n\nWright himself believed that values >0.25 represent very great genetic variation and that an \"F\" of 0.15–0.25 represented great variation. However, about 5% of human variation occurs between populations within continents, therefore \"F\" values between continental groups of humans (or races) of as low as 0.1 (or possibly lower) have been found in some studies, suggesting more moderate levels of genetic variation. Graves (1996) has countered that \"F\" should not be used as a marker of subspecies status, as the statistic is used to measure the degree of differentiation between populations, although see also Wright (1978).\n\nIn an ongoing debate, some geneticists argue that race is neither a meaningful concept nor a useful heuristic device, and even that genetic differences among groups are biologically meaningless, because more genetic variation exists within such races than among them, and that racial traits overlap without discrete boundaries.\n\nJeffrey Long and Rick Kittles give a long critique of the application of \"F\" to human populations in their 2003 paper \"Human Genetic Diversity and the Nonexistence of Biological Races\". They find that the figure of 85% is misleading because it implies that all human populations contain on average 85% of all genetic diversity. They claim that this does not correctly reflect human population history, because it treats all human groups as independent. A more realistic portrayal of the way human groups are related is to understand that some human groups are parental to other groups and that these groups represent paraphyletic groups to their descent groups. For example, under the recent African origin theory the human population in Africa is paraphyletic to all other human groups because it represents the ancestral group from which all non-African populations derive, but more than that, non-African groups only derive from a small non-representative sample of this African population. This means that all non-African groups are more closely related to each other and to some African groups (probably east Africans) than they are to others, and further that the migration out of Africa represented a genetic bottleneck, with much of the diversity that existed in Africa not being carried out of Africa by the emigrating groups. This view produces a version of human population movements that do not result in all human populations being independent; but rather, produces a series of dilutions of diversity the further from Africa any population lives, each founding event representing a genetic subset of its parental population. Long and Kittles find that rather than 85% of human genetic diversity existing in all human populations, about 100% of human diversity exists in a single African population, whereas only about 70% of human genetic diversity exists in a population derived from New Guinea. Long and Kittles argued that this still produces a global human population that is genetically homogeneous compared to other mammalian populations.\n\nIn his 2003 paper, \"\", A. W. F. Edwards argued that rather than using a locus-by-locus analysis of variation to derive taxonomy, it is possible to construct a human classification system based on characteristic genetic patterns, or \"clusters\" inferred from multilocus genetic data. Geographically based human studies since have shown that such genetic clusters can be derived from analyzing of a large number of loci which can assort individuals sampled into groups analogous to traditional continental racial groups. Joanna Mountain and Neil Risch cautioned that while genetic clusters may one day be shown to correspond to phenotypic variations between groups, such assumptions were premature as the relationship between genes and complex traits remains poorly understood. However, Risch denied such limitations render the analysis useless: \"Perhaps just using someone's actual birth year is not a very good way of measuring age. Does that mean we should throw it out? ... Any category you come up with is going to be imperfect, but that doesn't preclude you from using it or the fact that it has utility.\"\n\nEarly human genetic cluster analysis studies were conducted with samples taken from ancestral population groups living at extreme geographic distances from each other. It was thought that such large geographic distances would maximize the genetic variation between the groups sampled in the analysis and thus maximize the probability of finding cluster patterns unique to each group. In light of the historically recent acceleration of human migration (and correspondingly, human gene flow) on a global scale, further studies were conducted to judge the degree to which genetic cluster analysis can pattern ancestrally identified groups as well as geographically separated groups. One such study looked at a large multiethnic population in the United States, and \"detected only modest genetic differentiation between different current geographic locales within each race/ethnicity group. Thus, ancient geographic ancestry, which is highly correlated with self-identified race/ethnicity—as opposed to current residence—is the major determinant of genetic structure in the U.S. population.\" ()\n\nAnthropologists such as C. Loring Brace, the philosophers Jonathan Kaplan and Rasmus Winther, and the geneticist Joseph Graves, have argued that while there it is certainly possible to find biological and genetic variation that corresponds roughly to the groupings normally defined as \"continental races\", this is true for almost all geographically distinct populations. The cluster structure of the genetic data is therefore dependent on the initial hypotheses of the researcher and the populations sampled. When one samples continental groups, the clusters become continental; if one had chosen other sampling patterns, the clustering would be different. Weiss and Fullerton have noted that if one sampled only Icelanders, Mayans and Maoris, three distinct clusters would form and all other populations could be described as being clinally composed of admixtures of Maori, Icelandic and Mayan genetic materials. Kaplan and Winther therefore argue that, seen in this way, both Lewontin and Edwards are right in their arguments. They conclude that while racial groups are characterized by different allele frequencies, this does not mean that racial classification is a natural taxonomy of the human species, because multiple other genetic patterns can be found in human populations that crosscut racial distinctions. Moreover, the genomic data underdetermines whether one wishes to see subdivisions (i.e., splitters) or a continuum (i.e., lumpers). Under Kaplan and Winther's view, racial groupings are objective social constructions (see Mills 1998) that have conventional biological reality only insofar as the categories are chosen and constructed for pragmatic scientific reasons. In earlier work, Winther had identified \"diversity partitioning\" and \"clustering analysis\" as two separate methodologies, with distinct questions, assumptions, and protocols. Each is also associated with opposing ontological consequences vis-a-vis the metaphysics of race. Philosopher Lisa Gannett has argued that biogeographical ancestry, a concept devised by Mark Shriver and Tony Frudakis, is not an objective measure of the biological aspects of race as Shriver and Frudakis claim it is. She argues that it is actually just a \"local category shaped by the U.S. context of its production, especially the forensic aim of being able to predict the race or ethnicity of an unknown suspect based on DNA found at the crime scene.\"\n\nGuido Barbujani has written that human genetic variation is generally distributed continuously in gradients across much of Earth, and that there is no evidence that genetic boundaries between human populations exist as would be necessary for human races to exist.\n\nOver time, human genetic variation has formed a nested structure that is inconsistent with the concept of races that have evolved independently of one another.\n\nAs anthropologists and other evolutionary scientists have shifted away from the language of race to the term \"population\" to talk about genetic differences, historians, cultural anthropologists and other social scientists re-conceptualized the term \"race\" as a cultural category or social construct— i.e. a way among many possible ways in which a society chooses to divide its members into categories.\n\nMany social scientists have replaced the word race with the word \"ethnicity\" to refer to self-identifying groups based on beliefs concerning shared culture, ancestry and history. Alongside empirical and conceptual problems with \"race\", following the Second World War, evolutionary and social scientists were acutely aware of how beliefs about race had been used to justify discrimination, apartheid, slavery, and genocide. This questioning gained momentum in the 1960s during the civil rights movement in the United States and the emergence of numerous anti-colonial movements worldwide. They thus came to believe that race itself is a social construct, a concept that was believed to correspond to an objective reality but which was believed in because of its social functions.\n\nCraig Venter and Francis Collins of the National Institute of Health jointly made the announcement of the mapping of the human genome in 2000. Upon examining the data from the genome mapping, Venter realized that although the genetic variation within the human species is on the order of 1–3% (instead of the previously assumed 1%), the types of variations do not support notion of genetically defined races. Venter said, \"Race is a social concept. It's not a scientific one. There are no bright lines (that would stand out), if we could compare all the sequenced genomes of everyone on the planet.\" \"When we try to apply science to try to sort out these social differences, it all falls apart.\"\n\nStephan Palmié asserted that race \"is not a thing but a social relation\"; or, in the words of Katya Gibel Mevorach, \"a metonym\", \"a human invention whose criteria for differentiation are neither universal nor fixed but have always been used to manage difference.\" As such, the use of the term \"race\" itself must be analyzed. Moreover, they argue that biology will not explain why or how people use the idea of race: History and social relationships will.\n\nImani Perry has argued that race \"is produced by social arrangements and political decision making.\" Perry explains race more in stating, \"race is something that happens, rather than something that is. It is dynamic, but it holds no objective truth.\"\n\nSome scholars have challenged the notion that race is primarily a social construction by arguing that race has a biological basis. One of the researchers, Neil Risch, noted: \"we looked at the correlation between genetic structure [based on microsatellite markers] versus self-description, we found 99.9% concordance between the two. We actually had a higher discordance rate between self-reported sex and markers on the X chromosome! So you could argue that sex is also a problematic category. And there are differences between sex and gender; self-identification may not be correlated with biology perfectly. And there is sexism.\"\n\nCompared to 19th-century United States, 20th-century Brazil was characterized by a perceived relative absence of sharply defined racial groups. According to anthropologist Marvin Harris, this pattern reflects a different history and different social relations.\n\nBasically, race in Brazil was \"biologized\", but in a way that recognized the difference between ancestry (which determines genotype) and phenotypic differences. There, racial identity was not governed by rigid descent rule, such as the one-drop rule, as it was in the United States. A Brazilian child was never automatically identified with the racial type of one or both parents, nor were there only a very limited number of categories to choose from, to the extent that full siblings can pertain to different racial groups.\n\nOver a dozen racial categories would be recognized in conformity with all the possible combinations of hair color, hair texture, eye color, and skin color. These types grade into each other like the colors of the spectrum, and not one category stands significantly isolated from the rest. That is, race referred preferentially to appearance, not heredity, and appearance is a poor indication of ancestry, because only a few genes are responsible for someone's skin color and traits: a person who is considered white may have more African ancestry than a person who is considered black, and the reverse can be also true about European ancestry. The complexity of racial classifications in Brazil reflects the extent of miscegenation in Brazilian society, a society that remains highly, but not strictly, stratified along color lines. These socioeconomic factors are also significant to the limits of racial lines, because a minority of \"pardos\", or brown people, are likely to start declaring themselves white or black if socially upward, and being seen as relatively \"whiter\" as their perceived social status increases (much as in other regions of Latin America).\n\nFluidity of racial categories aside, the \"biologification\" of race in Brazil referred above would match contemporary concepts of race in the United States quite closely, though, if Brazilians are supposed to choose their race as one among, Asian and Indigenous apart, three IBGE's census categories. While assimilated Amerindians and people with very high quantities of Amerindian ancestry are usually grouped as \"caboclos\", a subgroup of \"pardos\" which roughly translates as both mestizo and hillbilly, for those of lower quantity of Amerindian descent a higher European genetic contribution is expected to be grouped as a \"pardo\". In several genetic tests, people with less than 60-65% of European descent and 5-10% of Amerindian descent usually cluster with Afro-Brazilians (as reported by the individuals), or 6.9% of the population, and those with about 45% or more of Subsaharan contribution most times do so (in average, Afro-Brazilian DNA was reported to be about 50% Subsaharan African, 37% European and 13% Amerindian).\n\nIf a more consistent report with the genetic groups in the gradation of miscegenation is to be considered (e.g. that would not cluster people with a balanced degree of African and non-African ancestry in the black group instead of the multiracial one, unlike elsewhere in Latin America where people of high quantity of African descent tend to classify themselves as mixed), more people would report themselves as white and \"pardo\" in Brazil (47.7% and 42.4% of the population as of 2010, respectively), because by research its population is believed to have between 65 and 80% of autosomal European ancestry, in average (also >35% of European mt-DNA and >95% of European Y-DNA).\n\nThis is not surprising, though: While the greatest number of slaves imported from Africa were sent to Brazil, totalizing roughly 3.5 million people, they lived in such miserable conditions that male African Y-DNA there is significantly rare due to the lack of resources and time involved with raising of children, so that most African descent originarily came from relations between white masters and female slaves. From the last decades of the Empire until the 1950s, the proportion of the white population increased significantly while Brazil welcomed 5.5 million immigrants between 1821 and 1932, not much behind its neighbor Argentina with 6.4 million, and it received more European immigrants in its colonial history than the United States. Between 1500 and 1760, 700.000 Europeans settled in Brazil, while 530.000 Europeans settled in the United States for the same given time. Thus, the historical construction of race in Brazilian society dealt primarily with gradations between persons of majoritarily European ancestry and little minority groups with otherwise lower quantity therefrom in recent times.\n\nAccording to European Council:\n\nThe European Union uses the terms racial origin and ethnic origin synonymously in its documents and according to it \"the use of the term 'racial origin' in this directive does not imply an acceptance of such [racial] theories\". Haney López warns that using \"race\" as a category within the law tends to legitimize its existence in the popular imagination. In the diverse geographic context of Europe, ethnicity and ethnic origin are arguably more resonant and are less encumbered by the ideological baggage associated with \"race\". In European context, historical resonance of \"race\" underscores its problematic nature. In some states, it is strongly associated with laws promulgated by the Nazi and Fascist governments in Europe during the 1930s and 1940s. Indeed, in 1996, the European Parliament adopted a resolution stating that \"the term should therefore be avoided in all official texts\".\n\nThe concept of racial origin relies on the notion that human beings can be separated into biologically distinct \"races\", an idea generally rejected by the scientific community. Since all human beings belong to the same species, the ECRI (European Commission against Racism and Intolerance) rejects theories based on the existence of different \"races\". However, in its Recommendation ECRI uses this term in order to ensure that those persons who are generally and erroneously perceived as belonging to \"another race\" are not excluded from the protection provided for by the legislation. The law claims to reject the existence of \"race\", yet penalize situations where someone is treated less favourably on this ground.\n\nSince the end of the Second World War, France has become an ethnically diverse country. Today, approximately five percent of the French population is non-European and non-white. This does not approach the number of non-white citizens in the United States (roughly 28–37%, depending on how Latinos are classified (see Demographics of the United States). Nevertheless, it amounts to at least three million people, and has forced the issues of ethnic diversity onto the French policy agenda. France has developed an approach to dealing with ethnic problems that stands in contrast to that of many advanced, industrialized countries. Unlike the United States, Britain, or even the Netherlands, France maintains a \"color-blind\" model of public policy. This means that it targets virtually no policies directly at racial or ethnic groups. Instead, it uses geographic or class criteria to address issues of social inequalities. It has, however, developed an extensive anti-racist policy repertoire since the early 1970s. Until recently, French policies focused primarily on issues of hate speech—going much further than their American counterparts—and relatively less on issues of discrimination in jobs, housing, and in provision of goods and services.\n\nIn the United States, there is disagreement on the nature of race within the biological sciences, whereas the social constructionist view is dominant in the social sciences; over time, biological views on race have become more controversial across all disciplines, with clear divides along generational, cultural, and racial lines.\n\nThe immigrants to the Americas came from every region of Europe, Africa, and Asia. They mixed among themselves and with the indigenous inhabitants of the continent. In the United States most people who self-identify as African–American have some European ancestors, while many people who identify as European American have some African or Amerindian ancestors.\n\nSince the early history of the United States, Amerindians, African–Americans, and European Americans have been classified as belonging to different races. Efforts to track mixing between groups led to a proliferation of categories, such as mulatto and octoroon. The criteria for membership in these races diverged in the late 19th century. During Reconstruction, increasing numbers of Americans began to consider anyone with \"one drop\" of known \"Black blood\" to be Black, regardless of appearance. By the early 20th century, this notion was made statutory in many states. Amerindians continue to be defined by a certain percentage of \"Indian blood\" (called \"blood quantum\"). To be White one had to have perceived \"pure\" White ancestry. The one-drop rule or hypodescent rule refers to the convention of defining a person as racially black if he or she has any known African ancestry. This rule meant that those that were mixed race but with some discernible African ancestry were defined as black. The one-drop rule is specific to not only those with African ancestry but to the United States, making it a particularly African-American experience.\n\nThe decennial censuses conducted since 1790 in the United States created an incentive to establish racial categories and fit people into these categories.\n\nThe term \"Hispanic\" as an ethnonym emerged in the 20th century with the rise of migration of laborers from the Spanish-speaking countries of Latin America to the United States. Today, the word \"Latino\" is often used as a synonym for \"Hispanic\". The definitions of both terms are non-race specific, and include people who consider themselves to be of distinct races (Black, White, Amerindian, Asian, and mixed groups). However, there is a common misconception in the US that Hispanic/Latino is a race or sometimes even that national origins such as Mexican, Cuban, Colombian, Salvadoran, etc. are races. In contrast to \"Latino\" or \"Hispanic\", \"Anglo\" refers to non-Hispanic White Americans or non-Hispanic European Americans, most of whom speak the English language but are not necessarily of English descent.\n\nOne result of debates over the meaning and validity of the concept of race is that the current literature across different disciplines regarding human variation lacks consensus, though within some fields, such as some branches of anthropology, there is strong consensus. Some studies use the word race in its early essentialist taxonomic sense. Many others still use the term race, but use it to mean a population, clade, or haplogroup. Others eschew the concept of race altogether, and use the concept of population as a less problematic unit of analysis.\n\nEduardo Bonilla-Silva, Sociology professor at Duke University, remarks, \"I contend that racism is, more than anything else, a matter of group power; it is about a dominant racial group (whites) striving to maintain its systemic advantages and minorities fighting to subvert the racial status quo.\" The types of practices that take place under this new color-blind racism is subtle, institutionalized, and supposedly not racial. Color-blind racism thrives on the idea that race is no longer an issue in the United States. There are contradictions between the alleged color-blindness of most whites and the persistence of a color-coded system of inequality. In Poland, the race concept was rejected by 25 percent of anthropologists in 2001, although: \"Unlike the U.S. anthropologists, Polish anthropologists tend to regard race as a term without taxonomic value, often as a substitute for population.\"\n\nWang, Štrkalj et al. (2003) examined the use of race as a biological concept in research papers published in China's only biological anthropology journal, \"Acta Anthropologica Sinica\". The study showed that the race concept was widely used among Chinese anthropologists. In a 2007 review paper, Štrkalj suggested that the stark contrast of the racial approach between the United States and China was due to the fact that race is a factor for social cohesion among the ethnically diverse people of China, whereas \"race\" is a very sensitive issue in America and the racial approach is considered to undermine social cohesion - with the result that in the socio-political context of US academics scientists are encouraged not to use racial categories, whereas in China they are encouraged to use them.\n\nLieberman et al. in a 2004 study researched the acceptance of race as a concept among anthropologists in the United States, Canada, the Spanish speaking areas, Europe, Russia and China. Rejection of race ranged from high to low, with the highest rejection rate in the United States and Canada, a moderate rejection rate in Europe, and the lowest rejection rate in Russia and China. Methods used in the studies reported included questionnaires and content analysis.\n\nKaszycka et al. (2009) in 2002–2003 surveyed European anthropologists' opinions toward the biological race concept. Three factors, country of academic education, discipline, and age, were found to be significant in differentiating the replies. Those educated in Western Europe, physical anthropologists, and middle-aged persons rejected race more frequently than those educated in Eastern Europe, people in other branches of science, and those from both younger and older generations.\" The survey shows that the views on race are sociopolitically (ideologically) influenced and highly dependent on education.\"\n\nWagner et al. (2017) surveyed American anthropologists' views on race and genetics. They found a consensus among them that biological races do not exist in humans, but that race does exist insofar as the social experiences of members of different races can have significant effects on health.\n\nThe concept of biological race has declined significantly in frequency of use in physical anthropology in the United States during the 20th century. A majority of physical anthropologists in the United States have rejected the concept of biological races. Since 1932, an increasing number of college textbooks introducing physical anthropology have rejected race as a valid concept: from 1932 to 1976, only seven out of thirty-two rejected race; from 1975 to 1984, thirteen out of thirty-three rejected race; from 1985 to 1993, thirteen out of nineteen rejected race. According to one academic journal entry, where 78 percent of the articles in the 1931 \"Journal of Physical Anthropology\" employed these or nearly synonymous terms reflecting a bio-race paradigm, only 36 percent did so in 1965, and just 28 percent did in 1996.\n\nThe \"Statement on 'Race'\" (1998) composed by a select committee of anthropologists and issued by the executive board of the American Anthropological Association as a statement they \"believe [...] represents generally the contemporary thinking and scholarly positions of a majority of anthropologists\", declares:\n\nA survey, taken in 1985 , asked 1,200 American scientists how many disagree with the following proposition: \"There are biological races in the species \"Homo sapiens\".\" The responses were for anthropologists:\nThe figure for physical anthropologists at PhD granting departments was slightly higher, rising from 41% to 42%, with 50% agreeing. Lieberman's study also showed that more women reject the concept of race than men. This survey, however, did not specify any particular definition of race (although it did clearly specify \"biological race\" within the \"species\" \"Homo sapiens\"); it is difficult to say whether those who supported the statement thought of race in taxonomic or population terms.\n\nThe same survey, taken in 1999, showed the following changing results for anthropologists:\n\nHowever, a line of research conducted by Cartmill (1998) seemed to limit the scope of Lieberman's finding that there was \"a significant degree of change in the status of the race concept\". Goran Štrkalj has argued that this may be because Lieberman and collaborators had looked at all the members of the American Anthropological Association irrespective of their field of research interest, while Cartmill had looked specifically at biological anthropologists interested in human variation.\n\nAccording to the 2000 edition of a popular physical anthropology textbook, forensic anthropologists are overwhelmingly in support of the idea of the basic biological reality of human races. Forensic physical anthropologist and professor George W. Gill has said that the idea that race is only skin deep \"is simply not true, as any experienced forensic anthropologist will affirm\" and \"Many morphological features tend to follow geographic boundaries coinciding often with climatic zones. This is not surprising since the selective forces of climate are probably the primary forces of nature that have shaped human races with regard not only to skin color and hair form but also the underlying bony structures of the nose, cheekbones, etc. (For example, more prominent noses humidify air better.)\" While he can see good arguments for both sides, the complete denial of the opposing evidence \"seems to stem largely from socio-political motivation and not science at all\". He also states that many biological anthropologists see races as real yet \"not one introductory textbook of physical anthropology even presents that perspective as a possibility. In a case as flagrant as this, we are not dealing with science but rather with blatant, politically motivated censorship\".\n\nIn partial response to Gill's statement, Professor of Biological Anthropology C. Loring Brace argues that the reason laymen and biological anthropologists can determine the geographic ancestry of an individual can be explained by the fact that biological characteristics are clinally distributed across the planet, and that does not translate into the concept of race. He states: \n\"Race\" is still sometimes used within forensic anthropology (when analyzing skeletal remains), biomedical research, and race-based medicine. Brace has criticized this, the practice of forensic anthropologists for using the controversial concept \"race\" out of convention when they in fact should be talking about regional ancestry. He argues that while forensic anthropologists can determine that a skeletal remain comes from a person with ancestors in a specific region of Africa, categorizing that skeletal as being \"black\" is a socially constructed category that is only meaningful in the particular context of the United States, and which is not itself scientifically valid.\n\nIn 2007, Ann Morning interviewed over 40 American biologists and anthropologists and found significant disagreements over the nature of race, with no one viewpoint holding a majority among either group. Morning also argues that a third position, \"antiessentialism\", which holds that race is not a useful concept for biologists, should be introduced into this debate in addition to \"constructionism\" and \"essentialism\".\n\nIn the same 1985 survey , 16% of the surveyed biologists and 36% of the surveyed developmental psychologists disagreed with the proposition: \"There are biological races in the species \"Homo sapiens\".\"\n\nThe authors of the study also examined 77 college textbooks in biology and 69 in physical anthropology published between 1932 and 1989. Physical anthropology texts argued that biological races exist until the 1970s, when they began to argue that races do not exist. In contrast, biology textbooks did not undergo such a reversal but many instead dropped their discussion of race altogether. The authors attributed this to biologists trying to avoid discussing the political implications of racial classifications, instead of discussing them, and to the ongoing discussions in biology about the validity of the concept \"subspecies\". The authors also noted that some widely used textbooks in biology such as Douglas J. Futuyma's 1986 \"Evolutionary Biology\" had abandoned the race concept, \"The concept of race, masking the overwhelming genetic similarity of all peoples and the mosaic patterns of variation that do not correspond to racial divisions, is not only socially dysfunctional but is biologically indefensible as well (pp. 5 18-5 19).\" \n\nA 1994 examination of 32 English sport/exercise science textbooks found that 7 (21.9%) claimed that there are biophysical differences due to race that might explain differences in sports performance, 24 (75%) did not mention nor refute the concept, and 1 (3.12%) expressed caution with the idea.\n\nIn February 2001, the editors of \"Archives of Pediatrics and Adolescent Medicine\" asked \"authors to not use race and ethnicity when there is no biological, scientific, or sociological reason for doing so.\" The editors also stated that \"analysis by race and ethnicity has become an analytical knee-jerk reflex.\" \"Nature Genetics\" now ask authors to \"explain why they make use of particular ethnic groups or populations, and how classification was achieved.\"\n\nMorning (2008) looked at high school biology textbooks during the 1952-2002 period and initially found a similar pattern with only 35% directly discussing race in the 1983–92 period from initially 92% doing so. However, this has increased somewhat after this to 43%. More indirect and brief discussions of race in the context of medical disorders have increased from none to 93% of textbooks. In general, the material on race has moved from surface traits to genetics and evolutionary history. The study argues that the textbooks' fundamental message about the existence of races has changed little.\n\nSurveying views on race in the scientific community in 2008, Morning says that they often split along culture and demographic lines and that, since Lieberman's surveys, biologists have failed to come to a clear consensus, noting that \"At best, one can conclude that biologists and anthropologists now appear equally divided in their beliefs about the nature of race.\"\n\nGissis (2008) examined several important American and British journals in genetics, epidemiology and medicine for their content during the 1946-2003 period. He wrote that \"Based upon my findings I argue that the category of race only \"seemingly\" disappeared from scientific discourse after World War II and has had a \"fluctuating yet continuous use\" during the time span from 1946 to 2003, and has even \"become more pronounced from the early 1970s on\"\".\n\n33 health services researchers from differing geographic regions were interviewed in a 2008 study. The researchers recognized the problems with racial and ethnic variables but the majority still believed these variables were necessary and useful.\n\nA 2010 examination of 18 widely used English anatomy textbooks found that they all represented human biological variation in superficial and outdated ways, many of them making use of the race concept in ways that were current in 1950s anthropology. The authors recommended that anatomical education should describe human anatomical variation in more detail and rely on newer research that demonstrates the inadequacies of simple racial typologies.\n\nIn the United States, federal government policy promotes the use of racially categorized data to identify and address health disparities between racial or ethnic groups. In clinical settings, race has sometimes been considered in the diagnosis and treatment of medical conditions. Doctors have noted that some medical conditions are more prevalent in certain racial or ethnic groups than in others, without being sure of the cause of those differences. Recent interest in race-based medicine, or race-targeted pharmacogenomics, has been fueled by the proliferation of human genetic data which followed the decoding of the human genome in the first decade of the twenty-first century. There is an active debate among biomedical researchers about the meaning and importance of race in their research. Proponents of the use of racial categories in biomedicine argue that continued use of racial categorizations in biomedical research and clinical practice makes possible the application of new genetic findings, and provides a clue to diagnosis. Biomedical researchers' positions on race fall into two main camps: those who consider the concept of race to have no biological basis and those who consider it to have the potential to be biologically meaningful. Members of the latter camp often base their arguments around the potential to create genome-based personalized medicine.\n\nOther researchers point out that finding a difference in disease prevalence between two socially defined groups does not necessarily imply genetic causation of the difference. They suggest that medical practices should maintain their focus on the individual rather than an individual's membership to any group. They argue that overemphasizing genetic contributions to health disparities carries various risks such as reinforcing stereotypes, promoting racism or ignoring the contribution of non-genetic factors to health disparities. International epidemiological data show that living conditions rather than race make the biggest difference in health outcomes even for diseases that have \"race-specific\" treatments. Some studies have found that patients are reluctant to accept racial categorization in medical practice.\n\nIn an attempt to provide general descriptions that may facilitate the job of law enforcement officers seeking to apprehend suspects, the United States FBI employs the term \"race\" to summarize the general appearance (skin color, hair texture, eye shape, and other such easily noticed characteristics) of individuals whom they are attempting to apprehend. From the perspective of law enforcement officers, it is generally more important to arrive at a description that will readily suggest the general appearance of an individual than to make a scientifically valid categorization by DNA or other such means. Thus, in addition to assigning a wanted individual to a racial category, such a description will include: height, weight, eye color, scars and other distinguishing characteristics.\n\nCriminal justice agencies in England and Wales use at least two separate racial/ethnic classification systems when reporting crime, as of 2010. One is the system used in the 2001 Census when individuals identify themselves as belonging to a particular ethnic group: W1 (White-British), W2 (White-Irish), W9 (Any other white background); M1 (White and black Caribbean), M2 (White and black African), M3 (White and Asian), M9 (Any other mixed background); A1 (Asian-Indian), A2 (Asian-Pakistani), A3 (Asian-Bangladeshi), A9 (Any other Asian background); B1 (Black Caribbean), B2 (Black African), B3 (Any other black background); O1 (Chinese), O9 (Any other). The other is categories used by the police when they visually identify \nsomeone as belonging to an ethnic group, e.g. at the time of a stop and search or an arrest: White – North European (IC1), White – South European (IC2), Black (IC3), Asian (IC4), Chinese, Japanese, or South East Asian (IC5), Middle Eastern (IC6), and Unknown (IC0). \"IC\" stands for \"Identification Code;\" these items are also referred to as Phoenix classifications. Officers are instructed to \"record the response that has been given\" even if the person gives an answer which may be incorrect; their own perception of the person's ethnic background is recorded separately. Comparability of the information being recorded by officers was brought into question by the Office for National Statistics (ONS) in September 2007, as part of its Equality Data Review; one problem cited was the number of reports that contained an ethnicity of \"Not Stated.\"\n\nIn many countries, such as France, the state is legally banned from maintaining data based on race, which often makes the police issue wanted notices to the public that include labels like \"dark skin complexion\", etc.\n\nIn the United States, the practice of racial profiling has been ruled to be both unconstitutional and a violation of civil rights. There is active debate regarding the cause of a marked correlation between the recorded crimes, punishments meted out, and the country's populations. Many consider \"de facto\" racial profiling an example of institutional racism in law enforcement. The history of misuse of racial categories to impact adversely one or more groups and/or to offer protection and advantage to another has a clear impact on debate of the legitimate use of known phenotypical or genotypical characteristics tied to the presumed race of both victims and perpetrators by the government.\n\nMass incarceration in the United States disproportionately impacts African American and Latino communities. Michelle Alexander, author of The New Jim Crow: Mass Incarceration in the Age of Colorblindness (2010), argues that mass incarceration is best understood as not only a system of overcrowded prisons. Mass incarceration is also, \"the larger web of laws, rules, policies, and customs that control those labeled criminals both in and out of prison.\" She defines it further as \"a system that locks people not only behind actual bars in actual prisons, but also behind virtual bars and virtual walls\", illustrating the second-class citizenship that is imposed on a disproportionate number of people of color, specifically African-Americans. She compares mass incarceration to Jim Crow laws, stating that both work as racial caste systems.\n\nRecent work using DNA cluster analysis to determine race background has been used by some criminal investigators to narrow their search for the identity of both suspects and victims. Proponents of DNA profiling in criminal investigations cite cases where leads based on DNA analysis proved useful, but the practice remains controversial among medical ethicists, defense lawyers and some in law enforcement.\n\nSimilarly, forensic anthropologists draw on highly heritable morphological features of human remains (e.g. cranial measurements) to aid in the identification of the body, including in terms of race. In a 1992 article, anthropologist Norman Sauer noted that anthropologists had generally abandoned the concept of race as a valid representation of human biological diversity, except for forensic anthropologists. He asked, \"If races don't exist, why are forensic anthropologists so good at identifying them?\" He concluded:\n\nIn a different approach, anthropologist C. Loring Brace said:\n\nIn association with a NOVA program in 2000 about race, he wrote an essay opposing use of the term.\n\nA 2002 study found that about 13% of human craniometric variation existed between regions, while 81% existed within regions (the other 6% existed between local populations within the same region). In contrast, the opposite pattern of genetic variation was observed for skin color (which is often used to define race), with 88% of variation between regions. The study concluded that \"The apportionment of genetic diversity in skin color is atypical, and cannot be used for purposes of classification.\"\nSimilarly, a 2009 study found that craniometrics could be used accurately to determine what part of the world someone was from based on their cranium; however, this study also found that there were no abrupt boundaries that separated craniometric variation into distinct racial groups. Another 2009 study showed that American blacks and whites had different skeletal morphologies, and that significant patterning in variation in these traits exists within continents. This suggests that classifying humans into races based on skeletal characteristics would necessitate many different \"races\" being defined.\n\nNew research in molecular genetics, and the marketing of genetic identities through the analysis of one's Y chromosome, mtDNA, or autosomal DNA to the general public in the form of \"Personalized Genetic Histories\" (PGH) has caused debate.\nTypically, a consumer of a commercial PGH service sends in a sample of DNA, which is analyzed by molecular biologists, and receives a report on ancestry. Shriver and Kittles remarked:\n\nThey noted that the general public was increasingly interested in such tests despite their lack of knowledge in some cases of what the results represent.\n\nThrough these reports, advances in molecular genetics are used to create or confirm stories individuals have about social identities. Abu el-Haj argued that genetic lineages, like older notions of race, suggest some idea of biological relatedness. But, unlike older notions of race, they are not directly connected to claims about human behaviour or character. She said that \"postgenomics does seem to be giving race a new lease on life.\"\n\nAbu el-Haj argues that genomics and the mapping of lineages and clusters liberates \"the new racial science from the older one by disentangling ancestry from culture and capacity.\" As an example, she refers to recent work by Hammer \"et al.\", which aimed to test the claim that present-day Jews are more closely related to one another than to neighbouring non-Jewish populations. Hammer \"et al.\" found that the degree of genetic similarity among Jews shifted depending on the locus investigated, and suggested that this was the result of natural selection acting on particular loci. They focused on the non-recombining Y-chromosome to \"circumvent some of the complications associated with selection\".\n\nAs another example, she points to work by Thomas \"et al.\", who sought to distinguish between the Y chromosomes of Jewish priests (Kohanim) (in Judaism, membership in the priesthood is passed on through the father's line) and the Y chromosomes of non-Jews. Abu el-Haj concluded that this new \"race science\" calls attention to the importance of \"ancestry\" (narrowly defined, as it does not include all ancestors) in some religions and in popular culture, and people's desire to use science to confirm their claims about ancestry; this \"race science\", she argues, is fundamentally different from older notions of race that were used to explain differences in human behaviour or social status:\nStephan Palmié has responded to Abu el-Haj's claim that genetic lineages make possible a new, politically, economically, and socially benign notion of race and racial difference by suggesting that efforts to link genetic history and personal identity will inevitably \"ground present social arrangements in a time-hallowed past\", that is, use biology to explain cultural differences and social inequalities.\n\nOne problem with these assignments is admixture. Many people have a highly varied ancestry. For example, in the United States, colonial and early federal history were periods of numerous interracial relationships, both outside and inside slavery. This has resulted in a majority of people who identify as African American having some European ancestors. Similarly, many people who identify as white have some African ancestors. In a survey in a northeastern U.S. university of college students who identified as \"white\", about 30% were estimated to have up to 10% African ancestry.\n\nOn the other hand, there are tests that rely on correlations between allele frequencies; often when allele frequencies correlate, these are called clusters. These sorts of tests use informative alleles called Ancestry-informative marker (AIM). These tests use contemporary people sampled from certain parts of the world as references to determine the likely proportion of ancestry for any given individual.\n\nIn a recent Public Broadcasting Service (PBS) programme on the subject of genetic ancestry testing, the academic Henry Louis Gates, who identifies as African American, said that he \"wasn't thrilled with the AIM results (it turns out that 50 percent of his ancestors are likely European).\" He said there had been family stories of white ancestors, but this was a higher proportion than he expected.\n\nIn 2003, Charles Rotimi, of Howard University's National Human Genome Center, argued that \"the nature or appearance of genetic clustering (grouping) of people is a function of how populations are sampled, of how criteria for boundaries between clusters are set, and of the level of resolution used.\" As these decisions may each bias the results, he concluded that people should be very cautious about relating genetic lineages or clusters to their personal sense of identity.\n\nOn the other hand, Rosenberg (2005) argued that if enough genetic markers and subjects are analyzed, then the clusters found are consistent. How many genetic markers a commercial service uses likely varies, although new technology has continually allowed increasing numbers to be analyzed. In the end, people usually base their individual identity more on family and personal relationships of community than data.\n\n\n\n\n\n\n\n\n"}
{"id": "25618", "url": "https://en.wikipedia.org/wiki?curid=25618", "title": "R", "text": "R\n\nR (named \"ar/or\" ) is the 18th letter of the modern English alphabet and the ISO basic Latin alphabet.\n\nThe original Semitic letter may have been inspired by an Egyptian hieroglyph for \"tp\", \"head\". It was used for by Semites because in their language, the word for \"head\" was \"rêš\" (also the name of the letter). It developed into Greek 'Ρ' (\"rhô\") and Latin R.\n\nThe descending stroke develops as a graphic variant in some Western Greek alphabets (writing \"rho\" as ), but it was not adopted in most Old Italic alphabets; most Old Italic alphabets show variants of their \"rho\" between a \"P\" and a \"D\" shape, but without the Western Greek descending stroke. \nIndeed, the oldest known forms of the Latin alphabet itself of the 7th to 6th centuries BC, in the Duenos and the Forum inscription, still write \"r\" using the \"P\" shape of the letter.\nThe Lapis Satricanus inscription shows the form of the Latin alphabet around 500 BC. Here, the rounded, closing Π shape of the \"p\" and the Ρ shape of the \"r\" have become difficult to distinguish. \nThe descending stroke of the Latin letter R has fully developed by the 3rd century BC, as seen in the Tomb of the Scipios sarcophagus inscriptions of that era. From around 50 AD, the letter \"P\" would be written with its loop fully closed, assuming the shape formerly taken by \"R\".\n\nThe minuscule (lowercase) form (\"r\") developed through several variations on the capital form. \nAlong with Latin minuscule writing in general, it developed ultimately from Roman cursive via the uncial script of Late Antiquity into the Carolingian minuscule of the 9th century.\n\nIn handwriting, it was common not to close the bottom of the loop but continue into the leg, saving an extra pen stroke. The loop-leg stroke shortened into the simple arc used in the Carolingian minuscule and until today.\n\nA calligraphic minuscule \"r\", known as r rotunda (ꝛ), was used in the sequence \"or\", bending the shape of the \"r\" to accommodate the bulge of the \"o\" (as in \"oꝛ\" as opposed to \"or\"). Later, the same variant was also used where \"r\" followed other lower case letters with a rounded loop towards the right (such as \"b, h, p\") and to write the geminate \"rr\" (as \"ꝛꝛ\"). Use of \"r rotunda\" was mostly tied to blackletter typefaces, and the glyph fell out of use along with blackletter fonts in English language contexts mostly by the 18th century.\n\nInsular script used a minuscule which retained two downward strokes, but which did not close the loop (\"Insular \"r\"\", ꞃ); this variant survives in the Gaelic type popular in Ireland until the mid-20th century (but now mostly limited to decorative purposes).\n\nThe name of the letter in Latin was \"er\" (), following the pattern of other letters representing continuants, such as F, L, M, N and S. This name is preserved in French and many other languages. In Middle English, the name of the letter changed from to , following a pattern exhibited in many other words such as \"farm\" (compare French \"ferme\"), and \"star\" (compare German \"Stern\").\nThe letter R is sometimes referred to as the \"littera canina\" (canine letter). This phrase has Latin origins: the Latin R was trilled to sound like a growling dog. A good example of a trilling R is the Spanish word for dog, \"perro\".\n\nIn William Shakespeare's \"Romeo and Juliet\", such a reference is made by Juliet's nurse in Act 2, scene 4, when she calls the letter R \"the dog's name\". The reference is also found in Ben Jonson's \"English Grammar\".\n\nThe letter is the eighth most common letter in English and the fourth-most common consonant (after , , and ).\n\nThe letter is used to form the ending \"-re\", which is used in certain words such as \"centre\" in some varieties of English spelling, such as British English. Canadian English also uses the \"-re\" ending, unlike American English, where the ending is usually replaced by \"-er\" (\"center\"). This does not affect pronunciation.\n\n represents a rhotic consonant in many languages, as shown in the table below.\n\nOther languages may use the letter in their alphabets (or Latin transliterations schemes) to represent rhotic consonants different from the alveolar trill. In Haitian Creole, it represents a sound so weak that it is often written interchangeably with , e.g. 'Kweyol' for 'Kreyol'.\n\nBrazilian Portuguese has a great number of allophones of such as , , , , , and , the latter three ones can be used only in certain contexts ( and as ; in the syllable coda, as an allophone of according to the European Portuguese norm and according to the Brazilian Portuguese norm). Usually at least two of them are present in a single dialect, such as Rio de Janeiro's , , and, for a few speakers, .\n\nThe International Phonetic Alphabet uses several variations of the letter to represent the different rhotic consonants; represents the alveolar trill.\n\n\n\n\n\n"}
{"id": "25622", "url": "https://en.wikipedia.org/wiki?curid=25622", "title": "Richard Bachman", "text": "Richard Bachman\n\nRichard Bachman is a pen name used by horror fiction author Stephen King.\n\nAt the beginning of Stephen King's career, the general view among publishers was that an author was limited to one book per year, since publishing more would be unacceptable to the public. King therefore wanted to write under another name, in order to increase his publication without over-saturating the market for the King \"brand\". He convinced his publisher, Signet Books, to print these novels under a pseudonym.\n\nIn his introduction to \"The Bachman Books,\" King states that adopting the nom de plume Bachman was also an attempt to make sense out of his career and try to answer the question of whether his success was due to talent or luck. He says he deliberately released the Bachman novels with as little marketing presence as possible and did his best to \"load the dice against\" Bachman. King concludes that he has yet to find an answer to the \"talent versus luck\" question, as he felt he was outed as Bachman too early to know. The Bachman book \"Thinner\" (1984) sold 28,000 copies during its initial run—and then ten times as many when it was revealed that Bachman was, in fact, King.\n\nThe pseudonym King originally selected (Gus Pillsbury) is King's maternal grandfather's name, but at the last moment King changed it to Richard Bachman. Richard is a tribute to crime author Donald E. Westlake's long-running pseudonym Richard Stark. (The surname Stark \"was\" later used in King's novel \"The Dark Half,\" in which an author's malevolent pseudonym, \"George Stark\", comes to life.) Bachman was inspired by Bachman–Turner Overdrive, a rock and roll band King was listening to at the time his publisher asked him to choose a pseudonym on the spot.\n\nKing provided biographical details for Bachman, initially in the \"about the author\" blurbs in the early novels. Known \"facts\" about Bachman were that he was born in New York, served a four-year stint in the Coast Guard, which he then followed with ten years in the merchant marine. Bachman finally settled down in rural central New Hampshire, where he ran a medium-sized dairy farm, writing at night. His fifth novel was dedicated to his wife, Claudia Inez Bachman, who also received credit for the bogus author photo on the book jacket. Other \"facts\" about the author were revealed in publicity dispatches from Bachman's publishers: the Bachmans had one child, a boy, who died in an unfortunate, Stephen King-ish type accident at the age of six, when he fell through a well and drowned. In 1982, a brain tumour was discovered near the base of Bachman's brain; tricky surgery removed it. After Bachman's true identity was revealed, later publicity dispatches (and about the author blurbs) revealed that Bachman died suddenly in late 1985 of \"cancer of the pseudonym, a rare form of schizonomia\".\n\nKing dedicated Bachman's early books—\"Rage\" (1977), \"The Long Walk\" (1979), \"Roadwork\" (1981), and \"The Running Man\" (1982)—to people close to him. The link between King and his shadow writer was exposed after a Washington, D.C. bookstore clerk, Steve Brown, noted similarities between the writing styles of King and Bachman. Brown located publisher's records at the Library of Congress which included a document naming King as the author of one of Bachman's novels. Brown wrote to King's publishers with a copy of the documents he had uncovered, and asked them what to do. Two weeks later, King telephoned Brown personally and suggested he write an article about how he discovered the truth, allowing himself to be interviewed. At the time of the announcement in 1985, King was working on \"Misery,\" which he had planned to release as a Bachman book.\n\nIn 1987, the Bachman novel \"The Running Man\" inspired the Paul Glaser film of the same name. King insisted that his name not be on the credits, and the screen credit for the film went to Richard Bachman.\n\nKing used the \"relationship\" between himself and Bachman as a concept in his 1989 book \"The Dark Half.\" In the novel a writer's darker pseudonym takes on a life of its own. King dedicated \"The Dark Half\" to \"the late Richard Bachman.\" Originally there were plans to make the book a collaboration between the two, although this was later scrapped.\n\nIn 1996, Bachman's \"The Regulators\" came out, with the publishers claiming the book's manuscript was found among Bachman's leftover papers by his widow. It was released as a companion novel with King's \"Desperation\"; the two novels took place in different universes but featured many of the same characters. The two book covers were designed to be placed together to form a single picture. In the foreword by King included with \"Desperation\" he said that there may be another Bachman novel left to be \"found.\"\n\nThe next Bachman book to be 'discovered' was \"Blaze.\" \"Blaze\" was, in fact, an unpublished novel of King's written before \"Carrie\" or the creation of Richard Bachman. For its publication King rewrote, edited, and updated the entire novel. It was published in 2007 under the Bachman pseudonym, with a foreword by King under his own name.\n\nKing has taken full ownership of the Bachman name on numerous occasions, as with the republication of the first four Bachman titles as \"The Bachman Books: Four Early Novels by Stephen King\" in 1985. The introduction, titled \"Why I Was Bachman,\" details the whole Bachman/King story. (In 1996, the collection was reissued with a new King essay, \"The Importance of Being Bachman.\")\n\nRichard Bachman was also referred to in Stephen King's \"The Dark Tower\" series of books. In the fifth book, \",\" the sinister children's book \"Charlie the Choo Choo\" is revealed to be written by \"Claudia y Inez Bachman.\" The spelling discrepancy of the added 'y' was later explained as a deus ex machina on the part of \"The White\" (a force of good throughout King's \"Tower\" series) to bring the total number of letters in her name to nineteen, a number prominent in King's series. In the next novel of the series, \",\" Stephen King briefly discusses his Richard Bachman pseudonym.\n\nAfter the Heath High School shooting, King announced that he would allow \"Rage\" to go out of print, fearing that it might inspire similar tragedies. \"Rage\" for a time continued to be available in the United Kingdom in \"The Bachman Books\" collection, although the collection now no longer contains \"Rage\". In a footnote to the preface of \"Blaze,\" dated 30 January 2007, King wrote of \"Rage\": \"Now out of print, and a good thing.\" King's other Bachman novels are available in the US in separate volumes.\n\nIn 2010, King appeared on the FX television show \"Sons of Anarchy\" in a cameo role. His character, named Bachman, performed contract work quietly disposing of deceased bodies.\n\nIn issue 29 of the comic adaptation of \"The Stand\", Richard (Rich) Bachman appears as one of the top lieutenants of Randall Flagg, replacing the character of Whitney Horgan from the original novel. He is drawn to resemble King.\n\nIn the 2013 \"Grimm\" episode \"Nameless\", Richard Bachman, being a pseudonym of Stephen King, was a plot point. King's novel, \"Rage\", had its title page used as a prop for the killer to write a note to the police.\n\n"}
